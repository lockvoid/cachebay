{"version":3,"file":"bench.cjs","sources":["/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/fbjs@3.0.5_encoding@0.1.13/node_modules/fbjs/lib/areEqual.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/fbjs@3.0.5_encoding@0.1.13/node_modules/fbjs/lib/emptyFunction.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/fbjs@3.0.5_encoding@0.1.13/node_modules/fbjs/lib/warning.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql-tag@2.12.6_graphql@16.11.0/node_modules/graphql-tag/lib/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/invariant@2.2.4/node_modules/invariant/invariant.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/handlers/RelayDefaultHandlerProvider.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/handlers/connection/ConnectionHandler.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/handlers/connection/ConnectionInterface.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/handlers/connection/MutationHandlers.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/multi-actor-environment/ActorIdentifier.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/multi-actor-environment/ActorUtils.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/RelayDeclarativeMutationConfig.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/RelayRecordProxy.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/RelayRecordSourceMutator.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/RelayRecordSourceProxy.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/RelayRecordSourceSelectorProxy.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/applyOptimisticMutation.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/commitLocalUpdate.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/commitMutation.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/createUpdatableProxy.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/readUpdatableFragment.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/readUpdatableQuery.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/mutations/validateMutation.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/network/ConvertToExecuteFunction.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/network/RelayNetwork.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/network/RelayObservable.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/network/RelayQueryResponseCache.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/network/wrapNetworkWithLogObserver.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/query/GraphQLTag.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/query/PreloadableQueryRegistry.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/query/fetchQuery.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/query/fetchQueryInternal.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/query/fetchQuery_DEPRECATED.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/ClientID.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/DataChecker.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/OperationExecutor.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayConcreteVariables.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayErrorTrie.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayModernEnvironment.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayModernFragmentSpecResolver.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayModernOperationDescriptor.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayModernRecord.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayModernSelector.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayModernStore.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayOperationTracker.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayOptimisticRecordSource.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayPublishQueue.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayReader.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayRecordSource.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayRecordState.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayReferenceMarker.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayResponseNormalizer.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayStoreSubscriptions.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/RelayStoreUtils.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/ResolverCache.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/ResolverFragments.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/StoreInspector.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/TypeID.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/ViewerPattern.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/cloneRelayHandleSourceField.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/cloneRelayScalarHandleSourceField.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/createFragmentSpecResolver.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/createRelayContext.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/defaultGetDataID.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/defaultRelayFieldLogger.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/experimental-live-resolvers/LiveResolverSuspenseSentinel.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/experimental-live-resolvers/getOutputTypeRecordIDs.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/hasOverlappingIDs.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/hasSignificantOverlappingIDs.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/isRelayModernEnvironment.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/normalizeResponse.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/store/readInlineData.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/subscription/requestSubscription.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/RelayConcreteNode.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/RelayDefaultHandleKey.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/RelayError.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/RelayFeatureFlags.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/RelayProfiler.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/RelayReplaySubject.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/StringInterner.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/createPayloadFor3DField.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/deepFreeze.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/generateID.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getFragmentIdentifier.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getOperation.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getPaginationMetadata.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getPaginationVariables.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getPendingOperationsForFragment.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getRefetchMetadata.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getRelayHandleKey.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getRequestIdentifier.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/getValueAtPath.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/handlePotentialSnapshotErrors.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/isEmptyObject.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/isPromise.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/isScalarAndEqual.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/recycleNodesInto.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/registerEnvironmentWithDevTools.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/resolveImmediate.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/shallowFreeze.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/stableCopy.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/withDuration.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/relay-runtime@16.2.0_encoding@0.1.13/node_modules/relay-runtime/lib/util/withProvidedVariables.js","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/benchmarks/api/materializeDocument.bench.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/benchmarks/api/utils.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/compiler/compile.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/compiler/fingerprint.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/compiler/index.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/compiler/lowering/flatten.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/compiler/utils.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/compiler/variables.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/canonical.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/client.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/constants.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/documents.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/errors.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/fragments.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/graph.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/inspect.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/instrumentation.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/operations.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/optimistic.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/planner.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/queries.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/ssr.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/packages/cachebay/src/core/utils.ts","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/arrayLikeToArray.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/arrayWithoutHoles.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/construct.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/createForOfIteratorHelper.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/defineProperty.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/getPrototypeOf.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/inheritsLoose.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/interopRequireDefault.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/isNativeFunction.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/isNativeReflectConstruct.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/iterableToArray.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/nonIterableSpread.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/objectSpread2.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/objectWithoutPropertiesLoose.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/setPrototypeOf.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/toConsumableArray.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/toPrimitive.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/toPropertyKey.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/typeof.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@babel+runtime@7.28.4/node_modules/@babel/runtime/helpers/wrapNativeSuper.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/core/cache.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/core/types/common.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/entityStore.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/helpers.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/inMemoryCache.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/key-extractor.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/object-canon.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/policies.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/reactiveVars.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/readFromStore.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/cache/inmemory/writeToStore.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/core/equalByQuery.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/masking/maskDefinition.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/masking/maskFragment.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/masking/utils.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/caching/caches.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/caching/getMemoryInternals.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/caching/sizes.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/arrays.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/canUse.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/canonicalStringify.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/cloneDeep.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/compact.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/makeUniqueId.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/maybeDeepFreeze.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/mergeDeep.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/objects.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/common/stringifyForDisplay.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/deprecation/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/globals/global.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/globals/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/globals/invariantWrappers.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/globals/maybe.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/graphql/DocumentTransform.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/graphql/directives.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/graphql/fragments.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/graphql/getFromAST.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/graphql/print.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/graphql/storeUtils.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/graphql/transform.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/utilities/policies/pagination.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@apollo+client@3.14.0_@types+react@19.2.2_graphql@16.11.0_react-dom@18.3.1_react@18.3.1__react@18.3.1/node_modules/@apollo/client/version.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@wry+caches@1.0.1/node_modules/@wry/caches/lib/strong.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@wry+caches@1.0.1/node_modules/@wry/caches/lib/weak.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@wry+context@0.7.4/node_modules/@wry/context/lib/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@wry+context@0.7.4/node_modules/@wry/context/lib/slot.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@wry+equality@0.5.7/node_modules/@wry/equality/lib/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/@wry+trie@0.5.0/node_modules/@wry/trie/lib/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/error/GraphQLError.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/error/syntaxError.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/jsutils/devAssert.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/jsutils/inspect.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/jsutils/instanceOf.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/jsutils/invariant.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/jsutils/isObjectLike.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/ast.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/blockString.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/characterClasses.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/directiveLocation.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/kinds.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/lexer.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/location.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/parser.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/printLocation.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/printString.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/printer.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/source.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/tokenKind.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/graphql@16.11.0/node_modules/graphql/language/visitor.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/optimism@0.18.1/node_modules/optimism/lib/context.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/optimism@0.18.1/node_modules/optimism/lib/dep.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/optimism@0.18.1/node_modules/optimism/lib/entry.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/optimism@0.18.1/node_modules/optimism/lib/helpers.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/optimism@0.18.1/node_modules/optimism/lib/index.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/ts-invariant@0.10.3/node_modules/ts-invariant/lib/invariant.js","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/tslib@2.8.1/node_modules/tslib/tslib.es6.mjs","/Users/kochnev/Projects/Ferment/villus-cachebay/node_modules/.pnpm/zen-observable-ts@1.2.5/node_modules/zen-observable-ts/module.js","webpack/runtime/async_module","webpack/runtime/compat_get_default_export","webpack/runtime/define_property_getters","webpack/runtime/has_own_property","webpack/runtime/make_namespace_object"],"sourcesContent":["\"use strict\";\n\n/**\n * Copyright (c) 2013-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n * \n */\nvar aStackPool = [];\nvar bStackPool = [];\n/**\n * Checks if two values are equal. Values may be primitives, arrays, or objects.\n * Returns true if both arguments have the same keys and values.\n *\n * @see http://underscorejs.org\n * @copyright 2009-2013 Jeremy Ashkenas, DocumentCloud Inc.\n * @license MIT\n */\n\nfunction areEqual(a, b) {\n  var aStack = aStackPool.length ? aStackPool.pop() : [];\n  var bStack = bStackPool.length ? bStackPool.pop() : [];\n  var result = eq(a, b, aStack, bStack);\n  aStack.length = 0;\n  bStack.length = 0;\n  aStackPool.push(aStack);\n  bStackPool.push(bStack);\n  return result;\n}\n\nfunction eq(a, b, aStack, bStack) {\n  if (a === b) {\n    // Identical objects are equal. `0 === -0`, but they aren't identical.\n    return a !== 0 || 1 / a == 1 / b;\n  }\n\n  if (a == null || b == null) {\n    // a or b can be `null` or `undefined`\n    return false;\n  }\n\n  if (typeof a != 'object' || typeof b != 'object') {\n    return false;\n  }\n\n  var objToStr = Object.prototype.toString;\n  var className = objToStr.call(a);\n\n  if (className != objToStr.call(b)) {\n    return false;\n  }\n\n  switch (className) {\n    case '[object String]':\n      return a == String(b);\n\n    case '[object Number]':\n      return isNaN(a) || isNaN(b) ? false : a == Number(b);\n\n    case '[object Date]':\n    case '[object Boolean]':\n      return +a == +b;\n\n    case '[object RegExp]':\n      return a.source == b.source && a.global == b.global && a.multiline == b.multiline && a.ignoreCase == b.ignoreCase;\n  } // Assume equality for cyclic structures.\n\n\n  var length = aStack.length;\n\n  while (length--) {\n    if (aStack[length] == a) {\n      return bStack[length] == b;\n    }\n  }\n\n  aStack.push(a);\n  bStack.push(b);\n  var size = 0; // Recursively compare objects and arrays.\n\n  if (className === '[object Array]') {\n    size = a.length;\n\n    if (size !== b.length) {\n      return false;\n    } // Deep compare the contents, ignoring non-numeric properties.\n\n\n    while (size--) {\n      if (!eq(a[size], b[size], aStack, bStack)) {\n        return false;\n      }\n    }\n  } else {\n    if (a.constructor !== b.constructor) {\n      return false;\n    }\n\n    if (a.hasOwnProperty('valueOf') && b.hasOwnProperty('valueOf')) {\n      return a.valueOf() == b.valueOf();\n    }\n\n    var keys = Object.keys(a);\n\n    if (keys.length != Object.keys(b).length) {\n      return false;\n    }\n\n    for (var i = 0; i < keys.length; i++) {\n      if (!eq(a[keys[i]], b[keys[i]], aStack, bStack)) {\n        return false;\n      }\n    }\n  }\n\n  aStack.pop();\n  bStack.pop();\n  return true;\n}\n\nmodule.exports = areEqual;","\"use strict\";\n\n/**\n * Copyright (c) 2013-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n * \n */\nfunction makeEmptyFunction(arg) {\n  return function () {\n    return arg;\n  };\n}\n/**\n * This function accepts and discards inputs; it has no side effects. This is\n * primarily useful idiomatically for overridable function endpoints which\n * always need to be callable, since JS lacks a null-call idiom ala Cocoa.\n */\n\n\nvar emptyFunction = function emptyFunction() {};\n\nemptyFunction.thatReturns = makeEmptyFunction;\nemptyFunction.thatReturnsFalse = makeEmptyFunction(false);\nemptyFunction.thatReturnsTrue = makeEmptyFunction(true);\nemptyFunction.thatReturnsNull = makeEmptyFunction(null);\n\nemptyFunction.thatReturnsThis = function () {\n  return this;\n};\n\nemptyFunction.thatReturnsArgument = function (arg) {\n  return arg;\n};\n\nmodule.exports = emptyFunction;","/**\n * Copyright (c) 2014-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n */\n'use strict';\n\nvar emptyFunction = require(\"./emptyFunction\");\n/**\n * Similar to invariant but only logs a warning if the condition is not met.\n * This can be used to log issues in development environments in critical\n * paths. Removing the logging code for production environments will keep the\n * same logic and follow the same code paths.\n */\n\n\nfunction printWarning(format) {\n  for (var _len = arguments.length, args = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n    args[_key - 1] = arguments[_key];\n  }\n\n  var argIndex = 0;\n  var message = 'Warning: ' + format.replace(/%s/g, function () {\n    return args[argIndex++];\n  });\n\n  if (typeof console !== 'undefined') {\n    console.error(message);\n  }\n\n  try {\n    // --- Welcome to debugging React ---\n    // This error was thrown as a convenience so that you can use this stack\n    // to find the callsite that caused this warning to fire.\n    throw new Error(message);\n  } catch (x) {}\n}\n\nvar warning = process.env.NODE_ENV !== \"production\" ? function (condition, format) {\n  if (format === undefined) {\n    throw new Error('`warning(condition, format, ...args)` requires a warning ' + 'message argument');\n  }\n\n  if (!condition) {\n    for (var _len2 = arguments.length, args = new Array(_len2 > 2 ? _len2 - 2 : 0), _key2 = 2; _key2 < _len2; _key2++) {\n      args[_key2 - 2] = arguments[_key2];\n    }\n\n    printWarning.apply(void 0, [format].concat(args));\n  }\n} : emptyFunction;\nmodule.exports = warning;","import { __assign } from \"tslib\";\nimport { parse } from 'graphql';\nvar docCache = new Map();\nvar fragmentSourceMap = new Map();\nvar printFragmentWarnings = true;\nvar experimentalFragmentVariables = false;\nfunction normalize(string) {\n    return string.replace(/[\\s,]+/g, ' ').trim();\n}\nfunction cacheKeyFromLoc(loc) {\n    return normalize(loc.source.body.substring(loc.start, loc.end));\n}\nfunction processFragments(ast) {\n    var seenKeys = new Set();\n    var definitions = [];\n    ast.definitions.forEach(function (fragmentDefinition) {\n        if (fragmentDefinition.kind === 'FragmentDefinition') {\n            var fragmentName = fragmentDefinition.name.value;\n            var sourceKey = cacheKeyFromLoc(fragmentDefinition.loc);\n            var sourceKeySet = fragmentSourceMap.get(fragmentName);\n            if (sourceKeySet && !sourceKeySet.has(sourceKey)) {\n                if (printFragmentWarnings) {\n                    console.warn(\"Warning: fragment with name \" + fragmentName + \" already exists.\\n\"\n                        + \"graphql-tag enforces all fragment names across your application to be unique; read more about\\n\"\n                        + \"this in the docs: http://dev.apollodata.com/core/fragments.html#unique-names\");\n                }\n            }\n            else if (!sourceKeySet) {\n                fragmentSourceMap.set(fragmentName, sourceKeySet = new Set);\n            }\n            sourceKeySet.add(sourceKey);\n            if (!seenKeys.has(sourceKey)) {\n                seenKeys.add(sourceKey);\n                definitions.push(fragmentDefinition);\n            }\n        }\n        else {\n            definitions.push(fragmentDefinition);\n        }\n    });\n    return __assign(__assign({}, ast), { definitions: definitions });\n}\nfunction stripLoc(doc) {\n    var workSet = new Set(doc.definitions);\n    workSet.forEach(function (node) {\n        if (node.loc)\n            delete node.loc;\n        Object.keys(node).forEach(function (key) {\n            var value = node[key];\n            if (value && typeof value === 'object') {\n                workSet.add(value);\n            }\n        });\n    });\n    var loc = doc.loc;\n    if (loc) {\n        delete loc.startToken;\n        delete loc.endToken;\n    }\n    return doc;\n}\nfunction parseDocument(source) {\n    var cacheKey = normalize(source);\n    if (!docCache.has(cacheKey)) {\n        var parsed = parse(source, {\n            experimentalFragmentVariables: experimentalFragmentVariables,\n            allowLegacyFragmentVariables: experimentalFragmentVariables\n        });\n        if (!parsed || parsed.kind !== 'Document') {\n            throw new Error('Not a valid GraphQL document.');\n        }\n        docCache.set(cacheKey, stripLoc(processFragments(parsed)));\n    }\n    return docCache.get(cacheKey);\n}\nexport function gql(literals) {\n    var args = [];\n    for (var _i = 1; _i < arguments.length; _i++) {\n        args[_i - 1] = arguments[_i];\n    }\n    if (typeof literals === 'string') {\n        literals = [literals];\n    }\n    var result = literals[0];\n    args.forEach(function (arg, i) {\n        if (arg && arg.kind === 'Document') {\n            result += arg.loc.source.body;\n        }\n        else {\n            result += arg;\n        }\n        result += literals[i + 1];\n    });\n    return parseDocument(result);\n}\nexport function resetCaches() {\n    docCache.clear();\n    fragmentSourceMap.clear();\n}\nexport function disableFragmentWarnings() {\n    printFragmentWarnings = false;\n}\nexport function enableExperimentalFragmentVariables() {\n    experimentalFragmentVariables = true;\n}\nexport function disableExperimentalFragmentVariables() {\n    experimentalFragmentVariables = false;\n}\nvar extras = {\n    gql: gql,\n    resetCaches: resetCaches,\n    disableFragmentWarnings: disableFragmentWarnings,\n    enableExperimentalFragmentVariables: enableExperimentalFragmentVariables,\n    disableExperimentalFragmentVariables: disableExperimentalFragmentVariables\n};\n(function (gql_1) {\n    gql_1.gql = extras.gql, gql_1.resetCaches = extras.resetCaches, gql_1.disableFragmentWarnings = extras.disableFragmentWarnings, gql_1.enableExperimentalFragmentVariables = extras.enableExperimentalFragmentVariables, gql_1.disableExperimentalFragmentVariables = extras.disableExperimentalFragmentVariables;\n})(gql || (gql = {}));\ngql[\"default\"] = gql;\nexport default gql;\n//# sourceMappingURL=index.js.map","/**\n * Copyright (c) 2013-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n'use strict';\n\n/**\n * Use invariant() to assert state which your program assumes to be true.\n *\n * Provide sprintf-style format (only %s is supported) and arguments\n * to provide information about what broke and what you were\n * expecting.\n *\n * The invariant message will be stripped in production, but the invariant\n * will remain to ensure logic does not differ in production.\n */\n\nvar NODE_ENV = process.env.NODE_ENV;\n\nvar invariant = function(condition, format, a, b, c, d, e, f) {\n  if (NODE_ENV !== 'production') {\n    if (format === undefined) {\n      throw new Error('invariant requires an error message argument');\n    }\n  }\n\n  if (!condition) {\n    var error;\n    if (format === undefined) {\n      error = new Error(\n        'Minified exception occurred; use the non-minified dev environment ' +\n        'for the full error message and additional helpful warnings.'\n      );\n    } else {\n      var args = [a, b, c, d, e, f];\n      var argIndex = 0;\n      error = new Error(\n        format.replace(/%s/g, function() { return args[argIndex++]; })\n      );\n      error.name = 'Invariant Violation';\n    }\n\n    error.framesToPop = 1; // we don't care about invariant's own frame\n    throw error;\n  }\n};\n\nmodule.exports = invariant;\n","/**\n * Relay v16.2.0\n *\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\nmodule.exports = require('./lib/index.js');\n","'use strict';\n\nvar ConnectionHandler = require('./connection/ConnectionHandler');\nvar MutationHandlers = require('./connection/MutationHandlers');\nvar invariant = require('invariant');\nfunction RelayDefaultHandlerProvider(handle) {\n  switch (handle) {\n    case 'connection':\n      return ConnectionHandler;\n    case 'deleteRecord':\n      return MutationHandlers.DeleteRecordHandler;\n    case 'deleteEdge':\n      return MutationHandlers.DeleteEdgeHandler;\n    case 'appendEdge':\n      return MutationHandlers.AppendEdgeHandler;\n    case 'prependEdge':\n      return MutationHandlers.PrependEdgeHandler;\n    case 'appendNode':\n      return MutationHandlers.AppendNodeHandler;\n    case 'prependNode':\n      return MutationHandlers.PrependNodeHandler;\n  }\n  !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayDefaultHandlerProvider: No handler provided for `%s`.', handle) : invariant(false) : void 0;\n}\nmodule.exports = RelayDefaultHandlerProvider;","'use strict';\n\nvar _require = require('../../store/ClientID'),\n  generateClientID = _require.generateClientID;\nvar _require2 = require('../../store/RelayStoreUtils'),\n  getStableStorageKey = _require2.getStableStorageKey;\nvar getRelayHandleKey = require('../../util/getRelayHandleKey');\nvar ConnectionInterface = require('./ConnectionInterface');\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nvar CONNECTION = 'connection';\nvar NEXT_EDGE_INDEX = '__connection_next_edge_index';\nfunction update(store, payload) {\n  var record = store.get(payload.dataID);\n  if (!record) {\n    return;\n  }\n  var _ConnectionInterface$ = ConnectionInterface.get(),\n    EDGES = _ConnectionInterface$.EDGES,\n    END_CURSOR = _ConnectionInterface$.END_CURSOR,\n    HAS_NEXT_PAGE = _ConnectionInterface$.HAS_NEXT_PAGE,\n    HAS_PREV_PAGE = _ConnectionInterface$.HAS_PREV_PAGE,\n    PAGE_INFO = _ConnectionInterface$.PAGE_INFO,\n    PAGE_INFO_TYPE = _ConnectionInterface$.PAGE_INFO_TYPE,\n    START_CURSOR = _ConnectionInterface$.START_CURSOR;\n  var serverConnection = record.getLinkedRecord(payload.fieldKey);\n  var serverPageInfo = serverConnection && serverConnection.getLinkedRecord(PAGE_INFO);\n  if (!serverConnection) {\n    record.setValue(null, payload.handleKey);\n    return;\n  }\n  var clientConnectionID = generateClientID(record.getDataID(), payload.handleKey);\n  var clientConnectionField = record.getLinkedRecord(payload.handleKey);\n  var clientConnection = clientConnectionField !== null && clientConnectionField !== void 0 ? clientConnectionField : store.get(clientConnectionID);\n  var clientPageInfo = clientConnection && clientConnection.getLinkedRecord(PAGE_INFO);\n  if (!clientConnection) {\n    var connection = store.create(clientConnectionID, serverConnection.getType());\n    connection.setValue(0, NEXT_EDGE_INDEX);\n    connection.copyFieldsFrom(serverConnection);\n    var serverEdges = serverConnection.getLinkedRecords(EDGES);\n    if (serverEdges) {\n      serverEdges = serverEdges.map(function (edge) {\n        return buildConnectionEdge(store, connection, edge);\n      });\n      connection.setLinkedRecords(serverEdges, EDGES);\n    }\n    record.setLinkedRecord(connection, payload.handleKey);\n    clientPageInfo = store.create(generateClientID(connection.getDataID(), PAGE_INFO), PAGE_INFO_TYPE);\n    clientPageInfo.setValue(false, HAS_NEXT_PAGE);\n    clientPageInfo.setValue(false, HAS_PREV_PAGE);\n    clientPageInfo.setValue(null, END_CURSOR);\n    clientPageInfo.setValue(null, START_CURSOR);\n    if (serverPageInfo) {\n      clientPageInfo.copyFieldsFrom(serverPageInfo);\n    }\n    connection.setLinkedRecord(clientPageInfo, PAGE_INFO);\n  } else {\n    if (clientConnectionField == null) {\n      record.setLinkedRecord(clientConnection, payload.handleKey);\n    }\n    var _connection = clientConnection;\n    var _serverEdges = serverConnection.getLinkedRecords(EDGES);\n    if (_serverEdges) {\n      _serverEdges = _serverEdges.map(function (edge) {\n        return buildConnectionEdge(store, _connection, edge);\n      });\n    }\n    var prevEdges = _connection.getLinkedRecords(EDGES);\n    var prevPageInfo = _connection.getLinkedRecord(PAGE_INFO);\n    _connection.copyFieldsFrom(serverConnection);\n    if (prevEdges) {\n      _connection.setLinkedRecords(prevEdges, EDGES);\n    }\n    if (prevPageInfo) {\n      _connection.setLinkedRecord(prevPageInfo, PAGE_INFO);\n    }\n    var nextEdges = [];\n    var args = payload.args;\n    if (prevEdges && _serverEdges) {\n      if (args.after != null) {\n        var _clientPageInfo;\n        var clientEndCursor = (_clientPageInfo = clientPageInfo) === null || _clientPageInfo === void 0 ? void 0 : _clientPageInfo.getValue(END_CURSOR);\n        var serverEndCursor = serverPageInfo === null || serverPageInfo === void 0 ? void 0 : serverPageInfo.getValue(END_CURSOR);\n        var isAddingEdgesAfterCurrentPage = clientPageInfo && args.after === clientEndCursor;\n        var isFillingOutCurrentPage = clientPageInfo && clientEndCursor === serverEndCursor;\n        if (isAddingEdgesAfterCurrentPage || isFillingOutCurrentPage) {\n          var nodeIDs = new Set();\n          mergeEdges(prevEdges, nextEdges, nodeIDs);\n          mergeEdges(_serverEdges, nextEdges, nodeIDs);\n        } else {\n          process.env.NODE_ENV !== \"production\" ? warning(false, 'Relay: Unexpected after cursor `%s`, edges must ' + 'be fetched from the end of the list (`%s`).', args.after, clientPageInfo && clientPageInfo.getValue(END_CURSOR)) : void 0;\n          return;\n        }\n      } else if (args.before != null) {\n        if (clientPageInfo && args.before === clientPageInfo.getValue(START_CURSOR)) {\n          var _nodeIDs = new Set();\n          mergeEdges(_serverEdges, nextEdges, _nodeIDs);\n          mergeEdges(prevEdges, nextEdges, _nodeIDs);\n        } else {\n          process.env.NODE_ENV !== \"production\" ? warning(false, 'Relay: Unexpected before cursor `%s`, edges must ' + 'be fetched from the beginning of the list (`%s`).', args.before, clientPageInfo && clientPageInfo.getValue(START_CURSOR)) : void 0;\n          return;\n        }\n      } else {\n        nextEdges = _serverEdges;\n      }\n    } else if (_serverEdges) {\n      nextEdges = _serverEdges;\n    } else {\n      nextEdges = prevEdges;\n    }\n    if (nextEdges != null && nextEdges !== prevEdges) {\n      _connection.setLinkedRecords(nextEdges, EDGES);\n    }\n    if (clientPageInfo && serverPageInfo) {\n      if (args.after == null && args.before == null) {\n        clientPageInfo.copyFieldsFrom(serverPageInfo);\n      } else if (args.before != null || args.after == null && args.last) {\n        clientPageInfo.setValue(!!serverPageInfo.getValue(HAS_PREV_PAGE), HAS_PREV_PAGE);\n        var startCursor = serverPageInfo.getValue(START_CURSOR);\n        if (typeof startCursor === 'string') {\n          clientPageInfo.setValue(startCursor, START_CURSOR);\n        }\n      } else if (args.after != null || args.before == null && args.first) {\n        clientPageInfo.setValue(!!serverPageInfo.getValue(HAS_NEXT_PAGE), HAS_NEXT_PAGE);\n        var endCursor = serverPageInfo.getValue(END_CURSOR);\n        if (typeof endCursor === 'string') {\n          clientPageInfo.setValue(endCursor, END_CURSOR);\n        }\n      }\n    }\n  }\n}\nfunction getConnection(record, key, filters) {\n  var handleKey = getRelayHandleKey(CONNECTION, key, null);\n  return record.getLinkedRecord(handleKey, filters);\n}\nfunction getConnectionID(recordID, key, filters) {\n  var handleKey = getRelayHandleKey(CONNECTION, key, null);\n  var storageKey = getStableStorageKey(handleKey, filters);\n  return generateClientID(recordID, storageKey);\n}\nfunction insertEdgeAfter(record, newEdge, cursor) {\n  var _ConnectionInterface$2 = ConnectionInterface.get(),\n    CURSOR = _ConnectionInterface$2.CURSOR,\n    EDGES = _ConnectionInterface$2.EDGES;\n  var edges = record.getLinkedRecords(EDGES);\n  if (!edges) {\n    record.setLinkedRecords([newEdge], EDGES);\n    return;\n  }\n  var nextEdges;\n  if (cursor == null) {\n    nextEdges = edges.concat(newEdge);\n  } else {\n    nextEdges = [];\n    var foundCursor = false;\n    for (var ii = 0; ii < edges.length; ii++) {\n      var edge = edges[ii];\n      nextEdges.push(edge);\n      if (edge == null) {\n        continue;\n      }\n      var edgeCursor = edge.getValue(CURSOR);\n      if (cursor === edgeCursor) {\n        nextEdges.push(newEdge);\n        foundCursor = true;\n      }\n    }\n    if (!foundCursor) {\n      nextEdges.push(newEdge);\n    }\n  }\n  record.setLinkedRecords(nextEdges, EDGES);\n}\nfunction createEdge(store, record, node, edgeType) {\n  var _ConnectionInterface$3 = ConnectionInterface.get(),\n    NODE = _ConnectionInterface$3.NODE;\n  var edgeID = generateClientID(record.getDataID(), node.getDataID());\n  var edge = store.get(edgeID);\n  if (!edge) {\n    edge = store.create(edgeID, edgeType);\n  }\n  edge.setLinkedRecord(node, NODE);\n  if (edge.getValue('cursor') == null) {\n    edge.setValue(null, 'cursor');\n  }\n  return edge;\n}\nfunction insertEdgeBefore(record, newEdge, cursor) {\n  var _ConnectionInterface$4 = ConnectionInterface.get(),\n    CURSOR = _ConnectionInterface$4.CURSOR,\n    EDGES = _ConnectionInterface$4.EDGES;\n  var edges = record.getLinkedRecords(EDGES);\n  if (!edges) {\n    record.setLinkedRecords([newEdge], EDGES);\n    return;\n  }\n  var nextEdges;\n  if (cursor == null) {\n    nextEdges = [newEdge].concat(edges);\n  } else {\n    nextEdges = [];\n    var foundCursor = false;\n    for (var ii = 0; ii < edges.length; ii++) {\n      var edge = edges[ii];\n      if (edge != null) {\n        var edgeCursor = edge.getValue(CURSOR);\n        if (cursor === edgeCursor) {\n          nextEdges.push(newEdge);\n          foundCursor = true;\n        }\n      }\n      nextEdges.push(edge);\n    }\n    if (!foundCursor) {\n      nextEdges.unshift(newEdge);\n    }\n  }\n  record.setLinkedRecords(nextEdges, EDGES);\n}\nfunction deleteNode(record, nodeID) {\n  var _ConnectionInterface$5 = ConnectionInterface.get(),\n    EDGES = _ConnectionInterface$5.EDGES,\n    NODE = _ConnectionInterface$5.NODE;\n  var edges = record.getLinkedRecords(EDGES);\n  if (!edges) {\n    return;\n  }\n  var nextEdges;\n  for (var ii = 0; ii < edges.length; ii++) {\n    var edge = edges[ii];\n    var node = edge && edge.getLinkedRecord(NODE);\n    if (node != null && node.getDataID() === nodeID) {\n      if (nextEdges === undefined) {\n        nextEdges = edges.slice(0, ii);\n      }\n    } else if (nextEdges !== undefined) {\n      nextEdges.push(edge);\n    }\n  }\n  if (nextEdges !== undefined) {\n    record.setLinkedRecords(nextEdges, EDGES);\n  }\n}\nfunction buildConnectionEdge(store, connection, edge) {\n  if (edge == null) {\n    return edge;\n  }\n  var _ConnectionInterface$6 = ConnectionInterface.get(),\n    EDGES = _ConnectionInterface$6.EDGES;\n  var edgeIndex = connection.getValue(NEXT_EDGE_INDEX);\n  !(typeof edgeIndex === 'number') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'ConnectionHandler: Expected %s to be a number, got `%s`.', NEXT_EDGE_INDEX, edgeIndex) : invariant(false) : void 0;\n  var edgeID = generateClientID(connection.getDataID(), EDGES, edgeIndex);\n  var connectionEdge = store.create(edgeID, edge.getType());\n  connectionEdge.copyFieldsFrom(edge);\n  if (connectionEdge.getValue('cursor') == null) {\n    connectionEdge.setValue(null, 'cursor');\n  }\n  connection.setValue(edgeIndex + 1, NEXT_EDGE_INDEX);\n  return connectionEdge;\n}\nfunction mergeEdges(sourceEdges, targetEdges, nodeIDs) {\n  var _ConnectionInterface$7 = ConnectionInterface.get(),\n    NODE = _ConnectionInterface$7.NODE;\n  for (var ii = 0; ii < sourceEdges.length; ii++) {\n    var edge = sourceEdges[ii];\n    if (!edge) {\n      continue;\n    }\n    var node = edge.getLinkedRecord(NODE);\n    var nodeID = node && node.getDataID();\n    if (nodeID) {\n      if (nodeIDs.has(nodeID)) {\n        continue;\n      }\n      nodeIDs.add(nodeID);\n    }\n    targetEdges.push(edge);\n  }\n}\nmodule.exports = {\n  buildConnectionEdge: buildConnectionEdge,\n  createEdge: createEdge,\n  deleteNode: deleteNode,\n  getConnection: getConnection,\n  getConnectionID: getConnectionID,\n  insertEdgeAfter: insertEdgeAfter,\n  insertEdgeBefore: insertEdgeBefore,\n  update: update\n};","'use strict';\n\nvar CONNECTION_CALLS = {\n  after: true,\n  before: true,\n  find: true,\n  first: true,\n  last: true,\n  surrounds: true\n};\nvar config = {\n  CURSOR: 'cursor',\n  EDGES: 'edges',\n  END_CURSOR: 'endCursor',\n  HAS_NEXT_PAGE: 'hasNextPage',\n  HAS_PREV_PAGE: 'hasPreviousPage',\n  NODE: 'node',\n  PAGE_INFO_TYPE: 'PageInfo',\n  PAGE_INFO: 'pageInfo',\n  START_CURSOR: 'startCursor'\n};\nvar ConnectionInterface = {\n  inject: function inject(newConfig) {\n    config = newConfig;\n  },\n  get: function get() {\n    return config;\n  },\n  isConnectionCall: function isConnectionCall(call) {\n    return CONNECTION_CALLS.hasOwnProperty(call.name);\n  }\n};\nmodule.exports = ConnectionInterface;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar ConnectionHandler = require('./ConnectionHandler');\nvar ConnectionInterface = require('./ConnectionInterface');\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nvar DeleteRecordHandler = {\n  update: function update(store, payload) {\n    var record = store.get(payload.dataID);\n    if (record != null) {\n      var idOrIds = record.getValue(payload.fieldKey);\n      if (typeof idOrIds === 'string') {\n        store[\"delete\"](idOrIds);\n      } else if (Array.isArray(idOrIds)) {\n        idOrIds.forEach(function (id) {\n          if (typeof id === 'string') {\n            store[\"delete\"](id);\n          }\n        });\n      }\n    }\n  }\n};\nvar DeleteEdgeHandler = {\n  update: function update(store, payload) {\n    var record = store.get(payload.dataID);\n    if (record == null) {\n      return;\n    }\n    var connections = payload.handleArgs.connections;\n    !(connections != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'MutationHandlers: Expected connection IDs to be specified.') : invariant(false) : void 0;\n    var idOrIds = record.getValue(payload.fieldKey);\n    var idList = Array.isArray(idOrIds) ? idOrIds : [idOrIds];\n    idList.forEach(function (id) {\n      if (typeof id === 'string') {\n        var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(connections),\n          _step;\n        try {\n          for (_iterator.s(); !(_step = _iterator.n()).done;) {\n            var connectionID = _step.value;\n            var connection = store.get(connectionID);\n            if (connection == null) {\n              process.env.NODE_ENV !== \"production\" ? warning(false, \"[Relay] The connection with id `%s` doesn't exist.\", connectionID) : void 0;\n              continue;\n            }\n            ConnectionHandler.deleteNode(connection, id);\n          }\n        } catch (err) {\n          _iterator.e(err);\n        } finally {\n          _iterator.f();\n        }\n      }\n    });\n  }\n};\nvar AppendEdgeHandler = {\n  update: edgeUpdater(ConnectionHandler.insertEdgeAfter)\n};\nvar PrependEdgeHandler = {\n  update: edgeUpdater(ConnectionHandler.insertEdgeBefore)\n};\nvar AppendNodeHandler = {\n  update: nodeUpdater(ConnectionHandler.insertEdgeAfter)\n};\nvar PrependNodeHandler = {\n  update: nodeUpdater(ConnectionHandler.insertEdgeBefore)\n};\nfunction edgeUpdater(insertFn) {\n  return function (store, payload) {\n    var _serverEdges;\n    var record = store.get(payload.dataID);\n    if (record == null) {\n      return;\n    }\n    var connections = payload.handleArgs.connections;\n    !(connections != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'MutationHandlers: Expected connection IDs to be specified.') : invariant(false) : void 0;\n    var singleServerEdge, serverEdges;\n    try {\n      singleServerEdge = record.getLinkedRecord(payload.fieldKey);\n    } catch (_unused) {}\n    if (!singleServerEdge) {\n      try {\n        serverEdges = record.getLinkedRecords(payload.fieldKey);\n      } catch (_unused2) {}\n    }\n    if (singleServerEdge == null && serverEdges == null) {\n      process.env.NODE_ENV !== \"production\" ? warning(false, 'MutationHandlers: Expected the server edge to be non-null.') : void 0;\n      return;\n    }\n    var _ConnectionInterface$ = ConnectionInterface.get(),\n      NODE = _ConnectionInterface$.NODE,\n      EDGES = _ConnectionInterface$.EDGES;\n    var serverEdgeList = (_serverEdges = serverEdges) !== null && _serverEdges !== void 0 ? _serverEdges : [singleServerEdge];\n    var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(serverEdgeList),\n      _step2;\n    try {\n      var _loop = function _loop() {\n        var serverEdge = _step2.value;\n        if (serverEdge == null) {\n          return \"continue\";\n        }\n        var serverNode = serverEdge.getLinkedRecord('node');\n        if (!serverNode) {\n          return \"continue\";\n        }\n        var serverNodeId = serverNode.getDataID();\n        var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])(connections),\n          _step3;\n        try {\n          for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n            var connectionID = _step3.value;\n            var connection = store.get(connectionID);\n            if (connection == null) {\n              process.env.NODE_ENV !== \"production\" ? warning(false, \"[Relay] The connection with id `%s` doesn't exist.\", connectionID) : void 0;\n              continue;\n            }\n            var nodeAlreadyExistsInConnection = (_connection$getLinked = connection.getLinkedRecords(EDGES)) === null || _connection$getLinked === void 0 ? void 0 : _connection$getLinked.some(function (edge) {\n              var _edge$getLinkedRecord;\n              return (edge === null || edge === void 0 ? void 0 : (_edge$getLinkedRecord = edge.getLinkedRecord(NODE)) === null || _edge$getLinkedRecord === void 0 ? void 0 : _edge$getLinkedRecord.getDataID()) === serverNodeId;\n            });\n            if (nodeAlreadyExistsInConnection) {\n              continue;\n            }\n            var clientEdge = ConnectionHandler.buildConnectionEdge(store, connection, serverEdge);\n            !(clientEdge != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'MutationHandlers: Failed to build the edge.') : invariant(false) : void 0;\n            insertFn(connection, clientEdge);\n          }\n        } catch (err) {\n          _iterator3.e(err);\n        } finally {\n          _iterator3.f();\n        }\n      };\n      for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n        var _connection$getLinked;\n        var _ret = _loop();\n        if (_ret === \"continue\") continue;\n      }\n    } catch (err) {\n      _iterator2.e(err);\n    } finally {\n      _iterator2.f();\n    }\n  };\n}\nfunction nodeUpdater(insertFn) {\n  return function (store, payload) {\n    var _serverNodes;\n    var record = store.get(payload.dataID);\n    if (record == null) {\n      return;\n    }\n    var _payload$handleArgs = payload.handleArgs,\n      connections = _payload$handleArgs.connections,\n      edgeTypeName = _payload$handleArgs.edgeTypeName;\n    !(connections != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'MutationHandlers: Expected connection IDs to be specified.') : invariant(false) : void 0;\n    !(edgeTypeName != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'MutationHandlers: Expected edge typename to be specified.') : invariant(false) : void 0;\n    var singleServerNode;\n    var serverNodes;\n    try {\n      singleServerNode = record.getLinkedRecord(payload.fieldKey);\n    } catch (_unused3) {}\n    if (!singleServerNode) {\n      try {\n        serverNodes = record.getLinkedRecords(payload.fieldKey);\n      } catch (_unused4) {}\n    }\n    if (singleServerNode == null && serverNodes == null) {\n      process.env.NODE_ENV !== \"production\" ? warning(false, 'MutationHandlers: Expected target node to exist.') : void 0;\n      return;\n    }\n    var _ConnectionInterface$2 = ConnectionInterface.get(),\n      NODE = _ConnectionInterface$2.NODE,\n      EDGES = _ConnectionInterface$2.EDGES;\n    var serverNodeList = (_serverNodes = serverNodes) !== null && _serverNodes !== void 0 ? _serverNodes : [singleServerNode];\n    var _iterator4 = (0, _createForOfIteratorHelper2[\"default\"])(serverNodeList),\n      _step4;\n    try {\n      var _loop2 = function _loop2() {\n        var serverNode = _step4.value;\n        if (serverNode == null) {\n          return \"continue\";\n        }\n        var serverNodeId = serverNode.getDataID();\n        var _iterator5 = (0, _createForOfIteratorHelper2[\"default\"])(connections),\n          _step5;\n        try {\n          for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n            var connectionID = _step5.value;\n            var connection = store.get(connectionID);\n            if (connection == null) {\n              process.env.NODE_ENV !== \"production\" ? warning(false, \"[Relay] The connection with id `%s` doesn't exist.\", connectionID) : void 0;\n              continue;\n            }\n            var nodeAlreadyExistsInConnection = (_connection$getLinked2 = connection.getLinkedRecords(EDGES)) === null || _connection$getLinked2 === void 0 ? void 0 : _connection$getLinked2.some(function (edge) {\n              var _edge$getLinkedRecord2;\n              return (edge === null || edge === void 0 ? void 0 : (_edge$getLinkedRecord2 = edge.getLinkedRecord(NODE)) === null || _edge$getLinkedRecord2 === void 0 ? void 0 : _edge$getLinkedRecord2.getDataID()) === serverNodeId;\n            });\n            if (nodeAlreadyExistsInConnection) {\n              continue;\n            }\n            var clientEdge = ConnectionHandler.createEdge(store, connection, serverNode, edgeTypeName);\n            !(clientEdge != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'MutationHandlers: Failed to build the edge.') : invariant(false) : void 0;\n            insertFn(connection, clientEdge);\n          }\n        } catch (err) {\n          _iterator5.e(err);\n        } finally {\n          _iterator5.f();\n        }\n      };\n      for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n        var _connection$getLinked2;\n        var _ret2 = _loop2();\n        if (_ret2 === \"continue\") continue;\n      }\n    } catch (err) {\n      _iterator4.e(err);\n    } finally {\n      _iterator4.f();\n    }\n  };\n}\nmodule.exports = {\n  AppendEdgeHandler: AppendEdgeHandler,\n  DeleteRecordHandler: DeleteRecordHandler,\n  PrependEdgeHandler: PrependEdgeHandler,\n  AppendNodeHandler: AppendNodeHandler,\n  PrependNodeHandler: PrependNodeHandler,\n  DeleteEdgeHandler: DeleteEdgeHandler\n};","'use strict';\n\nvar ConnectionHandler = require('./handlers/connection/ConnectionHandler');\nvar ConnectionInterface = require('./handlers/connection/ConnectionInterface');\nvar MutationHandlers = require('./handlers/connection/MutationHandlers');\nvar RelayDefaultHandlerProvider = require('./handlers/RelayDefaultHandlerProvider');\nvar applyOptimisticMutation = require('./mutations/applyOptimisticMutation');\nvar commitLocalUpdate = require('./mutations/commitLocalUpdate');\nvar commitMutation = require('./mutations/commitMutation');\nvar RelayDeclarativeMutationConfig = require('./mutations/RelayDeclarativeMutationConfig');\nvar RelayNetwork = require('./network/RelayNetwork');\nvar RelayObservable = require('./network/RelayObservable');\nvar RelayQueryResponseCache = require('./network/RelayQueryResponseCache');\nvar fetchQuery = require('./query/fetchQuery');\nvar fetchQuery_DEPRECATED = require('./query/fetchQuery_DEPRECATED');\nvar fetchQueryInternal = require('./query/fetchQueryInternal');\nvar GraphQLTag = require('./query/GraphQLTag');\nvar PreloadableQueryRegistry = require('./query/PreloadableQueryRegistry');\nvar _require = require('./store/ClientID'),\n  generateClientID = _require.generateClientID,\n  generateUniqueClientID = _require.generateUniqueClientID,\n  isClientID = _require.isClientID;\nvar createFragmentSpecResolver = require('./store/createFragmentSpecResolver');\nvar createRelayContext = require('./store/createRelayContext');\nvar _require2 = require('./store/experimental-live-resolvers/LiveResolverSuspenseSentinel'),\n  isSuspenseSentinel = _require2.isSuspenseSentinel,\n  suspenseSentinel = _require2.suspenseSentinel;\nvar isRelayModernEnvironment = require('./store/isRelayModernEnvironment');\nvar normalizeResponse = require('./store/normalizeResponse');\nvar readInlineData = require('./store/readInlineData');\nvar RelayConcreteVariables = require('./store/RelayConcreteVariables');\nvar RelayModernEnvironment = require('./store/RelayModernEnvironment');\nvar RelayModernOperationDescriptor = require('./store/RelayModernOperationDescriptor');\nvar RelayModernRecord = require('./store/RelayModernRecord');\nvar RelayModernSelector = require('./store/RelayModernSelector');\nvar RelayModernStore = require('./store/RelayModernStore');\nvar RelayOperationTracker = require('./store/RelayOperationTracker');\nvar RelayRecordSource = require('./store/RelayRecordSource');\nvar RelayStoreUtils = require('./store/RelayStoreUtils');\nvar ResolverFragments = require('./store/ResolverFragments');\nvar ViewerPattern = require('./store/ViewerPattern');\nvar requestSubscription = require('./subscription/requestSubscription');\nvar createPayloadFor3DField = require('./util/createPayloadFor3DField');\nvar deepFreeze = require('./util/deepFreeze');\nvar getFragmentIdentifier = require('./util/getFragmentIdentifier');\nvar getPaginationMetadata = require('./util/getPaginationMetadata');\nvar getPaginationVariables = require('./util/getPaginationVariables');\nvar getPendingOperationsForFragment = require('./util/getPendingOperationsForFragment');\nvar getRefetchMetadata = require('./util/getRefetchMetadata');\nvar getRelayHandleKey = require('./util/getRelayHandleKey');\nvar getRequestIdentifier = require('./util/getRequestIdentifier');\nvar getValueAtPath = require('./util/getValueAtPath');\nvar handlePotentialSnapshotErrors = require('./util/handlePotentialSnapshotErrors');\nvar isPromise = require('./util/isPromise');\nvar isScalarAndEqual = require('./util/isScalarAndEqual');\nvar recycleNodesInto = require('./util/recycleNodesInto');\nvar RelayConcreteNode = require('./util/RelayConcreteNode');\nvar RelayDefaultHandleKey = require('./util/RelayDefaultHandleKey');\nvar RelayError = require('./util/RelayError');\nvar RelayFeatureFlags = require('./util/RelayFeatureFlags');\nvar RelayProfiler = require('./util/RelayProfiler');\nvar RelayReplaySubject = require('./util/RelayReplaySubject');\nvar stableCopy = require('./util/stableCopy');\nvar withProvidedVariables = require('./util/withProvidedVariables');\nif (process.env.NODE_ENV !== \"production\") {\n  var mapStr = typeof Map !== 'function' ? 'Map' : null;\n  var setStr = typeof Set !== 'function' ? 'Set' : null;\n  var promiseStr = typeof Promise !== 'function' ? 'Promise' : null;\n  var objStr = typeof Object.assign !== 'function' ? 'Object.assign' : null;\n  if (mapStr || setStr || promiseStr || objStr) {\n    throw new Error(\"relay-runtime requires \".concat([mapStr, setStr, promiseStr, objStr].filter(Boolean).join(', and '), \" to exist. \") + 'Use a polyfill to provide these for older browsers.');\n  }\n}\nmodule.exports = {\n  Environment: RelayModernEnvironment,\n  Network: RelayNetwork,\n  Observable: RelayObservable,\n  QueryResponseCache: RelayQueryResponseCache,\n  RecordSource: RelayRecordSource,\n  Record: RelayModernRecord,\n  ReplaySubject: RelayReplaySubject,\n  Store: RelayModernStore,\n  areEqualSelectors: RelayModernSelector.areEqualSelectors,\n  createFragmentSpecResolver: createFragmentSpecResolver,\n  createNormalizationSelector: RelayModernSelector.createNormalizationSelector,\n  createOperationDescriptor: RelayModernOperationDescriptor.createOperationDescriptor,\n  createReaderSelector: RelayModernSelector.createReaderSelector,\n  createRequestDescriptor: RelayModernOperationDescriptor.createRequestDescriptor,\n  getArgumentValues: RelayStoreUtils.getArgumentValues,\n  getDataIDsFromFragment: RelayModernSelector.getDataIDsFromFragment,\n  getDataIDsFromObject: RelayModernSelector.getDataIDsFromObject,\n  getNode: GraphQLTag.getNode,\n  getFragment: GraphQLTag.getFragment,\n  getInlineDataFragment: GraphQLTag.getInlineDataFragment,\n  getModuleComponentKey: RelayStoreUtils.getModuleComponentKey,\n  getModuleOperationKey: RelayStoreUtils.getModuleOperationKey,\n  getPaginationFragment: GraphQLTag.getPaginationFragment,\n  getPluralSelector: RelayModernSelector.getPluralSelector,\n  getRefetchableFragment: GraphQLTag.getRefetchableFragment,\n  getRequest: GraphQLTag.getRequest,\n  getRequestIdentifier: getRequestIdentifier,\n  getSelector: RelayModernSelector.getSelector,\n  getSelectorsFromObject: RelayModernSelector.getSelectorsFromObject,\n  getSingularSelector: RelayModernSelector.getSingularSelector,\n  getStorageKey: RelayStoreUtils.getStorageKey,\n  getVariablesFromFragment: RelayModernSelector.getVariablesFromFragment,\n  getVariablesFromObject: RelayModernSelector.getVariablesFromObject,\n  getVariablesFromPluralFragment: RelayModernSelector.getVariablesFromPluralFragment,\n  getVariablesFromSingularFragment: RelayModernSelector.getVariablesFromSingularFragment,\n  handlePotentialSnapshotErrors: handlePotentialSnapshotErrors,\n  graphql: GraphQLTag.graphql,\n  isFragment: GraphQLTag.isFragment,\n  isInlineDataFragment: GraphQLTag.isInlineDataFragment,\n  isSuspenseSentinel: isSuspenseSentinel,\n  suspenseSentinel: suspenseSentinel,\n  isRequest: GraphQLTag.isRequest,\n  readInlineData: readInlineData,\n  MutationTypes: RelayDeclarativeMutationConfig.MutationTypes,\n  RangeOperations: RelayDeclarativeMutationConfig.RangeOperations,\n  DefaultHandlerProvider: RelayDefaultHandlerProvider,\n  ConnectionHandler: ConnectionHandler,\n  MutationHandlers: MutationHandlers,\n  VIEWER_ID: ViewerPattern.VIEWER_ID,\n  VIEWER_TYPE: ViewerPattern.VIEWER_TYPE,\n  applyOptimisticMutation: applyOptimisticMutation,\n  commitLocalUpdate: commitLocalUpdate,\n  commitMutation: commitMutation,\n  fetchQuery: fetchQuery,\n  fetchQuery_DEPRECATED: fetchQuery_DEPRECATED,\n  isRelayModernEnvironment: isRelayModernEnvironment,\n  requestSubscription: requestSubscription,\n  ConnectionInterface: ConnectionInterface,\n  PreloadableQueryRegistry: PreloadableQueryRegistry,\n  RelayProfiler: RelayProfiler,\n  createPayloadFor3DField: createPayloadFor3DField,\n  RelayConcreteNode: RelayConcreteNode,\n  RelayError: RelayError,\n  RelayFeatureFlags: RelayFeatureFlags,\n  DEFAULT_HANDLE_KEY: RelayDefaultHandleKey.DEFAULT_HANDLE_KEY,\n  FRAGMENTS_KEY: RelayStoreUtils.FRAGMENTS_KEY,\n  FRAGMENT_OWNER_KEY: RelayStoreUtils.FRAGMENT_OWNER_KEY,\n  ID_KEY: RelayStoreUtils.ID_KEY,\n  REF_KEY: RelayStoreUtils.REF_KEY,\n  REFS_KEY: RelayStoreUtils.REFS_KEY,\n  ROOT_ID: RelayStoreUtils.ROOT_ID,\n  ROOT_TYPE: RelayStoreUtils.ROOT_TYPE,\n  TYPENAME_KEY: RelayStoreUtils.TYPENAME_KEY,\n  deepFreeze: deepFreeze,\n  generateClientID: generateClientID,\n  generateUniqueClientID: generateUniqueClientID,\n  getRelayHandleKey: getRelayHandleKey,\n  isClientID: isClientID,\n  isPromise: isPromise,\n  isScalarAndEqual: isScalarAndEqual,\n  recycleNodesInto: recycleNodesInto,\n  stableCopy: stableCopy,\n  getFragmentIdentifier: getFragmentIdentifier,\n  getRefetchMetadata: getRefetchMetadata,\n  getPaginationMetadata: getPaginationMetadata,\n  getPaginationVariables: getPaginationVariables,\n  getPendingOperationsForFragment: getPendingOperationsForFragment,\n  getValueAtPath: getValueAtPath,\n  __internal: {\n    ResolverFragments: ResolverFragments,\n    OperationTracker: RelayOperationTracker,\n    createRelayContext: createRelayContext,\n    getOperationVariables: RelayConcreteVariables.getOperationVariables,\n    getLocalVariables: RelayConcreteVariables.getLocalVariables,\n    fetchQuery: fetchQueryInternal.fetchQuery,\n    fetchQueryDeduped: fetchQueryInternal.fetchQueryDeduped,\n    getPromiseForActiveRequest: fetchQueryInternal.getPromiseForActiveRequest,\n    getObservableForActiveRequest: fetchQueryInternal.getObservableForActiveRequest,\n    normalizeResponse: normalizeResponse,\n    withProvidedVariables: withProvidedVariables\n  }\n};","'use strict';\n\nvar invariant = require('invariant');\nvar INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE = 'INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE';\nfunction assertInternalActorIdentifier(actorIdentifier) {\n  !(actorIdentifier === INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Expected to use only internal version of the `actorIdentifier`. \"%s\" was provided.', actorIdentifier) : invariant(false) : void 0;\n}\nmodule.exports = {\n  assertInternalActorIdentifier: assertInternalActorIdentifier,\n  getActorIdentifier: function getActorIdentifier(actorID) {\n    return actorID;\n  },\n  getDefaultActorIdentifier: function getDefaultActorIdentifier() {\n    throw new Error('Not Implemented');\n  },\n  INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE: INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE\n};","'use strict';\n\nvar ACTOR_IDENTIFIER_FIELD_NAME = 'actor_key';\nvar _require = require('./ActorIdentifier'),\n  getActorIdentifier = _require.getActorIdentifier;\nfunction getActorIdentifierFromPayload(payload) {\n  if (payload != null && typeof payload === 'object' && typeof payload[ACTOR_IDENTIFIER_FIELD_NAME] === 'string') {\n    return getActorIdentifier(payload[ACTOR_IDENTIFIER_FIELD_NAME]);\n  }\n}\nmodule.exports = {\n  ACTOR_IDENTIFIER_FIELD_NAME: ACTOR_IDENTIFIER_FIELD_NAME,\n  getActorIdentifierFromPayload: getActorIdentifierFromPayload\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar ConnectionHandler = require('../handlers/connection/ConnectionHandler');\nvar warning = require(\"fbjs/lib/warning\");\nvar MutationTypes = Object.freeze({\n  RANGE_ADD: 'RANGE_ADD',\n  RANGE_DELETE: 'RANGE_DELETE',\n  NODE_DELETE: 'NODE_DELETE'\n});\nvar RangeOperations = Object.freeze({\n  APPEND: 'append',\n  PREPEND: 'prepend'\n});\nfunction convert(configs, request, optimisticUpdater, updater) {\n  var configOptimisticUpdates = optimisticUpdater ? [optimisticUpdater] : [];\n  var configUpdates = updater ? [updater] : [];\n  configs.forEach(function (config) {\n    switch (config.type) {\n      case 'NODE_DELETE':\n        var nodeDeleteResult = nodeDelete(config, request);\n        if (nodeDeleteResult) {\n          configOptimisticUpdates.push(nodeDeleteResult);\n          configUpdates.push(nodeDeleteResult);\n        }\n        break;\n      case 'RANGE_ADD':\n        var rangeAddResult = rangeAdd(config, request);\n        if (rangeAddResult) {\n          configOptimisticUpdates.push(rangeAddResult);\n          configUpdates.push(rangeAddResult);\n        }\n        break;\n      case 'RANGE_DELETE':\n        var rangeDeleteResult = rangeDelete(config, request);\n        if (rangeDeleteResult) {\n          configOptimisticUpdates.push(rangeDeleteResult);\n          configUpdates.push(rangeDeleteResult);\n        }\n        break;\n    }\n  });\n  return {\n    optimisticUpdater: function optimisticUpdater(store, data) {\n      configOptimisticUpdates.forEach(function (eachOptimisticUpdater) {\n        eachOptimisticUpdater(store, data);\n      });\n    },\n    updater: function updater(store, data) {\n      configUpdates.forEach(function (eachUpdater) {\n        eachUpdater(store, data);\n      });\n    }\n  };\n}\nfunction nodeDelete(config, request) {\n  var deletedIDFieldName = config.deletedIDFieldName;\n  var rootField = getRootField(request);\n  if (!rootField) {\n    return null;\n  }\n  return function (store, data) {\n    var payload = store.getRootField(rootField);\n    if (!payload) {\n      return;\n    }\n    var deleteID = payload.getValue(deletedIDFieldName);\n    var deleteIDs = Array.isArray(deleteID) ? deleteID : [deleteID];\n    deleteIDs.forEach(function (id) {\n      if (id && typeof id === 'string') {\n        store[\"delete\"](id);\n      }\n    });\n  };\n}\nfunction rangeAdd(config, request) {\n  var parentID = config.parentID,\n    connectionInfo = config.connectionInfo,\n    edgeName = config.edgeName;\n  if (!parentID) {\n    process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayDeclarativeMutationConfig: For mutation config RANGE_ADD ' + 'to work you must include a parentID') : void 0;\n    return null;\n  }\n  var rootField = getRootField(request);\n  if (!connectionInfo || !rootField) {\n    return null;\n  }\n  return function (store, data) {\n    var parent = store.get(parentID);\n    if (!parent) {\n      return;\n    }\n    var payload = store.getRootField(rootField);\n    if (!payload) {\n      return;\n    }\n    var serverEdge = payload.getLinkedRecord(edgeName);\n    var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(connectionInfo),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var info = _step.value;\n        if (!serverEdge) {\n          continue;\n        }\n        var connection = ConnectionHandler.getConnection(parent, info.key, info.filters);\n        if (!connection) {\n          continue;\n        }\n        var clientEdge = ConnectionHandler.buildConnectionEdge(store, connection, serverEdge);\n        if (!clientEdge) {\n          continue;\n        }\n        switch (info.rangeBehavior) {\n          case 'append':\n            ConnectionHandler.insertEdgeAfter(connection, clientEdge);\n            break;\n          case 'prepend':\n            ConnectionHandler.insertEdgeBefore(connection, clientEdge);\n            break;\n          default:\n            process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayDeclarativeMutationConfig: RANGE_ADD range behavior `%s` ' + 'will not work as expected in RelayModern, supported range ' + \"behaviors are 'append', 'prepend'.\", info.rangeBehavior) : void 0;\n            break;\n        }\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n  };\n}\nfunction rangeDelete(config, request) {\n  var parentID = config.parentID,\n    connectionKeys = config.connectionKeys,\n    pathToConnection = config.pathToConnection,\n    deletedIDFieldName = config.deletedIDFieldName;\n  if (!parentID) {\n    process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayDeclarativeMutationConfig: For mutation config RANGE_DELETE ' + 'to work you must include a parentID') : void 0;\n    return null;\n  }\n  var rootField = getRootField(request);\n  if (!rootField) {\n    return null;\n  }\n  return function (store, data) {\n    if (!data) {\n      return;\n    }\n    var deleteIDs = [];\n    var deletedIDField = data[rootField];\n    if (deletedIDField && Array.isArray(deletedIDFieldName)) {\n      var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(deletedIDFieldName),\n        _step2;\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var eachField = _step2.value;\n          if (deletedIDField && typeof deletedIDField === 'object') {\n            deletedIDField = deletedIDField[eachField];\n          }\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n      if (Array.isArray(deletedIDField)) {\n        deletedIDField.forEach(function (idObject) {\n          if (idObject && idObject.id && typeof idObject === 'object' && typeof idObject.id === 'string') {\n            deleteIDs.push(idObject.id);\n          }\n        });\n      } else if (deletedIDField && deletedIDField.id && typeof deletedIDField.id === 'string') {\n        deleteIDs.push(deletedIDField.id);\n      }\n    } else if (deletedIDField && typeof deletedIDFieldName === 'string' && typeof deletedIDField === 'object') {\n      deletedIDField = deletedIDField[deletedIDFieldName];\n      if (typeof deletedIDField === 'string') {\n        deleteIDs.push(deletedIDField);\n      } else if (Array.isArray(deletedIDField)) {\n        deletedIDField.forEach(function (id) {\n          if (typeof id === 'string') {\n            deleteIDs.push(id);\n          }\n        });\n      }\n    }\n    deleteNode(parentID, connectionKeys, pathToConnection, store, deleteIDs);\n  };\n}\nfunction deleteNode(parentID, connectionKeys, pathToConnection, store, deleteIDs) {\n  process.env.NODE_ENV !== \"production\" ? warning(connectionKeys != null, 'RelayDeclarativeMutationConfig: RANGE_DELETE must provide a ' + 'connectionKeys') : void 0;\n  var parent = store.get(parentID);\n  if (!parent) {\n    return;\n  }\n  if (pathToConnection.length < 2) {\n    process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayDeclarativeMutationConfig: RANGE_DELETE ' + 'pathToConnection must include at least parent and connection') : void 0;\n    return;\n  }\n  var recordProxy = parent;\n  for (var i = 1; i < pathToConnection.length - 1; i++) {\n    if (recordProxy) {\n      recordProxy = recordProxy.getLinkedRecord(pathToConnection[i]);\n    }\n  }\n  if (!connectionKeys || !recordProxy) {\n    process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayDeclarativeMutationConfig: RANGE_DELETE ' + 'pathToConnection is incorrect. Unable to find connection with ' + 'parentID: %s and path: %s', parentID, pathToConnection.toString()) : void 0;\n    return;\n  }\n  var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])(connectionKeys),\n    _step3;\n  try {\n    var _loop = function _loop() {\n      var key = _step3.value;\n      var connection = ConnectionHandler.getConnection(recordProxy, key.key, key.filters);\n      if (connection) {\n        deleteIDs.forEach(function (deleteID) {\n          ConnectionHandler.deleteNode(connection, deleteID);\n        });\n      }\n    };\n    for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n      _loop();\n    }\n  } catch (err) {\n    _iterator3.e(err);\n  } finally {\n    _iterator3.f();\n  }\n}\nfunction getRootField(request) {\n  if (request.fragment.selections && request.fragment.selections.length > 0 && request.fragment.selections[0].kind === 'LinkedField') {\n    return request.fragment.selections[0].name;\n  }\n  return null;\n}\nmodule.exports = {\n  MutationTypes: MutationTypes,\n  RangeOperations: RangeOperations,\n  convert: convert\n};","'use strict';\n\nvar _require = require('../store/ClientID'),\n  generateClientID = _require.generateClientID;\nvar _require2 = require('../store/RelayStoreUtils'),\n  getStableStorageKey = _require2.getStableStorageKey;\nvar invariant = require('invariant');\nvar RelayRecordProxy = /*#__PURE__*/function () {\n  function RelayRecordProxy(source, mutator, dataID) {\n    this._dataID = dataID;\n    this._mutator = mutator;\n    this._source = source;\n  }\n  var _proto = RelayRecordProxy.prototype;\n  _proto.copyFieldsFrom = function copyFieldsFrom(source) {\n    this._mutator.copyFields(source.getDataID(), this._dataID);\n  };\n  _proto.getDataID = function getDataID() {\n    return this._dataID;\n  };\n  _proto.getType = function getType() {\n    var type = this._mutator.getType(this._dataID);\n    !(type != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordProxy: Cannot get the type of deleted record `%s`.', this._dataID) : invariant(false) : void 0;\n    return type;\n  };\n  _proto.getValue = function getValue(name, args) {\n    var storageKey = getStableStorageKey(name, args);\n    return this._mutator.getValue(this._dataID, storageKey);\n  };\n  _proto.setValue = function setValue(value, name, args) {\n    !isValidLeafValue(value) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordProxy#setValue(): Expected a scalar or array of scalars, ' + 'got `%s`.', JSON.stringify(value)) : invariant(false) : void 0;\n    return this.setValue__UNSAFE(value, name, args);\n  };\n  _proto.setValue__UNSAFE = function setValue__UNSAFE(value, name, args) {\n    var storageKey = getStableStorageKey(name, args);\n    this._mutator.setValue(this._dataID, storageKey, value);\n    return this;\n  };\n  _proto.getLinkedRecord = function getLinkedRecord(name, args) {\n    var storageKey = getStableStorageKey(name, args);\n    var linkedID = this._mutator.getLinkedRecordID(this._dataID, storageKey);\n    return linkedID != null ? this._source.get(linkedID) : linkedID;\n  };\n  _proto.setLinkedRecord = function setLinkedRecord(record, name, args) {\n    !(record instanceof RelayRecordProxy) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordProxy#setLinkedRecord(): Expected a record, got `%s`.', record) : invariant(false) : void 0;\n    var storageKey = getStableStorageKey(name, args);\n    var linkedID = record.getDataID();\n    this._mutator.setLinkedRecordID(this._dataID, storageKey, linkedID);\n    return this;\n  };\n  _proto.getOrCreateLinkedRecord = function getOrCreateLinkedRecord(name, typeName, args) {\n    var linkedRecord = this.getLinkedRecord(name, args);\n    if (!linkedRecord) {\n      var _this$_source$get;\n      var storageKey = getStableStorageKey(name, args);\n      var clientID = generateClientID(this.getDataID(), storageKey);\n      linkedRecord = (_this$_source$get = this._source.get(clientID)) !== null && _this$_source$get !== void 0 ? _this$_source$get : this._source.create(clientID, typeName);\n      this.setLinkedRecord(linkedRecord, name, args);\n    }\n    return linkedRecord;\n  };\n  _proto.getLinkedRecords = function getLinkedRecords(name, args) {\n    var _this = this;\n    var storageKey = getStableStorageKey(name, args);\n    var linkedIDs = this._mutator.getLinkedRecordIDs(this._dataID, storageKey);\n    if (linkedIDs == null) {\n      return linkedIDs;\n    }\n    return linkedIDs.map(function (linkedID) {\n      return linkedID != null ? _this._source.get(linkedID) : linkedID;\n    });\n  };\n  _proto.setLinkedRecords = function setLinkedRecords(records, name, args) {\n    !Array.isArray(records) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordProxy#setLinkedRecords(): Expected records to be an array, got `%s`.', records) : invariant(false) : void 0;\n    var storageKey = getStableStorageKey(name, args);\n    var linkedIDs = records.map(function (record) {\n      return record && record.getDataID();\n    });\n    this._mutator.setLinkedRecordIDs(this._dataID, storageKey, linkedIDs);\n    return this;\n  };\n  _proto.invalidateRecord = function invalidateRecord() {\n    this._source.markIDForInvalidation(this._dataID);\n  };\n  return RelayRecordProxy;\n}();\nfunction isValidLeafValue(value) {\n  return value == null || typeof value !== 'object' || Array.isArray(value) && value.every(isValidLeafValue);\n}\nmodule.exports = RelayRecordProxy;","'use strict';\n\nvar RelayModernRecord = require('../store/RelayModernRecord');\nvar _require = require('../store/RelayRecordState'),\n  EXISTENT = _require.EXISTENT;\nvar invariant = require('invariant');\nvar RelayRecordSourceMutator = /*#__PURE__*/function () {\n  function RelayRecordSourceMutator(base, sink) {\n    this.__sources = [sink, base];\n    this._base = base;\n    this._sink = sink;\n  }\n  var _proto = RelayRecordSourceMutator.prototype;\n  _proto.unstable_getRawRecordWithChanges = function unstable_getRawRecordWithChanges(dataID) {\n    var baseRecord = this._base.get(dataID);\n    var sinkRecord = this._sink.get(dataID);\n    if (sinkRecord === undefined) {\n      if (baseRecord == null) {\n        return baseRecord;\n      }\n      var nextRecord = RelayModernRecord.clone(baseRecord);\n      if (process.env.NODE_ENV !== \"production\") {\n        RelayModernRecord.freeze(nextRecord);\n      }\n      return nextRecord;\n    } else if (sinkRecord === null) {\n      return null;\n    } else if (baseRecord != null) {\n      var _nextRecord = RelayModernRecord.update(baseRecord, sinkRecord);\n      if (process.env.NODE_ENV !== \"production\") {\n        if (_nextRecord !== baseRecord) {\n          RelayModernRecord.freeze(_nextRecord);\n        }\n      }\n      return _nextRecord;\n    } else {\n      var _nextRecord2 = RelayModernRecord.clone(sinkRecord);\n      if (process.env.NODE_ENV !== \"production\") {\n        RelayModernRecord.freeze(_nextRecord2);\n      }\n      return _nextRecord2;\n    }\n  };\n  _proto._getSinkRecord = function _getSinkRecord(dataID) {\n    var sinkRecord = this._sink.get(dataID);\n    if (!sinkRecord) {\n      var baseRecord = this._base.get(dataID);\n      !baseRecord ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceMutator: Cannot modify non-existent record `%s`.', dataID) : invariant(false) : void 0;\n      sinkRecord = RelayModernRecord.create(dataID, RelayModernRecord.getType(baseRecord));\n      this._sink.set(dataID, sinkRecord);\n    }\n    return sinkRecord;\n  };\n  _proto.copyFields = function copyFields(sourceID, sinkID) {\n    var sinkSource = this._sink.get(sourceID);\n    var baseSource = this._base.get(sourceID);\n    !(sinkSource || baseSource) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceMutator#copyFields(): Cannot copy fields from ' + 'non-existent record `%s`.', sourceID) : invariant(false) : void 0;\n    var sink = this._getSinkRecord(sinkID);\n    if (baseSource) {\n      RelayModernRecord.copyFields(baseSource, sink);\n    }\n    if (sinkSource) {\n      RelayModernRecord.copyFields(sinkSource, sink);\n    }\n  };\n  _proto.copyFieldsFromRecord = function copyFieldsFromRecord(record, sinkID) {\n    var sink = this._getSinkRecord(sinkID);\n    RelayModernRecord.copyFields(record, sink);\n  };\n  _proto.create = function create(dataID, typeName) {\n    !(this._base.getStatus(dataID) !== EXISTENT && this._sink.getStatus(dataID) !== EXISTENT) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceMutator#create(): Cannot create a record with id ' + '`%s`, this record already exists.', dataID) : invariant(false) : void 0;\n    var record = RelayModernRecord.create(dataID, typeName);\n    this._sink.set(dataID, record);\n  };\n  _proto[\"delete\"] = function _delete(dataID) {\n    this._sink[\"delete\"](dataID);\n  };\n  _proto.getStatus = function getStatus(dataID) {\n    return this._sink.has(dataID) ? this._sink.getStatus(dataID) : this._base.getStatus(dataID);\n  };\n  _proto.getType = function getType(dataID) {\n    for (var ii = 0; ii < this.__sources.length; ii++) {\n      var record = this.__sources[ii].get(dataID);\n      if (record) {\n        return RelayModernRecord.getType(record);\n      } else if (record === null) {\n        return null;\n      }\n    }\n  };\n  _proto.getValue = function getValue(dataID, storageKey) {\n    for (var ii = 0; ii < this.__sources.length; ii++) {\n      var record = this.__sources[ii].get(dataID);\n      if (record) {\n        var value = RelayModernRecord.getValue(record, storageKey);\n        if (value !== undefined) {\n          return value;\n        }\n      } else if (record === null) {\n        return null;\n      }\n    }\n  };\n  _proto.setValue = function setValue(dataID, storageKey, value) {\n    var sinkRecord = this._getSinkRecord(dataID);\n    RelayModernRecord.setValue(sinkRecord, storageKey, value);\n  };\n  _proto.getLinkedRecordID = function getLinkedRecordID(dataID, storageKey) {\n    for (var ii = 0; ii < this.__sources.length; ii++) {\n      var record = this.__sources[ii].get(dataID);\n      if (record) {\n        var linkedID = RelayModernRecord.getLinkedRecordID(record, storageKey);\n        if (linkedID !== undefined) {\n          return linkedID;\n        }\n      } else if (record === null) {\n        return null;\n      }\n    }\n  };\n  _proto.setLinkedRecordID = function setLinkedRecordID(dataID, storageKey, linkedID) {\n    var sinkRecord = this._getSinkRecord(dataID);\n    RelayModernRecord.setLinkedRecordID(sinkRecord, storageKey, linkedID);\n  };\n  _proto.getLinkedRecordIDs = function getLinkedRecordIDs(dataID, storageKey) {\n    for (var ii = 0; ii < this.__sources.length; ii++) {\n      var record = this.__sources[ii].get(dataID);\n      if (record) {\n        var linkedIDs = RelayModernRecord.getLinkedRecordIDs(record, storageKey);\n        if (linkedIDs !== undefined) {\n          return linkedIDs;\n        }\n      } else if (record === null) {\n        return null;\n      }\n    }\n  };\n  _proto.setLinkedRecordIDs = function setLinkedRecordIDs(dataID, storageKey, linkedIDs) {\n    var sinkRecord = this._getSinkRecord(dataID);\n    RelayModernRecord.setLinkedRecordIDs(sinkRecord, storageKey, linkedIDs);\n  };\n  return RelayRecordSourceMutator;\n}();\nmodule.exports = RelayRecordSourceMutator;","'use strict';\n\nvar RelayModernRecord = require('../store/RelayModernRecord');\nvar _require = require('../store/RelayRecordState'),\n  EXISTENT = _require.EXISTENT,\n  NONEXISTENT = _require.NONEXISTENT;\nvar _require2 = require('../store/RelayStoreUtils'),\n  ROOT_ID = _require2.ROOT_ID,\n  ROOT_TYPE = _require2.ROOT_TYPE;\nvar _require3 = require('./readUpdatableFragment'),\n  _readUpdatableFragment = _require3.readUpdatableFragment;\nvar _require4 = require('./readUpdatableQuery'),\n  _readUpdatableQuery = _require4.readUpdatableQuery;\nvar RelayRecordProxy = require('./RelayRecordProxy');\nvar invariant = require('invariant');\nvar RelayRecordSourceProxy = /*#__PURE__*/function () {\n  function RelayRecordSourceProxy(mutator, getDataID, handlerProvider, missingFieldHandlers) {\n    this.__mutator = mutator;\n    this._handlerProvider = handlerProvider || null;\n    this._proxies = {};\n    this._getDataID = getDataID;\n    this._invalidatedStore = false;\n    this._idsMarkedForInvalidation = new Set();\n    this._missingFieldHandlers = missingFieldHandlers;\n  }\n  var _proto = RelayRecordSourceProxy.prototype;\n  _proto.publishSource = function publishSource(source, fieldPayloads) {\n    var _this = this;\n    var dataIDs = source.getRecordIDs();\n    dataIDs.forEach(function (dataID) {\n      var status = source.getStatus(dataID);\n      if (status === EXISTENT) {\n        var sourceRecord = source.get(dataID);\n        if (sourceRecord) {\n          if (_this.__mutator.getStatus(dataID) !== EXISTENT) {\n            _this.create(dataID, RelayModernRecord.getType(sourceRecord));\n          }\n          _this.__mutator.copyFieldsFromRecord(sourceRecord, dataID);\n        }\n      } else if (status === NONEXISTENT) {\n        _this[\"delete\"](dataID);\n      }\n    });\n    if (fieldPayloads && fieldPayloads.length) {\n      fieldPayloads.forEach(function (fieldPayload) {\n        var handler = _this._handlerProvider && _this._handlerProvider(fieldPayload.handle);\n        !handler ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernEnvironment: Expected a handler to be provided for handle `%s`.', fieldPayload.handle) : invariant(false) : void 0;\n        handler.update(_this, fieldPayload);\n      });\n    }\n  };\n  _proto.create = function create(dataID, typeName) {\n    this.__mutator.create(dataID, typeName);\n    delete this._proxies[dataID];\n    var record = this.get(dataID);\n    !record ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceProxy#create(): Expected the created record to exist.') : invariant(false) : void 0;\n    return record;\n  };\n  _proto[\"delete\"] = function _delete(dataID) {\n    !(dataID !== ROOT_ID) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceProxy#delete(): Cannot delete the root record.') : invariant(false) : void 0;\n    delete this._proxies[dataID];\n    this.__mutator[\"delete\"](dataID);\n  };\n  _proto.get = function get(dataID) {\n    if (!this._proxies.hasOwnProperty(dataID)) {\n      var status = this.__mutator.getStatus(dataID);\n      if (status === EXISTENT) {\n        this._proxies[dataID] = new RelayRecordProxy(this, this.__mutator, dataID);\n      } else {\n        this._proxies[dataID] = status === NONEXISTENT ? null : undefined;\n      }\n    }\n    return this._proxies[dataID];\n  };\n  _proto.getRoot = function getRoot() {\n    var root = this.get(ROOT_ID);\n    if (!root) {\n      root = this.create(ROOT_ID, ROOT_TYPE);\n    }\n    !(root && root.getType() === ROOT_TYPE) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceProxy#getRoot(): Expected the source to contain a ' + 'root record, %s.', root == null ? 'no root record found' : \"found a root record of type `\".concat(root.getType(), \"`\")) : invariant(false) : void 0;\n    return root;\n  };\n  _proto.invalidateStore = function invalidateStore() {\n    this._invalidatedStore = true;\n  };\n  _proto.isStoreMarkedForInvalidation = function isStoreMarkedForInvalidation() {\n    return this._invalidatedStore;\n  };\n  _proto.markIDForInvalidation = function markIDForInvalidation(dataID) {\n    this._idsMarkedForInvalidation.add(dataID);\n  };\n  _proto.getIDsMarkedForInvalidation = function getIDsMarkedForInvalidation() {\n    return this._idsMarkedForInvalidation;\n  };\n  _proto.readUpdatableQuery = function readUpdatableQuery(query, variables) {\n    return _readUpdatableQuery(query, variables, this, this._missingFieldHandlers);\n  };\n  _proto.readUpdatableFragment = function readUpdatableFragment(fragment, fragmentReference) {\n    return _readUpdatableFragment(fragment, fragmentReference, this, this._missingFieldHandlers);\n  };\n  return RelayRecordSourceProxy;\n}();\nmodule.exports = RelayRecordSourceProxy;","'use strict';\n\nvar _require = require('../store/RelayStoreUtils'),\n  ROOT_TYPE = _require.ROOT_TYPE,\n  getStorageKey = _require.getStorageKey;\nvar _require2 = require('./readUpdatableFragment'),\n  _readUpdatableFragment = _require2.readUpdatableFragment;\nvar _require3 = require('./readUpdatableQuery'),\n  _readUpdatableQuery = _require3.readUpdatableQuery;\nvar invariant = require('invariant');\nvar RelayRecordSourceSelectorProxy = /*#__PURE__*/function () {\n  function RelayRecordSourceSelectorProxy(mutator, recordSource, readSelector, missingFieldHandlers) {\n    this.__mutator = mutator;\n    this.__recordSource = recordSource;\n    this._readSelector = readSelector;\n    this._missingFieldHandlers = missingFieldHandlers;\n  }\n  var _proto = RelayRecordSourceSelectorProxy.prototype;\n  _proto.create = function create(dataID, typeName) {\n    return this.__recordSource.create(dataID, typeName);\n  };\n  _proto[\"delete\"] = function _delete(dataID) {\n    this.__recordSource[\"delete\"](dataID);\n  };\n  _proto.get = function get(dataID) {\n    return this.__recordSource.get(dataID);\n  };\n  _proto.getRoot = function getRoot() {\n    return this.__recordSource.getRoot();\n  };\n  _proto.getOperationRoot = function getOperationRoot() {\n    var root = this.__recordSource.get(this._readSelector.dataID);\n    if (!root) {\n      root = this.__recordSource.create(this._readSelector.dataID, ROOT_TYPE);\n    }\n    return root;\n  };\n  _proto._getRootField = function _getRootField(selector, fieldName, plural) {\n    var field = selector.node.selections.find(function (selection) {\n      return selection.kind === 'LinkedField' && selection.name === fieldName || selection.kind === 'RequiredField' && selection.field.name === fieldName;\n    });\n    if (field && field.kind === 'RequiredField') {\n      field = field.field;\n    }\n    !(field && field.kind === 'LinkedField') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceSelectorProxy#getRootField(): Cannot find root ' + 'field `%s`, no such field is defined on GraphQL document `%s`.', fieldName, selector.node.name) : invariant(false) : void 0;\n    !(field.plural === plural) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayRecordSourceSelectorProxy#getRootField(): Expected root field ' + '`%s` to be %s.', fieldName, plural ? 'plural' : 'singular') : invariant(false) : void 0;\n    return field;\n  };\n  _proto.getRootField = function getRootField(fieldName) {\n    var field = this._getRootField(this._readSelector, fieldName, false);\n    var storageKey = getStorageKey(field, this._readSelector.variables);\n    return this.getOperationRoot().getLinkedRecord(storageKey);\n  };\n  _proto.getPluralRootField = function getPluralRootField(fieldName) {\n    var field = this._getRootField(this._readSelector, fieldName, true);\n    var storageKey = getStorageKey(field, this._readSelector.variables);\n    return this.getOperationRoot().getLinkedRecords(storageKey);\n  };\n  _proto.invalidateStore = function invalidateStore() {\n    this.__recordSource.invalidateStore();\n  };\n  _proto.readUpdatableQuery = function readUpdatableQuery(query, variables) {\n    return _readUpdatableQuery(query, variables, this, this._missingFieldHandlers);\n  };\n  _proto.readUpdatableFragment = function readUpdatableFragment(fragment, fragmentReference) {\n    return _readUpdatableFragment(fragment, fragmentReference, this, this._missingFieldHandlers);\n  };\n  return RelayRecordSourceSelectorProxy;\n}();\nmodule.exports = RelayRecordSourceSelectorProxy;","'use strict';\n\nvar _require = require('../query/GraphQLTag'),\n  getRequest = _require.getRequest;\nvar isRelayModernEnvironment = require('../store/isRelayModernEnvironment');\nvar _require2 = require('../store/RelayModernOperationDescriptor'),\n  createOperationDescriptor = _require2.createOperationDescriptor;\nvar RelayDeclarativeMutationConfig = require('./RelayDeclarativeMutationConfig');\nvar invariant = require('invariant');\nfunction applyOptimisticMutation(environment, config) {\n  !isRelayModernEnvironment(environment) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'commitMutation: expected `environment` to be an instance of ' + '`RelayModernEnvironment`.') : invariant(false) : void 0;\n  var mutation = getRequest(config.mutation);\n  if (mutation.params.operationKind !== 'mutation') {\n    throw new Error('commitMutation: Expected mutation operation');\n  }\n  var optimisticUpdater = config.optimisticUpdater;\n  var configs = config.configs,\n    optimisticResponse = config.optimisticResponse,\n    variables = config.variables;\n  var operation = createOperationDescriptor(mutation, variables);\n  if (configs) {\n    var _RelayDeclarativeMuta = RelayDeclarativeMutationConfig.convert(configs, mutation, optimisticUpdater);\n    optimisticUpdater = _RelayDeclarativeMuta.optimisticUpdater;\n  }\n  return environment.applyMutation({\n    operation: operation,\n    response: optimisticResponse,\n    updater: optimisticUpdater\n  });\n}\nmodule.exports = applyOptimisticMutation;","'use strict';\n\nfunction commitLocalUpdate(environment, updater) {\n  environment.commitUpdate(updater);\n}\nmodule.exports = commitLocalUpdate;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar _require = require('../query/GraphQLTag'),\n  getRequest = _require.getRequest;\nvar _require2 = require('../store/ClientID'),\n  generateUniqueClientID = _require2.generateUniqueClientID;\nvar isRelayModernEnvironment = require('../store/isRelayModernEnvironment');\nvar _require3 = require('../store/RelayModernOperationDescriptor'),\n  createOperationDescriptor = _require3.createOperationDescriptor;\nvar RelayDeclarativeMutationConfig = require('./RelayDeclarativeMutationConfig');\nvar validateMutation = require('./validateMutation');\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nfunction commitMutation(environment, config) {\n  !isRelayModernEnvironment(environment) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'commitMutation: expected `environment` to be an instance of ' + '`RelayModernEnvironment`.') : invariant(false) : void 0;\n  var mutation = getRequest(config.mutation);\n  if (mutation.params.operationKind !== 'mutation') {\n    throw new Error('commitMutation: Expected mutation operation');\n  }\n  if (mutation.kind !== 'Request') {\n    throw new Error('commitMutation: Expected mutation to be of type request');\n  }\n  var optimisticResponse = config.optimisticResponse,\n    optimisticUpdater = config.optimisticUpdater,\n    updater = config.updater;\n  var configs = config.configs,\n    cacheConfig = config.cacheConfig,\n    onError = config.onError,\n    onUnsubscribe = config.onUnsubscribe,\n    variables = config.variables,\n    uploadables = config.uploadables;\n  var operation = createOperationDescriptor(mutation, variables, cacheConfig, generateUniqueClientID());\n  if (typeof optimisticResponse === 'function') {\n    optimisticResponse = optimisticResponse();\n    process.env.NODE_ENV !== \"production\" ? warning(false, 'commitMutation: Expected `optimisticResponse` to be an object, ' + 'received a function.') : void 0;\n  }\n  if (process.env.NODE_ENV !== \"production\") {\n    if (optimisticResponse instanceof Object) {\n      validateMutation(optimisticResponse, mutation, variables);\n    }\n  }\n  if (configs) {\n    var _RelayDeclarativeMuta = RelayDeclarativeMutationConfig.convert(configs, mutation, optimisticUpdater, updater);\n    optimisticUpdater = _RelayDeclarativeMuta.optimisticUpdater;\n    updater = _RelayDeclarativeMuta.updater;\n  }\n  var errors = [];\n  var subscription = environment.executeMutation({\n    operation: operation,\n    optimisticResponse: optimisticResponse,\n    optimisticUpdater: optimisticUpdater,\n    updater: updater,\n    uploadables: uploadables\n  }).subscribe({\n    next: function next(payload) {\n      var _config$onNext;\n      if (Array.isArray(payload)) {\n        payload.forEach(function (item) {\n          if (item.errors) {\n            errors.push.apply(errors, (0, _toConsumableArray2[\"default\"])(item.errors));\n          }\n        });\n      } else {\n        if (payload.errors) {\n          errors.push.apply(errors, (0, _toConsumableArray2[\"default\"])(payload.errors));\n        }\n      }\n      (_config$onNext = config.onNext) === null || _config$onNext === void 0 ? void 0 : _config$onNext.call(config);\n    },\n    complete: function complete() {\n      var onCompleted = config.onCompleted;\n      if (onCompleted) {\n        var snapshot = environment.lookup(operation.fragment);\n        onCompleted(snapshot.data, errors.length !== 0 ? errors : null);\n      }\n    },\n    error: onError,\n    unsubscribe: onUnsubscribe\n  });\n  return {\n    dispose: subscription.unsubscribe\n  };\n}\nmodule.exports = commitMutation;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _require = require('../store/RelayStoreUtils'),\n  getArgumentValues = _require.getArgumentValues;\nvar _require2 = require('../util/RelayConcreteNode'),\n  ACTOR_CHANGE = _require2.ACTOR_CHANGE,\n  ALIASED_FRAGMENT_SPREAD = _require2.ALIASED_FRAGMENT_SPREAD,\n  ALIASED_INLINE_FRAGMENT_SPREAD = _require2.ALIASED_INLINE_FRAGMENT_SPREAD,\n  CLIENT_EDGE_TO_CLIENT_OBJECT = _require2.CLIENT_EDGE_TO_CLIENT_OBJECT,\n  CLIENT_EDGE_TO_SERVER_OBJECT = _require2.CLIENT_EDGE_TO_SERVER_OBJECT,\n  CLIENT_EXTENSION = _require2.CLIENT_EXTENSION,\n  CONDITION = _require2.CONDITION,\n  DEFER = _require2.DEFER,\n  FRAGMENT_SPREAD = _require2.FRAGMENT_SPREAD,\n  INLINE_DATA_FRAGMENT_SPREAD = _require2.INLINE_DATA_FRAGMENT_SPREAD,\n  INLINE_FRAGMENT = _require2.INLINE_FRAGMENT,\n  LINKED_FIELD = _require2.LINKED_FIELD,\n  MODULE_IMPORT = _require2.MODULE_IMPORT,\n  RELAY_LIVE_RESOLVER = _require2.RELAY_LIVE_RESOLVER,\n  RELAY_RESOLVER = _require2.RELAY_RESOLVER,\n  REQUIRED_FIELD = _require2.REQUIRED_FIELD,\n  SCALAR_FIELD = _require2.SCALAR_FIELD,\n  STREAM = _require2.STREAM;\nvar nonUpdatableKeys = ['id', '__id', '__typename', 'js'];\nfunction createUpdatableProxy(updatableProxyRootRecord, variables, selections, recordSourceProxy, missingFieldHandlers) {\n  var mutableUpdatableProxy = {};\n  updateProxyFromSelections(mutableUpdatableProxy, updatableProxyRootRecord, variables, selections, recordSourceProxy, missingFieldHandlers);\n  if (process.env.NODE_ENV !== \"production\") {\n    Object.freeze(mutableUpdatableProxy);\n  }\n  return mutableUpdatableProxy;\n}\nfunction updateProxyFromSelections(mutableUpdatableProxy, updatableProxyRootRecord, variables, selections, recordSourceProxy, missingFieldHandlers) {\n  var _selection$alias3;\n  var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(selections),\n    _step;\n  try {\n    var _loop = function _loop() {\n      var selection = _step.value;\n      switch (selection.kind) {\n        case LINKED_FIELD:\n          if (selection.plural) {\n            Object.defineProperty(mutableUpdatableProxy, (_selection$alias = selection.alias) !== null && _selection$alias !== void 0 ? _selection$alias : selection.name, {\n              get: createGetterForPluralLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers),\n              set: createSetterForPluralLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy)\n            });\n          } else {\n            Object.defineProperty(mutableUpdatableProxy, (_selection$alias2 = selection.alias) !== null && _selection$alias2 !== void 0 ? _selection$alias2 : selection.name, {\n              get: createGetterForSingularLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers),\n              set: createSetterForSingularLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy)\n            });\n          }\n          break;\n        case SCALAR_FIELD:\n          var scalarFieldName = (_selection$alias3 = selection.alias) !== null && _selection$alias3 !== void 0 ? _selection$alias3 : selection.name;\n          Object.defineProperty(mutableUpdatableProxy, scalarFieldName, {\n            get: function get() {\n              var _selection$args;\n              var newVariables = getArgumentValues((_selection$args = selection.args) !== null && _selection$args !== void 0 ? _selection$args : [], variables);\n              var value = updatableProxyRootRecord.getValue(selection.name, newVariables);\n              if (value == null) {\n                value = getScalarUsingMissingFieldHandlers(selection, newVariables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers);\n              }\n              return value;\n            },\n            set: nonUpdatableKeys.includes(selection.name) ? undefined : function (newValue) {\n              var _selection$args2;\n              var newVariables = getArgumentValues((_selection$args2 = selection.args) !== null && _selection$args2 !== void 0 ? _selection$args2 : [], variables);\n              updatableProxyRootRecord.setValue__UNSAFE(newValue, selection.name, newVariables);\n            }\n          });\n          break;\n        case INLINE_FRAGMENT:\n          if (updatableProxyRootRecord.getType() === selection.type) {\n            updateProxyFromSelections(mutableUpdatableProxy, updatableProxyRootRecord, variables, selection.selections, recordSourceProxy, missingFieldHandlers);\n          }\n          break;\n        case CLIENT_EXTENSION:\n          updateProxyFromSelections(mutableUpdatableProxy, updatableProxyRootRecord, variables, selection.selections, recordSourceProxy, missingFieldHandlers);\n          break;\n        case FRAGMENT_SPREAD:\n          break;\n        case CONDITION:\n        case ACTOR_CHANGE:\n        case ALIASED_FRAGMENT_SPREAD:\n        case INLINE_DATA_FRAGMENT_SPREAD:\n        case ALIASED_INLINE_FRAGMENT_SPREAD:\n        case CLIENT_EDGE_TO_CLIENT_OBJECT:\n        case CLIENT_EDGE_TO_SERVER_OBJECT:\n        case DEFER:\n        case MODULE_IMPORT:\n        case RELAY_LIVE_RESOLVER:\n        case REQUIRED_FIELD:\n        case STREAM:\n        case RELAY_RESOLVER:\n          throw new Error('Encountered an unexpected ReaderSelection variant in RelayRecordSourceProxy. This indicates a bug in Relay.');\n        default:\n          selection.kind;\n          throw new Error('Encountered an unexpected ReaderSelection variant in RelayRecordSourceProxy. This indicates a bug in Relay.');\n      }\n    };\n    for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var _selection$alias;\n      var _selection$alias2;\n      _loop();\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n}\nfunction createSetterForPluralLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy) {\n  return function set(newValue) {\n    var _selection$args3;\n    var newVariables = getArgumentValues((_selection$args3 = selection.args) !== null && _selection$args3 !== void 0 ? _selection$args3 : [], variables);\n    if (newValue == null) {\n      throw new Error('Do not assign null to plural linked fields; assign an empty array instead.');\n    } else {\n      var recordProxies = newValue.map(function (item) {\n        if (item == null) {\n          throw new Error('When assigning an array of items, none of the items should be null or undefined.');\n        }\n        var __id = item.__id;\n        if (__id == null) {\n          throw new Error('The __id field must be present on each item passed to the setter. This indicates a bug in Relay.');\n        }\n        var newValueRecord = recordSourceProxy.get(__id);\n        if (newValueRecord == null) {\n          throw new Error(\"Did not find item with data id \".concat(__id, \" in the store.\"));\n        }\n        return newValueRecord;\n      });\n      updatableProxyRootRecord.setLinkedRecords(recordProxies, selection.name, newVariables);\n    }\n  };\n}\nfunction createSetterForSingularLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy) {\n  return function set(newValue) {\n    var _selection$args4;\n    var newVariables = getArgumentValues((_selection$args4 = selection.args) !== null && _selection$args4 !== void 0 ? _selection$args4 : [], variables);\n    if (newValue == null) {\n      updatableProxyRootRecord.setValue(newValue, selection.name, newVariables);\n    } else {\n      var __id = newValue.__id;\n      if (__id == null) {\n        throw new Error('The __id field must be present on the argument. This indicates a bug in Relay.');\n      }\n      var newValueRecord = recordSourceProxy.get(__id);\n      if (newValueRecord == null) {\n        throw new Error(\"Did not find item with data id \".concat(__id, \" in the store.\"));\n      }\n      updatableProxyRootRecord.setLinkedRecord(newValueRecord, selection.name, newVariables);\n    }\n  };\n}\nfunction createGetterForPluralLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers) {\n  return function () {\n    var _selection$args5;\n    var newVariables = getArgumentValues((_selection$args5 = selection.args) !== null && _selection$args5 !== void 0 ? _selection$args5 : [], variables);\n    var linkedRecords = updatableProxyRootRecord.getLinkedRecords(selection.name, newVariables);\n    if (linkedRecords === undefined) {\n      linkedRecords = getPluralLinkedRecordUsingMissingFieldHandlers(selection, newVariables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers);\n    }\n    if (linkedRecords != null) {\n      return linkedRecords.map(function (linkedRecord) {\n        if (linkedRecord != null) {\n          var updatableProxy = {};\n          updateProxyFromSelections(updatableProxy, linkedRecord, variables, selection.selections, recordSourceProxy, missingFieldHandlers);\n          if (process.env.NODE_ENV !== \"production\") {\n            Object.freeze(updatableProxy);\n          }\n          return updatableProxy;\n        } else {\n          return linkedRecord;\n        }\n      });\n    } else {\n      return linkedRecords;\n    }\n  };\n}\nfunction createGetterForSingularLinkedField(selection, variables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers) {\n  return function () {\n    var _selection$args6;\n    var newVariables = getArgumentValues((_selection$args6 = selection.args) !== null && _selection$args6 !== void 0 ? _selection$args6 : [], variables);\n    var linkedRecord = updatableProxyRootRecord.getLinkedRecord(selection.name, newVariables);\n    if (linkedRecord === undefined) {\n      linkedRecord = getLinkedRecordUsingMissingFieldHandlers(selection, newVariables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers);\n    }\n    if (linkedRecord != null) {\n      var updatableProxy = {};\n      updateProxyFromSelections(updatableProxy, linkedRecord, variables, selection.selections, recordSourceProxy, missingFieldHandlers);\n      if (process.env.NODE_ENV !== \"production\") {\n        Object.freeze(updatableProxy);\n      }\n      return updatableProxy;\n    } else {\n      return linkedRecord;\n    }\n  };\n}\nfunction getLinkedRecordUsingMissingFieldHandlers(selection, newVariables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers) {\n  var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(missingFieldHandlers),\n    _step2;\n  try {\n    for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n      var handler = _step2.value;\n      if (handler.kind === 'linked') {\n        var newId = handler.handle(selection, updatableProxyRootRecord, newVariables, recordSourceProxy);\n        if (newId != null) {\n          return recordSourceProxy.get(newId);\n        }\n      }\n    }\n  } catch (err) {\n    _iterator2.e(err);\n  } finally {\n    _iterator2.f();\n  }\n}\nfunction getPluralLinkedRecordUsingMissingFieldHandlers(selection, newVariables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers) {\n  var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])(missingFieldHandlers),\n    _step3;\n  try {\n    for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n      var handler = _step3.value;\n      if (handler.kind === 'pluralLinked') {\n        var newIds = handler.handle(selection, updatableProxyRootRecord, newVariables, recordSourceProxy);\n        if (newIds != null) {\n          return newIds.map(function (newId) {\n            if (newId != null) {\n              return recordSourceProxy.get(newId);\n            }\n          });\n        }\n      }\n    }\n  } catch (err) {\n    _iterator3.e(err);\n  } finally {\n    _iterator3.f();\n  }\n}\nfunction getScalarUsingMissingFieldHandlers(selection, newVariables, updatableProxyRootRecord, recordSourceProxy, missingFieldHandlers) {\n  var _iterator4 = (0, _createForOfIteratorHelper2[\"default\"])(missingFieldHandlers),\n    _step4;\n  try {\n    for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n      var handler = _step4.value;\n      if (handler.kind === 'scalar') {\n        var value = handler.handle(selection, updatableProxyRootRecord, newVariables, recordSourceProxy);\n        if (value !== undefined) {\n          return value;\n        }\n      }\n    }\n  } catch (err) {\n    _iterator4.e(err);\n  } finally {\n    _iterator4.f();\n  }\n}\nmodule.exports = {\n  createUpdatableProxy: createUpdatableProxy\n};","'use strict';\n\nvar _require = require('../query/GraphQLTag'),\n  getFragment = _require.getFragment;\nvar _require2 = require('../store/RelayModernSelector'),\n  getVariablesFromFragment = _require2.getVariablesFromFragment;\nvar _require3 = require('../store/RelayStoreUtils'),\n  ID_KEY = _require3.ID_KEY;\nvar _require4 = require('./createUpdatableProxy'),\n  createUpdatableProxy = _require4.createUpdatableProxy;\nvar invariant = require('invariant');\nfunction readUpdatableFragment(fragment, fragmentReference, proxy, missingFieldHandlers) {\n  var updatableFragment = getFragment(fragment);\n  var fragmentVariables = getVariablesFromFragment(updatableFragment, fragmentReference);\n  var id = fragmentReference[ID_KEY];\n  var fragmentRoot = proxy.get(id);\n  !(fragmentRoot != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, \"No record with \".concat(id, \" was found. This likely indicates a problem with Relay.\")) : invariant(false) : void 0;\n  return {\n    updatableData: createUpdatableProxy(fragmentRoot, fragmentVariables, updatableFragment.selections, proxy, missingFieldHandlers)\n  };\n}\nmodule.exports = {\n  readUpdatableFragment: readUpdatableFragment\n};","'use strict';\n\nvar _require = require('../query/GraphQLTag'),\n  getUpdatableQuery = _require.getUpdatableQuery;\nvar _require2 = require('./createUpdatableProxy'),\n  createUpdatableProxy = _require2.createUpdatableProxy;\nfunction readUpdatableQuery(query, variables, proxy, missingFieldHandlers) {\n  var updatableQuery = getUpdatableQuery(query);\n  return {\n    updatableData: createUpdatableProxy(proxy.getRoot(), variables, updatableQuery.fragment.selections, proxy, missingFieldHandlers)\n  };\n}\nmodule.exports = {\n  readUpdatableQuery: readUpdatableQuery\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar _require = require('../util/RelayConcreteNode'),\n  ACTOR_CHANGE = _require.ACTOR_CHANGE,\n  CLIENT_COMPONENT = _require.CLIENT_COMPONENT,\n  CLIENT_EDGE_TO_CLIENT_OBJECT = _require.CLIENT_EDGE_TO_CLIENT_OBJECT,\n  CLIENT_EXTENSION = _require.CLIENT_EXTENSION,\n  CONDITION = _require.CONDITION,\n  DEFER = _require.DEFER,\n  FRAGMENT_SPREAD = _require.FRAGMENT_SPREAD,\n  INLINE_FRAGMENT = _require.INLINE_FRAGMENT,\n  LINKED_FIELD = _require.LINKED_FIELD,\n  LINKED_HANDLE = _require.LINKED_HANDLE,\n  MODULE_IMPORT = _require.MODULE_IMPORT,\n  RELAY_LIVE_RESOLVER = _require.RELAY_LIVE_RESOLVER,\n  RELAY_RESOLVER = _require.RELAY_RESOLVER,\n  SCALAR_FIELD = _require.SCALAR_FIELD,\n  SCALAR_HANDLE = _require.SCALAR_HANDLE,\n  STREAM = _require.STREAM,\n  TYPE_DISCRIMINATOR = _require.TYPE_DISCRIMINATOR;\nvar warning = require(\"fbjs/lib/warning\");\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar validateMutation = function validateMutation() {};\nif (process.env.NODE_ENV !== \"production\") {\n  var addFieldToDiff = function addFieldToDiff(path, diff, isScalar) {\n    var deepLoc = diff;\n    path.split('.').forEach(function (key, index, arr) {\n      if (deepLoc[key] == null) {\n        deepLoc[key] = {};\n      }\n      if (isScalar && index === arr.length - 1) {\n        deepLoc[key] = '<scalar>';\n      }\n      deepLoc = deepLoc[key];\n    });\n  };\n  validateMutation = function validateMutation(optimisticResponse, mutation, variables) {\n    var operationName = mutation.operation.name;\n    var context = {\n      path: 'ROOT',\n      visitedPaths: new Set(),\n      variables: variables || {},\n      missingDiff: {},\n      extraDiff: {},\n      moduleImportPaths: new Set()\n    };\n    validateSelections(optimisticResponse, mutation.operation.selections, context);\n    validateOptimisticResponse(optimisticResponse, context);\n    process.env.NODE_ENV !== \"production\" ? warning(context.missingDiff.ROOT == null, 'Expected `optimisticResponse` to match structure of server response for mutation `%s`, please define fields for all of\\n%s', operationName, JSON.stringify(context.missingDiff.ROOT, null, 2)) : void 0;\n    process.env.NODE_ENV !== \"production\" ? warning(context.extraDiff.ROOT == null, 'Expected `optimisticResponse` to match structure of server response for mutation `%s`, please remove all fields of\\n%s', operationName, JSON.stringify(context.extraDiff.ROOT, null, 2)) : void 0;\n  };\n  var validateSelections = function validateSelections(optimisticResponse, selections, context) {\n    selections.forEach(function (selection) {\n      return validateSelection(optimisticResponse, selection, context);\n    });\n  };\n  var validateSelection = function validateSelection(optimisticResponse, selection, context) {\n    switch (selection.kind) {\n      case CONDITION:\n        validateSelections(optimisticResponse, selection.selections, context);\n        return;\n      case CLIENT_COMPONENT:\n      case FRAGMENT_SPREAD:\n        validateSelections(optimisticResponse, selection.fragment.selections, context);\n        return;\n      case SCALAR_FIELD:\n      case LINKED_FIELD:\n        return validateField(optimisticResponse, selection, context);\n      case ACTOR_CHANGE:\n        return validateField(optimisticResponse, selection.linkedField, context);\n      case INLINE_FRAGMENT:\n        var type = selection.type;\n        var isConcreteType = selection.abstractKey == null;\n        validateAbstractKey(context, selection.abstractKey);\n        selection.selections.forEach(function (subselection) {\n          if (isConcreteType && optimisticResponse.__typename !== type) {\n            return;\n          }\n          validateSelection(optimisticResponse, subselection, context);\n        });\n        return;\n      case CLIENT_EXTENSION:\n        selection.selections.forEach(function (subselection) {\n          validateSelection(optimisticResponse, subselection, context);\n        });\n        return;\n      case MODULE_IMPORT:\n        return validateModuleImport(context);\n      case TYPE_DISCRIMINATOR:\n        return validateAbstractKey(context, selection.abstractKey);\n      case RELAY_RESOLVER:\n      case RELAY_LIVE_RESOLVER:\n      case CLIENT_EDGE_TO_CLIENT_OBJECT:\n      case LINKED_HANDLE:\n      case SCALAR_HANDLE:\n      case DEFER:\n      case STREAM:\n        {\n          return;\n        }\n      default:\n        selection;\n        return;\n    }\n  };\n  var validateModuleImport = function validateModuleImport(context) {\n    context.moduleImportPaths.add(context.path);\n  };\n  var validateAbstractKey = function validateAbstractKey(context, abstractKey) {\n    if (abstractKey != null) {\n      var path = \"\".concat(context.path, \".\").concat(abstractKey);\n      context.visitedPaths.add(path);\n    }\n  };\n  var validateField = function validateField(optimisticResponse, field, context) {\n    var fieldName = field.alias || field.name;\n    var path = \"\".concat(context.path, \".\").concat(fieldName);\n    context.visitedPaths.add(path);\n    switch (field.kind) {\n      case SCALAR_FIELD:\n        if (hasOwnProperty.call(optimisticResponse, fieldName) === false) {\n          addFieldToDiff(path, context.missingDiff, true);\n        }\n        return;\n      case LINKED_FIELD:\n        var selections = field.selections;\n        if (optimisticResponse[fieldName] === null || hasOwnProperty.call(optimisticResponse, fieldName) && optimisticResponse[fieldName] === undefined) {\n          return;\n        }\n        if (field.plural) {\n          if (Array.isArray(optimisticResponse[fieldName])) {\n            optimisticResponse[fieldName].forEach(function (r) {\n              if (r !== null) {\n                validateSelections(r, selections, (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, context), {}, {\n                  path: path\n                }));\n              }\n            });\n            return;\n          } else {\n            addFieldToDiff(path, context.missingDiff);\n            return;\n          }\n        } else {\n          if (optimisticResponse[fieldName] instanceof Object) {\n            validateSelections(optimisticResponse[fieldName], selections, (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, context), {}, {\n              path: path\n            }));\n            return;\n          } else {\n            addFieldToDiff(path, context.missingDiff);\n            return;\n          }\n        }\n    }\n  };\n  var validateOptimisticResponse = function validateOptimisticResponse(optimisticResponse, context) {\n    if (Array.isArray(optimisticResponse)) {\n      optimisticResponse.forEach(function (r) {\n        if (r instanceof Object) {\n          validateOptimisticResponse(r, context);\n        }\n      });\n      return;\n    }\n    Object.keys(optimisticResponse).forEach(function (key) {\n      var value = optimisticResponse[key];\n      var path = \"\".concat(context.path, \".\").concat(key);\n      if (context.moduleImportPaths.has(path)) {\n        return;\n      }\n      if (!context.visitedPaths.has(path)) {\n        addFieldToDiff(path, context.extraDiff);\n        return;\n      }\n      if (value instanceof Object) {\n        validateOptimisticResponse(value, (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, context), {}, {\n          path: path\n        }));\n      }\n    });\n  };\n}\nmodule.exports = validateMutation;","'use strict';\n\nvar RelayObservable = require('./RelayObservable');\nfunction convertFetch(fn) {\n  return function fetch(request, variables, cacheConfig, uploadables, logRequestInfo) {\n    var result = fn(request, variables, cacheConfig, uploadables, logRequestInfo);\n    if (result instanceof Error) {\n      return RelayObservable.create(function (sink) {\n        return sink.error(result);\n      });\n    }\n    return RelayObservable.from(result);\n  };\n}\nmodule.exports = {\n  convertFetch: convertFetch\n};","'use strict';\n\nvar withProvidedVariables = require('../util/withProvidedVariables');\nvar _require = require('./ConvertToExecuteFunction'),\n  convertFetch = _require.convertFetch;\nvar invariant = require('invariant');\nfunction create(fetchFn, subscribe) {\n  var observeFetch = convertFetch(fetchFn);\n  function execute(request, variables, cacheConfig, uploadables, logRequestInfo) {\n    var operationVariables = withProvidedVariables(variables, request.providedVariables);\n    if (request.operationKind === 'subscription') {\n      !subscribe ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayNetwork: This network layer does not support Subscriptions. ' + 'To use Subscriptions, provide a custom network layer.') : invariant(false) : void 0;\n      !!uploadables ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayNetwork: Cannot provide uploadables while subscribing.') : invariant(false) : void 0;\n      return subscribe(request, operationVariables, cacheConfig);\n    }\n    var pollInterval = cacheConfig.poll;\n    if (pollInterval != null) {\n      !!uploadables ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayNetwork: Cannot provide uploadables while polling.') : invariant(false) : void 0;\n      return observeFetch(request, operationVariables, {\n        force: true\n      }).poll(pollInterval);\n    }\n    return observeFetch(request, operationVariables, cacheConfig, uploadables, logRequestInfo);\n  }\n  return {\n    execute: execute\n  };\n}\nmodule.exports = {\n  create: create\n};","'use strict';\n\nvar isPromise = require('../util/isPromise');\nvar hostReportError = swallowError;\nvar RelayObservable = /*#__PURE__*/function () {\n  RelayObservable.create = function create(source) {\n    return new RelayObservable(source);\n  };\n  function RelayObservable(source) {\n    if (process.env.NODE_ENV !== \"production\") {\n      if (!source || typeof source !== 'function') {\n        throw new Error('Source must be a Function: ' + String(source));\n      }\n    }\n    this._source = source;\n  }\n  RelayObservable.onUnhandledError = function onUnhandledError(callback) {\n    hostReportError = callback;\n  };\n  RelayObservable.from = function from(obj) {\n    return isObservable(obj) ? fromObservable(obj) : isPromise(obj) ? fromPromise(obj) : fromValue(obj);\n  };\n  var _proto = RelayObservable.prototype;\n  _proto[\"catch\"] = function _catch(fn) {\n    var _this = this;\n    return RelayObservable.create(function (sink) {\n      var subscription;\n      _this.subscribe({\n        start: function start(sub) {\n          subscription = sub;\n        },\n        next: sink.next,\n        complete: sink.complete,\n        error: function error(_error2) {\n          try {\n            fn(_error2).subscribe({\n              start: function start(sub) {\n                subscription = sub;\n              },\n              next: sink.next,\n              complete: sink.complete,\n              error: sink.error\n            });\n          } catch (error2) {\n            sink.error(error2, true);\n          }\n        }\n      });\n      return function () {\n        return subscription.unsubscribe();\n      };\n    });\n  };\n  _proto.concat = function concat(next) {\n    var _this2 = this;\n    return RelayObservable.create(function (sink) {\n      var current;\n      _this2.subscribe({\n        start: function start(subscription) {\n          current = subscription;\n        },\n        next: sink.next,\n        error: sink.error,\n        complete: function complete() {\n          current = next.subscribe(sink);\n        }\n      });\n      return function () {\n        current && current.unsubscribe();\n      };\n    });\n  };\n  _proto[\"do\"] = function _do(observer) {\n    var _this3 = this;\n    return RelayObservable.create(function (sink) {\n      var both = function both(action) {\n        return function () {\n          try {\n            observer[action] && observer[action].apply(observer, arguments);\n          } catch (error) {\n            hostReportError(error, true);\n          }\n          sink[action] && sink[action].apply(sink, arguments);\n        };\n      };\n      return _this3.subscribe({\n        start: both('start'),\n        next: both('next'),\n        error: both('error'),\n        complete: both('complete'),\n        unsubscribe: both('unsubscribe')\n      });\n    });\n  };\n  _proto[\"finally\"] = function _finally(fn) {\n    var _this4 = this;\n    return RelayObservable.create(function (sink) {\n      var subscription = _this4.subscribe(sink);\n      return function () {\n        subscription.unsubscribe();\n        fn();\n      };\n    });\n  };\n  _proto.ifEmpty = function ifEmpty(alternate) {\n    var _this5 = this;\n    return RelayObservable.create(function (sink) {\n      var hasValue = false;\n      var current;\n      current = _this5.subscribe({\n        next: function next(value) {\n          hasValue = true;\n          sink.next(value);\n        },\n        error: sink.error,\n        complete: function complete() {\n          if (hasValue) {\n            sink.complete();\n          } else {\n            current = alternate.subscribe(sink);\n          }\n        }\n      });\n      return function () {\n        current && current.unsubscribe();\n      };\n    });\n  };\n  _proto.subscribe = function subscribe(observer) {\n    if (process.env.NODE_ENV !== \"production\") {\n      if (!observer || typeof observer !== 'object') {\n        throw new Error('Observer must be an Object with callbacks: ' + String(observer));\n      }\n    }\n    return _subscribe(this._source, observer);\n  };\n  _proto.map = function map(fn) {\n    var _this6 = this;\n    return RelayObservable.create(function (sink) {\n      var subscription = _this6.subscribe({\n        complete: sink.complete,\n        error: sink.error,\n        next: function next(value) {\n          try {\n            var mapValue = fn(value);\n            sink.next(mapValue);\n          } catch (error) {\n            sink.error(error, true);\n          }\n        }\n      });\n      return function () {\n        subscription.unsubscribe();\n      };\n    });\n  };\n  _proto.mergeMap = function mergeMap(fn) {\n    var _this7 = this;\n    return RelayObservable.create(function (sink) {\n      var subscriptions = [];\n      function start(subscription) {\n        this._sub = subscription;\n        subscriptions.push(subscription);\n      }\n      function complete() {\n        subscriptions.splice(subscriptions.indexOf(this._sub), 1);\n        if (subscriptions.length === 0) {\n          sink.complete();\n        }\n      }\n      _this7.subscribe({\n        start: start,\n        next: function next(value) {\n          try {\n            if (!sink.closed) {\n              RelayObservable.from(fn(value)).subscribe({\n                start: start,\n                next: sink.next,\n                error: sink.error,\n                complete: complete\n              });\n            }\n          } catch (error) {\n            sink.error(error, true);\n          }\n        },\n        error: sink.error,\n        complete: complete\n      });\n      return function () {\n        subscriptions.forEach(function (sub) {\n          return sub.unsubscribe();\n        });\n        subscriptions.length = 0;\n      };\n    });\n  };\n  _proto.poll = function poll(pollInterval) {\n    var _this8 = this;\n    if (process.env.NODE_ENV !== \"production\") {\n      if (typeof pollInterval !== 'number' || pollInterval <= 0) {\n        throw new Error('RelayObservable: Expected pollInterval to be positive, got: ' + pollInterval);\n      }\n    }\n    return RelayObservable.create(function (sink) {\n      var subscription;\n      var timeout;\n      var poll = function poll() {\n        subscription = _this8.subscribe({\n          next: sink.next,\n          error: sink.error,\n          complete: function complete() {\n            timeout = setTimeout(poll, pollInterval);\n          }\n        });\n      };\n      poll();\n      return function () {\n        clearTimeout(timeout);\n        subscription.unsubscribe();\n      };\n    });\n  };\n  _proto.toPromise = function toPromise() {\n    var _this9 = this;\n    return new Promise(function (resolve, reject) {\n      var resolved = false;\n      _this9.subscribe({\n        next: function next(val) {\n          if (!resolved) {\n            resolved = true;\n            resolve(val);\n          }\n        },\n        error: reject,\n        complete: resolve\n      });\n    });\n  };\n  return RelayObservable;\n}();\nfunction isObservable(obj) {\n  return typeof obj === 'object' && obj !== null && typeof obj.subscribe === 'function';\n}\nfunction fromObservable(obj) {\n  return obj instanceof RelayObservable ? obj : RelayObservable.create(function (sink) {\n    return obj.subscribe(sink);\n  });\n}\nfunction fromPromise(promise) {\n  return RelayObservable.create(function (sink) {\n    promise.then(function (value) {\n      sink.next(value);\n      sink.complete();\n    }, sink.error);\n  });\n}\nfunction fromValue(value) {\n  return RelayObservable.create(function (sink) {\n    sink.next(value);\n    sink.complete();\n  });\n}\nfunction _subscribe(source, observer) {\n  var closed = false;\n  var cleanup;\n  var withClosed = function withClosed(obj) {\n    return Object.defineProperty(obj, 'closed', {\n      get: function get() {\n        return closed;\n      }\n    });\n  };\n  function doCleanup() {\n    if (cleanup) {\n      if (cleanup.unsubscribe) {\n        cleanup.unsubscribe();\n      } else {\n        try {\n          cleanup();\n        } catch (error) {\n          hostReportError(error, true);\n        }\n      }\n      cleanup = undefined;\n    }\n  }\n  var subscription = withClosed({\n    unsubscribe: function unsubscribe() {\n      if (!closed) {\n        closed = true;\n        try {\n          observer.unsubscribe && observer.unsubscribe(subscription);\n        } catch (error) {\n          hostReportError(error, true);\n        } finally {\n          doCleanup();\n        }\n      }\n    }\n  });\n  try {\n    observer.start && observer.start(subscription);\n  } catch (error) {\n    hostReportError(error, true);\n  }\n  if (closed) {\n    return subscription;\n  }\n  var sink = withClosed({\n    next: function next(value) {\n      if (!closed && observer.next) {\n        try {\n          observer.next(value);\n        } catch (error) {\n          hostReportError(error, true);\n        }\n      }\n    },\n    error: function error(_error3, isUncaughtThrownError) {\n      if (closed || !observer.error) {\n        closed = true;\n        hostReportError(_error3, isUncaughtThrownError || false);\n        doCleanup();\n      } else {\n        closed = true;\n        try {\n          observer.error(_error3);\n        } catch (error2) {\n          hostReportError(error2, true);\n        } finally {\n          doCleanup();\n        }\n      }\n    },\n    complete: function complete() {\n      if (!closed) {\n        closed = true;\n        try {\n          observer.complete && observer.complete();\n        } catch (error) {\n          hostReportError(error, true);\n        } finally {\n          doCleanup();\n        }\n      }\n    }\n  });\n  try {\n    cleanup = source(sink);\n  } catch (error) {\n    sink.error(error, true);\n  }\n  if (process.env.NODE_ENV !== \"production\") {\n    if (cleanup !== undefined && typeof cleanup !== 'function' && (!cleanup || typeof cleanup.unsubscribe !== 'function')) {\n      throw new Error('Returned cleanup function which cannot be called: ' + String(cleanup));\n    }\n  }\n  if (closed) {\n    doCleanup();\n  }\n  return subscription;\n}\nfunction swallowError(_error, _isUncaughtThrownError) {}\nif (process.env.NODE_ENV !== \"production\") {\n  RelayObservable.onUnhandledError(function (error, isUncaughtThrownError) {\n    if (typeof fail === 'function') {\n      fail(String(error));\n    } else if (isUncaughtThrownError) {\n      setTimeout(function () {\n        throw error;\n      });\n    } else if (typeof console !== 'undefined') {\n      console.error('RelayObservable: Unhandled Error', error);\n    }\n  });\n}\nmodule.exports = RelayObservable;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar stableCopy = require('../util/stableCopy');\nvar invariant = require('invariant');\nvar RelayQueryResponseCache = /*#__PURE__*/function () {\n  function RelayQueryResponseCache(_ref) {\n    var size = _ref.size,\n      ttl = _ref.ttl;\n    !(size > 0) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayQueryResponseCache: Expected the max cache size to be > 0, got ' + '`%s`.', size) : invariant(false) : void 0;\n    !(ttl > 0) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayQueryResponseCache: Expected the max ttl to be > 0, got `%s`.', ttl) : invariant(false) : void 0;\n    this._responses = new Map();\n    this._size = size;\n    this._ttl = ttl;\n  }\n  var _proto = RelayQueryResponseCache.prototype;\n  _proto.clear = function clear() {\n    this._responses.clear();\n  };\n  _proto.get = function get(queryID, variables) {\n    var _this = this;\n    var cacheKey = getCacheKey(queryID, variables);\n    this._responses.forEach(function (response, key) {\n      if (!isCurrent(response.fetchTime, _this._ttl)) {\n        _this._responses[\"delete\"](key);\n      }\n    });\n    var response = this._responses.get(cacheKey);\n    if (response == null) {\n      return null;\n    }\n    if (Array.isArray(response.payload)) {\n      return response.payload.map(function (payload) {\n        return (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, payload), {}, {\n          extensions: (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, payload.extensions), {}, {\n            cacheTimestamp: response.fetchTime\n          })\n        });\n      });\n    }\n    return (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, response.payload), {}, {\n      extensions: (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, response.payload.extensions), {}, {\n        cacheTimestamp: response.fetchTime\n      })\n    });\n  };\n  _proto.set = function set(queryID, variables, payload) {\n    var fetchTime = Date.now();\n    var cacheKey = getCacheKey(queryID, variables);\n    this._responses[\"delete\"](cacheKey);\n    this._responses.set(cacheKey, {\n      fetchTime: fetchTime,\n      payload: payload\n    });\n    if (this._responses.size > this._size) {\n      var firstKey = this._responses.keys().next();\n      if (!firstKey.done) {\n        this._responses[\"delete\"](firstKey.value);\n      }\n    }\n  };\n  return RelayQueryResponseCache;\n}();\nfunction getCacheKey(queryID, variables) {\n  return JSON.stringify(stableCopy({\n    queryID: queryID,\n    variables: variables\n  }));\n}\nfunction isCurrent(fetchTime, ttl) {\n  return fetchTime + ttl >= Date.now();\n}\nmodule.exports = RelayQueryResponseCache;","'use strict';\n\nvar generateID = require('../util/generateID');\nfunction wrapNetworkWithLogObserver(env, network) {\n  return {\n    execute: function execute(params, variables, cacheConfig, uploadables) {\n      var networkRequestId = generateID();\n      var logObserver = {\n        start: function start(subscription) {\n          env.__log({\n            name: 'network.start',\n            networkRequestId: networkRequestId,\n            params: params,\n            variables: variables,\n            cacheConfig: cacheConfig\n          });\n        },\n        next: function next(response) {\n          env.__log({\n            name: 'network.next',\n            networkRequestId: networkRequestId,\n            response: response\n          });\n        },\n        error: function error(_error) {\n          env.__log({\n            name: 'network.error',\n            networkRequestId: networkRequestId,\n            error: _error\n          });\n        },\n        complete: function complete() {\n          env.__log({\n            name: 'network.complete',\n            networkRequestId: networkRequestId\n          });\n        },\n        unsubscribe: function unsubscribe() {\n          env.__log({\n            name: 'network.unsubscribe',\n            networkRequestId: networkRequestId\n          });\n        }\n      };\n      var logRequestInfo = function logRequestInfo(info) {\n        env.__log({\n          name: 'network.info',\n          networkRequestId: networkRequestId,\n          info: info\n        });\n      };\n      return network.execute(params, variables, cacheConfig, uploadables, logRequestInfo)[\"do\"](logObserver);\n    }\n  };\n}\nmodule.exports = wrapNetworkWithLogObserver;","'use strict';\n\nvar RelayConcreteNode = require('../util/RelayConcreteNode');\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nfunction graphql(strings) {\n  !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'graphql: Unexpected invocation at runtime. Either the Babel transform ' + 'was not set up, or it failed to identify this call site. Make sure it ' + 'is being used verbatim as `graphql`. Note also that there cannot be ' + 'a space between graphql and the backtick that follows.') : invariant(false) : void 0;\n}\nfunction getNode(taggedNode) {\n  var node = taggedNode;\n  if (typeof node === 'function') {\n    node = node();\n    process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayGraphQLTag: node `%s` unexpectedly wrapped in a function.', node.kind === 'Fragment' ? node.name : node.operation.name) : void 0;\n  } else if (node[\"default\"]) {\n    node = node[\"default\"];\n  }\n  return node;\n}\nfunction isFragment(node) {\n  var fragment = getNode(node);\n  return typeof fragment === 'object' && fragment !== null && fragment.kind === RelayConcreteNode.FRAGMENT;\n}\nfunction isRequest(node) {\n  var request = getNode(node);\n  return typeof request === 'object' && request !== null && request.kind === RelayConcreteNode.REQUEST;\n}\nfunction isUpdatableQuery(node) {\n  var updatableQuery = getNode(node);\n  return typeof updatableQuery === 'object' && updatableQuery !== null && updatableQuery.kind === RelayConcreteNode.UPDATABLE_QUERY;\n}\nfunction isInlineDataFragment(node) {\n  var fragment = getNode(node);\n  return typeof fragment === 'object' && fragment !== null && fragment.kind === RelayConcreteNode.INLINE_DATA_FRAGMENT;\n}\nfunction getFragment(taggedNode) {\n  var fragment = getNode(taggedNode);\n  !isFragment(fragment) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'GraphQLTag: Expected a fragment, got `%s`.', JSON.stringify(fragment)) : invariant(false) : void 0;\n  return fragment;\n}\nfunction getPaginationFragment(taggedNode) {\n  var _fragment$metadata;\n  var fragment = getFragment(taggedNode);\n  var refetch = (_fragment$metadata = fragment.metadata) === null || _fragment$metadata === void 0 ? void 0 : _fragment$metadata.refetch;\n  var connection = refetch === null || refetch === void 0 ? void 0 : refetch.connection;\n  if (refetch === null || typeof refetch !== 'object' || connection === null || typeof connection !== 'object') {\n    return null;\n  }\n  return fragment;\n}\nfunction getRefetchableFragment(taggedNode) {\n  var _fragment$metadata2;\n  var fragment = getFragment(taggedNode);\n  var refetch = (_fragment$metadata2 = fragment.metadata) === null || _fragment$metadata2 === void 0 ? void 0 : _fragment$metadata2.refetch;\n  if (refetch === null || typeof refetch !== 'object') {\n    return null;\n  }\n  return fragment;\n}\nfunction getRequest(taggedNode) {\n  var request = getNode(taggedNode);\n  !isRequest(request) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'GraphQLTag: Expected a request, got `%s`.', JSON.stringify(request)) : invariant(false) : void 0;\n  return request;\n}\nfunction getUpdatableQuery(taggedNode) {\n  var updatableQuery = getNode(taggedNode);\n  !isUpdatableQuery(updatableQuery) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'GraphQLTag: Expected a request, got `%s`.', JSON.stringify(updatableQuery)) : invariant(false) : void 0;\n  return updatableQuery;\n}\nfunction getInlineDataFragment(taggedNode) {\n  var fragment = getNode(taggedNode);\n  !isInlineDataFragment(fragment) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'GraphQLTag: Expected an inline data fragment, got `%s`.', JSON.stringify(fragment)) : invariant(false) : void 0;\n  return fragment;\n}\nmodule.exports = {\n  getFragment: getFragment,\n  getNode: getNode,\n  getPaginationFragment: getPaginationFragment,\n  getRefetchableFragment: getRefetchableFragment,\n  getRequest: getRequest,\n  getUpdatableQuery: getUpdatableQuery,\n  getInlineDataFragment: getInlineDataFragment,\n  graphql: graphql,\n  isFragment: isFragment,\n  isRequest: isRequest,\n  isUpdatableQuery: isUpdatableQuery,\n  isInlineDataFragment: isInlineDataFragment\n};","'use strict';\n\nvar PreloadableQueryRegistry = /*#__PURE__*/function () {\n  function PreloadableQueryRegistry() {\n    this._preloadableQueries = new Map();\n    this._callbacks = new Map();\n  }\n  var _proto = PreloadableQueryRegistry.prototype;\n  _proto.set = function set(key, value) {\n    this._preloadableQueries.set(key, value);\n    var callbacks = this._callbacks.get(key);\n    if (callbacks != null) {\n      callbacks.forEach(function (cb) {\n        try {\n          cb(value);\n        } catch (e) {\n          setTimeout(function () {\n            throw e;\n          }, 0);\n        }\n      });\n    }\n  };\n  _proto.get = function get(key) {\n    return this._preloadableQueries.get(key);\n  };\n  _proto.onLoad = function onLoad(key, callback) {\n    var _this$_callbacks$get;\n    var callbacks = (_this$_callbacks$get = this._callbacks.get(key)) !== null && _this$_callbacks$get !== void 0 ? _this$_callbacks$get : new Set();\n    callbacks.add(callback);\n    var dispose = function dispose() {\n      callbacks[\"delete\"](callback);\n    };\n    this._callbacks.set(key, callbacks);\n    return {\n      dispose: dispose\n    };\n  };\n  _proto.clear = function clear() {\n    this._preloadableQueries.clear();\n  };\n  return PreloadableQueryRegistry;\n}();\nvar preloadableQueryRegistry = new PreloadableQueryRegistry();\nmodule.exports = preloadableQueryRegistry;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar RelayObservable = require('../network/RelayObservable');\nvar _require = require('../store/RelayModernOperationDescriptor'),\n  createOperationDescriptor = _require.createOperationDescriptor;\nvar handlePotentialSnapshotErrors = require('../util/handlePotentialSnapshotErrors');\nvar fetchQueryInternal = require('./fetchQueryInternal');\nvar _require2 = require('./GraphQLTag'),\n  getRequest = _require2.getRequest;\nvar invariant = require('invariant');\nfunction fetchQuery(environment, query, variables, options) {\n  var _options$fetchPolicy;\n  var queryNode = getRequest(query);\n  !(queryNode.params.operationKind === 'query') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'fetchQuery: Expected query operation') : invariant(false) : void 0;\n  var networkCacheConfig = (0, _objectSpread2[\"default\"])({\n    force: true\n  }, options === null || options === void 0 ? void 0 : options.networkCacheConfig);\n  var operation = createOperationDescriptor(queryNode, variables, networkCacheConfig);\n  var fetchPolicy = (_options$fetchPolicy = options === null || options === void 0 ? void 0 : options.fetchPolicy) !== null && _options$fetchPolicy !== void 0 ? _options$fetchPolicy : 'network-only';\n  function readData(snapshot) {\n    handlePotentialSnapshotErrors(environment, snapshot.missingRequiredFields, snapshot.relayResolverErrors, snapshot.errorResponseFields);\n    return snapshot.data;\n  }\n  switch (fetchPolicy) {\n    case 'network-only':\n      {\n        return getNetworkObservable(environment, operation).map(readData);\n      }\n    case 'store-or-network':\n      {\n        if (environment.check(operation).status === 'available') {\n          return RelayObservable.from(environment.lookup(operation.fragment)).map(readData);\n        }\n        return getNetworkObservable(environment, operation).map(readData);\n      }\n    default:\n      fetchPolicy;\n      throw new Error('fetchQuery: Invalid fetchPolicy ' + fetchPolicy);\n  }\n}\nfunction getNetworkObservable(environment, operation) {\n  return fetchQueryInternal.fetchQuery(environment, operation).map(function () {\n    return environment.lookup(operation.fragment);\n  });\n}\nmodule.exports = fetchQuery;","'use strict';\n\nvar Observable = require('../network/RelayObservable');\nvar RelayReplaySubject = require('../util/RelayReplaySubject');\nvar invariant = require('invariant');\nvar WEAKMAP_SUPPORTED = typeof WeakMap === 'function';\nvar requestCachesByEnvironment = WEAKMAP_SUPPORTED ? new WeakMap() : new Map();\nfunction fetchQuery(environment, operation) {\n  return fetchQueryDeduped(environment, operation.request.identifier, function () {\n    return environment.execute({\n      operation: operation\n    });\n  });\n}\nfunction fetchQueryDeduped(environment, identifier, fetchFn) {\n  return Observable.create(function (sink) {\n    var requestCache = getRequestCache(environment);\n    var cachedRequest = requestCache.get(identifier);\n    if (!cachedRequest) {\n      fetchFn()[\"finally\"](function () {\n        return requestCache[\"delete\"](identifier);\n      }).subscribe({\n        start: function start(subscription) {\n          cachedRequest = {\n            identifier: identifier,\n            subject: new RelayReplaySubject(),\n            subjectForInFlightStatus: new RelayReplaySubject(),\n            subscription: subscription,\n            promise: null\n          };\n          requestCache.set(identifier, cachedRequest);\n        },\n        next: function next(response) {\n          var cachedReq = getCachedRequest(requestCache, identifier);\n          cachedReq.subject.next(response);\n          cachedReq.subjectForInFlightStatus.next(response);\n        },\n        error: function error(_error) {\n          var cachedReq = getCachedRequest(requestCache, identifier);\n          cachedReq.subject.error(_error);\n          cachedReq.subjectForInFlightStatus.error(_error);\n        },\n        complete: function complete() {\n          var cachedReq = getCachedRequest(requestCache, identifier);\n          cachedReq.subject.complete();\n          cachedReq.subjectForInFlightStatus.complete();\n        },\n        unsubscribe: function unsubscribe(subscription) {\n          var cachedReq = getCachedRequest(requestCache, identifier);\n          cachedReq.subject.unsubscribe();\n          cachedReq.subjectForInFlightStatus.unsubscribe();\n        }\n      });\n    }\n    !(cachedRequest != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, '[fetchQueryInternal] fetchQueryDeduped: Expected `start` to be ' + 'called synchronously') : invariant(false) : void 0;\n    return getObservableForCachedRequest(requestCache, cachedRequest).subscribe(sink);\n  });\n}\nfunction getObservableForCachedRequest(requestCache, cachedRequest) {\n  return Observable.create(function (sink) {\n    var subscription = cachedRequest.subject.subscribe(sink);\n    return function () {\n      subscription.unsubscribe();\n      var cachedRequestInstance = requestCache.get(cachedRequest.identifier);\n      if (cachedRequestInstance) {\n        var requestSubscription = cachedRequestInstance.subscription;\n        if (requestSubscription != null && cachedRequestInstance.subject.getObserverCount() === 0) {\n          requestSubscription.unsubscribe();\n          requestCache[\"delete\"](cachedRequest.identifier);\n        }\n      }\n    };\n  });\n}\nfunction getActiveStatusObservableForCachedRequest(environment, requestCache, cachedRequest) {\n  return Observable.create(function (sink) {\n    var subscription = cachedRequest.subjectForInFlightStatus.subscribe({\n      error: sink.error,\n      next: function next(response) {\n        if (!environment.isRequestActive(cachedRequest.identifier)) {\n          sink.complete();\n          return;\n        }\n        sink.next();\n      },\n      complete: sink.complete,\n      unsubscribe: sink.complete\n    });\n    return function () {\n      subscription.unsubscribe();\n    };\n  });\n}\nfunction getPromiseForActiveRequest(environment, request) {\n  var requestCache = getRequestCache(environment);\n  var cachedRequest = requestCache.get(request.identifier);\n  if (!cachedRequest) {\n    return null;\n  }\n  if (!environment.isRequestActive(cachedRequest.identifier)) {\n    return null;\n  }\n  var promise = new Promise(function (resolve, reject) {\n    var resolveOnNext = false;\n    getActiveStatusObservableForCachedRequest(environment, requestCache, cachedRequest).subscribe({\n      complete: resolve,\n      error: reject,\n      next: function next(response) {\n        if (resolveOnNext) {\n          resolve(response);\n        }\n      }\n    });\n    resolveOnNext = true;\n  });\n  return promise;\n}\nfunction getObservableForActiveRequest(environment, request) {\n  var requestCache = getRequestCache(environment);\n  var cachedRequest = requestCache.get(request.identifier);\n  if (!cachedRequest) {\n    return null;\n  }\n  if (!environment.isRequestActive(cachedRequest.identifier)) {\n    return null;\n  }\n  return getActiveStatusObservableForCachedRequest(environment, requestCache, cachedRequest);\n}\nfunction getRequestCache(environment) {\n  var cached = requestCachesByEnvironment.get(environment);\n  if (cached != null) {\n    return cached;\n  }\n  var requestCache = new Map();\n  requestCachesByEnvironment.set(environment, requestCache);\n  return requestCache;\n}\nfunction getCachedRequest(requestCache, identifier) {\n  var cached = requestCache.get(identifier);\n  !(cached != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, '[fetchQueryInternal] getCachedRequest: Expected request to be cached') : invariant(false) : void 0;\n  return cached;\n}\nmodule.exports = {\n  fetchQuery: fetchQuery,\n  fetchQueryDeduped: fetchQueryDeduped,\n  getPromiseForActiveRequest: getPromiseForActiveRequest,\n  getObservableForActiveRequest: getObservableForActiveRequest\n};","'use strict';\n\nvar _require = require('../store/RelayModernOperationDescriptor'),\n  createOperationDescriptor = _require.createOperationDescriptor;\nvar _require2 = require('./GraphQLTag'),\n  getRequest = _require2.getRequest;\nfunction fetchQuery_DEPRECATED(environment, taggedNode, variables, cacheConfig) {\n  var query = getRequest(taggedNode);\n  if (query.params.operationKind !== 'query') {\n    throw new Error('fetchQuery: Expected query operation');\n  }\n  var operation = createOperationDescriptor(query, variables, cacheConfig);\n  return environment.execute({\n    operation: operation\n  }).map(function () {\n    return environment.lookup(operation.fragment).data;\n  }).toPromise();\n}\nmodule.exports = fetchQuery_DEPRECATED;","'use strict';\n\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar _require = require('../util/StringInterner'),\n  intern = _require.intern;\nvar PREFIX = 'client:';\nfunction generateClientID(id, storageKey, index) {\n  var internedId = RelayFeatureFlags.STRING_INTERN_LEVEL <= 0 ? id : intern(id, RelayFeatureFlags.MAX_DATA_ID_LENGTH);\n  var key = internedId + ':' + storageKey;\n  if (index != null) {\n    key += ':' + index;\n  }\n  if (key.indexOf(PREFIX) !== 0) {\n    key = PREFIX + key;\n  }\n  return key;\n}\nfunction isClientID(id) {\n  return id.indexOf(PREFIX) === 0;\n}\nvar localID = 0;\nfunction generateUniqueClientID() {\n  return \"\".concat(PREFIX, \"local:\").concat(localID++);\n}\nfunction generateClientObjectClientID(typename, localId, index) {\n  var key = \"\".concat(PREFIX).concat(typename, \":\").concat(localId);\n  if (index != null) {\n    key += ':' + index;\n  }\n  return key;\n}\nmodule.exports = {\n  generateClientID: generateClientID,\n  generateClientObjectClientID: generateClientObjectClientID,\n  generateUniqueClientID: generateUniqueClientID,\n  isClientID: isClientID\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar RelayRecordSourceMutator = require('../mutations/RelayRecordSourceMutator');\nvar RelayRecordSourceProxy = require('../mutations/RelayRecordSourceProxy');\nvar getOperation = require('../util/getOperation');\nvar RelayConcreteNode = require('../util/RelayConcreteNode');\nvar _require = require('./ClientID'),\n  isClientID = _require.isClientID;\nvar cloneRelayHandleSourceField = require('./cloneRelayHandleSourceField');\nvar cloneRelayScalarHandleSourceField = require('./cloneRelayScalarHandleSourceField');\nvar _require2 = require('./RelayConcreteVariables'),\n  getLocalVariables = _require2.getLocalVariables;\nvar RelayModernRecord = require('./RelayModernRecord');\nvar _require3 = require('./RelayRecordState'),\n  EXISTENT = _require3.EXISTENT,\n  UNKNOWN = _require3.UNKNOWN;\nvar RelayStoreUtils = require('./RelayStoreUtils');\nvar _require4 = require('./TypeID'),\n  TYPE_SCHEMA_TYPE = _require4.TYPE_SCHEMA_TYPE,\n  generateTypeID = _require4.generateTypeID;\nvar invariant = require('invariant');\nvar ACTOR_CHANGE = RelayConcreteNode.ACTOR_CHANGE,\n  CONDITION = RelayConcreteNode.CONDITION,\n  CLIENT_COMPONENT = RelayConcreteNode.CLIENT_COMPONENT,\n  CLIENT_EXTENSION = RelayConcreteNode.CLIENT_EXTENSION,\n  CLIENT_EDGE_TO_CLIENT_OBJECT = RelayConcreteNode.CLIENT_EDGE_TO_CLIENT_OBJECT,\n  DEFER = RelayConcreteNode.DEFER,\n  FRAGMENT_SPREAD = RelayConcreteNode.FRAGMENT_SPREAD,\n  INLINE_FRAGMENT = RelayConcreteNode.INLINE_FRAGMENT,\n  LINKED_FIELD = RelayConcreteNode.LINKED_FIELD,\n  LINKED_HANDLE = RelayConcreteNode.LINKED_HANDLE,\n  MODULE_IMPORT = RelayConcreteNode.MODULE_IMPORT,\n  RELAY_RESOLVER = RelayConcreteNode.RELAY_RESOLVER,\n  RELAY_LIVE_RESOLVER = RelayConcreteNode.RELAY_LIVE_RESOLVER,\n  SCALAR_FIELD = RelayConcreteNode.SCALAR_FIELD,\n  SCALAR_HANDLE = RelayConcreteNode.SCALAR_HANDLE,\n  STREAM = RelayConcreteNode.STREAM,\n  TYPE_DISCRIMINATOR = RelayConcreteNode.TYPE_DISCRIMINATOR;\nvar getModuleOperationKey = RelayStoreUtils.getModuleOperationKey,\n  getStorageKey = RelayStoreUtils.getStorageKey,\n  getArgumentValues = RelayStoreUtils.getArgumentValues;\nfunction check(getSourceForActor, getTargetForActor, defaultActorIdentifier, selector, handlers, operationLoader, getDataID, shouldProcessClientComponents) {\n  var dataID = selector.dataID,\n    node = selector.node,\n    variables = selector.variables;\n  var checker = new DataChecker(getSourceForActor, getTargetForActor, defaultActorIdentifier, variables, handlers, operationLoader, getDataID, shouldProcessClientComponents);\n  return checker.check(node, dataID);\n}\nvar DataChecker = /*#__PURE__*/function () {\n  function DataChecker(getSourceForActor, getTargetForActor, defaultActorIdentifier, variables, handlers, operationLoader, getDataID, shouldProcessClientComponents) {\n    this._getSourceForActor = getSourceForActor;\n    this._getTargetForActor = getTargetForActor;\n    this._getDataID = getDataID;\n    this._source = getSourceForActor(defaultActorIdentifier);\n    this._mutatorRecordSourceProxyCache = new Map();\n    var _this$_getMutatorAndR = this._getMutatorAndRecordProxyForActor(defaultActorIdentifier),\n      mutator = _this$_getMutatorAndR[0],\n      recordSourceProxy = _this$_getMutatorAndR[1];\n    this._mostRecentlyInvalidatedAt = null;\n    this._handlers = handlers;\n    this._mutator = mutator;\n    this._operationLoader = operationLoader !== null && operationLoader !== void 0 ? operationLoader : null;\n    this._recordSourceProxy = recordSourceProxy;\n    this._recordWasMissing = false;\n    this._variables = variables;\n    this._shouldProcessClientComponents = shouldProcessClientComponents;\n  }\n  var _proto = DataChecker.prototype;\n  _proto._getMutatorAndRecordProxyForActor = function _getMutatorAndRecordProxyForActor(actorIdentifier) {\n    var tuple = this._mutatorRecordSourceProxyCache.get(actorIdentifier);\n    if (tuple == null) {\n      var target = this._getTargetForActor(actorIdentifier);\n      var mutator = new RelayRecordSourceMutator(this._getSourceForActor(actorIdentifier), target);\n      var recordSourceProxy = new RelayRecordSourceProxy(mutator, this._getDataID, undefined, this._handlers);\n      tuple = [mutator, recordSourceProxy];\n      this._mutatorRecordSourceProxyCache.set(actorIdentifier, tuple);\n    }\n    return tuple;\n  };\n  _proto.check = function check(node, dataID) {\n    this._assignClientAbstractTypes(node);\n    this._traverse(node, dataID);\n    return this._recordWasMissing === true ? {\n      status: 'missing',\n      mostRecentlyInvalidatedAt: this._mostRecentlyInvalidatedAt\n    } : {\n      status: 'available',\n      mostRecentlyInvalidatedAt: this._mostRecentlyInvalidatedAt\n    };\n  };\n  _proto._getVariableValue = function _getVariableValue(name) {\n    !this._variables.hasOwnProperty(name) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayAsyncLoader(): Undefined variable `%s`.', name) : invariant(false) : void 0;\n    return this._variables[name];\n  };\n  _proto._handleMissing = function _handleMissing() {\n    this._recordWasMissing = true;\n  };\n  _proto._handleMissingScalarField = function _handleMissingScalarField(field, dataID) {\n    if (field.name === 'id' && field.alias == null && isClientID(dataID)) {\n      return undefined;\n    }\n    var args = field.args != undefined ? getArgumentValues(field.args, this._variables) : {};\n    var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(this._handlers),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var handler = _step.value;\n        if (handler.kind === 'scalar') {\n          var newValue = handler.handle(field, this._recordSourceProxy.get(dataID), args, this._recordSourceProxy);\n          if (newValue !== undefined) {\n            return newValue;\n          }\n        }\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n    this._handleMissing();\n  };\n  _proto._handleMissingLinkField = function _handleMissingLinkField(field, dataID) {\n    var args = field.args != undefined ? getArgumentValues(field.args, this._variables) : {};\n    var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(this._handlers),\n      _step2;\n    try {\n      for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n        var handler = _step2.value;\n        if (handler.kind === 'linked') {\n          var newValue = handler.handle(field, this._recordSourceProxy.get(dataID), args, this._recordSourceProxy);\n          if (newValue !== undefined && (newValue === null || this._mutator.getStatus(newValue) === EXISTENT)) {\n            return newValue;\n          }\n        }\n      }\n    } catch (err) {\n      _iterator2.e(err);\n    } finally {\n      _iterator2.f();\n    }\n    this._handleMissing();\n  };\n  _proto._handleMissingPluralLinkField = function _handleMissingPluralLinkField(field, dataID) {\n    var _this = this;\n    var args = field.args != undefined ? getArgumentValues(field.args, this._variables) : {};\n    var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])(this._handlers),\n      _step3;\n    try {\n      for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n        var handler = _step3.value;\n        if (handler.kind === 'pluralLinked') {\n          var newValue = handler.handle(field, this._recordSourceProxy.get(dataID), args, this._recordSourceProxy);\n          if (newValue != null) {\n            var allItemsKnown = newValue.every(function (linkedID) {\n              return linkedID != null && _this._mutator.getStatus(linkedID) === EXISTENT;\n            });\n            if (allItemsKnown) {\n              return newValue;\n            }\n          } else if (newValue === null) {\n            return null;\n          }\n        }\n      }\n    } catch (err) {\n      _iterator3.e(err);\n    } finally {\n      _iterator3.f();\n    }\n    this._handleMissing();\n  };\n  _proto._traverse = function _traverse(node, dataID) {\n    var status = this._mutator.getStatus(dataID);\n    if (status === UNKNOWN) {\n      this._handleMissing();\n    }\n    if (status === EXISTENT) {\n      var record = this._source.get(dataID);\n      var invalidatedAt = RelayModernRecord.getInvalidationEpoch(record);\n      if (invalidatedAt != null) {\n        this._mostRecentlyInvalidatedAt = this._mostRecentlyInvalidatedAt != null ? Math.max(this._mostRecentlyInvalidatedAt, invalidatedAt) : invalidatedAt;\n      }\n      this._traverseSelections(node.selections, dataID);\n    }\n  };\n  _proto._traverseSelections = function _traverseSelections(selections, dataID) {\n    var _this2 = this;\n    selections.forEach(function (selection) {\n      switch (selection.kind) {\n        case SCALAR_FIELD:\n          _this2._checkScalar(selection, dataID);\n          break;\n        case LINKED_FIELD:\n          if (selection.plural) {\n            _this2._checkPluralLink(selection, dataID);\n          } else {\n            _this2._checkLink(selection, dataID);\n          }\n          break;\n        case ACTOR_CHANGE:\n          _this2._checkActorChange(selection.linkedField, dataID);\n          break;\n        case CONDITION:\n          var conditionValue = Boolean(_this2._getVariableValue(selection.condition));\n          if (conditionValue === selection.passingValue) {\n            _this2._traverseSelections(selection.selections, dataID);\n          }\n          break;\n        case INLINE_FRAGMENT:\n          {\n            var _abstractKey = selection.abstractKey;\n            if (_abstractKey == null) {\n              var typeName = _this2._mutator.getType(dataID);\n              if (typeName === selection.type) {\n                _this2._traverseSelections(selection.selections, dataID);\n              }\n            } else {\n              var _recordType = _this2._mutator.getType(dataID);\n              !(_recordType != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'DataChecker: Expected record `%s` to have a known type', dataID) : invariant(false) : void 0;\n              var _typeID = generateTypeID(_recordType);\n              var _implementsInterface = _this2._mutator.getValue(_typeID, _abstractKey);\n              if (_implementsInterface === true) {\n                _this2._traverseSelections(selection.selections, dataID);\n              } else if (_implementsInterface == null) {\n                _this2._handleMissing();\n              }\n            }\n            break;\n          }\n        case LINKED_HANDLE:\n          {\n            var handleField = cloneRelayHandleSourceField(selection, selections, _this2._variables);\n            if (handleField.plural) {\n              _this2._checkPluralLink(handleField, dataID);\n            } else {\n              _this2._checkLink(handleField, dataID);\n            }\n            break;\n          }\n        case SCALAR_HANDLE:\n          {\n            var _handleField = cloneRelayScalarHandleSourceField(selection, selections, _this2._variables);\n            _this2._checkScalar(_handleField, dataID);\n            break;\n          }\n        case MODULE_IMPORT:\n          _this2._checkModuleImport(selection, dataID);\n          break;\n        case DEFER:\n        case STREAM:\n          _this2._traverseSelections(selection.selections, dataID);\n          break;\n        case FRAGMENT_SPREAD:\n          var prevVariables = _this2._variables;\n          _this2._variables = getLocalVariables(_this2._variables, selection.fragment.argumentDefinitions, selection.args);\n          _this2._traverseSelections(selection.fragment.selections, dataID);\n          _this2._variables = prevVariables;\n          break;\n        case CLIENT_EXTENSION:\n          var recordWasMissing = _this2._recordWasMissing;\n          _this2._traverseSelections(selection.selections, dataID);\n          _this2._recordWasMissing = recordWasMissing;\n          break;\n        case TYPE_DISCRIMINATOR:\n          var abstractKey = selection.abstractKey;\n          var recordType = _this2._mutator.getType(dataID);\n          !(recordType != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'DataChecker: Expected record `%s` to have a known type', dataID) : invariant(false) : void 0;\n          var typeID = generateTypeID(recordType);\n          var implementsInterface = _this2._mutator.getValue(typeID, abstractKey);\n          if (implementsInterface == null) {\n            _this2._handleMissing();\n          }\n          break;\n        case CLIENT_COMPONENT:\n          if (_this2._shouldProcessClientComponents === false) {\n            break;\n          }\n          _this2._traverseSelections(selection.fragment.selections, dataID);\n          break;\n        case RELAY_RESOLVER:\n          _this2._checkResolver(selection, dataID);\n          break;\n        case RELAY_LIVE_RESOLVER:\n          _this2._checkResolver(selection, dataID);\n          break;\n        case CLIENT_EDGE_TO_CLIENT_OBJECT:\n          _this2._checkResolver(selection.backingField, dataID);\n          break;\n        default:\n          selection;\n          !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayAsyncLoader(): Unexpected ast kind `%s`.', selection.kind) : invariant(false) : void 0;\n      }\n    });\n  };\n  _proto._checkResolver = function _checkResolver(resolver, dataID) {\n    if (resolver.fragment) {\n      this._traverseSelections([resolver.fragment], dataID);\n    }\n  };\n  _proto._checkModuleImport = function _checkModuleImport(moduleImport, dataID) {\n    var operationLoader = this._operationLoader;\n    !(operationLoader !== null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'DataChecker: Expected an operationLoader to be configured when using `@module`.') : invariant(false) : void 0;\n    var operationKey = getModuleOperationKey(moduleImport.documentName);\n    var operationReference = this._mutator.getValue(dataID, operationKey);\n    if (operationReference == null) {\n      if (operationReference === undefined) {\n        this._handleMissing();\n      }\n      return;\n    }\n    var normalizationRootNode = operationLoader.get(operationReference);\n    if (normalizationRootNode != null) {\n      var operation = getOperation(normalizationRootNode);\n      var prevVariables = this._variables;\n      this._variables = getLocalVariables(this._variables, operation.argumentDefinitions, moduleImport.args);\n      this._traverse(operation, dataID);\n      this._variables = prevVariables;\n    } else {\n      this._handleMissing();\n    }\n  };\n  _proto._checkScalar = function _checkScalar(field, dataID) {\n    var storageKey = getStorageKey(field, this._variables);\n    var fieldValue = this._mutator.getValue(dataID, storageKey);\n    if (fieldValue === undefined) {\n      fieldValue = this._handleMissingScalarField(field, dataID);\n      if (fieldValue !== undefined) {\n        this._mutator.setValue(dataID, storageKey, fieldValue);\n      }\n    }\n  };\n  _proto._checkLink = function _checkLink(field, dataID) {\n    var storageKey = getStorageKey(field, this._variables);\n    var linkedID = this._mutator.getLinkedRecordID(dataID, storageKey);\n    if (linkedID === undefined) {\n      linkedID = this._handleMissingLinkField(field, dataID);\n      if (linkedID != null) {\n        this._mutator.setLinkedRecordID(dataID, storageKey, linkedID);\n      } else if (linkedID === null) {\n        this._mutator.setValue(dataID, storageKey, null);\n      }\n    }\n    if (linkedID != null) {\n      this._traverse(field, linkedID);\n    }\n  };\n  _proto._checkPluralLink = function _checkPluralLink(field, dataID) {\n    var _this3 = this;\n    var storageKey = getStorageKey(field, this._variables);\n    var linkedIDs = this._mutator.getLinkedRecordIDs(dataID, storageKey);\n    if (linkedIDs === undefined) {\n      linkedIDs = this._handleMissingPluralLinkField(field, dataID);\n      if (linkedIDs != null) {\n        this._mutator.setLinkedRecordIDs(dataID, storageKey, linkedIDs);\n      } else if (linkedIDs === null) {\n        this._mutator.setValue(dataID, storageKey, null);\n      }\n    }\n    if (linkedIDs) {\n      linkedIDs.forEach(function (linkedID) {\n        if (linkedID != null) {\n          _this3._traverse(field, linkedID);\n        }\n      });\n    }\n  };\n  _proto._checkActorChange = function _checkActorChange(field, dataID) {\n    var storageKey = getStorageKey(field, this._variables);\n    var record = this._source.get(dataID);\n    var tuple = record != null ? RelayModernRecord.getActorLinkedRecordID(record, storageKey) : record;\n    if (tuple == null) {\n      if (tuple === undefined) {\n        this._handleMissing();\n      }\n    } else {\n      var actorIdentifier = tuple[0],\n        linkedID = tuple[1];\n      var prevSource = this._source;\n      var prevMutator = this._mutator;\n      var prevRecordSourceProxy = this._recordSourceProxy;\n      var _this$_getMutatorAndR2 = this._getMutatorAndRecordProxyForActor(actorIdentifier),\n        mutator = _this$_getMutatorAndR2[0],\n        recordSourceProxy = _this$_getMutatorAndR2[1];\n      this._source = this._getSourceForActor(actorIdentifier);\n      this._mutator = mutator;\n      this._recordSourceProxy = recordSourceProxy;\n      this._assignClientAbstractTypes(field);\n      this._traverse(field, linkedID);\n      this._source = prevSource;\n      this._mutator = prevMutator;\n      this._recordSourceProxy = prevRecordSourceProxy;\n    }\n  };\n  _proto._assignClientAbstractTypes = function _assignClientAbstractTypes(node) {\n    var clientAbstractTypes = node.clientAbstractTypes;\n    if (clientAbstractTypes != null) {\n      for (var _i = 0, _Object$keys = Object.keys(clientAbstractTypes); _i < _Object$keys.length; _i++) {\n        var abstractType = _Object$keys[_i];\n        var _iterator4 = (0, _createForOfIteratorHelper2[\"default\"])(clientAbstractTypes[abstractType]),\n          _step4;\n        try {\n          for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n            var concreteType = _step4.value;\n            var typeID = generateTypeID(concreteType);\n            if (this._source.get(typeID) == null) {\n              this._mutator.create(typeID, TYPE_SCHEMA_TYPE);\n            }\n            if (this._mutator.getValue(typeID, abstractType) == null) {\n              this._mutator.setValue(typeID, abstractType, true);\n            }\n          }\n        } catch (err) {\n          _iterator4.e(err);\n        } finally {\n          _iterator4.f();\n        }\n      }\n    }\n  };\n  return DataChecker;\n}();\nmodule.exports = {\n  check: check\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar RelayObservable = require('../network/RelayObservable');\nvar generateID = require('../util/generateID');\nvar getOperation = require('../util/getOperation');\nvar RelayError = require('../util/RelayError');\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar stableCopy = require('../util/stableCopy');\nvar withDuration = require('../util/withDuration');\nvar _require = require('./ClientID'),\n  generateClientID = _require.generateClientID,\n  generateUniqueClientID = _require.generateUniqueClientID;\nvar _require2 = require('./RelayConcreteVariables'),\n  getLocalVariables = _require2.getLocalVariables;\nvar RelayModernRecord = require('./RelayModernRecord');\nvar _require3 = require('./RelayModernSelector'),\n  createNormalizationSelector = _require3.createNormalizationSelector,\n  createReaderSelector = _require3.createReaderSelector;\nvar RelayRecordSource = require('./RelayRecordSource');\nvar _require4 = require('./RelayStoreUtils'),\n  ROOT_TYPE = _require4.ROOT_TYPE,\n  TYPENAME_KEY = _require4.TYPENAME_KEY,\n  getStorageKey = _require4.getStorageKey;\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nfunction execute(config) {\n  return new Executor(config);\n}\nvar Executor = /*#__PURE__*/function () {\n  function Executor(_ref2) {\n    var _this = this;\n    var actorIdentifier = _ref2.actorIdentifier,\n      getDataID = _ref2.getDataID,\n      getPublishQueue = _ref2.getPublishQueue,\n      getStore = _ref2.getStore,\n      isClientPayload = _ref2.isClientPayload,\n      operation = _ref2.operation,\n      operationExecutions = _ref2.operationExecutions,\n      operationLoader = _ref2.operationLoader,\n      operationTracker = _ref2.operationTracker,\n      optimisticConfig = _ref2.optimisticConfig,\n      scheduler = _ref2.scheduler,\n      shouldProcessClientComponents = _ref2.shouldProcessClientComponents,\n      sink = _ref2.sink,\n      source = _ref2.source,\n      treatMissingFieldsAsNull = _ref2.treatMissingFieldsAsNull,\n      updater = _ref2.updater,\n      log = _ref2.log,\n      normalizeResponse = _ref2.normalizeResponse;\n    this._actorIdentifier = actorIdentifier;\n    this._getDataID = getDataID;\n    this._treatMissingFieldsAsNull = treatMissingFieldsAsNull;\n    this._incrementalPayloadsPending = false;\n    this._incrementalResults = new Map();\n    this._log = log;\n    this._executeId = generateID();\n    this._nextSubscriptionId = 0;\n    this._operation = operation;\n    this._operationExecutions = operationExecutions;\n    this._operationLoader = operationLoader;\n    this._operationTracker = operationTracker;\n    this._operationUpdateEpochs = new Map();\n    this._optimisticUpdates = null;\n    this._pendingModulePayloadsCount = 0;\n    this._getPublishQueue = getPublishQueue;\n    this._scheduler = scheduler;\n    this._sink = sink;\n    this._source = new Map();\n    this._state = 'started';\n    this._getStore = getStore;\n    this._subscriptions = new Map();\n    this._updater = updater;\n    this._isClientPayload = isClientPayload === true;\n    this._isSubscriptionOperation = this._operation.request.node.params.operationKind === 'subscription';\n    this._shouldProcessClientComponents = shouldProcessClientComponents;\n    this._retainDisposables = new Map();\n    this._seenActors = new Set();\n    this._completeFns = [];\n    this._normalizeResponse = normalizeResponse;\n    var id = this._nextSubscriptionId++;\n    source.subscribe({\n      complete: function complete() {\n        return _this._complete(id);\n      },\n      error: function error(_error2) {\n        return _this._error(_error2);\n      },\n      next: function next(response) {\n        try {\n          _this._next(id, response);\n        } catch (error) {\n          sink.error(error);\n        }\n      },\n      start: function start(subscription) {\n        var _this$_operation$requ;\n        _this._start(id, subscription);\n        _this._log({\n          name: 'execute.start',\n          executeId: _this._executeId,\n          params: _this._operation.request.node.params,\n          variables: _this._operation.request.variables,\n          cacheConfig: (_this$_operation$requ = _this._operation.request.cacheConfig) !== null && _this$_operation$requ !== void 0 ? _this$_operation$requ : {}\n        });\n      }\n    });\n    if (optimisticConfig != null) {\n      this._processOptimisticResponse(optimisticConfig.response != null ? {\n        data: optimisticConfig.response\n      } : null, optimisticConfig.updater, false);\n    }\n  }\n  var _proto = Executor.prototype;\n  _proto.cancel = function cancel() {\n    var _this2 = this;\n    if (this._state === 'completed') {\n      return;\n    }\n    this._state = 'completed';\n    this._operationExecutions[\"delete\"](this._operation.request.identifier);\n    if (this._subscriptions.size !== 0) {\n      this._subscriptions.forEach(function (sub) {\n        return sub.unsubscribe();\n      });\n      this._subscriptions.clear();\n    }\n    var optimisticUpdates = this._optimisticUpdates;\n    if (optimisticUpdates !== null) {\n      this._optimisticUpdates = null;\n      optimisticUpdates.forEach(function (update) {\n        return _this2._getPublishQueueAndSaveActor().revertUpdate(update);\n      });\n      this._runPublishQueue();\n    }\n    this._incrementalResults.clear();\n    if (this._asyncStoreUpdateDisposable != null) {\n      this._asyncStoreUpdateDisposable.dispose();\n      this._asyncStoreUpdateDisposable = null;\n    }\n    this._completeFns = [];\n    this._completeOperationTracker();\n    this._disposeRetainedData();\n  };\n  _proto._updateActiveState = function _updateActiveState() {\n    var activeState;\n    switch (this._state) {\n      case 'started':\n        {\n          activeState = 'active';\n          break;\n        }\n      case 'loading_incremental':\n        {\n          activeState = 'active';\n          break;\n        }\n      case 'completed':\n        {\n          activeState = 'inactive';\n          break;\n        }\n      case 'loading_final':\n        {\n          activeState = this._pendingModulePayloadsCount > 0 ? 'active' : 'inactive';\n          break;\n        }\n      default:\n        this._state;\n        !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: invalid executor state.') : invariant(false) : void 0;\n    }\n    this._operationExecutions.set(this._operation.request.identifier, activeState);\n  };\n  _proto._schedule = function _schedule(task) {\n    var _this3 = this;\n    var scheduler = this._scheduler;\n    if (scheduler != null) {\n      var id = this._nextSubscriptionId++;\n      RelayObservable.create(function (sink) {\n        var cancellationToken = scheduler.schedule(function () {\n          try {\n            task();\n            sink.complete();\n          } catch (error) {\n            sink.error(error);\n          }\n        });\n        return function () {\n          return scheduler.cancel(cancellationToken);\n        };\n      }).subscribe({\n        complete: function complete() {\n          return _this3._complete(id);\n        },\n        error: function error(_error3) {\n          return _this3._error(_error3);\n        },\n        start: function start(subscription) {\n          return _this3._start(id, subscription);\n        }\n      });\n    } else {\n      task();\n    }\n  };\n  _proto._complete = function _complete(id) {\n    this._subscriptions[\"delete\"](id);\n    if (this._subscriptions.size === 0) {\n      this.cancel();\n      this._sink.complete();\n      this._log({\n        name: 'execute.complete',\n        executeId: this._executeId\n      });\n    }\n  };\n  _proto._error = function _error(error) {\n    this.cancel();\n    this._sink.error(error);\n    this._log({\n      name: 'execute.error',\n      executeId: this._executeId,\n      error: error\n    });\n  };\n  _proto._start = function _start(id, subscription) {\n    this._subscriptions.set(id, subscription);\n    this._updateActiveState();\n  };\n  _proto._next = function _next(_id, response) {\n    var _this4 = this;\n    this._schedule(function () {\n      var _withDuration = withDuration(function () {\n          _this4._handleNext(response);\n          _this4._maybeCompleteSubscriptionOperationTracking();\n        }),\n        duration = _withDuration[0];\n      _this4._log({\n        name: 'execute.next',\n        executeId: _this4._executeId,\n        response: response,\n        duration: duration\n      });\n    });\n  };\n  _proto._handleErrorResponse = function _handleErrorResponse(responses) {\n    var _this5 = this;\n    var results = [];\n    responses.forEach(function (response) {\n      if (response.data === null && response.extensions != null && !response.hasOwnProperty('errors')) {\n        return;\n      } else if (response.data == null) {\n        var errors = response.hasOwnProperty('errors') && response.errors != null ? response.errors : null;\n        var messages = errors ? errors.map(function (_ref3) {\n          var message = _ref3.message;\n          return message;\n        }).join('\\n') : '(No errors)';\n        var error = RelayError.create('RelayNetwork', 'No data returned for operation `' + _this5._operation.request.node.params.name + '`, got error(s):\\n' + messages + '\\n\\nSee the error `source` property for more information.');\n        error.source = {\n          errors: errors,\n          operation: _this5._operation.request.node,\n          variables: _this5._operation.request.variables\n        };\n        error.stack;\n        throw error;\n      } else {\n        var responseWithData = response;\n        results.push(responseWithData);\n      }\n    });\n    return results;\n  };\n  _proto._handleOptimisticResponses = function _handleOptimisticResponses(responses) {\n    var _response$extensions;\n    if (responses.length > 1) {\n      if (responses.some(function (responsePart) {\n        var _responsePart$extensi;\n        return ((_responsePart$extensi = responsePart.extensions) === null || _responsePart$extensi === void 0 ? void 0 : _responsePart$extensi.isOptimistic) === true;\n      })) {\n        !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Optimistic responses cannot be batched.') : invariant(false) : void 0;\n      }\n      return false;\n    }\n    var response = responses[0];\n    var isOptimistic = ((_response$extensions = response.extensions) === null || _response$extensions === void 0 ? void 0 : _response$extensions.isOptimistic) === true;\n    if (isOptimistic && this._state !== 'started') {\n      !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: optimistic payload received after server payload.') : invariant(false) : void 0;\n    }\n    if (isOptimistic) {\n      this._processOptimisticResponse(response, null, this._treatMissingFieldsAsNull);\n      this._sink.next(response);\n      return true;\n    }\n    return false;\n  };\n  _proto._handleNext = function _handleNext(response) {\n    if (this._state === 'completed') {\n      return;\n    }\n    this._seenActors.clear();\n    var responses = Array.isArray(response) ? response : [response];\n    var responsesWithData = this._handleErrorResponse(responses);\n    if (responsesWithData.length === 0) {\n      var isFinal = responses.some(function (x) {\n        var _x$extensions;\n        return ((_x$extensions = x.extensions) === null || _x$extensions === void 0 ? void 0 : _x$extensions.is_final) === true;\n      });\n      if (isFinal) {\n        this._state = 'loading_final';\n        this._updateActiveState();\n        this._incrementalPayloadsPending = false;\n      }\n      this._sink.next(response);\n      return;\n    }\n    var isOptimistic = this._handleOptimisticResponses(responsesWithData);\n    if (isOptimistic) {\n      return;\n    }\n    var _partitionGraphQLResp = partitionGraphQLResponses(responsesWithData),\n      nonIncrementalResponses = _partitionGraphQLResp[0],\n      incrementalResponses = _partitionGraphQLResp[1];\n    var hasNonIncrementalResponses = nonIncrementalResponses.length > 0;\n    if (hasNonIncrementalResponses) {\n      if (this._isSubscriptionOperation) {\n        var nextID = generateUniqueClientID();\n        this._operation = {\n          request: this._operation.request,\n          fragment: createReaderSelector(this._operation.fragment.node, nextID, this._operation.fragment.variables, this._operation.fragment.owner),\n          root: createNormalizationSelector(this._operation.root.node, nextID, this._operation.root.variables)\n        };\n      }\n      var payloadFollowups = this._processResponses(nonIncrementalResponses);\n      this._processPayloadFollowups(payloadFollowups);\n    }\n    if (incrementalResponses.length > 0) {\n      var _payloadFollowups = this._processIncrementalResponses(incrementalResponses);\n      this._processPayloadFollowups(_payloadFollowups);\n    }\n    if (this._isSubscriptionOperation) {\n      if (responsesWithData[0].extensions == null) {\n        responsesWithData[0].extensions = {\n          __relay_subscription_root_id: this._operation.fragment.dataID\n        };\n      } else {\n        responsesWithData[0].extensions.__relay_subscription_root_id = this._operation.fragment.dataID;\n      }\n    }\n    var updatedOwners = this._runPublishQueue(hasNonIncrementalResponses ? this._operation : undefined);\n    if (hasNonIncrementalResponses) {\n      if (this._incrementalPayloadsPending) {\n        this._retainData();\n      }\n    }\n    this._updateOperationTracker(updatedOwners);\n    this._sink.next(response);\n  };\n  _proto._processOptimisticResponse = function _processOptimisticResponse(response, updater, treatMissingFieldsAsNull) {\n    var _this6 = this;\n    !(this._optimisticUpdates === null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: environment.execute: only support one optimistic response per ' + 'execute.') : invariant(false) : void 0;\n    if (response == null && updater == null) {\n      return;\n    }\n    var optimisticUpdates = [];\n    if (response) {\n      var payload = this._normalizeResponse(response, this._operation.root, ROOT_TYPE, {\n        actorIdentifier: this._actorIdentifier,\n        getDataID: this._getDataID,\n        path: [],\n        shouldProcessClientComponents: this._shouldProcessClientComponents,\n        treatMissingFieldsAsNull: treatMissingFieldsAsNull\n      });\n      validateOptimisticResponsePayload(payload);\n      optimisticUpdates.push({\n        operation: this._operation,\n        payload: payload,\n        updater: updater\n      });\n      this._processOptimisticFollowups(payload, optimisticUpdates);\n    } else if (updater) {\n      optimisticUpdates.push({\n        operation: this._operation,\n        payload: {\n          errors: null,\n          fieldPayloads: null,\n          incrementalPlaceholders: null,\n          followupPayloads: null,\n          source: RelayRecordSource.create(),\n          isFinal: false\n        },\n        updater: updater\n      });\n    }\n    this._optimisticUpdates = optimisticUpdates;\n    optimisticUpdates.forEach(function (update) {\n      return _this6._getPublishQueueAndSaveActor().applyUpdate(update);\n    });\n    var updatedOwners = this._runPublishQueue();\n    if (RelayFeatureFlags.ENABLE_OPERATION_TRACKER_OPTIMISTIC_UPDATES) {\n      this._updateOperationTracker(updatedOwners);\n    }\n  };\n  _proto._processOptimisticFollowups = function _processOptimisticFollowups(payload, optimisticUpdates) {\n    if (payload.followupPayloads && payload.followupPayloads.length) {\n      var followupPayloads = payload.followupPayloads;\n      var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(followupPayloads),\n        _step;\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var followupPayload = _step.value;\n          switch (followupPayload.kind) {\n            case 'ModuleImportPayload':\n              var operationLoader = this._expectOperationLoader();\n              var operation = operationLoader.get(followupPayload.operationReference);\n              if (operation == null) {\n                this._processAsyncOptimisticModuleImport(followupPayload);\n              } else {\n                var moduleImportOptimisticUpdates = this._processOptimisticModuleImport(operation, followupPayload);\n                optimisticUpdates.push.apply(optimisticUpdates, (0, _toConsumableArray2[\"default\"])(moduleImportOptimisticUpdates));\n              }\n              break;\n            case 'ActorPayload':\n              process.env.NODE_ENV !== \"production\" ? warning(false, 'OperationExecutor: Unexpected optimistic ActorPayload. These updates are not supported.') : void 0;\n              break;\n            default:\n              followupPayload;\n              !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Unexpected followup kind `%s`. when processing optimistic updates.', followupPayload.kind) : invariant(false) : void 0;\n          }\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n    }\n  };\n  _proto._normalizeFollowupPayload = function _normalizeFollowupPayload(followupPayload, normalizationNode) {\n    var variables;\n    if (normalizationNode.kind === 'SplitOperation' && followupPayload.kind === 'ModuleImportPayload') {\n      variables = getLocalVariables(followupPayload.variables, normalizationNode.argumentDefinitions, followupPayload.args);\n    } else {\n      variables = followupPayload.variables;\n    }\n    var selector = createNormalizationSelector(normalizationNode, followupPayload.dataID, variables);\n    return this._normalizeResponse({\n      data: followupPayload.data\n    }, selector, followupPayload.typeName, {\n      actorIdentifier: this._actorIdentifier,\n      getDataID: this._getDataID,\n      path: followupPayload.path,\n      treatMissingFieldsAsNull: this._treatMissingFieldsAsNull,\n      shouldProcessClientComponents: this._shouldProcessClientComponents\n    });\n  };\n  _proto._processOptimisticModuleImport = function _processOptimisticModuleImport(normalizationRootNode, moduleImportPayload) {\n    var operation = getOperation(normalizationRootNode);\n    var optimisticUpdates = [];\n    var modulePayload = this._normalizeFollowupPayload(moduleImportPayload, operation);\n    validateOptimisticResponsePayload(modulePayload);\n    optimisticUpdates.push({\n      operation: this._operation,\n      payload: modulePayload,\n      updater: null\n    });\n    this._processOptimisticFollowups(modulePayload, optimisticUpdates);\n    return optimisticUpdates;\n  };\n  _proto._processAsyncOptimisticModuleImport = function _processAsyncOptimisticModuleImport(moduleImportPayload) {\n    var _this7 = this;\n    this._expectOperationLoader().load(moduleImportPayload.operationReference).then(function (operation) {\n      if (operation == null || _this7._state !== 'started') {\n        return;\n      }\n      var moduleImportOptimisticUpdates = _this7._processOptimisticModuleImport(operation, moduleImportPayload);\n      moduleImportOptimisticUpdates.forEach(function (update) {\n        return _this7._getPublishQueueAndSaveActor().applyUpdate(update);\n      });\n      if (_this7._optimisticUpdates == null) {\n        process.env.NODE_ENV !== \"production\" ? warning(false, 'OperationExecutor: Unexpected ModuleImport optimistic ' + 'update in operation %s.' + _this7._operation.request.node.params.name) : void 0;\n      } else {\n        var _this$_optimisticUpda;\n        (_this$_optimisticUpda = _this7._optimisticUpdates).push.apply(_this$_optimisticUpda, (0, _toConsumableArray2[\"default\"])(moduleImportOptimisticUpdates));\n        _this7._runPublishQueue();\n      }\n    });\n  };\n  _proto._processResponses = function _processResponses(responses) {\n    var _this8 = this;\n    if (this._optimisticUpdates !== null) {\n      this._optimisticUpdates.forEach(function (update) {\n        _this8._getPublishQueueAndSaveActor().revertUpdate(update);\n      });\n      this._optimisticUpdates = null;\n    }\n    this._incrementalPayloadsPending = false;\n    this._incrementalResults.clear();\n    this._source.clear();\n    return responses.map(function (payloadPart) {\n      var relayPayload = _this8._normalizeResponse(payloadPart, _this8._operation.root, ROOT_TYPE, {\n        actorIdentifier: _this8._actorIdentifier,\n        getDataID: _this8._getDataID,\n        path: [],\n        treatMissingFieldsAsNull: _this8._treatMissingFieldsAsNull,\n        shouldProcessClientComponents: _this8._shouldProcessClientComponents\n      });\n      _this8._getPublishQueueAndSaveActor().commitPayload(_this8._operation, relayPayload, _this8._updater);\n      return relayPayload;\n    });\n  };\n  _proto._processPayloadFollowups = function _processPayloadFollowups(payloads) {\n    var _this9 = this;\n    if (this._state === 'completed') {\n      return;\n    }\n    payloads.forEach(function (payload) {\n      var incrementalPlaceholders = payload.incrementalPlaceholders,\n        followupPayloads = payload.followupPayloads,\n        isFinal = payload.isFinal;\n      _this9._state = isFinal ? 'loading_final' : 'loading_incremental';\n      _this9._updateActiveState();\n      if (isFinal) {\n        _this9._incrementalPayloadsPending = false;\n      }\n      if (followupPayloads && followupPayloads.length !== 0) {\n        followupPayloads.forEach(function (followupPayload) {\n          var _followupPayload$acto;\n          var prevActorIdentifier = _this9._actorIdentifier;\n          _this9._actorIdentifier = (_followupPayload$acto = followupPayload.actorIdentifier) !== null && _followupPayload$acto !== void 0 ? _followupPayload$acto : _this9._actorIdentifier;\n          _this9._processFollowupPayload(followupPayload);\n          _this9._actorIdentifier = prevActorIdentifier;\n        });\n      }\n      if (incrementalPlaceholders && incrementalPlaceholders.length !== 0) {\n        _this9._incrementalPayloadsPending = _this9._state !== 'loading_final';\n        incrementalPlaceholders.forEach(function (incrementalPlaceholder) {\n          var _incrementalPlacehold;\n          var prevActorIdentifier = _this9._actorIdentifier;\n          _this9._actorIdentifier = (_incrementalPlacehold = incrementalPlaceholder.actorIdentifier) !== null && _incrementalPlacehold !== void 0 ? _incrementalPlacehold : _this9._actorIdentifier;\n          _this9._processIncrementalPlaceholder(payload, incrementalPlaceholder);\n          _this9._actorIdentifier = prevActorIdentifier;\n        });\n        if (_this9._isClientPayload || _this9._state === 'loading_final') {\n          process.env.NODE_ENV !== \"production\" ? warning(_this9._isClientPayload, 'RelayModernEnvironment: Operation `%s` contains @defer/@stream ' + 'directives but was executed in non-streaming mode. See ' + 'https://fburl.com/relay-incremental-delivery-non-streaming-warning.', _this9._operation.request.node.params.name) : void 0;\n          var relayPayloads = [];\n          incrementalPlaceholders.forEach(function (placeholder) {\n            if (placeholder.kind === 'defer') {\n              relayPayloads.push(_this9._processDeferResponse(placeholder.label, placeholder.path, placeholder, {\n                data: placeholder.data\n              }));\n            }\n          });\n          if (relayPayloads.length > 0) {\n            _this9._processPayloadFollowups(relayPayloads);\n          }\n        }\n      }\n    });\n  };\n  _proto._maybeCompleteSubscriptionOperationTracking = function _maybeCompleteSubscriptionOperationTracking() {\n    if (!this._isSubscriptionOperation) {\n      return;\n    }\n    if (this._pendingModulePayloadsCount === 0 && this._incrementalPayloadsPending === false) {\n      this._completeOperationTracker();\n    }\n  };\n  _proto._processFollowupPayload = function _processFollowupPayload(followupPayload) {\n    var _this10 = this;\n    switch (followupPayload.kind) {\n      case 'ModuleImportPayload':\n        var operationLoader = this._expectOperationLoader();\n        var node = operationLoader.get(followupPayload.operationReference);\n        if (node != null) {\n          this._processFollowupPayloadWithNormalizationNode(followupPayload, getOperation(node));\n        } else {\n          var id = this._nextSubscriptionId++;\n          this._pendingModulePayloadsCount++;\n          var decrementPendingCount = function decrementPendingCount() {\n            _this10._pendingModulePayloadsCount--;\n            _this10._maybeCompleteSubscriptionOperationTracking();\n          };\n          var networkObservable = RelayObservable.from(new Promise(function (resolve, reject) {\n            operationLoader.load(followupPayload.operationReference).then(resolve, reject);\n          }));\n          RelayObservable.create(function (sink) {\n            var cancellationToken;\n            var subscription = networkObservable.subscribe({\n              next: function next(loadedNode) {\n                if (loadedNode != null) {\n                  var publishModuleImportPayload = function publishModuleImportPayload() {\n                    try {\n                      var operation = getOperation(loadedNode);\n                      var batchAsyncModuleUpdatesFN = RelayFeatureFlags.BATCH_ASYNC_MODULE_UPDATES_FN;\n                      var shouldScheduleAsyncStoreUpdate = batchAsyncModuleUpdatesFN != null && _this10._pendingModulePayloadsCount > 1;\n                      var _withDuration2 = withDuration(function () {\n                          _this10._handleFollowupPayload(followupPayload, operation);\n                          if (shouldScheduleAsyncStoreUpdate) {\n                            _this10._scheduleAsyncStoreUpdate(batchAsyncModuleUpdatesFN, sink.complete);\n                          } else {\n                            var updatedOwners = _this10._runPublishQueue();\n                            _this10._updateOperationTracker(updatedOwners);\n                          }\n                        }),\n                        duration = _withDuration2[0];\n                      _this10._log({\n                        name: 'execute.async.module',\n                        executeId: _this10._executeId,\n                        operationName: operation.name,\n                        duration: duration\n                      });\n                      if (!shouldScheduleAsyncStoreUpdate) {\n                        sink.complete();\n                      }\n                    } catch (error) {\n                      sink.error(error);\n                    }\n                  };\n                  var scheduler = _this10._scheduler;\n                  if (scheduler == null) {\n                    publishModuleImportPayload();\n                  } else {\n                    cancellationToken = scheduler.schedule(publishModuleImportPayload);\n                  }\n                } else {\n                  sink.complete();\n                }\n              },\n              error: sink.error\n            });\n            return function () {\n              subscription.unsubscribe();\n              if (_this10._scheduler != null && cancellationToken != null) {\n                _this10._scheduler.cancel(cancellationToken);\n              }\n            };\n          }).subscribe({\n            complete: function complete() {\n              _this10._complete(id);\n              decrementPendingCount();\n            },\n            error: function error(_error4) {\n              _this10._error(_error4);\n              decrementPendingCount();\n            },\n            start: function start(subscription) {\n              return _this10._start(id, subscription);\n            }\n          });\n        }\n        break;\n      case 'ActorPayload':\n        this._processFollowupPayloadWithNormalizationNode(followupPayload, followupPayload.node);\n        break;\n      default:\n        followupPayload;\n        !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Unexpected followup kind `%s`.', followupPayload.kind) : invariant(false) : void 0;\n    }\n  };\n  _proto._processFollowupPayloadWithNormalizationNode = function _processFollowupPayloadWithNormalizationNode(followupPayload, normalizationNode) {\n    this._handleFollowupPayload(followupPayload, normalizationNode);\n    this._maybeCompleteSubscriptionOperationTracking();\n  };\n  _proto._handleFollowupPayload = function _handleFollowupPayload(followupPayload, normalizationNode) {\n    var relayPayload = this._normalizeFollowupPayload(followupPayload, normalizationNode);\n    this._getPublishQueueAndSaveActor().commitPayload(this._operation, relayPayload);\n    this._processPayloadFollowups([relayPayload]);\n  };\n  _proto._processIncrementalPlaceholder = function _processIncrementalPlaceholder(relayPayload, placeholder) {\n    var _relayPayload$fieldPa;\n    var label = placeholder.label,\n      path = placeholder.path;\n    var pathKey = path.map(String).join('.');\n    var resultForLabel = this._incrementalResults.get(label);\n    if (resultForLabel == null) {\n      resultForLabel = new Map();\n      this._incrementalResults.set(label, resultForLabel);\n    }\n    var resultForPath = resultForLabel.get(pathKey);\n    var pendingResponses = resultForPath != null && resultForPath.kind === 'response' ? resultForPath.responses : null;\n    resultForLabel.set(pathKey, {\n      kind: 'placeholder',\n      placeholder: placeholder\n    });\n    var parentID;\n    if (placeholder.kind === 'stream') {\n      parentID = placeholder.parentID;\n    } else if (placeholder.kind === 'defer') {\n      parentID = placeholder.selector.dataID;\n    } else {\n      placeholder;\n      !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Unsupported incremental placeholder kind `%s`.', placeholder.kind) : invariant(false) : void 0;\n    }\n    var parentRecord = relayPayload.source.get(parentID);\n    var parentPayloads = ((_relayPayload$fieldPa = relayPayload.fieldPayloads) !== null && _relayPayload$fieldPa !== void 0 ? _relayPayload$fieldPa : []).filter(function (fieldPayload) {\n      var fieldID = generateClientID(fieldPayload.dataID, fieldPayload.fieldKey);\n      return fieldPayload.dataID === parentID || fieldID === parentID;\n    });\n    !(parentRecord != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected record `%s` to exist.', parentID) : invariant(false) : void 0;\n    var nextParentRecord;\n    var nextParentPayloads;\n    var previousParentEntry = this._source.get(parentID);\n    if (previousParentEntry != null) {\n      nextParentRecord = RelayModernRecord.update(previousParentEntry.record, parentRecord);\n      var handlePayloads = new Map();\n      var dedupePayload = function dedupePayload(payload) {\n        var key = stableStringify(payload);\n        handlePayloads.set(key, payload);\n      };\n      previousParentEntry.fieldPayloads.forEach(dedupePayload);\n      parentPayloads.forEach(dedupePayload);\n      nextParentPayloads = Array.from(handlePayloads.values());\n    } else {\n      nextParentRecord = parentRecord;\n      nextParentPayloads = parentPayloads;\n    }\n    this._source.set(parentID, {\n      record: nextParentRecord,\n      fieldPayloads: nextParentPayloads\n    });\n    if (pendingResponses != null) {\n      var payloadFollowups = this._processIncrementalResponses(pendingResponses);\n      this._processPayloadFollowups(payloadFollowups);\n    }\n  };\n  _proto._processIncrementalResponses = function _processIncrementalResponses(incrementalResponses) {\n    var _this11 = this;\n    var relayPayloads = [];\n    incrementalResponses.forEach(function (incrementalResponse) {\n      var label = incrementalResponse.label,\n        path = incrementalResponse.path,\n        response = incrementalResponse.response;\n      var resultForLabel = _this11._incrementalResults.get(label);\n      if (resultForLabel == null) {\n        resultForLabel = new Map();\n        _this11._incrementalResults.set(label, resultForLabel);\n      }\n      if (label.indexOf('$defer$') !== -1) {\n        var pathKey = path.map(String).join('.');\n        var resultForPath = resultForLabel.get(pathKey);\n        if (resultForPath == null) {\n          resultForPath = {\n            kind: 'response',\n            responses: [incrementalResponse]\n          };\n          resultForLabel.set(pathKey, resultForPath);\n          return;\n        } else if (resultForPath.kind === 'response') {\n          resultForPath.responses.push(incrementalResponse);\n          return;\n        }\n        var placeholder = resultForPath.placeholder;\n        !(placeholder.kind === 'defer') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected data for path `%s` for label `%s` ' + 'to be data for @defer, was `@%s`.', pathKey, label, placeholder.kind) : invariant(false) : void 0;\n        relayPayloads.push(_this11._processDeferResponse(label, path, placeholder, response));\n      } else {\n        var _pathKey = path.slice(0, -2).map(String).join('.');\n        var _resultForPath = resultForLabel.get(_pathKey);\n        if (_resultForPath == null) {\n          _resultForPath = {\n            kind: 'response',\n            responses: [incrementalResponse]\n          };\n          resultForLabel.set(_pathKey, _resultForPath);\n          return;\n        } else if (_resultForPath.kind === 'response') {\n          _resultForPath.responses.push(incrementalResponse);\n          return;\n        }\n        var _placeholder = _resultForPath.placeholder;\n        !(_placeholder.kind === 'stream') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected data for path `%s` for label `%s` ' + 'to be data for @stream, was `@%s`.', _pathKey, label, _placeholder.kind) : invariant(false) : void 0;\n        relayPayloads.push(_this11._processStreamResponse(label, path, _placeholder, response));\n      }\n    });\n    return relayPayloads;\n  };\n  _proto._processDeferResponse = function _processDeferResponse(label, path, placeholder, response) {\n    var _placeholder$actorIde;\n    var parentID = placeholder.selector.dataID;\n    var prevActorIdentifier = this._actorIdentifier;\n    this._actorIdentifier = (_placeholder$actorIde = placeholder.actorIdentifier) !== null && _placeholder$actorIde !== void 0 ? _placeholder$actorIde : this._actorIdentifier;\n    var relayPayload = this._normalizeResponse(response, placeholder.selector, placeholder.typeName, {\n      actorIdentifier: this._actorIdentifier,\n      getDataID: this._getDataID,\n      path: placeholder.path,\n      treatMissingFieldsAsNull: this._treatMissingFieldsAsNull,\n      shouldProcessClientComponents: this._shouldProcessClientComponents\n    });\n    this._getPublishQueueAndSaveActor().commitPayload(this._operation, relayPayload);\n    var parentEntry = this._source.get(parentID);\n    !(parentEntry != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected the parent record `%s` for @defer ' + 'data to exist.', parentID) : invariant(false) : void 0;\n    var fieldPayloads = parentEntry.fieldPayloads;\n    if (fieldPayloads.length !== 0) {\n      var _response$extensions2;\n      var handleFieldsRelayPayload = {\n        errors: null,\n        fieldPayloads: fieldPayloads,\n        incrementalPlaceholders: null,\n        followupPayloads: null,\n        source: RelayRecordSource.create(),\n        isFinal: ((_response$extensions2 = response.extensions) === null || _response$extensions2 === void 0 ? void 0 : _response$extensions2.is_final) === true\n      };\n      this._getPublishQueueAndSaveActor().commitPayload(this._operation, handleFieldsRelayPayload);\n    }\n    this._actorIdentifier = prevActorIdentifier;\n    return relayPayload;\n  };\n  _proto._processStreamResponse = function _processStreamResponse(label, path, placeholder, response) {\n    var parentID = placeholder.parentID,\n      node = placeholder.node,\n      variables = placeholder.variables,\n      actorIdentifier = placeholder.actorIdentifier;\n    var prevActorIdentifier = this._actorIdentifier;\n    this._actorIdentifier = actorIdentifier !== null && actorIdentifier !== void 0 ? actorIdentifier : this._actorIdentifier;\n    var field = node.selections[0];\n    !(field != null && field.kind === 'LinkedField' && field.plural === true) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected @stream to be used on a plural field.') : invariant(false) : void 0;\n    var _this$_normalizeStrea = this._normalizeStreamItem(response, parentID, field, variables, path, placeholder.path),\n      fieldPayloads = _this$_normalizeStrea.fieldPayloads,\n      itemID = _this$_normalizeStrea.itemID,\n      itemIndex = _this$_normalizeStrea.itemIndex,\n      prevIDs = _this$_normalizeStrea.prevIDs,\n      relayPayload = _this$_normalizeStrea.relayPayload,\n      storageKey = _this$_normalizeStrea.storageKey;\n    this._getPublishQueueAndSaveActor().commitPayload(this._operation, relayPayload, function (store) {\n      var currentParentRecord = store.get(parentID);\n      if (currentParentRecord == null) {\n        return;\n      }\n      var currentItems = currentParentRecord.getLinkedRecords(storageKey);\n      if (currentItems == null) {\n        return;\n      }\n      if (currentItems.length !== prevIDs.length || currentItems.some(function (currentItem, index) {\n        return prevIDs[index] !== (currentItem && currentItem.getDataID());\n      })) {\n        return;\n      }\n      var nextItems = (0, _toConsumableArray2[\"default\"])(currentItems);\n      nextItems[itemIndex] = store.get(itemID);\n      currentParentRecord.setLinkedRecords(nextItems, storageKey);\n    });\n    if (fieldPayloads.length !== 0) {\n      var handleFieldsRelayPayload = {\n        errors: null,\n        fieldPayloads: fieldPayloads,\n        incrementalPlaceholders: null,\n        followupPayloads: null,\n        source: RelayRecordSource.create(),\n        isFinal: false\n      };\n      this._getPublishQueueAndSaveActor().commitPayload(this._operation, handleFieldsRelayPayload);\n    }\n    this._actorIdentifier = prevActorIdentifier;\n    return relayPayload;\n  };\n  _proto._normalizeStreamItem = function _normalizeStreamItem(response, parentID, field, variables, path, normalizationPath) {\n    var _field$alias, _field$concreteType, _ref, _this$_getDataID;\n    var data = response.data;\n    !(typeof data === 'object') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected the GraphQL @stream payload `data` ' + 'value to be an object.') : invariant(false) : void 0;\n    var responseKey = (_field$alias = field.alias) !== null && _field$alias !== void 0 ? _field$alias : field.name;\n    var storageKey = getStorageKey(field, variables);\n    var parentEntry = this._source.get(parentID);\n    !(parentEntry != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected the parent record `%s` for @stream ' + 'data to exist.', parentID) : invariant(false) : void 0;\n    var parentRecord = parentEntry.record,\n      fieldPayloads = parentEntry.fieldPayloads;\n    var prevIDs = RelayModernRecord.getLinkedRecordIDs(parentRecord, storageKey);\n    !(prevIDs != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected record `%s` to have fetched field ' + '`%s` with @stream.', parentID, field.name) : invariant(false) : void 0;\n    var finalPathEntry = path[path.length - 1];\n    var itemIndex = parseInt(finalPathEntry, 10);\n    !(itemIndex === finalPathEntry && itemIndex >= 0) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected path for @stream to end in a ' + 'positive integer index, got `%s`', finalPathEntry) : invariant(false) : void 0;\n    var typeName = (_field$concreteType = field.concreteType) !== null && _field$concreteType !== void 0 ? _field$concreteType : data[TYPENAME_KEY];\n    !(typeof typeName === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected @stream field `%s` to have a ' + '__typename.', field.name) : invariant(false) : void 0;\n    var itemID = (_ref = (_this$_getDataID = this._getDataID(data, typeName)) !== null && _this$_getDataID !== void 0 ? _this$_getDataID : prevIDs === null || prevIDs === void 0 ? void 0 : prevIDs[itemIndex]) !== null && _ref !== void 0 ? _ref : generateClientID(parentID, storageKey, itemIndex);\n    !(typeof itemID === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected id of elements of field `%s` to ' + 'be strings.', storageKey) : invariant(false) : void 0;\n    var selector = createNormalizationSelector(field, itemID, variables);\n    var nextParentRecord = RelayModernRecord.clone(parentRecord);\n    var nextIDs = (0, _toConsumableArray2[\"default\"])(prevIDs);\n    nextIDs[itemIndex] = itemID;\n    RelayModernRecord.setLinkedRecordIDs(nextParentRecord, storageKey, nextIDs);\n    this._source.set(parentID, {\n      record: nextParentRecord,\n      fieldPayloads: fieldPayloads\n    });\n    var relayPayload = this._normalizeResponse(response, selector, typeName, {\n      actorIdentifier: this._actorIdentifier,\n      getDataID: this._getDataID,\n      path: [].concat((0, _toConsumableArray2[\"default\"])(normalizationPath), [responseKey, String(itemIndex)]),\n      treatMissingFieldsAsNull: this._treatMissingFieldsAsNull,\n      shouldProcessClientComponents: this._shouldProcessClientComponents\n    });\n    return {\n      fieldPayloads: fieldPayloads,\n      itemID: itemID,\n      itemIndex: itemIndex,\n      prevIDs: prevIDs,\n      relayPayload: relayPayload,\n      storageKey: storageKey\n    };\n  };\n  _proto._scheduleAsyncStoreUpdate = function _scheduleAsyncStoreUpdate(scheduleFn, completeFn) {\n    var _this12 = this;\n    this._completeFns.push(completeFn);\n    if (this._asyncStoreUpdateDisposable != null) {\n      return;\n    }\n    this._asyncStoreUpdateDisposable = scheduleFn(function () {\n      _this12._asyncStoreUpdateDisposable = null;\n      var updatedOwners = _this12._runPublishQueue();\n      _this12._updateOperationTracker(updatedOwners);\n      var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(_this12._completeFns),\n        _step2;\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var complete = _step2.value;\n          complete();\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n      _this12._completeFns = [];\n    });\n  };\n  _proto._updateOperationTracker = function _updateOperationTracker(updatedOwners) {\n    if (updatedOwners != null && updatedOwners.length > 0) {\n      this._operationTracker.update(this._operation.request, new Set(updatedOwners));\n    }\n  };\n  _proto._completeOperationTracker = function _completeOperationTracker() {\n    this._operationTracker.complete(this._operation.request);\n  };\n  _proto._getPublishQueueAndSaveActor = function _getPublishQueueAndSaveActor() {\n    this._seenActors.add(this._actorIdentifier);\n    return this._getPublishQueue(this._actorIdentifier);\n  };\n  _proto._getActorsToVisit = function _getActorsToVisit() {\n    if (this._seenActors.size === 0) {\n      return new Set([this._actorIdentifier]);\n    } else {\n      return this._seenActors;\n    }\n  };\n  _proto._runPublishQueue = function _runPublishQueue(operation) {\n    var updatedOwners = new Set();\n    var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])(this._getActorsToVisit()),\n      _step3;\n    try {\n      for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n        var actorIdentifier = _step3.value;\n        var owners = this._getPublishQueue(actorIdentifier).run(operation);\n        owners.forEach(function (owner) {\n          return updatedOwners.add(owner);\n        });\n      }\n    } catch (err) {\n      _iterator3.e(err);\n    } finally {\n      _iterator3.f();\n    }\n    return Array.from(updatedOwners);\n  };\n  _proto._retainData = function _retainData() {\n    var _iterator4 = (0, _createForOfIteratorHelper2[\"default\"])(this._getActorsToVisit()),\n      _step4;\n    try {\n      for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n        var actorIdentifier = _step4.value;\n        if (!this._retainDisposables.has(actorIdentifier)) {\n          this._retainDisposables.set(actorIdentifier, this._getStore(actorIdentifier).retain(this._operation));\n        }\n      }\n    } catch (err) {\n      _iterator4.e(err);\n    } finally {\n      _iterator4.f();\n    }\n  };\n  _proto._disposeRetainedData = function _disposeRetainedData() {\n    var _iterator5 = (0, _createForOfIteratorHelper2[\"default\"])(this._retainDisposables.values()),\n      _step5;\n    try {\n      for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n        var disposable = _step5.value;\n        disposable.dispose();\n      }\n    } catch (err) {\n      _iterator5.e(err);\n    } finally {\n      _iterator5.f();\n    }\n    this._retainDisposables.clear();\n  };\n  _proto._expectOperationLoader = function _expectOperationLoader() {\n    var operationLoader = this._operationLoader;\n    !operationLoader ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: Expected an operationLoader to be ' + 'configured when using `@match`.') : invariant(false) : void 0;\n    return operationLoader;\n  };\n  return Executor;\n}();\nfunction partitionGraphQLResponses(responses) {\n  var nonIncrementalResponses = [];\n  var incrementalResponses = [];\n  responses.forEach(function (response) {\n    if (response.path != null || response.label != null) {\n      var label = response.label,\n        path = response.path;\n      if (label == null || path == null) {\n        !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: invalid incremental payload, expected ' + '`path` and `label` to either both be null/undefined, or ' + '`path` to be an `Array<string | number>` and `label` to be a ' + '`string`.') : invariant(false) : void 0;\n      }\n      incrementalResponses.push({\n        label: label,\n        path: path,\n        response: response\n      });\n    } else {\n      nonIncrementalResponses.push(response);\n    }\n  });\n  return [nonIncrementalResponses, incrementalResponses];\n}\nfunction stableStringify(value) {\n  var _JSON$stringify;\n  return (_JSON$stringify = JSON.stringify(stableCopy(value))) !== null && _JSON$stringify !== void 0 ? _JSON$stringify : '';\n}\nfunction validateOptimisticResponsePayload(payload) {\n  var incrementalPlaceholders = payload.incrementalPlaceholders;\n  if (incrementalPlaceholders != null && incrementalPlaceholders.length !== 0) {\n    !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'OperationExecutor: optimistic responses cannot be returned ' + 'for operations that use incremental data delivery (@defer, ' + '@stream, and @stream_connection).') : invariant(false) : void 0;\n  }\n}\nmodule.exports = {\n  execute: execute\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar _require = require('./RelayStoreUtils'),\n  getArgumentValues = _require.getArgumentValues;\nvar invariant = require('invariant');\nfunction getFragmentVariables(fragment, rootVariables, argumentVariables) {\n  if (fragment.argumentDefinitions == null) {\n    return argumentVariables;\n  }\n  var variables;\n  fragment.argumentDefinitions.forEach(function (definition) {\n    if (argumentVariables.hasOwnProperty(definition.name)) {\n      return;\n    }\n    variables = variables || (0, _objectSpread2[\"default\"])({}, argumentVariables);\n    switch (definition.kind) {\n      case 'LocalArgument':\n        variables[definition.name] = definition.defaultValue;\n        break;\n      case 'RootArgument':\n        if (!rootVariables.hasOwnProperty(definition.name)) {\n          variables[definition.name] = undefined;\n          break;\n        }\n        variables[definition.name] = rootVariables[definition.name];\n        break;\n      default:\n        definition;\n        !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayConcreteVariables: Unexpected node kind `%s` in fragment `%s`.', definition.kind, fragment.name) : invariant(false) : void 0;\n    }\n  });\n  return variables || argumentVariables;\n}\nfunction getOperationVariables(operation, providedVariables, variables) {\n  var operationVariables = {};\n  operation.argumentDefinitions.forEach(function (def) {\n    var value = def.defaultValue;\n    if (variables[def.name] != null) {\n      value = variables[def.name];\n    }\n    operationVariables[def.name] = value;\n  });\n  if (providedVariables != null) {\n    Object.keys(providedVariables).forEach(function (varName) {\n      operationVariables[varName] = providedVariables[varName].get();\n    });\n  }\n  return operationVariables;\n}\nfunction getLocalVariables(currentVariables, argumentDefinitions, args) {\n  if (argumentDefinitions == null) {\n    return currentVariables;\n  }\n  var nextVariables = (0, _objectSpread2[\"default\"])({}, currentVariables);\n  var nextArgs = args ? getArgumentValues(args, currentVariables) : {};\n  argumentDefinitions.forEach(function (def) {\n    var _nextArgs$def$name;\n    var value = (_nextArgs$def$name = nextArgs[def.name]) !== null && _nextArgs$def$name !== void 0 ? _nextArgs$def$name : def.defaultValue;\n    nextVariables[def.name] = value;\n  });\n  return nextVariables;\n}\nmodule.exports = {\n  getLocalVariables: getLocalVariables,\n  getFragmentVariables: getFragmentVariables,\n  getOperationVariables: getOperationVariables\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar _objectWithoutPropertiesLoose2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectWithoutPropertiesLoose\"));\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _inheritsLoose2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inheritsLoose\"));\nvar _wrapNativeSuper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/wrapNativeSuper\"));\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar _excluded = [\"path\", \"locations\"];\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar SELF = Symbol('$SELF');\nvar RelayFieldError = /*#__PURE__*/function (_Error) {\n  (0, _inheritsLoose2[\"default\"])(RelayFieldError, _Error);\n  function RelayFieldError(message) {\n    var _this;\n    var errors = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n    _this = _Error.call(this, message) || this;\n    _this.name = 'RelayFieldError';\n    _this.message = message;\n    _this.errors = errors;\n    return _this;\n  }\n  return RelayFieldError;\n}( /*#__PURE__*/(0, _wrapNativeSuper2[\"default\"])(Error));\nfunction buildErrorTrie(errors) {\n  if (errors == null) {\n    return null;\n  }\n  if (!RelayFeatureFlags.ENABLE_FIELD_ERROR_HANDLING) {\n    return null;\n  }\n  var trie = new Map();\n  var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(errors),\n    _step;\n  try {\n    ERRORS: for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var _step$value = _step.value,\n        path = _step$value.path,\n        _ = _step$value.locations,\n        error = (0, _objectWithoutPropertiesLoose2[\"default\"])(_step$value, _excluded);\n      if (path == null) {\n        continue;\n      }\n      var length = path.length;\n      if (length === 0) {\n        continue;\n      }\n      var lastIndex = length - 1;\n      var currentTrie = trie;\n      for (var index = 0; index < lastIndex; index++) {\n        var key = path[index];\n        var existingValue = currentTrie.get(key);\n        if (existingValue instanceof Map) {\n          currentTrie = existingValue;\n          continue;\n        }\n        var newValue = new Map();\n        if (Array.isArray(existingValue)) {\n          newValue.set(SELF, existingValue);\n        }\n        currentTrie.set(key, newValue);\n        currentTrie = newValue;\n      }\n      var lastKey = path[lastIndex];\n      var container = currentTrie.get(lastKey);\n      if (container instanceof Map) {\n        currentTrie = container;\n        container = currentTrie.get(lastKey);\n        lastKey = SELF;\n      }\n      if (Array.isArray(container)) {\n        container.push(error);\n      } else {\n        currentTrie.set(lastKey, [error]);\n      }\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n  return trie;\n}\nfunction getErrorsByKey(trie, key) {\n  var value = trie.get(key);\n  if (value == null) {\n    return null;\n  }\n  if (Array.isArray(value)) {\n    return value;\n  }\n  var errors = [];\n  recursivelyCopyErrorsIntoArray(value, errors);\n  return errors;\n}\nfunction recursivelyCopyErrorsIntoArray(trieOrSet, errors) {\n  var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(trieOrSet),\n    _step2;\n  try {\n    for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n      var _step2$value = _step2.value,\n        childKey = _step2$value[0],\n        value = _step2$value[1];\n      var oldLength = errors.length;\n      if (Array.isArray(value)) {\n        errors.push.apply(errors, (0, _toConsumableArray2[\"default\"])(value));\n      } else {\n        recursivelyCopyErrorsIntoArray(value, errors);\n      }\n      if (childKey === SELF) {\n        continue;\n      }\n      var newLength = errors.length;\n      for (var index = oldLength; index < newLength; index++) {\n        var error = errors[index];\n        if (error.path == null) {\n          errors[index] = (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, error), {}, {\n            path: [childKey]\n          });\n        } else {\n          error.path.unshift(childKey);\n        }\n      }\n    }\n  } catch (err) {\n    _iterator2.e(err);\n  } finally {\n    _iterator2.f();\n  }\n}\nfunction getNestedErrorTrieByKey(trie, key) {\n  var value = trie.get(key);\n  if (value instanceof Map) {\n    return value;\n  }\n  return null;\n}\nmodule.exports = {\n  SELF: SELF,\n  buildErrorTrie: buildErrorTrie,\n  getNestedErrorTrieByKey: getNestedErrorTrieByKey,\n  getErrorsByKey: getErrorsByKey,\n  RelayFieldError: RelayFieldError\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar RelayDefaultHandlerProvider = require('../handlers/RelayDefaultHandlerProvider');\nvar _require = require('../multi-actor-environment/ActorIdentifier'),\n  INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE = _require.INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE,\n  assertInternalActorIdentifier = _require.assertInternalActorIdentifier;\nvar RelayObservable = require('../network/RelayObservable');\nvar wrapNetworkWithLogObserver = require('../network/wrapNetworkWithLogObserver');\nvar RelayOperationTracker = require('../store/RelayOperationTracker');\nvar registerEnvironmentWithDevTools = require('../util/registerEnvironmentWithDevTools');\nvar defaultGetDataID = require('./defaultGetDataID');\nvar defaultRelayFieldLogger = require('./defaultRelayFieldLogger');\nvar normalizeResponse = require('./normalizeResponse');\nvar OperationExecutor = require('./OperationExecutor');\nvar RelayPublishQueue = require('./RelayPublishQueue');\nvar RelayRecordSource = require('./RelayRecordSource');\nvar invariant = require('invariant');\nvar RelayModernEnvironment = /*#__PURE__*/function () {\n  function RelayModernEnvironment(config) {\n    var _this = this;\n    var _config$log, _config$relayFieldLog, _config$UNSTABLE_defa, _config$getDataID, _config$missingFieldH, _config$handlerProvid, _config$scheduler, _config$isServer, _config$normalizeResp, _config$operationTrac;\n    this.configName = config.configName;\n    this._treatMissingFieldsAsNull = config.treatMissingFieldsAsNull === true;\n    var operationLoader = config.operationLoader;\n    if (process.env.NODE_ENV !== \"production\") {\n      if (operationLoader != null) {\n        !(typeof operationLoader === 'object' && typeof operationLoader.get === 'function' && typeof operationLoader.load === 'function') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernEnvironment: Expected `operationLoader` to be an object ' + 'with get() and load() functions, got `%s`.', operationLoader) : invariant(false) : void 0;\n      }\n    }\n    this.__log = (_config$log = config.log) !== null && _config$log !== void 0 ? _config$log : emptyFunction;\n    this.relayFieldLogger = (_config$relayFieldLog = config.relayFieldLogger) !== null && _config$relayFieldLog !== void 0 ? _config$relayFieldLog : defaultRelayFieldLogger;\n    this._defaultRenderPolicy = (_config$UNSTABLE_defa = config.UNSTABLE_defaultRenderPolicy) !== null && _config$UNSTABLE_defa !== void 0 ? _config$UNSTABLE_defa : 'partial';\n    this._operationLoader = operationLoader;\n    this._operationExecutions = new Map();\n    this._network = wrapNetworkWithLogObserver(this, config.network);\n    this._getDataID = (_config$getDataID = config.getDataID) !== null && _config$getDataID !== void 0 ? _config$getDataID : defaultGetDataID;\n    this._missingFieldHandlers = (_config$missingFieldH = config.missingFieldHandlers) !== null && _config$missingFieldH !== void 0 ? _config$missingFieldH : [];\n    this._publishQueue = new RelayPublishQueue(config.store, (_config$handlerProvid = config.handlerProvider) !== null && _config$handlerProvid !== void 0 ? _config$handlerProvid : RelayDefaultHandlerProvider, this._getDataID, this._missingFieldHandlers);\n    this._scheduler = (_config$scheduler = config.scheduler) !== null && _config$scheduler !== void 0 ? _config$scheduler : null;\n    this._store = config.store;\n    this.options = config.options;\n    this._isServer = (_config$isServer = config.isServer) !== null && _config$isServer !== void 0 ? _config$isServer : false;\n    this._normalizeResponse = (_config$normalizeResp = config.normalizeResponse) !== null && _config$normalizeResp !== void 0 ? _config$normalizeResp : normalizeResponse;\n    this.__setNet = function (newNet) {\n      return _this._network = wrapNetworkWithLogObserver(_this, newNet);\n    };\n    if (process.env.NODE_ENV !== \"production\") {\n      var _require2 = require('./StoreInspector'),\n        inspect = _require2.inspect;\n      this.DEBUG_inspect = function (dataID) {\n        return inspect(_this, dataID);\n      };\n    }\n    this._operationTracker = (_config$operationTrac = config.operationTracker) !== null && _config$operationTrac !== void 0 ? _config$operationTrac : new RelayOperationTracker();\n    this._shouldProcessClientComponents = config.shouldProcessClientComponents;\n    registerEnvironmentWithDevTools(this);\n  }\n  var _proto = RelayModernEnvironment.prototype;\n  _proto.getStore = function getStore() {\n    return this._store;\n  };\n  _proto.getNetwork = function getNetwork() {\n    return this._network;\n  };\n  _proto.getOperationTracker = function getOperationTracker() {\n    return this._operationTracker;\n  };\n  _proto.getScheduler = function getScheduler() {\n    return this._scheduler;\n  };\n  _proto.isRequestActive = function isRequestActive(requestIdentifier) {\n    var activeState = this._operationExecutions.get(requestIdentifier);\n    return activeState === 'active';\n  };\n  _proto.UNSTABLE_getDefaultRenderPolicy = function UNSTABLE_getDefaultRenderPolicy() {\n    return this._defaultRenderPolicy;\n  };\n  _proto.applyUpdate = function applyUpdate(optimisticUpdate) {\n    var _this2 = this;\n    var dispose = function dispose() {\n      _this2._scheduleUpdates(function () {\n        _this2._publishQueue.revertUpdate(optimisticUpdate);\n        _this2._publishQueue.run();\n      });\n    };\n    this._scheduleUpdates(function () {\n      _this2._publishQueue.applyUpdate(optimisticUpdate);\n      _this2._publishQueue.run();\n    });\n    return {\n      dispose: dispose\n    };\n  };\n  _proto.revertUpdate = function revertUpdate(update) {\n    var _this3 = this;\n    this._scheduleUpdates(function () {\n      _this3._publishQueue.revertUpdate(update);\n      _this3._publishQueue.run();\n    });\n  };\n  _proto.replaceUpdate = function replaceUpdate(update, newUpdate) {\n    var _this4 = this;\n    this._scheduleUpdates(function () {\n      _this4._publishQueue.revertUpdate(update);\n      _this4._publishQueue.applyUpdate(newUpdate);\n      _this4._publishQueue.run();\n    });\n  };\n  _proto.applyMutation = function applyMutation(optimisticConfig) {\n    var subscription = this._execute({\n      createSource: function createSource() {\n        return RelayObservable.create(function (_sink) {});\n      },\n      isClientPayload: false,\n      operation: optimisticConfig.operation,\n      optimisticConfig: optimisticConfig,\n      updater: null\n    }).subscribe({});\n    return {\n      dispose: function dispose() {\n        return subscription.unsubscribe();\n      }\n    };\n  };\n  _proto.check = function check(operation) {\n    if (this._missingFieldHandlers.length === 0 && !operationHasClientAbstractTypes(operation)) {\n      return this._store.check(operation);\n    }\n    return this._checkSelectorAndHandleMissingFields(operation, this._missingFieldHandlers);\n  };\n  _proto.commitPayload = function commitPayload(operation, payload) {\n    this._execute({\n      createSource: function createSource() {\n        return RelayObservable.from({\n          data: payload\n        });\n      },\n      isClientPayload: true,\n      operation: operation,\n      optimisticConfig: null,\n      updater: null\n    }).subscribe({});\n  };\n  _proto.commitUpdate = function commitUpdate(updater) {\n    var _this5 = this;\n    this._scheduleUpdates(function () {\n      _this5._publishQueue.commitUpdate(updater);\n      _this5._publishQueue.run();\n    });\n  };\n  _proto.lookup = function lookup(readSelector) {\n    return this._store.lookup(readSelector);\n  };\n  _proto.subscribe = function subscribe(snapshot, callback) {\n    return this._store.subscribe(snapshot, callback);\n  };\n  _proto.retain = function retain(operation) {\n    return this._store.retain(operation);\n  };\n  _proto.isServer = function isServer() {\n    return this._isServer;\n  };\n  _proto._checkSelectorAndHandleMissingFields = function _checkSelectorAndHandleMissingFields(operation, handlers) {\n    var _this6 = this;\n    var target = RelayRecordSource.create();\n    var source = this._store.getSource();\n    var result = this._store.check(operation, {\n      handlers: handlers,\n      defaultActorIdentifier: INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE,\n      getSourceForActor: function getSourceForActor(actorIdentifier) {\n        assertInternalActorIdentifier(actorIdentifier);\n        return source;\n      },\n      getTargetForActor: function getTargetForActor(actorIdentifier) {\n        assertInternalActorIdentifier(actorIdentifier);\n        return target;\n      }\n    });\n    if (target.size() > 0) {\n      this._scheduleUpdates(function () {\n        _this6._publishQueue.commitSource(target);\n        _this6._publishQueue.run();\n      });\n    }\n    return result;\n  };\n  _proto._scheduleUpdates = function _scheduleUpdates(task) {\n    var scheduler = this._scheduler;\n    if (scheduler != null) {\n      scheduler.schedule(task);\n    } else {\n      task();\n    }\n  };\n  _proto.execute = function execute(_ref) {\n    var _this7 = this;\n    var operation = _ref.operation;\n    return this._execute({\n      createSource: function createSource() {\n        return _this7.getNetwork().execute(operation.request.node.params, operation.request.variables, operation.request.cacheConfig || {}, null);\n      },\n      isClientPayload: false,\n      operation: operation,\n      optimisticConfig: null,\n      updater: null\n    });\n  };\n  _proto.executeSubscription = function executeSubscription(_ref2) {\n    var _this8 = this;\n    var operation = _ref2.operation,\n      updater = _ref2.updater;\n    return this._execute({\n      createSource: function createSource() {\n        return _this8.getNetwork().execute(operation.request.node.params, operation.request.variables, operation.request.cacheConfig || {}, null);\n      },\n      isClientPayload: false,\n      operation: operation,\n      optimisticConfig: null,\n      updater: updater\n    });\n  };\n  _proto.executeMutation = function executeMutation(_ref3) {\n    var _this9 = this;\n    var operation = _ref3.operation,\n      optimisticResponse = _ref3.optimisticResponse,\n      optimisticUpdater = _ref3.optimisticUpdater,\n      updater = _ref3.updater,\n      uploadables = _ref3.uploadables;\n    var optimisticConfig;\n    if (optimisticResponse || optimisticUpdater) {\n      optimisticConfig = {\n        operation: operation,\n        response: optimisticResponse,\n        updater: optimisticUpdater\n      };\n    }\n    return this._execute({\n      createSource: function createSource() {\n        return _this9.getNetwork().execute(operation.request.node.params, operation.request.variables, (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, operation.request.cacheConfig), {}, {\n          force: true\n        }), uploadables);\n      },\n      isClientPayload: false,\n      operation: operation,\n      optimisticConfig: optimisticConfig,\n      updater: updater\n    });\n  };\n  _proto.executeWithSource = function executeWithSource(_ref4) {\n    var operation = _ref4.operation,\n      source = _ref4.source;\n    return this._execute({\n      createSource: function createSource() {\n        return source;\n      },\n      isClientPayload: false,\n      operation: operation,\n      optimisticConfig: null,\n      updater: null\n    });\n  };\n  _proto.toJSON = function toJSON() {\n    var _this$configName;\n    return \"RelayModernEnvironment(\".concat((_this$configName = this.configName) !== null && _this$configName !== void 0 ? _this$configName : '', \")\");\n  };\n  _proto._execute = function _execute(_ref5) {\n    var _this10 = this;\n    var createSource = _ref5.createSource,\n      isClientPayload = _ref5.isClientPayload,\n      operation = _ref5.operation,\n      optimisticConfig = _ref5.optimisticConfig,\n      updater = _ref5.updater;\n    var publishQueue = this._publishQueue;\n    var store = this._store;\n    return RelayObservable.create(function (sink) {\n      var executor = OperationExecutor.execute({\n        actorIdentifier: INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE,\n        getDataID: _this10._getDataID,\n        isClientPayload: isClientPayload,\n        log: _this10.__log,\n        operation: operation,\n        operationExecutions: _this10._operationExecutions,\n        operationLoader: _this10._operationLoader,\n        operationTracker: _this10._operationTracker,\n        optimisticConfig: optimisticConfig,\n        getPublishQueue: function getPublishQueue(actorIdentifier) {\n          assertInternalActorIdentifier(actorIdentifier);\n          return publishQueue;\n        },\n        scheduler: _this10._scheduler,\n        shouldProcessClientComponents: _this10._shouldProcessClientComponents,\n        sink: sink,\n        source: createSource(),\n        getStore: function getStore(actorIdentifier) {\n          assertInternalActorIdentifier(actorIdentifier);\n          return store;\n        },\n        treatMissingFieldsAsNull: _this10._treatMissingFieldsAsNull,\n        updater: updater,\n        normalizeResponse: _this10._normalizeResponse\n      });\n      return function () {\n        return executor.cancel();\n      };\n    });\n  };\n  return RelayModernEnvironment;\n}();\nfunction operationHasClientAbstractTypes(operation) {\n  return operation.root.node.kind === 'Operation' && operation.root.node.clientAbstractTypes != null;\n}\nRelayModernEnvironment.prototype['@@RelayModernEnvironment'] = true;\nfunction emptyFunction() {}\nmodule.exports = RelayModernEnvironment;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar getPendingOperationsForFragment = require('../util/getPendingOperationsForFragment');\nvar handlePotentialSnapshotErrors = require('../util/handlePotentialSnapshotErrors');\nvar isScalarAndEqual = require('../util/isScalarAndEqual');\nvar recycleNodesInto = require('../util/recycleNodesInto');\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar _require = require('./RelayModernOperationDescriptor'),\n  createRequestDescriptor = _require.createRequestDescriptor;\nvar _require2 = require('./RelayModernSelector'),\n  areEqualSelectors = _require2.areEqualSelectors,\n  createReaderSelector = _require2.createReaderSelector,\n  getSelectorsFromObject = _require2.getSelectorsFromObject;\nvar areEqual = require(\"fbjs/lib/areEqual\");\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nvar RelayModernFragmentSpecResolver = /*#__PURE__*/function () {\n  function RelayModernFragmentSpecResolver(context, fragments, props, callback, rootIsQueryRenderer) {\n    var _this = this;\n    (0, _defineProperty2[\"default\"])(this, \"_onChange\", function () {\n      _this._stale = true;\n      if (typeof _this._callback === 'function') {\n        _this._callback();\n      }\n    });\n    this._callback = callback;\n    this._context = context;\n    this._data = {};\n    this._fragments = fragments;\n    this._props = {};\n    this._resolvers = {};\n    this._stale = false;\n    this._rootIsQueryRenderer = rootIsQueryRenderer;\n    this.setProps(props);\n  }\n  var _proto = RelayModernFragmentSpecResolver.prototype;\n  _proto.dispose = function dispose() {\n    for (var key in this._resolvers) {\n      if (this._resolvers.hasOwnProperty(key)) {\n        disposeCallback(this._resolvers[key]);\n      }\n    }\n  };\n  _proto.resolve = function resolve() {\n    if (this._stale) {\n      var prevData = this._data;\n      var nextData;\n      for (var key in this._resolvers) {\n        if (this._resolvers.hasOwnProperty(key)) {\n          var resolver = this._resolvers[key];\n          var prevItem = prevData[key];\n          if (resolver) {\n            var nextItem = resolver.resolve();\n            if (nextData || nextItem !== prevItem) {\n              nextData = nextData || (0, _objectSpread2[\"default\"])({}, prevData);\n              nextData[key] = nextItem;\n            }\n          } else {\n            var prop = this._props[key];\n            var _nextItem = prop !== undefined ? prop : null;\n            if (nextData || !isScalarAndEqual(_nextItem, prevItem)) {\n              nextData = nextData || (0, _objectSpread2[\"default\"])({}, prevData);\n              nextData[key] = _nextItem;\n            }\n          }\n        }\n      }\n      this._data = nextData || prevData;\n      this._stale = false;\n    }\n    return this._data;\n  };\n  _proto.setCallback = function setCallback(props, callback) {\n    this._callback = callback;\n    if (RelayFeatureFlags.ENABLE_CONTAINERS_SUBSCRIBE_ON_COMMIT === true) {\n      this.setProps(props);\n    }\n  };\n  _proto.setProps = function setProps(props) {\n    this._props = {};\n    var ownedSelectors = getSelectorsFromObject(this._fragments, props);\n    for (var key in ownedSelectors) {\n      if (ownedSelectors.hasOwnProperty(key)) {\n        var ownedSelector = ownedSelectors[key];\n        var resolver = this._resolvers[key];\n        if (ownedSelector == null) {\n          if (resolver != null) {\n            resolver.dispose();\n          }\n          resolver = null;\n        } else if (ownedSelector.kind === 'PluralReaderSelector') {\n          if (resolver == null) {\n            resolver = new SelectorListResolver(this._context.environment, this._rootIsQueryRenderer, ownedSelector, this._callback != null, this._onChange);\n          } else {\n            !(resolver instanceof SelectorListResolver) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernFragmentSpecResolver: Expected prop `%s` to always be an array.', key) : invariant(false) : void 0;\n            resolver.setSelector(ownedSelector);\n          }\n        } else {\n          if (resolver == null) {\n            resolver = new SelectorResolver(this._context.environment, this._rootIsQueryRenderer, ownedSelector, this._callback != null, this._onChange);\n          } else {\n            !(resolver instanceof SelectorResolver) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernFragmentSpecResolver: Expected prop `%s` to always be an object.', key) : invariant(false) : void 0;\n            resolver.setSelector(ownedSelector);\n          }\n        }\n        this._props[key] = props[key];\n        this._resolvers[key] = resolver;\n      }\n    }\n    this._stale = true;\n  };\n  _proto.setVariables = function setVariables(variables, request) {\n    for (var key in this._resolvers) {\n      if (this._resolvers.hasOwnProperty(key)) {\n        var resolver = this._resolvers[key];\n        if (resolver) {\n          resolver.setVariables(variables, request);\n        }\n      }\n    }\n    this._stale = true;\n  };\n  return RelayModernFragmentSpecResolver;\n}();\nvar SelectorResolver = /*#__PURE__*/function () {\n  function SelectorResolver(environment, rootIsQueryRenderer, selector, subscribeOnConstruction, callback) {\n    var _this2 = this;\n    (0, _defineProperty2[\"default\"])(this, \"_onChange\", function (snapshot) {\n      _this2._data = snapshot.data;\n      _this2._isMissingData = snapshot.isMissingData;\n      _this2._missingRequiredFields = snapshot.missingRequiredFields;\n      _this2._errorResponseFields = snapshot.errorResponseFields;\n      _this2._relayResolverErrors = snapshot.relayResolverErrors;\n      _this2._callback();\n    });\n    var _snapshot = environment.lookup(selector);\n    this._callback = callback;\n    this._data = _snapshot.data;\n    this._isMissingData = _snapshot.isMissingData;\n    this._missingRequiredFields = _snapshot.missingRequiredFields;\n    this._errorResponseFields = _snapshot.errorResponseFields;\n    this._relayResolverErrors = _snapshot.relayResolverErrors;\n    this._environment = environment;\n    this._rootIsQueryRenderer = rootIsQueryRenderer;\n    this._selector = selector;\n    if (RelayFeatureFlags.ENABLE_CONTAINERS_SUBSCRIBE_ON_COMMIT === true) {\n      if (subscribeOnConstruction) {\n        this._subscription = environment.subscribe(_snapshot, this._onChange);\n      }\n    } else {\n      this._subscription = environment.subscribe(_snapshot, this._onChange);\n    }\n  }\n  var _proto2 = SelectorResolver.prototype;\n  _proto2.dispose = function dispose() {\n    if (this._subscription) {\n      this._subscription.dispose();\n      this._subscription = null;\n    }\n  };\n  _proto2.resolve = function resolve() {\n    if (this._isMissingData === true) {\n      var pendingOperationsResult = getPendingOperationsForFragment(this._environment, this._selector.node, this._selector.owner);\n      var promise = pendingOperationsResult === null || pendingOperationsResult === void 0 ? void 0 : pendingOperationsResult.promise;\n      if (promise != null) {\n        if (this._rootIsQueryRenderer) {\n          process.env.NODE_ENV !== \"production\" ? warning(false, 'Relay: Relay Container for fragment `%s` has missing data and ' + 'would suspend. When using features such as @defer or @module, ' + 'use `useFragment` instead of a Relay Container.', this._selector.node.name) : void 0;\n        } else {\n          var _pendingOperationsRes;\n          var pendingOperations = (_pendingOperationsRes = pendingOperationsResult === null || pendingOperationsResult === void 0 ? void 0 : pendingOperationsResult.pendingOperations) !== null && _pendingOperationsRes !== void 0 ? _pendingOperationsRes : [];\n          process.env.NODE_ENV !== \"production\" ? warning(false, 'Relay: Relay Container for fragment `%s` suspended. When using ' + 'features such as @defer or @module, use `useFragment` instead ' + 'of a Relay Container.', this._selector.node.name) : void 0;\n          this._environment.__log({\n            name: 'suspense.fragment',\n            data: this._data,\n            fragment: this._selector.node,\n            isRelayHooks: false,\n            isMissingData: this._isMissingData,\n            isPromiseCached: false,\n            pendingOperations: pendingOperations\n          });\n          throw promise;\n        }\n      }\n    }\n    handlePotentialSnapshotErrors(this._environment, this._missingRequiredFields, this._relayResolverErrors, this._errorResponseFields);\n    return this._data;\n  };\n  _proto2.setSelector = function setSelector(selector) {\n    if (this._subscription != null && areEqualSelectors(selector, this._selector)) {\n      return;\n    }\n    this.dispose();\n    var snapshot = this._environment.lookup(selector);\n    this._data = recycleNodesInto(this._data, snapshot.data);\n    this._isMissingData = snapshot.isMissingData;\n    this._missingRequiredFields = snapshot.missingRequiredFields;\n    this._errorResponseFields = snapshot.errorResponseFields;\n    this._relayResolverErrors = snapshot.relayResolverErrors;\n    this._selector = selector;\n    this._subscription = this._environment.subscribe(snapshot, this._onChange);\n  };\n  _proto2.setVariables = function setVariables(variables, request) {\n    if (areEqual(variables, this._selector.variables)) {\n      return;\n    }\n    var requestDescriptor = createRequestDescriptor(request, variables);\n    var selector = createReaderSelector(this._selector.node, this._selector.dataID, variables, requestDescriptor);\n    this.setSelector(selector);\n  };\n  return SelectorResolver;\n}();\nvar SelectorListResolver = /*#__PURE__*/function () {\n  function SelectorListResolver(environment, rootIsQueryRenderer, selector, subscribeOnConstruction, callback) {\n    var _this3 = this;\n    (0, _defineProperty2[\"default\"])(this, \"_onChange\", function (data) {\n      _this3._stale = true;\n      _this3._callback();\n    });\n    this._callback = callback;\n    this._data = [];\n    this._environment = environment;\n    this._resolvers = [];\n    this._stale = true;\n    this._rootIsQueryRenderer = rootIsQueryRenderer;\n    this._subscribeOnConstruction = subscribeOnConstruction;\n    this.setSelector(selector);\n  }\n  var _proto3 = SelectorListResolver.prototype;\n  _proto3.dispose = function dispose() {\n    this._resolvers.forEach(disposeCallback);\n  };\n  _proto3.resolve = function resolve() {\n    if (this._stale) {\n      var prevData = this._data;\n      var nextData;\n      for (var ii = 0; ii < this._resolvers.length; ii++) {\n        var prevItem = prevData[ii];\n        var nextItem = this._resolvers[ii].resolve();\n        if (nextData || nextItem !== prevItem) {\n          nextData = nextData || prevData.slice(0, ii);\n          nextData.push(nextItem);\n        }\n      }\n      if (!nextData && this._resolvers.length !== prevData.length) {\n        nextData = prevData.slice(0, this._resolvers.length);\n      }\n      this._data = nextData || prevData;\n      this._stale = false;\n    }\n    return this._data;\n  };\n  _proto3.setSelector = function setSelector(selector) {\n    var selectors = selector.selectors;\n    while (this._resolvers.length > selectors.length) {\n      var resolver = this._resolvers.pop();\n      resolver.dispose();\n    }\n    for (var ii = 0; ii < selectors.length; ii++) {\n      if (ii < this._resolvers.length) {\n        this._resolvers[ii].setSelector(selectors[ii]);\n      } else {\n        this._resolvers[ii] = new SelectorResolver(this._environment, this._rootIsQueryRenderer, selectors[ii], this._subscribeOnConstruction, this._onChange);\n      }\n    }\n    this._stale = true;\n  };\n  _proto3.setVariables = function setVariables(variables, request) {\n    this._resolvers.forEach(function (resolver) {\n      return resolver.setVariables(variables, request);\n    });\n    this._stale = true;\n  };\n  return SelectorListResolver;\n}();\nfunction disposeCallback(disposable) {\n  disposable && disposable.dispose();\n}\nmodule.exports = RelayModernFragmentSpecResolver;","'use strict';\n\nvar deepFreeze = require('../util/deepFreeze');\nvar getRequestIdentifier = require('../util/getRequestIdentifier');\nvar _require = require('./RelayConcreteVariables'),\n  getOperationVariables = _require.getOperationVariables;\nvar _require2 = require('./RelayModernSelector'),\n  createNormalizationSelector = _require2.createNormalizationSelector,\n  createReaderSelector = _require2.createReaderSelector;\nvar _require3 = require('./RelayStoreUtils'),\n  ROOT_ID = _require3.ROOT_ID;\nfunction createOperationDescriptor(request, variables, cacheConfig) {\n  var dataID = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : ROOT_ID;\n  var operation = request.operation;\n  var operationVariables = getOperationVariables(operation, request.params.providedVariables, variables);\n  var requestDescriptor = createRequestDescriptor(request, operationVariables, cacheConfig);\n  var operationDescriptor = {\n    fragment: createReaderSelector(request.fragment, dataID, operationVariables, requestDescriptor),\n    request: requestDescriptor,\n    root: createNormalizationSelector(operation, dataID, operationVariables)\n  };\n  if (process.env.NODE_ENV !== \"production\") {\n    Object.freeze(operationDescriptor.fragment);\n    Object.freeze(operationDescriptor.root);\n    Object.freeze(operationDescriptor);\n  }\n  return operationDescriptor;\n}\nfunction createRequestDescriptor(request, variables, cacheConfig) {\n  var requestDescriptor = {\n    identifier: getRequestIdentifier(request.params, variables),\n    node: request,\n    variables: variables,\n    cacheConfig: cacheConfig\n  };\n  if (process.env.NODE_ENV !== \"production\") {\n    deepFreeze(variables);\n    Object.freeze(request);\n    Object.freeze(requestDescriptor);\n  }\n  return requestDescriptor;\n}\nmodule.exports = {\n  createOperationDescriptor: createOperationDescriptor,\n  createRequestDescriptor: createRequestDescriptor\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _objectWithoutPropertiesLoose2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectWithoutPropertiesLoose\"));\nvar _toPropertyKey2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toPropertyKey\"));\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar deepFreeze = require('../util/deepFreeze');\nvar _require = require('./ClientID'),\n  generateClientObjectClientID = _require.generateClientObjectClientID,\n  isClientID = _require.isClientID;\nvar _require2 = require('./experimental-live-resolvers/LiveResolverSuspenseSentinel'),\n  isSuspenseSentinel = _require2.isSuspenseSentinel;\nvar _require3 = require('./RelayStoreUtils'),\n  ACTOR_IDENTIFIER_KEY = _require3.ACTOR_IDENTIFIER_KEY,\n  ERRORS_KEY = _require3.ERRORS_KEY,\n  ID_KEY = _require3.ID_KEY,\n  INVALIDATED_AT_KEY = _require3.INVALIDATED_AT_KEY,\n  REF_KEY = _require3.REF_KEY,\n  REFS_KEY = _require3.REFS_KEY,\n  RELAY_RESOLVER_VALUE_KEY = _require3.RELAY_RESOLVER_VALUE_KEY,\n  ROOT_ID = _require3.ROOT_ID,\n  TYPENAME_KEY = _require3.TYPENAME_KEY;\nvar areEqual = require(\"fbjs/lib/areEqual\");\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nfunction clone(record) {\n  return (0, _objectSpread2[\"default\"])({}, record);\n}\nfunction copyFields(source, sink) {\n  for (var key in source) {\n    if (source.hasOwnProperty(key)) {\n      if (key !== ID_KEY && key !== TYPENAME_KEY) {\n        sink[key] = source[key];\n      }\n    }\n  }\n}\nfunction create(dataID, typeName) {\n  var record = {};\n  record[ID_KEY] = dataID;\n  record[TYPENAME_KEY] = typeName;\n  return record;\n}\nfunction fromObject(json) {\n  return json;\n}\nfunction getDataID(record) {\n  return record[ID_KEY];\n}\nfunction getFields(record) {\n  if (ERRORS_KEY in record) {\n    return Object.keys(record).filter(function (field) {\n      return field !== ERRORS_KEY;\n    });\n  }\n  return Object.keys(record);\n}\nfunction getType(record) {\n  return record[TYPENAME_KEY];\n}\nfunction getErrors(record, storageKey) {\n  var _record$ERRORS_KEY;\n  return (_record$ERRORS_KEY = record[ERRORS_KEY]) === null || _record$ERRORS_KEY === void 0 ? void 0 : _record$ERRORS_KEY[storageKey];\n}\nfunction getValue(record, storageKey) {\n  var value = record[storageKey];\n  if (value && typeof value === 'object') {\n    !(!value.hasOwnProperty(REF_KEY) && !value.hasOwnProperty(REFS_KEY)) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernRecord.getValue(): Expected a scalar (non-link) value for `%s.%s` ' + 'but found %s.', record[ID_KEY], storageKey, value.hasOwnProperty(REF_KEY) ? 'a linked record' : 'plural linked records') : invariant(false) : void 0;\n  }\n  return value;\n}\nfunction hasValue(record, storageKey) {\n  return storageKey in record;\n}\nfunction getLinkedRecordID(record, storageKey) {\n  var maybeLink = record[storageKey];\n  if (maybeLink == null) {\n    return maybeLink;\n  }\n  var link = maybeLink;\n  !(typeof link === 'object' && link && typeof link[REF_KEY] === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernRecord.getLinkedRecordID(): Expected `%s.%s` to be a linked ID, ' + 'was `%s`.%s', record[ID_KEY], storageKey, JSON.stringify(link), typeof link === 'object' && link[REFS_KEY] !== undefined ? ' It appears to be a plural linked record: did you mean to call ' + 'getLinkedRecords() instead of getLinkedRecord()?' : '') : invariant(false) : void 0;\n  return link[REF_KEY];\n}\nfunction hasLinkedRecordID(record, storageKey) {\n  var maybeLink = record[storageKey];\n  if (maybeLink == null) {\n    return false;\n  }\n  var link = maybeLink;\n  return typeof link === 'object' && link && typeof link[REF_KEY] === 'string';\n}\nfunction getLinkedRecordIDs(record, storageKey) {\n  var links = record[storageKey];\n  if (links == null) {\n    return links;\n  }\n  !(typeof links === 'object' && Array.isArray(links[REFS_KEY])) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernRecord.getLinkedRecordIDs(): Expected `%s.%s` to contain an array ' + 'of linked IDs, got `%s`.%s', record[ID_KEY], storageKey, JSON.stringify(links), typeof links === 'object' && links[REF_KEY] !== undefined ? ' It appears to be a singular linked record: did you mean to call ' + 'getLinkedRecord() instead of getLinkedRecords()?' : '') : invariant(false) : void 0;\n  return links[REFS_KEY];\n}\nfunction hasLinkedRecordIDs(record, storageKey) {\n  var links = record[storageKey];\n  if (links == null) {\n    return false;\n  }\n  return typeof links === 'object' && Array.isArray(links[REFS_KEY]) && links[REFS_KEY].every(function (link) {\n    return typeof link === 'string';\n  });\n}\nfunction getInvalidationEpoch(record) {\n  if (record == null) {\n    return null;\n  }\n  var invalidatedAt = record[INVALIDATED_AT_KEY];\n  if (typeof invalidatedAt !== 'number') {\n    return null;\n  }\n  return invalidatedAt;\n}\nfunction update(prevRecord, nextRecord) {\n  var _updated2;\n  if (process.env.NODE_ENV !== \"production\") {\n    var _getType, _getType2;\n    var prevID = getDataID(prevRecord);\n    var nextID = getDataID(nextRecord);\n    process.env.NODE_ENV !== \"production\" ? warning(prevID === nextID, 'RelayModernRecord: Invalid record update, expected both versions of ' + 'the record to have the same id, got `%s` and `%s`.', prevID, nextID) : void 0;\n    var prevType = (_getType = getType(prevRecord)) !== null && _getType !== void 0 ? _getType : null;\n    var nextType = (_getType2 = getType(nextRecord)) !== null && _getType2 !== void 0 ? _getType2 : null;\n    process.env.NODE_ENV !== \"production\" ? warning(isClientID(nextID) && nextID !== ROOT_ID || prevType === nextType, 'RelayModernRecord: Invalid record update, expected both versions of ' + 'record `%s` to have the same `%s` but got conflicting types `%s` ' + 'and `%s`. The GraphQL server likely violated the globally unique ' + 'id requirement by returning the same id for different objects.', prevID, TYPENAME_KEY, prevType, nextType) : void 0;\n  }\n  var prevErrorsByKey = prevRecord[ERRORS_KEY];\n  var nextErrorsByKey = nextRecord[ERRORS_KEY];\n  var updated = null;\n  if (prevErrorsByKey == null && nextErrorsByKey == null) {\n    var _updated;\n    for (var storageKey in nextRecord) {\n      if (updated || !areEqual(prevRecord[storageKey], nextRecord[storageKey])) {\n        updated = updated !== null ? updated : (0, _objectSpread2[\"default\"])({}, prevRecord);\n        updated[storageKey] = nextRecord[storageKey];\n      }\n    }\n    return (_updated = updated) !== null && _updated !== void 0 ? _updated : prevRecord;\n  }\n  for (var _storageKey2 in nextRecord) {\n    if (_storageKey2 === ERRORS_KEY) {\n      continue;\n    }\n    var nextValue = nextRecord[_storageKey2];\n    var nextErrors = nextErrorsByKey === null || nextErrorsByKey === void 0 ? void 0 : nextErrorsByKey[_storageKey2];\n    if (updated == null) {\n      var prevValue = prevRecord[_storageKey2];\n      var prevErrors = prevErrorsByKey === null || prevErrorsByKey === void 0 ? void 0 : prevErrorsByKey[_storageKey2];\n      if (areEqual(prevValue, nextValue) && areEqual(prevErrors, nextErrors)) {\n        continue;\n      }\n      updated = (0, _objectSpread2[\"default\"])({}, prevRecord);\n      if (prevErrorsByKey != null) {\n        updated[ERRORS_KEY] = (0, _objectSpread2[\"default\"])({}, prevErrorsByKey);\n      }\n    }\n    setValue(updated, _storageKey2, nextValue);\n    setErrors(updated, _storageKey2, nextErrors);\n  }\n  return (_updated2 = updated) !== null && _updated2 !== void 0 ? _updated2 : prevRecord;\n}\nfunction merge(record1, record2) {\n  if (process.env.NODE_ENV !== \"production\") {\n    var _getType3, _getType4;\n    var prevID = getDataID(record1);\n    var nextID = getDataID(record2);\n    process.env.NODE_ENV !== \"production\" ? warning(prevID === nextID, 'RelayModernRecord: Invalid record merge, expected both versions of ' + 'the record to have the same id, got `%s` and `%s`.', prevID, nextID) : void 0;\n    var prevType = (_getType3 = getType(record1)) !== null && _getType3 !== void 0 ? _getType3 : null;\n    var nextType = (_getType4 = getType(record2)) !== null && _getType4 !== void 0 ? _getType4 : null;\n    process.env.NODE_ENV !== \"production\" ? warning(isClientID(nextID) && nextID !== ROOT_ID || prevType === nextType, 'RelayModernRecord: Invalid record merge, expected both versions of ' + 'record `%s` to have the same `%s` but got conflicting types `%s` ' + 'and `%s`. The GraphQL server likely violated the globally unique ' + 'id requirement by returning the same id for different objects.', prevID, TYPENAME_KEY, prevType, nextType) : void 0;\n  }\n  if (ERRORS_KEY in record1 || ERRORS_KEY in record2) {\n    var errors1 = record1[ERRORS_KEY],\n      fields1 = (0, _objectWithoutPropertiesLoose2[\"default\"])(record1, [ERRORS_KEY].map(_toPropertyKey2[\"default\"]));\n    var errors2 = record2[ERRORS_KEY],\n      fields2 = (0, _objectWithoutPropertiesLoose2[\"default\"])(record2, [ERRORS_KEY].map(_toPropertyKey2[\"default\"]));\n    var updated = (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, fields1), fields2);\n    if (errors1 == null && errors2 == null) {\n      return updated;\n    }\n    var updatedErrors = {};\n    for (var storageKey in errors1) {\n      if (fields2.hasOwnProperty(storageKey)) {\n        continue;\n      }\n      updatedErrors[storageKey] = errors1[storageKey];\n    }\n    for (var _storageKey3 in errors2) {\n      updatedErrors[_storageKey3] = errors2[_storageKey3];\n    }\n    for (var _storageKey in updatedErrors) {\n      updated[ERRORS_KEY] = updatedErrors;\n      break;\n    }\n    return updated;\n  } else {\n    return (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, record1), record2);\n  }\n}\nfunction freeze(record) {\n  deepFreeze(record);\n}\nfunction setErrors(record, storageKey, errors) {\n  if (process.env.NODE_ENV !== \"production\") {\n    process.env.NODE_ENV !== \"production\" ? warning(storageKey in record, 'RelayModernRecord: Invalid error update, `%s` should not be undefined.', storageKey) : void 0;\n  }\n  var errorsByStorageKey = record[ERRORS_KEY];\n  if (errors != null && errors.length > 0) {\n    if (errorsByStorageKey == null) {\n      record[ERRORS_KEY] = (0, _defineProperty2[\"default\"])({}, storageKey, errors);\n    } else {\n      errorsByStorageKey[storageKey] = errors;\n    }\n  } else if (errorsByStorageKey != null) {\n    if (delete errorsByStorageKey[storageKey]) {\n      for (var otherStorageKey in errorsByStorageKey) {\n        if (errorsByStorageKey.hasOwnProperty(otherStorageKey)) {\n          return;\n        }\n      }\n      delete record[ERRORS_KEY];\n    }\n  }\n}\nfunction setValue(record, storageKey, value) {\n  if (process.env.NODE_ENV !== \"production\") {\n    var prevID = getDataID(record);\n    if (storageKey === ID_KEY) {\n      process.env.NODE_ENV !== \"production\" ? warning(prevID === value, 'RelayModernRecord: Invalid field update, expected both versions of ' + 'the record to have the same id, got `%s` and `%s`.', prevID, value) : void 0;\n    } else if (storageKey === TYPENAME_KEY) {\n      var _getType5;\n      var prevType = (_getType5 = getType(record)) !== null && _getType5 !== void 0 ? _getType5 : null;\n      var nextType = value !== null && value !== void 0 ? value : null;\n      process.env.NODE_ENV !== \"production\" ? warning(isClientID(getDataID(record)) && getDataID(record) !== ROOT_ID || prevType === nextType, 'RelayModernRecord: Invalid field update, expected both versions of ' + 'record `%s` to have the same `%s` but got conflicting types `%s` ' + 'and `%s`. The GraphQL server likely violated the globally unique ' + 'id requirement by returning the same id for different objects.', prevID, TYPENAME_KEY, prevType, nextType) : void 0;\n    }\n  }\n  record[storageKey] = value;\n}\nfunction setLinkedRecordID(record, storageKey, linkedID) {\n  var link = {};\n  link[REF_KEY] = linkedID;\n  record[storageKey] = link;\n}\nfunction setLinkedRecordIDs(record, storageKey, linkedIDs) {\n  var links = {};\n  links[REFS_KEY] = linkedIDs;\n  record[storageKey] = links;\n}\nfunction setActorLinkedRecordID(record, storageKey, actorIdentifier, linkedID) {\n  var link = {};\n  link[REF_KEY] = linkedID;\n  link[ACTOR_IDENTIFIER_KEY] = actorIdentifier;\n  record[storageKey] = link;\n}\nfunction getActorLinkedRecordID(record, storageKey) {\n  var link = record[storageKey];\n  if (link == null) {\n    return link;\n  }\n  !(typeof link === 'object' && typeof link[REF_KEY] === 'string' && link[ACTOR_IDENTIFIER_KEY] != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernRecord.getActorLinkedRecordID(): Expected `%s.%s` to be an actor specific linked ID, ' + 'was `%s`.', record[ID_KEY], storageKey, JSON.stringify(link)) : invariant(false) : void 0;\n  return [link[ACTOR_IDENTIFIER_KEY], link[REF_KEY]];\n}\nfunction getResolverLinkedRecordID(record, typeName) {\n  var id = getValue(record, RELAY_RESOLVER_VALUE_KEY);\n  if (id == null || isSuspenseSentinel(id)) {\n    return null;\n  }\n  if (typeof id === 'object') {\n    id = id.id;\n  }\n  !(typeof id === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernRecord.getResolverLinkedRecordID(): Expected value to be a linked ID, ' + 'was `%s`.', JSON.stringify(id)) : invariant(false) : void 0;\n  return generateClientObjectClientID(typeName, id);\n}\nfunction getResolverLinkedRecordIDs(record, typeName) {\n  var resolverValue = getValue(record, RELAY_RESOLVER_VALUE_KEY);\n  if (resolverValue == null || isSuspenseSentinel(resolverValue)) {\n    return null;\n  }\n  !Array.isArray(resolverValue) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernRecord.getResolverLinkedRecordIDs(): Expected value to be an array of linked IDs, ' + 'was `%s`.', JSON.stringify(resolverValue)) : invariant(false) : void 0;\n  return resolverValue.map(function (id) {\n    if (id == null) {\n      return null;\n    }\n    if (typeof id === 'object') {\n      id = id.id;\n    }\n    !(typeof id === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernRecord.getResolverLinkedRecordIDs(): Expected item within resolver linked field to be a DataID, ' + 'was `%s`.', JSON.stringify(id)) : invariant(false) : void 0;\n    return generateClientObjectClientID(typeName, id);\n  });\n}\nfunction toJSON(record) {\n  return record;\n}\nmodule.exports = {\n  clone: clone,\n  copyFields: copyFields,\n  create: create,\n  freeze: freeze,\n  fromObject: fromObject,\n  getDataID: getDataID,\n  getErrors: getErrors,\n  getFields: getFields,\n  getInvalidationEpoch: getInvalidationEpoch,\n  getLinkedRecordID: getLinkedRecordID,\n  getLinkedRecordIDs: getLinkedRecordIDs,\n  getType: getType,\n  getValue: getValue,\n  hasValue: hasValue,\n  hasLinkedRecordID: hasLinkedRecordID,\n  hasLinkedRecordIDs: hasLinkedRecordIDs,\n  merge: merge,\n  setErrors: setErrors,\n  setValue: setValue,\n  setLinkedRecordID: setLinkedRecordID,\n  setLinkedRecordIDs: setLinkedRecordIDs,\n  update: update,\n  getActorLinkedRecordID: getActorLinkedRecordID,\n  setActorLinkedRecordID: setActorLinkedRecordID,\n  getResolverLinkedRecordID: getResolverLinkedRecordID,\n  getResolverLinkedRecordIDs: getResolverLinkedRecordIDs,\n  toJSON: toJSON\n};","'use strict';\n\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar _require = require('./RelayConcreteVariables'),\n  getFragmentVariables = _require.getFragmentVariables;\nvar _require2 = require('./RelayStoreUtils'),\n  CLIENT_EDGE_TRAVERSAL_PATH = _require2.CLIENT_EDGE_TRAVERSAL_PATH,\n  FRAGMENT_OWNER_KEY = _require2.FRAGMENT_OWNER_KEY,\n  FRAGMENT_POINTER_IS_WITHIN_UNMATCHED_TYPE_REFINEMENT = _require2.FRAGMENT_POINTER_IS_WITHIN_UNMATCHED_TYPE_REFINEMENT,\n  FRAGMENTS_KEY = _require2.FRAGMENTS_KEY,\n  ID_KEY = _require2.ID_KEY;\nvar areEqual = require(\"fbjs/lib/areEqual\");\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nfunction getSingularSelector(fragment, item) {\n  !(typeof item === 'object' && item !== null && !Array.isArray(item)) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernSelector: Expected value for fragment `%s` to be an object, got ' + '`%s`.', fragment.name, JSON.stringify(item)) : invariant(false) : void 0;\n  var dataID = item[ID_KEY];\n  var fragments = item[FRAGMENTS_KEY];\n  var mixedOwner = item[FRAGMENT_OWNER_KEY];\n  var mixedClientEdgeTraversalPath = item[CLIENT_EDGE_TRAVERSAL_PATH];\n  if (typeof dataID === 'string' && typeof fragments === 'object' && fragments !== null && typeof fragments[fragment.name] === 'object' && fragments[fragment.name] !== null && typeof mixedOwner === 'object' && mixedOwner !== null && (mixedClientEdgeTraversalPath == null || Array.isArray(mixedClientEdgeTraversalPath))) {\n    var owner = mixedOwner;\n    var clientEdgeTraversalPath = mixedClientEdgeTraversalPath;\n    var argumentVariables = fragments[fragment.name];\n    var fragmentVariables = getFragmentVariables(fragment, owner.variables, argumentVariables);\n    var isWithinUnmatchedTypeRefinement = argumentVariables[FRAGMENT_POINTER_IS_WITHIN_UNMATCHED_TYPE_REFINEMENT] === true;\n    return createReaderSelector(fragment, dataID, fragmentVariables, owner, isWithinUnmatchedTypeRefinement, clientEdgeTraversalPath);\n  }\n  if (process.env.NODE_ENV !== \"production\") {\n    var stringifiedItem = JSON.stringify(item);\n    if (stringifiedItem.length > 499) {\n      stringifiedItem = stringifiedItem.substr(0, 498) + \"\\u2026\";\n    }\n    process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayModernSelector: Expected object to contain data for fragment `%s`, got ' + '`%s`. Make sure that the parent operation/fragment included fragment ' + '`...%s` without `@relay(mask: false)`.', fragment.name, stringifiedItem, fragment.name) : void 0;\n  }\n  return null;\n}\nfunction getPluralSelector(fragment, items) {\n  var selectors = null;\n  items.forEach(function (item, ii) {\n    var selector = item != null ? getSingularSelector(fragment, item) : null;\n    if (selector != null) {\n      selectors = selectors || [];\n      selectors.push(selector);\n    }\n  });\n  if (selectors == null) {\n    return null;\n  } else {\n    return {\n      kind: 'PluralReaderSelector',\n      selectors: selectors\n    };\n  }\n}\nfunction getSelector(fragment, item) {\n  if (item == null) {\n    return item;\n  } else if (fragment.metadata && fragment.metadata.plural === true) {\n    !Array.isArray(item) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernSelector: Expected value for fragment `%s` to be an array, got `%s`. ' + 'Remove `@relay(plural: true)` from fragment `%s` to allow the prop to be an object.', fragment.name, JSON.stringify(item), fragment.name) : invariant(false) : void 0;\n    return getPluralSelector(fragment, item);\n  } else {\n    !!Array.isArray(item) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernSelector: Expected value for fragment `%s` to be an object, got `%s`. ' + 'Add `@relay(plural: true)` to fragment `%s` to allow the prop to be an array of items.', fragment.name, JSON.stringify(item), fragment.name) : invariant(false) : void 0;\n    return getSingularSelector(fragment, item);\n  }\n}\nfunction getSelectorsFromObject(fragments, object) {\n  var selectors = {};\n  for (var key in fragments) {\n    if (fragments.hasOwnProperty(key)) {\n      var fragment = fragments[key];\n      var item = object[key];\n      selectors[key] = getSelector(fragment, item);\n    }\n  }\n  return selectors;\n}\nfunction getDataIDsFromObject(fragments, object) {\n  var ids = {};\n  for (var key in fragments) {\n    if (fragments.hasOwnProperty(key)) {\n      var fragment = fragments[key];\n      var item = object[key];\n      ids[key] = getDataIDsFromFragment(fragment, item);\n    }\n  }\n  return ids;\n}\nfunction getDataIDsFromFragment(fragment, item) {\n  if (item == null) {\n    return item;\n  } else if (fragment.metadata && fragment.metadata.plural === true) {\n    !Array.isArray(item) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernSelector: Expected value for fragment `%s` to be an array, got `%s`. ' + 'Remove `@relay(plural: true)` from fragment `%s` to allow the prop to be an object.', fragment.name, JSON.stringify(item), fragment.name) : invariant(false) : void 0;\n    return getDataIDs(fragment, item);\n  } else {\n    !!Array.isArray(item) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernFragmentSpecResolver: Expected value for fragment `%s` to be an object, got `%s`. ' + 'Add `@relay(plural: true)` to fragment `%s` to allow the prop to be an array of items.', fragment.name, JSON.stringify(item), fragment.name) : invariant(false) : void 0;\n    return getDataID(fragment, item);\n  }\n}\nfunction getDataIDs(fragment, items) {\n  var ids = null;\n  items.forEach(function (item) {\n    var id = item != null ? getDataID(fragment, item) : null;\n    if (id != null) {\n      ids = ids || [];\n      ids.push(id);\n    }\n  });\n  return ids;\n}\nfunction getDataID(fragment, item) {\n  !(typeof item === 'object' && item !== null && !Array.isArray(item)) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernSelector: Expected value for fragment `%s` to be an object, got ' + '`%s`.', fragment.name, JSON.stringify(item)) : invariant(false) : void 0;\n  var dataID = item[ID_KEY];\n  if (typeof dataID === 'string') {\n    return dataID;\n  }\n  process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayModernSelector: Expected object to contain data for fragment `%s`, got ' + '`%s`. Make sure that the parent operation/fragment included fragment ' + '`...%s` without `@relay(mask: false)`, or `null` is passed as the fragment ' + \"reference for `%s` if it's conditonally included and the condition isn't met.\", fragment.name, JSON.stringify(item), fragment.name, fragment.name) : void 0;\n  return null;\n}\nfunction getVariablesFromObject(fragments, object) {\n  var variables = {};\n  for (var key in fragments) {\n    if (fragments.hasOwnProperty(key)) {\n      var fragment = fragments[key];\n      var item = object[key];\n      var itemVariables = getVariablesFromFragment(fragment, item);\n      Object.assign(variables, itemVariables);\n    }\n  }\n  return variables;\n}\nfunction getVariablesFromFragment(fragment, item) {\n  var _fragment$metadata;\n  if (item == null) {\n    return {};\n  } else if (((_fragment$metadata = fragment.metadata) === null || _fragment$metadata === void 0 ? void 0 : _fragment$metadata.plural) === true) {\n    !Array.isArray(item) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernSelector: Expected value for fragment `%s` to be an array, got `%s`. ' + 'Remove `@relay(plural: true)` from fragment `%s` to allow the prop to be an object.', fragment.name, JSON.stringify(item), fragment.name) : invariant(false) : void 0;\n    return getVariablesFromPluralFragment(fragment, item);\n  } else {\n    !!Array.isArray(item) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernFragmentSpecResolver: Expected value for fragment `%s` to be an object, got `%s`. ' + 'Add `@relay(plural: true)` to fragment `%s` to allow the prop to be an array of items.', fragment.name, JSON.stringify(item), fragment.name) : invariant(false) : void 0;\n    return getVariablesFromSingularFragment(fragment, item) || {};\n  }\n}\nfunction getVariablesFromSingularFragment(fragment, item) {\n  var selector = getSingularSelector(fragment, item);\n  if (!selector) {\n    return null;\n  }\n  return selector.variables;\n}\nfunction getVariablesFromPluralFragment(fragment, items) {\n  var variables = {};\n  items.forEach(function (value, ii) {\n    if (value != null) {\n      var itemVariables = getVariablesFromSingularFragment(fragment, value);\n      if (itemVariables != null) {\n        Object.assign(variables, itemVariables);\n      }\n    }\n  });\n  return variables;\n}\nfunction areEqualSingularSelectors(thisSelector, thatSelector) {\n  return thisSelector.dataID === thatSelector.dataID && thisSelector.node === thatSelector.node && areEqual(thisSelector.variables, thatSelector.variables) && areEqualOwners(thisSelector.owner, thatSelector.owner) && (!RelayFeatureFlags.ENABLE_STRICT_EQUAL_SELECTORS || thisSelector.isWithinUnmatchedTypeRefinement === thatSelector.isWithinUnmatchedTypeRefinement && areEqualClientEdgeTraversalPaths(thisSelector.clientEdgeTraversalPath, thatSelector.clientEdgeTraversalPath));\n}\nfunction areEqualOwners(thisOwner, thatOwner) {\n  if (thisOwner === thatOwner) {\n    return true;\n  } else {\n    return thisOwner.identifier === thatOwner.identifier && areEqual(thisOwner.cacheConfig, thatOwner.cacheConfig);\n  }\n}\nfunction areEqualClientEdgeTraversalPaths(thisPath, thatPath) {\n  if (thisPath === thatPath) {\n    return true;\n  }\n  if (thisPath == null || thatPath == null || thisPath.length !== thatPath.length) {\n    return false;\n  }\n  var idx = thisPath.length;\n  while (idx--) {\n    var a = thisPath[idx];\n    var b = thatPath[idx];\n    if (a === b) {\n      continue;\n    }\n    if (a == null || b == null || a.clientEdgeDestinationID !== b.clientEdgeDestinationID || a.readerClientEdge !== b.readerClientEdge) {\n      return false;\n    }\n  }\n  return true;\n}\nfunction areEqualSelectors(a, b) {\n  if (a === b) {\n    return true;\n  } else if (a == null) {\n    return b == null;\n  } else if (b == null) {\n    return a == null;\n  } else if (a.kind === 'SingularReaderSelector' && b.kind === 'SingularReaderSelector') {\n    return areEqualSingularSelectors(a, b);\n  } else if (a.kind === 'PluralReaderSelector' && b.kind === 'PluralReaderSelector') {\n    return a.selectors.length === b.selectors.length && a.selectors.every(function (s, i) {\n      return areEqualSingularSelectors(s, b.selectors[i]);\n    });\n  } else {\n    return false;\n  }\n}\nfunction createReaderSelector(fragment, dataID, variables, request) {\n  var isWithinUnmatchedTypeRefinement = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n  var clientEdgeTraversalPath = arguments.length > 5 ? arguments[5] : undefined;\n  return {\n    kind: 'SingularReaderSelector',\n    dataID: dataID,\n    isWithinUnmatchedTypeRefinement: isWithinUnmatchedTypeRefinement,\n    clientEdgeTraversalPath: clientEdgeTraversalPath !== null && clientEdgeTraversalPath !== void 0 ? clientEdgeTraversalPath : null,\n    node: fragment,\n    variables: variables,\n    owner: request\n  };\n}\nfunction createNormalizationSelector(node, dataID, variables) {\n  return {\n    dataID: dataID,\n    node: node,\n    variables: variables\n  };\n}\nmodule.exports = {\n  areEqualSelectors: areEqualSelectors,\n  createReaderSelector: createReaderSelector,\n  createNormalizationSelector: createNormalizationSelector,\n  getDataIDsFromFragment: getDataIDsFromFragment,\n  getDataIDsFromObject: getDataIDsFromObject,\n  getSingularSelector: getSingularSelector,\n  getPluralSelector: getPluralSelector,\n  getSelector: getSelector,\n  getSelectorsFromObject: getSelectorsFromObject,\n  getVariablesFromSingularFragment: getVariablesFromSingularFragment,\n  getVariablesFromPluralFragment: getVariablesFromPluralFragment,\n  getVariablesFromFragment: getVariablesFromFragment,\n  getVariablesFromObject: getVariablesFromObject\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _require = require('../multi-actor-environment/ActorIdentifier'),\n  INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE = _require.INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE,\n  assertInternalActorIdentifier = _require.assertInternalActorIdentifier;\nvar deepFreeze = require('../util/deepFreeze');\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar resolveImmediate = require('../util/resolveImmediate');\nvar DataChecker = require('./DataChecker');\nvar defaultGetDataID = require('./defaultGetDataID');\nvar RelayModernRecord = require('./RelayModernRecord');\nvar RelayOptimisticRecordSource = require('./RelayOptimisticRecordSource');\nvar RelayReader = require('./RelayReader');\nvar RelayReferenceMarker = require('./RelayReferenceMarker');\nvar RelayStoreSubscriptions = require('./RelayStoreSubscriptions');\nvar RelayStoreUtils = require('./RelayStoreUtils');\nvar _require2 = require('./RelayStoreUtils'),\n  ROOT_ID = _require2.ROOT_ID,\n  ROOT_TYPE = _require2.ROOT_TYPE;\nvar _require3 = require('./ResolverCache'),\n  RecordResolverCache = _require3.RecordResolverCache;\nvar invariant = require('invariant');\nvar DEFAULT_RELEASE_BUFFER_SIZE = 10;\nvar RelayModernStore = /*#__PURE__*/function () {\n  function RelayModernStore(source, options) {\n    var _this = this;\n    var _options$gcReleaseBuf, _options$gcScheduler, _options$getDataID, _options$log, _options$operationLoa;\n    (0, _defineProperty2[\"default\"])(this, \"_gcStep\", function () {\n      if (_this._gcRun) {\n        if (_this._gcRun.next().done) {\n          _this._gcRun = null;\n        } else {\n          _this._gcScheduler(_this._gcStep);\n        }\n      }\n    });\n    if (process.env.NODE_ENV !== \"production\") {\n      var storeIDs = source.getRecordIDs();\n      for (var ii = 0; ii < storeIDs.length; ii++) {\n        var record = source.get(storeIDs[ii]);\n        if (record) {\n          RelayModernRecord.freeze(record);\n        }\n      }\n    }\n    this._currentWriteEpoch = 0;\n    this._gcHoldCounter = 0;\n    this._gcReleaseBufferSize = (_options$gcReleaseBuf = options === null || options === void 0 ? void 0 : options.gcReleaseBufferSize) !== null && _options$gcReleaseBuf !== void 0 ? _options$gcReleaseBuf : DEFAULT_RELEASE_BUFFER_SIZE;\n    this._gcRun = null;\n    this._gcScheduler = (_options$gcScheduler = options === null || options === void 0 ? void 0 : options.gcScheduler) !== null && _options$gcScheduler !== void 0 ? _options$gcScheduler : resolveImmediate;\n    this._getDataID = (_options$getDataID = options === null || options === void 0 ? void 0 : options.getDataID) !== null && _options$getDataID !== void 0 ? _options$getDataID : defaultGetDataID;\n    this._globalInvalidationEpoch = null;\n    this._invalidationSubscriptions = new Set();\n    this._invalidatedRecordIDs = new Set();\n    this.__log = (_options$log = options === null || options === void 0 ? void 0 : options.log) !== null && _options$log !== void 0 ? _options$log : null;\n    this._queryCacheExpirationTime = options === null || options === void 0 ? void 0 : options.queryCacheExpirationTime;\n    this._operationLoader = (_options$operationLoa = options === null || options === void 0 ? void 0 : options.operationLoader) !== null && _options$operationLoa !== void 0 ? _options$operationLoa : null;\n    this._optimisticSource = null;\n    this._recordSource = source;\n    this._releaseBuffer = [];\n    this._roots = new Map();\n    this._shouldScheduleGC = false;\n    this._resolverCache = new RecordResolverCache(function () {\n      return _this._getMutableRecordSource();\n    });\n    this._storeSubscriptions = new RelayStoreSubscriptions(options === null || options === void 0 ? void 0 : options.log, this._resolverCache);\n    this._updatedRecordIDs = new Set();\n    this._shouldProcessClientComponents = options === null || options === void 0 ? void 0 : options.shouldProcessClientComponents;\n    initializeRecordSource(this._recordSource);\n  }\n  var _proto = RelayModernStore.prototype;\n  _proto.getSource = function getSource() {\n    var _this$_optimisticSour;\n    return (_this$_optimisticSour = this._optimisticSource) !== null && _this$_optimisticSour !== void 0 ? _this$_optimisticSour : this._recordSource;\n  };\n  _proto._getMutableRecordSource = function _getMutableRecordSource() {\n    var _this$_optimisticSour2;\n    return (_this$_optimisticSour2 = this._optimisticSource) !== null && _this$_optimisticSour2 !== void 0 ? _this$_optimisticSour2 : this._recordSource;\n  };\n  _proto.check = function check(operation, options) {\n    var _options$handlers, _options$getSourceFor, _options$getTargetFor, _options$defaultActor;\n    var selector = operation.root;\n    var source = this._getMutableRecordSource();\n    var globalInvalidationEpoch = this._globalInvalidationEpoch;\n    var rootEntry = this._roots.get(operation.request.identifier);\n    var operationLastWrittenAt = rootEntry != null ? rootEntry.epoch : null;\n    if (globalInvalidationEpoch != null) {\n      if (operationLastWrittenAt == null || operationLastWrittenAt <= globalInvalidationEpoch) {\n        return {\n          status: 'stale'\n        };\n      }\n    }\n    var handlers = (_options$handlers = options === null || options === void 0 ? void 0 : options.handlers) !== null && _options$handlers !== void 0 ? _options$handlers : [];\n    var getSourceForActor = (_options$getSourceFor = options === null || options === void 0 ? void 0 : options.getSourceForActor) !== null && _options$getSourceFor !== void 0 ? _options$getSourceFor : function (actorIdentifier) {\n      assertInternalActorIdentifier(actorIdentifier);\n      return source;\n    };\n    var getTargetForActor = (_options$getTargetFor = options === null || options === void 0 ? void 0 : options.getTargetForActor) !== null && _options$getTargetFor !== void 0 ? _options$getTargetFor : function (actorIdentifier) {\n      assertInternalActorIdentifier(actorIdentifier);\n      return source;\n    };\n    var operationAvailability = DataChecker.check(getSourceForActor, getTargetForActor, (_options$defaultActor = options === null || options === void 0 ? void 0 : options.defaultActorIdentifier) !== null && _options$defaultActor !== void 0 ? _options$defaultActor : INTERNAL_ACTOR_IDENTIFIER_DO_NOT_USE, selector, handlers, this._operationLoader, this._getDataID, this._shouldProcessClientComponents);\n    return getAvailabilityStatus(operationAvailability, operationLastWrittenAt, rootEntry === null || rootEntry === void 0 ? void 0 : rootEntry.fetchTime, this._queryCacheExpirationTime);\n  };\n  _proto.retain = function retain(operation) {\n    var _this2 = this;\n    var id = operation.request.identifier;\n    var disposed = false;\n    var dispose = function dispose() {\n      if (disposed) {\n        return;\n      }\n      disposed = true;\n      var rootEntry = _this2._roots.get(id);\n      if (rootEntry == null) {\n        return;\n      }\n      rootEntry.refCount--;\n      if (rootEntry.refCount === 0) {\n        var _queryCacheExpirationTime = _this2._queryCacheExpirationTime;\n        var rootEntryIsStale = rootEntry.fetchTime != null && _queryCacheExpirationTime != null && rootEntry.fetchTime <= Date.now() - _queryCacheExpirationTime;\n        if (rootEntryIsStale) {\n          _this2._roots[\"delete\"](id);\n          _this2.scheduleGC();\n        } else {\n          _this2._releaseBuffer.push(id);\n          if (_this2._releaseBuffer.length > _this2._gcReleaseBufferSize) {\n            var _id = _this2._releaseBuffer.shift();\n            _this2._roots[\"delete\"](_id);\n            _this2.scheduleGC();\n          }\n        }\n      }\n    };\n    var rootEntry = this._roots.get(id);\n    if (rootEntry != null) {\n      if (rootEntry.refCount === 0) {\n        this._releaseBuffer = this._releaseBuffer.filter(function (_id) {\n          return _id !== id;\n        });\n      }\n      rootEntry.refCount += 1;\n    } else {\n      this._roots.set(id, {\n        operation: operation,\n        refCount: 1,\n        epoch: null,\n        fetchTime: null\n      });\n    }\n    return {\n      dispose: dispose\n    };\n  };\n  _proto.lookup = function lookup(selector) {\n    var source = this.getSource();\n    var snapshot = RelayReader.read(source, selector, this._resolverCache);\n    if (process.env.NODE_ENV !== \"production\") {\n      deepFreeze(snapshot);\n    }\n    return snapshot;\n  };\n  _proto.notify = function notify(sourceOperation, invalidateStore) {\n    var _this3 = this;\n    var log = this.__log;\n    if (log != null) {\n      log({\n        name: 'store.notify.start',\n        sourceOperation: sourceOperation\n      });\n    }\n    this._currentWriteEpoch++;\n    if (invalidateStore === true) {\n      this._globalInvalidationEpoch = this._currentWriteEpoch;\n    }\n    if (RelayFeatureFlags.ENABLE_RELAY_RESOLVERS) {\n      this._resolverCache.invalidateDataIDs(this._updatedRecordIDs);\n    }\n    var source = this.getSource();\n    var updatedOwners = [];\n    this._storeSubscriptions.updateSubscriptions(source, this._updatedRecordIDs, updatedOwners, sourceOperation);\n    this._invalidationSubscriptions.forEach(function (subscription) {\n      _this3._updateInvalidationSubscription(subscription, invalidateStore === true);\n    });\n    if (log != null) {\n      log({\n        name: 'store.notify.complete',\n        sourceOperation: sourceOperation,\n        updatedRecordIDs: this._updatedRecordIDs,\n        invalidatedRecordIDs: this._invalidatedRecordIDs\n      });\n    }\n    this._updatedRecordIDs.clear();\n    this._invalidatedRecordIDs.clear();\n    if (sourceOperation != null) {\n      var id = sourceOperation.request.identifier;\n      var rootEntry = this._roots.get(id);\n      if (rootEntry != null) {\n        rootEntry.epoch = this._currentWriteEpoch;\n        rootEntry.fetchTime = Date.now();\n      } else if (sourceOperation.request.node.params.operationKind === 'query' && this._gcReleaseBufferSize > 0 && this._releaseBuffer.length < this._gcReleaseBufferSize) {\n        var temporaryRootEntry = {\n          operation: sourceOperation,\n          refCount: 0,\n          epoch: this._currentWriteEpoch,\n          fetchTime: Date.now()\n        };\n        this._releaseBuffer.push(id);\n        this._roots.set(id, temporaryRootEntry);\n      }\n    }\n    return updatedOwners;\n  };\n  _proto.publish = function publish(source, idsMarkedForInvalidation) {\n    var target = this._getMutableRecordSource();\n    updateTargetFromSource(target, source, this._currentWriteEpoch + 1, idsMarkedForInvalidation, this._updatedRecordIDs, this._invalidatedRecordIDs);\n    var log = this.__log;\n    if (log != null) {\n      log({\n        name: 'store.publish',\n        source: source,\n        optimistic: target === this._optimisticSource\n      });\n    }\n  };\n  _proto.subscribe = function subscribe(snapshot, callback) {\n    return this._storeSubscriptions.subscribe(snapshot, callback);\n  };\n  _proto.holdGC = function holdGC() {\n    var _this4 = this;\n    if (this._gcRun) {\n      this._gcRun = null;\n      this._shouldScheduleGC = true;\n    }\n    this._gcHoldCounter++;\n    var dispose = function dispose() {\n      if (_this4._gcHoldCounter > 0) {\n        _this4._gcHoldCounter--;\n        if (_this4._gcHoldCounter === 0 && _this4._shouldScheduleGC) {\n          _this4.scheduleGC();\n          _this4._shouldScheduleGC = false;\n        }\n      }\n    };\n    return {\n      dispose: dispose\n    };\n  };\n  _proto.toJSON = function toJSON() {\n    return 'RelayModernStore()';\n  };\n  _proto.getEpoch = function getEpoch() {\n    return this._currentWriteEpoch;\n  };\n  _proto.__getUpdatedRecordIDs = function __getUpdatedRecordIDs() {\n    return this._updatedRecordIDs;\n  };\n  _proto.lookupInvalidationState = function lookupInvalidationState(dataIDs) {\n    var _this5 = this;\n    var invalidations = new Map();\n    dataIDs.forEach(function (dataID) {\n      var _RelayModernRecord$ge;\n      var record = _this5.getSource().get(dataID);\n      invalidations.set(dataID, (_RelayModernRecord$ge = RelayModernRecord.getInvalidationEpoch(record)) !== null && _RelayModernRecord$ge !== void 0 ? _RelayModernRecord$ge : null);\n    });\n    invalidations.set('global', this._globalInvalidationEpoch);\n    return {\n      dataIDs: dataIDs,\n      invalidations: invalidations\n    };\n  };\n  _proto.checkInvalidationState = function checkInvalidationState(prevInvalidationState) {\n    var latestInvalidationState = this.lookupInvalidationState(prevInvalidationState.dataIDs);\n    var currentInvalidations = latestInvalidationState.invalidations;\n    var prevInvalidations = prevInvalidationState.invalidations;\n    if (currentInvalidations.get('global') !== prevInvalidations.get('global')) {\n      return true;\n    }\n    var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(prevInvalidationState.dataIDs),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var dataID = _step.value;\n        if (currentInvalidations.get(dataID) !== prevInvalidations.get(dataID)) {\n          return true;\n        }\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n    return false;\n  };\n  _proto.subscribeToInvalidationState = function subscribeToInvalidationState(invalidationState, callback) {\n    var _this6 = this;\n    var subscription = {\n      callback: callback,\n      invalidationState: invalidationState\n    };\n    var dispose = function dispose() {\n      _this6._invalidationSubscriptions[\"delete\"](subscription);\n    };\n    this._invalidationSubscriptions.add(subscription);\n    return {\n      dispose: dispose\n    };\n  };\n  _proto._updateInvalidationSubscription = function _updateInvalidationSubscription(subscription, invalidatedStore) {\n    var _this7 = this;\n    var callback = subscription.callback,\n      invalidationState = subscription.invalidationState;\n    var dataIDs = invalidationState.dataIDs;\n    var isSubscribedToInvalidatedIDs = invalidatedStore || dataIDs.some(function (dataID) {\n      return _this7._invalidatedRecordIDs.has(dataID);\n    });\n    if (!isSubscribedToInvalidatedIDs) {\n      return;\n    }\n    callback();\n  };\n  _proto.snapshot = function snapshot() {\n    !(this._optimisticSource == null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernStore: Unexpected call to snapshot() while a previous ' + 'snapshot exists.') : invariant(false) : void 0;\n    var log = this.__log;\n    if (log != null) {\n      log({\n        name: 'store.snapshot'\n      });\n    }\n    this._storeSubscriptions.snapshotSubscriptions(this.getSource());\n    if (this._gcRun) {\n      this._gcRun = null;\n      this._shouldScheduleGC = true;\n    }\n    this._optimisticSource = RelayOptimisticRecordSource.create(this.getSource());\n  };\n  _proto.restore = function restore() {\n    !(this._optimisticSource != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernStore: Unexpected call to restore(), expected a snapshot ' + 'to exist (make sure to call snapshot()).') : invariant(false) : void 0;\n    var log = this.__log;\n    if (log != null) {\n      log({\n        name: 'store.restore'\n      });\n    }\n    this._optimisticSource = null;\n    if (this._shouldScheduleGC) {\n      this.scheduleGC();\n    }\n    this._storeSubscriptions.restoreSubscriptions();\n  };\n  _proto.scheduleGC = function scheduleGC() {\n    if (this._gcHoldCounter > 0) {\n      this._shouldScheduleGC = true;\n      return;\n    }\n    if (this._gcRun) {\n      return;\n    }\n    this._gcRun = this._collect();\n    this._gcScheduler(this._gcStep);\n  };\n  _proto.__gc = function __gc() {\n    if (this._optimisticSource != null) {\n      return;\n    }\n    var gcRun = this._collect();\n    while (!gcRun.next().done) {}\n  };\n  _proto._collect = function* _collect() {\n    top: while (true) {\n      var startEpoch = this._currentWriteEpoch;\n      var references = new Set();\n      var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(this._roots.values()),\n        _step2;\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var operation = _step2.value.operation;\n          var selector = operation.root;\n          RelayReferenceMarker.mark(this._recordSource, selector, references, this._operationLoader, this._shouldProcessClientComponents);\n          yield;\n          if (startEpoch !== this._currentWriteEpoch) {\n            continue top;\n          }\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n      var log = this.__log;\n      if (log != null) {\n        log({\n          name: 'store.gc',\n          references: references\n        });\n      }\n      if (references.size === 0) {\n        this._recordSource.clear();\n      } else {\n        var storeIDs = this._recordSource.getRecordIDs();\n        for (var ii = 0; ii < storeIDs.length; ii++) {\n          var dataID = storeIDs[ii];\n          if (!references.has(dataID)) {\n            this._recordSource.remove(dataID);\n          }\n        }\n      }\n      return;\n    }\n  };\n  return RelayModernStore;\n}();\nfunction initializeRecordSource(target) {\n  if (!target.has(ROOT_ID)) {\n    var rootRecord = RelayModernRecord.create(ROOT_ID, ROOT_TYPE);\n    target.set(ROOT_ID, rootRecord);\n  }\n}\nfunction updateTargetFromSource(target, source, currentWriteEpoch, idsMarkedForInvalidation, updatedRecordIDs, invalidatedRecordIDs) {\n  if (idsMarkedForInvalidation) {\n    idsMarkedForInvalidation.forEach(function (dataID) {\n      var targetRecord = target.get(dataID);\n      var sourceRecord = source.get(dataID);\n      if (sourceRecord === null) {\n        return;\n      }\n      var nextRecord;\n      if (targetRecord != null) {\n        nextRecord = RelayModernRecord.clone(targetRecord);\n      } else {\n        nextRecord = sourceRecord != null ? RelayModernRecord.clone(sourceRecord) : null;\n      }\n      if (!nextRecord) {\n        return;\n      }\n      RelayModernRecord.setValue(nextRecord, RelayStoreUtils.INVALIDATED_AT_KEY, currentWriteEpoch);\n      invalidatedRecordIDs.add(dataID);\n      target.set(dataID, nextRecord);\n    });\n  }\n  var dataIDs = source.getRecordIDs();\n  for (var ii = 0; ii < dataIDs.length; ii++) {\n    var dataID = dataIDs[ii];\n    var sourceRecord = source.get(dataID);\n    var targetRecord = target.get(dataID);\n    if (process.env.NODE_ENV !== \"production\") {\n      if (sourceRecord) {\n        RelayModernRecord.freeze(sourceRecord);\n      }\n    }\n    if (sourceRecord && targetRecord) {\n      var nextRecord = RelayModernRecord.update(targetRecord, sourceRecord);\n      if (nextRecord !== targetRecord) {\n        if (process.env.NODE_ENV !== \"production\") {\n          RelayModernRecord.freeze(nextRecord);\n        }\n        updatedRecordIDs.add(dataID);\n        target.set(dataID, nextRecord);\n      }\n    } else if (sourceRecord === null) {\n      target[\"delete\"](dataID);\n      if (targetRecord !== null) {\n        updatedRecordIDs.add(dataID);\n      }\n    } else if (sourceRecord) {\n      target.set(dataID, sourceRecord);\n      updatedRecordIDs.add(dataID);\n    }\n  }\n}\nfunction getAvailabilityStatus(operationAvailability, operationLastWrittenAt, operationFetchTime, queryCacheExpirationTime) {\n  var mostRecentlyInvalidatedAt = operationAvailability.mostRecentlyInvalidatedAt,\n    status = operationAvailability.status;\n  if (typeof mostRecentlyInvalidatedAt === 'number') {\n    if (operationLastWrittenAt == null || mostRecentlyInvalidatedAt > operationLastWrittenAt) {\n      return {\n        status: 'stale'\n      };\n    }\n  }\n  if (status === 'missing') {\n    return {\n      status: 'missing'\n    };\n  }\n  if (operationFetchTime != null && queryCacheExpirationTime != null) {\n    var isStale = operationFetchTime <= Date.now() - queryCacheExpirationTime;\n    if (isStale) {\n      return {\n        status: 'stale'\n      };\n    }\n  }\n  return {\n    status: 'available',\n    fetchTime: operationFetchTime !== null && operationFetchTime !== void 0 ? operationFetchTime : null\n  };\n}\nmodule.exports = RelayModernStore;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar invariant = require('invariant');\nvar RelayOperationTracker = /*#__PURE__*/function () {\n  function RelayOperationTracker() {\n    this._ownersToPendingOperations = new Map();\n    this._pendingOperationsToOwners = new Map();\n    this._ownersToPendingPromise = new Map();\n  }\n  var _proto = RelayOperationTracker.prototype;\n  _proto.update = function update(pendingOperation, affectedOwners) {\n    if (affectedOwners.size === 0) {\n      return;\n    }\n    var pendingOperationIdentifier = pendingOperation.identifier;\n    var newlyAffectedOwnersIdentifier = new Set();\n    var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(affectedOwners),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var owner = _step.value;\n        var ownerIdentifier = owner.identifier;\n        var pendingOperationsAffectingOwner = this._ownersToPendingOperations.get(ownerIdentifier);\n        if (pendingOperationsAffectingOwner != null) {\n          if (!pendingOperationsAffectingOwner.has(pendingOperationIdentifier)) {\n            pendingOperationsAffectingOwner.set(pendingOperationIdentifier, pendingOperation);\n            newlyAffectedOwnersIdentifier.add(ownerIdentifier);\n          }\n        } else {\n          this._ownersToPendingOperations.set(ownerIdentifier, new Map([[pendingOperationIdentifier, pendingOperation]]));\n          newlyAffectedOwnersIdentifier.add(ownerIdentifier);\n        }\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n    if (newlyAffectedOwnersIdentifier.size === 0) {\n      return;\n    }\n    var ownersAffectedByPendingOperation = this._pendingOperationsToOwners.get(pendingOperationIdentifier) || new Set();\n    var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(newlyAffectedOwnersIdentifier),\n      _step2;\n    try {\n      for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n        var _ownerIdentifier = _step2.value;\n        this._resolveOwnerResolvers(_ownerIdentifier);\n        ownersAffectedByPendingOperation.add(_ownerIdentifier);\n      }\n    } catch (err) {\n      _iterator2.e(err);\n    } finally {\n      _iterator2.f();\n    }\n    this._pendingOperationsToOwners.set(pendingOperationIdentifier, ownersAffectedByPendingOperation);\n  };\n  _proto.complete = function complete(pendingOperation) {\n    var pendingOperationIdentifier = pendingOperation.identifier;\n    var affectedOwnersIdentifier = this._pendingOperationsToOwners.get(pendingOperationIdentifier);\n    if (affectedOwnersIdentifier == null) {\n      return;\n    }\n    var completedOwnersIdentifier = new Set();\n    var updatedOwnersIdentifier = new Set();\n    var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])(affectedOwnersIdentifier),\n      _step3;\n    try {\n      for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n        var ownerIdentifier = _step3.value;\n        var pendingOperationsAffectingOwner = this._ownersToPendingOperations.get(ownerIdentifier);\n        if (!pendingOperationsAffectingOwner) {\n          continue;\n        }\n        pendingOperationsAffectingOwner[\"delete\"](pendingOperationIdentifier);\n        if (pendingOperationsAffectingOwner.size > 0) {\n          updatedOwnersIdentifier.add(ownerIdentifier);\n        } else {\n          completedOwnersIdentifier.add(ownerIdentifier);\n        }\n      }\n    } catch (err) {\n      _iterator3.e(err);\n    } finally {\n      _iterator3.f();\n    }\n    var _iterator4 = (0, _createForOfIteratorHelper2[\"default\"])(completedOwnersIdentifier),\n      _step4;\n    try {\n      for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n        var _ownerIdentifier2 = _step4.value;\n        this._resolveOwnerResolvers(_ownerIdentifier2);\n        this._ownersToPendingOperations[\"delete\"](_ownerIdentifier2);\n      }\n    } catch (err) {\n      _iterator4.e(err);\n    } finally {\n      _iterator4.f();\n    }\n    var _iterator5 = (0, _createForOfIteratorHelper2[\"default\"])(updatedOwnersIdentifier),\n      _step5;\n    try {\n      for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n        var _ownerIdentifier3 = _step5.value;\n        this._resolveOwnerResolvers(_ownerIdentifier3);\n      }\n    } catch (err) {\n      _iterator5.e(err);\n    } finally {\n      _iterator5.f();\n    }\n    this._pendingOperationsToOwners[\"delete\"](pendingOperationIdentifier);\n  };\n  _proto._resolveOwnerResolvers = function _resolveOwnerResolvers(ownerIdentifier) {\n    var promiseEntry = this._ownersToPendingPromise.get(ownerIdentifier);\n    if (promiseEntry != null) {\n      promiseEntry.resolve();\n    }\n    this._ownersToPendingPromise[\"delete\"](ownerIdentifier);\n  };\n  _proto.getPendingOperationsAffectingOwner = function getPendingOperationsAffectingOwner(owner) {\n    var ownerIdentifier = owner.identifier;\n    var pendingOperationsForOwner = this._ownersToPendingOperations.get(ownerIdentifier);\n    if (pendingOperationsForOwner == null || pendingOperationsForOwner.size === 0) {\n      return null;\n    }\n    var cachedPromiseEntry = this._ownersToPendingPromise.get(ownerIdentifier);\n    if (cachedPromiseEntry != null) {\n      return {\n        promise: cachedPromiseEntry.promise,\n        pendingOperations: cachedPromiseEntry.pendingOperations\n      };\n    }\n    var resolve;\n    var promise = new Promise(function (r) {\n      resolve = r;\n    });\n    !(resolve != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayOperationTracker: Expected resolver to be defined. If you' + 'are seeing this, it is likely a bug in Relay.') : invariant(false) : void 0;\n    var pendingOperations = Array.from(pendingOperationsForOwner.values());\n    this._ownersToPendingPromise.set(ownerIdentifier, {\n      promise: promise,\n      resolve: resolve,\n      pendingOperations: pendingOperations\n    });\n    return {\n      promise: promise,\n      pendingOperations: pendingOperations\n    };\n  };\n  return RelayOperationTracker;\n}();\nmodule.exports = RelayOperationTracker;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar RelayModernRecord = require('./RelayModernRecord');\nvar RelayRecordSource = require('./RelayRecordSource');\nvar invariant = require('invariant');\nvar UNPUBLISH_RECORD_SENTINEL = RelayModernRecord.fromObject(Object.freeze({\n  __UNPUBLISH_RECORD_SENTINEL: true\n}));\nvar RelayOptimisticRecordSource = /*#__PURE__*/function () {\n  function RelayOptimisticRecordSource(base) {\n    this._base = base;\n    this._sink = RelayRecordSource.create();\n  }\n  var _proto = RelayOptimisticRecordSource.prototype;\n  _proto.has = function has(dataID) {\n    if (this._sink.has(dataID)) {\n      var sinkRecord = this._sink.get(dataID);\n      return sinkRecord !== UNPUBLISH_RECORD_SENTINEL;\n    } else {\n      return this._base.has(dataID);\n    }\n  };\n  _proto.get = function get(dataID) {\n    if (this._sink.has(dataID)) {\n      var sinkRecord = this._sink.get(dataID);\n      if (sinkRecord === UNPUBLISH_RECORD_SENTINEL) {\n        return undefined;\n      } else {\n        return sinkRecord;\n      }\n    } else {\n      return this._base.get(dataID);\n    }\n  };\n  _proto.getStatus = function getStatus(dataID) {\n    var record = this.get(dataID);\n    if (record === undefined) {\n      return 'UNKNOWN';\n    } else if (record === null) {\n      return 'NONEXISTENT';\n    } else {\n      return 'EXISTENT';\n    }\n  };\n  _proto.clear = function clear() {\n    this._base = RelayRecordSource.create();\n    this._sink.clear();\n  };\n  _proto[\"delete\"] = function _delete(dataID) {\n    this._sink[\"delete\"](dataID);\n  };\n  _proto.remove = function remove(dataID) {\n    this._sink.set(dataID, UNPUBLISH_RECORD_SENTINEL);\n  };\n  _proto.set = function set(dataID, record) {\n    this._sink.set(dataID, record);\n  };\n  _proto.getRecordIDs = function getRecordIDs() {\n    return Object.keys(this.toJSON());\n  };\n  _proto.size = function size() {\n    return Object.keys(this.toJSON()).length;\n  };\n  _proto.toJSON = function toJSON() {\n    var _this = this;\n    var merged = (0, _objectSpread2[\"default\"])({}, this._base.toJSON());\n    this._sink.getRecordIDs().forEach(function (dataID) {\n      var record = _this.get(dataID);\n      if (record === undefined) {\n        delete merged[dataID];\n      } else {\n        merged[dataID] = RelayModernRecord.toJSON(record);\n      }\n    });\n    return merged;\n  };\n  _proto.getOptimisticRecordIDs = function getOptimisticRecordIDs() {\n    return new Set(this._sink.getRecordIDs());\n  };\n  return RelayOptimisticRecordSource;\n}();\nfunction create(base) {\n  return new RelayOptimisticRecordSource(base);\n}\nfunction getOptimisticRecordIDs(source) {\n  !(source instanceof RelayOptimisticRecordSource) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'getOptimisticRecordIDs: Instance of RelayOptimisticRecordSource is expected') : invariant(false) : void 0;\n  return source.getOptimisticRecordIDs();\n}\nmodule.exports = {\n  create: create,\n  getOptimisticRecordIDs: getOptimisticRecordIDs\n};","'use strict';\n\nvar _global$ErrorUtils$ap, _global$ErrorUtils;\nvar RelayRecordSourceMutator = require('../mutations/RelayRecordSourceMutator');\nvar RelayRecordSourceProxy = require('../mutations/RelayRecordSourceProxy');\nvar RelayRecordSourceSelectorProxy = require('../mutations/RelayRecordSourceSelectorProxy');\nvar RelayReader = require('./RelayReader');\nvar RelayRecordSource = require('./RelayRecordSource');\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nvar _global = typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : undefined;\nvar applyWithGuard = (_global$ErrorUtils$ap = _global === null || _global === void 0 ? void 0 : (_global$ErrorUtils = _global.ErrorUtils) === null || _global$ErrorUtils === void 0 ? void 0 : _global$ErrorUtils.applyWithGuard) !== null && _global$ErrorUtils$ap !== void 0 ? _global$ErrorUtils$ap : function (callback, context, args, onError, name) {\n  return callback.apply(context, args);\n};\nvar RelayPublishQueue = /*#__PURE__*/function () {\n  function RelayPublishQueue(store, handlerProvider, getDataID, missingFieldHandlers) {\n    this._hasStoreSnapshot = false;\n    this._handlerProvider = handlerProvider || null;\n    this._pendingBackupRebase = false;\n    this._pendingData = new Set();\n    this._pendingOptimisticUpdates = new Set();\n    this._store = store;\n    this._appliedOptimisticUpdates = new Set();\n    this._gcHold = null;\n    this._getDataID = getDataID;\n    this._missingFieldHandlers = missingFieldHandlers;\n  }\n  var _proto = RelayPublishQueue.prototype;\n  _proto.applyUpdate = function applyUpdate(updater) {\n    !(!this._appliedOptimisticUpdates.has(updater) && !this._pendingOptimisticUpdates.has(updater)) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayPublishQueue: Cannot apply the same update function more than ' + 'once concurrently.') : invariant(false) : void 0;\n    this._pendingOptimisticUpdates.add(updater);\n  };\n  _proto.revertUpdate = function revertUpdate(updater) {\n    if (this._pendingOptimisticUpdates.has(updater)) {\n      this._pendingOptimisticUpdates[\"delete\"](updater);\n    } else if (this._appliedOptimisticUpdates.has(updater)) {\n      this._pendingBackupRebase = true;\n      this._appliedOptimisticUpdates[\"delete\"](updater);\n    }\n  };\n  _proto.revertAll = function revertAll() {\n    this._pendingBackupRebase = true;\n    this._pendingOptimisticUpdates.clear();\n    this._appliedOptimisticUpdates.clear();\n  };\n  _proto.commitPayload = function commitPayload(operation, payload, updater) {\n    this._pendingBackupRebase = true;\n    this._pendingData.add({\n      kind: 'payload',\n      operation: operation,\n      payload: payload,\n      updater: updater\n    });\n  };\n  _proto.commitUpdate = function commitUpdate(updater) {\n    this._pendingBackupRebase = true;\n    this._pendingData.add({\n      kind: 'updater',\n      updater: updater\n    });\n  };\n  _proto.commitSource = function commitSource(source) {\n    this._pendingBackupRebase = true;\n    this._pendingData.add({\n      kind: 'source',\n      source: source\n    });\n  };\n  _proto.run = function run(sourceOperation) {\n    var runWillClearGcHold = this._appliedOptimisticUpdates === 0 && !!this._gcHold;\n    var runIsANoop = !this._pendingBackupRebase && this._pendingOptimisticUpdates.size === 0 && !runWillClearGcHold;\n    if (process.env.NODE_ENV !== \"production\") {\n      process.env.NODE_ENV !== \"production\" ? warning(!runIsANoop, 'RelayPublishQueue.run was called, but the call would have been a noop.') : void 0;\n      process.env.NODE_ENV !== \"production\" ? warning(this._isRunning !== true, 'A store update was detected within another store update. Please ' + \"make sure new store updates aren't being executed within an \" + 'updater function for a different update.') : void 0;\n      this._isRunning = true;\n    }\n    if (runIsANoop) {\n      if (process.env.NODE_ENV !== \"production\") {\n        this._isRunning = false;\n      }\n      return [];\n    }\n    if (this._pendingBackupRebase) {\n      if (this._hasStoreSnapshot) {\n        this._store.restore();\n        this._hasStoreSnapshot = false;\n      }\n    }\n    var invalidatedStore = this._commitData();\n    if (this._pendingOptimisticUpdates.size || this._pendingBackupRebase && this._appliedOptimisticUpdates.size) {\n      if (!this._hasStoreSnapshot) {\n        this._store.snapshot();\n        this._hasStoreSnapshot = true;\n      }\n      this._applyUpdates();\n    }\n    this._pendingBackupRebase = false;\n    if (this._appliedOptimisticUpdates.size > 0) {\n      if (!this._gcHold) {\n        this._gcHold = this._store.holdGC();\n      }\n    } else {\n      if (this._gcHold) {\n        this._gcHold.dispose();\n        this._gcHold = null;\n      }\n    }\n    if (process.env.NODE_ENV !== \"production\") {\n      this._isRunning = false;\n    }\n    return this._store.notify(sourceOperation, invalidatedStore);\n  };\n  _proto._publishSourceFromPayload = function _publishSourceFromPayload(pendingPayload) {\n    var _this = this;\n    var payload = pendingPayload.payload,\n      operation = pendingPayload.operation,\n      updater = pendingPayload.updater;\n    var source = payload.source,\n      fieldPayloads = payload.fieldPayloads;\n    var mutator = new RelayRecordSourceMutator(this._store.getSource(), source);\n    var recordSourceProxy = new RelayRecordSourceProxy(mutator, this._getDataID, this._handlerProvider, this._missingFieldHandlers);\n    if (fieldPayloads && fieldPayloads.length) {\n      fieldPayloads.forEach(function (fieldPayload) {\n        var handler = _this._handlerProvider && _this._handlerProvider(fieldPayload.handle);\n        !handler ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernEnvironment: Expected a handler to be provided for ' + 'handle `%s`.', fieldPayload.handle) : invariant(false) : void 0;\n        handler.update(recordSourceProxy, fieldPayload);\n      });\n    }\n    if (updater) {\n      var selector = operation.fragment;\n      !(selector != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayModernEnvironment: Expected a selector to be provided with updater function.') : invariant(false) : void 0;\n      var recordSourceSelectorProxy = new RelayRecordSourceSelectorProxy(mutator, recordSourceProxy, selector, this._missingFieldHandlers);\n      var selectorData = lookupSelector(source, selector);\n      updater(recordSourceSelectorProxy, selectorData);\n    }\n    var idsMarkedForInvalidation = recordSourceProxy.getIDsMarkedForInvalidation();\n    this._store.publish(source, idsMarkedForInvalidation);\n    return recordSourceProxy.isStoreMarkedForInvalidation();\n  };\n  _proto._commitData = function _commitData() {\n    var _this2 = this;\n    if (!this._pendingData.size) {\n      return false;\n    }\n    var invalidatedStore = false;\n    this._pendingData.forEach(function (data) {\n      if (data.kind === 'payload') {\n        var payloadInvalidatedStore = _this2._publishSourceFromPayload(data);\n        invalidatedStore = invalidatedStore || payloadInvalidatedStore;\n      } else if (data.kind === 'source') {\n        var source = data.source;\n        _this2._store.publish(source);\n      } else {\n        var updater = data.updater;\n        var sink = RelayRecordSource.create();\n        var mutator = new RelayRecordSourceMutator(_this2._store.getSource(), sink);\n        var recordSourceProxy = new RelayRecordSourceProxy(mutator, _this2._getDataID, _this2._handlerProvider, _this2._missingFieldHandlers);\n        applyWithGuard(updater, null, [recordSourceProxy], null, 'RelayPublishQueue:commitData');\n        invalidatedStore = invalidatedStore || recordSourceProxy.isStoreMarkedForInvalidation();\n        var idsMarkedForInvalidation = recordSourceProxy.getIDsMarkedForInvalidation();\n        _this2._store.publish(sink, idsMarkedForInvalidation);\n      }\n    });\n    this._pendingData.clear();\n    return invalidatedStore;\n  };\n  _proto._applyUpdates = function _applyUpdates() {\n    var _this3 = this;\n    var sink = RelayRecordSource.create();\n    var mutator = new RelayRecordSourceMutator(this._store.getSource(), sink);\n    var recordSourceProxy = new RelayRecordSourceProxy(mutator, this._getDataID, this._handlerProvider, this._missingFieldHandlers);\n    var processUpdate = function processUpdate(optimisticUpdate) {\n      if (optimisticUpdate.storeUpdater) {\n        var storeUpdater = optimisticUpdate.storeUpdater;\n        applyWithGuard(storeUpdater, null, [recordSourceProxy], null, 'RelayPublishQueue:applyUpdates');\n      } else {\n        var operation = optimisticUpdate.operation,\n          payload = optimisticUpdate.payload,\n          updater = optimisticUpdate.updater;\n        var source = payload.source,\n          fieldPayloads = payload.fieldPayloads;\n        if (source) {\n          recordSourceProxy.publishSource(source, fieldPayloads);\n        }\n        if (updater) {\n          var selectorData;\n          if (source) {\n            selectorData = lookupSelector(source, operation.fragment);\n          }\n          var recordSourceSelectorProxy = new RelayRecordSourceSelectorProxy(mutator, recordSourceProxy, operation.fragment, _this3._missingFieldHandlers);\n          applyWithGuard(updater, null, [recordSourceSelectorProxy, selectorData], null, 'RelayPublishQueue:applyUpdates');\n        }\n      }\n    };\n    if (this._pendingBackupRebase && this._appliedOptimisticUpdates.size) {\n      this._appliedOptimisticUpdates.forEach(processUpdate);\n    }\n    if (this._pendingOptimisticUpdates.size) {\n      this._pendingOptimisticUpdates.forEach(function (optimisticUpdate) {\n        processUpdate(optimisticUpdate);\n        _this3._appliedOptimisticUpdates.add(optimisticUpdate);\n      });\n      this._pendingOptimisticUpdates.clear();\n    }\n    this._store.publish(sink);\n  };\n  return RelayPublishQueue;\n}();\nfunction lookupSelector(source, selector) {\n  var selectorData = RelayReader.read(source, selector).data;\n  if (process.env.NODE_ENV !== \"production\") {\n    var deepFreeze = require('../util/deepFreeze');\n    if (selectorData) {\n      deepFreeze(selectorData);\n    }\n  }\n  return selectorData;\n}\nmodule.exports = RelayPublishQueue;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar _require = require('../util/RelayConcreteNode'),\n  ACTOR_CHANGE = _require.ACTOR_CHANGE,\n  ALIASED_FRAGMENT_SPREAD = _require.ALIASED_FRAGMENT_SPREAD,\n  ALIASED_INLINE_FRAGMENT_SPREAD = _require.ALIASED_INLINE_FRAGMENT_SPREAD,\n  CLIENT_EDGE_TO_CLIENT_OBJECT = _require.CLIENT_EDGE_TO_CLIENT_OBJECT,\n  CLIENT_EDGE_TO_SERVER_OBJECT = _require.CLIENT_EDGE_TO_SERVER_OBJECT,\n  CLIENT_EXTENSION = _require.CLIENT_EXTENSION,\n  CONDITION = _require.CONDITION,\n  DEFER = _require.DEFER,\n  FRAGMENT_SPREAD = _require.FRAGMENT_SPREAD,\n  INLINE_DATA_FRAGMENT_SPREAD = _require.INLINE_DATA_FRAGMENT_SPREAD,\n  INLINE_FRAGMENT = _require.INLINE_FRAGMENT,\n  LINKED_FIELD = _require.LINKED_FIELD,\n  MODULE_IMPORT = _require.MODULE_IMPORT,\n  RELAY_LIVE_RESOLVER = _require.RELAY_LIVE_RESOLVER,\n  RELAY_RESOLVER = _require.RELAY_RESOLVER,\n  REQUIRED_FIELD = _require.REQUIRED_FIELD,\n  SCALAR_FIELD = _require.SCALAR_FIELD,\n  STREAM = _require.STREAM;\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar _require2 = require('./experimental-live-resolvers/LiveResolverSuspenseSentinel'),\n  isSuspenseSentinel = _require2.isSuspenseSentinel;\nvar RelayConcreteVariables = require('./RelayConcreteVariables');\nvar RelayModernRecord = require('./RelayModernRecord');\nvar _require3 = require('./RelayStoreUtils'),\n  CLIENT_EDGE_TRAVERSAL_PATH = _require3.CLIENT_EDGE_TRAVERSAL_PATH,\n  FRAGMENT_OWNER_KEY = _require3.FRAGMENT_OWNER_KEY,\n  FRAGMENT_PROP_NAME_KEY = _require3.FRAGMENT_PROP_NAME_KEY,\n  FRAGMENTS_KEY = _require3.FRAGMENTS_KEY,\n  ID_KEY = _require3.ID_KEY,\n  MODULE_COMPONENT_KEY = _require3.MODULE_COMPONENT_KEY,\n  ROOT_ID = _require3.ROOT_ID,\n  getArgumentValues = _require3.getArgumentValues,\n  getModuleComponentKey = _require3.getModuleComponentKey,\n  getStorageKey = _require3.getStorageKey;\nvar _require4 = require('./ResolverCache'),\n  NoopResolverCache = _require4.NoopResolverCache;\nvar _require5 = require('./ResolverFragments'),\n  RESOLVER_FRAGMENT_MISSING_DATA_SENTINEL = _require5.RESOLVER_FRAGMENT_MISSING_DATA_SENTINEL,\n  withResolverContext = _require5.withResolverContext;\nvar _require6 = require('./TypeID'),\n  generateTypeID = _require6.generateTypeID;\nvar invariant = require('invariant');\nfunction read(recordSource, selector, resolverCache) {\n  var reader = new RelayReader(recordSource, selector, resolverCache !== null && resolverCache !== void 0 ? resolverCache : new NoopResolverCache());\n  return reader.read();\n}\nvar RelayReader = /*#__PURE__*/function () {\n  function RelayReader(recordSource, selector, resolverCache) {\n    var _selector$clientEdgeT;\n    this._clientEdgeTraversalPath = RelayFeatureFlags.ENABLE_CLIENT_EDGES && (_selector$clientEdgeT = selector.clientEdgeTraversalPath) !== null && _selector$clientEdgeT !== void 0 && _selector$clientEdgeT.length ? (0, _toConsumableArray2[\"default\"])(selector.clientEdgeTraversalPath) : [];\n    this._missingClientEdges = [];\n    this._missingLiveResolverFields = [];\n    this._isMissingData = false;\n    this._isWithinUnmatchedTypeRefinement = false;\n    this._missingRequiredFields = null;\n    this._errorResponseFields = null;\n    this._owner = selector.owner;\n    this._recordSource = recordSource;\n    this._seenRecords = new Set();\n    this._selector = selector;\n    this._variables = selector.variables;\n    this._resolverCache = resolverCache;\n    this._resolverErrors = [];\n    this._fragmentName = selector.node.name;\n    this._updatedDataIDs = new Set();\n  }\n  var _proto = RelayReader.prototype;\n  _proto.read = function read() {\n    var _this$_selector = this._selector,\n      node = _this$_selector.node,\n      dataID = _this$_selector.dataID,\n      isWithinUnmatchedTypeRefinement = _this$_selector.isWithinUnmatchedTypeRefinement;\n    var abstractKey = node.abstractKey;\n    var record = this._recordSource.get(dataID);\n    var isDataExpectedToBePresent = !isWithinUnmatchedTypeRefinement;\n    if (isDataExpectedToBePresent && abstractKey == null && record != null) {\n      var recordType = RelayModernRecord.getType(record);\n      if (recordType !== node.type && dataID !== ROOT_ID) {\n        isDataExpectedToBePresent = false;\n      }\n    }\n    if (isDataExpectedToBePresent && abstractKey != null && record != null) {\n      var implementsInterface = this._implementsInterface(record, abstractKey);\n      if (implementsInterface === false) {\n        isDataExpectedToBePresent = false;\n      } else if (implementsInterface == null) {\n        this._isMissingData = true;\n      }\n    }\n    this._isWithinUnmatchedTypeRefinement = !isDataExpectedToBePresent;\n    var data = this._traverse(node, dataID, null);\n    if (this._updatedDataIDs.size > 0) {\n      this._resolverCache.notifyUpdatedSubscribers(this._updatedDataIDs);\n      this._updatedDataIDs.clear();\n    }\n    return {\n      data: data,\n      isMissingData: this._isMissingData && isDataExpectedToBePresent,\n      missingClientEdges: RelayFeatureFlags.ENABLE_CLIENT_EDGES && this._missingClientEdges.length ? this._missingClientEdges : null,\n      missingLiveResolverFields: this._missingLiveResolverFields,\n      seenRecords: this._seenRecords,\n      selector: this._selector,\n      missingRequiredFields: this._missingRequiredFields,\n      relayResolverErrors: this._resolverErrors,\n      errorResponseFields: this._errorResponseFields\n    };\n  };\n  _proto._maybeAddErrorResponseFields = function _maybeAddErrorResponseFields(record, storageKey) {\n    if (!RelayFeatureFlags.ENABLE_FIELD_ERROR_HANDLING) {\n      return;\n    }\n    var errors = RelayModernRecord.getErrors(record, storageKey);\n    if (errors == null) {\n      return;\n    }\n    var owner = this._fragmentName;\n    if (this._errorResponseFields == null) {\n      this._errorResponseFields = [];\n    }\n    var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(errors),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var _error$path;\n        var error = _step.value;\n        this._errorResponseFields.push({\n          owner: owner,\n          path: ((_error$path = error.path) !== null && _error$path !== void 0 ? _error$path : []).join('.'),\n          error: error\n        });\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n  };\n  _proto._markDataAsMissing = function _markDataAsMissing() {\n    this._isMissingData = true;\n    if (RelayFeatureFlags.ENABLE_CLIENT_EDGES && this._clientEdgeTraversalPath.length) {\n      var top = this._clientEdgeTraversalPath[this._clientEdgeTraversalPath.length - 1];\n      if (top !== null) {\n        this._missingClientEdges.push({\n          request: top.readerClientEdge.operation,\n          clientEdgeDestinationID: top.clientEdgeDestinationID\n        });\n      }\n    }\n  };\n  _proto._traverse = function _traverse(node, dataID, prevData) {\n    var record = this._recordSource.get(dataID);\n    this._seenRecords.add(dataID);\n    if (record == null) {\n      if (record === undefined) {\n        this._markDataAsMissing();\n      }\n      return record;\n    }\n    var data = prevData || {};\n    var hadRequiredData = this._traverseSelections(node.selections, record, data);\n    return hadRequiredData ? data : null;\n  };\n  _proto._getVariableValue = function _getVariableValue(name) {\n    !this._variables.hasOwnProperty(name) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader(): Undefined variable `%s`.', name) : invariant(false) : void 0;\n    return this._variables[name];\n  };\n  _proto._maybeReportUnexpectedNull = function _maybeReportUnexpectedNull(fieldPath, action) {\n    var _this$_missingRequire;\n    if (((_this$_missingRequire = this._missingRequiredFields) === null || _this$_missingRequire === void 0 ? void 0 : _this$_missingRequire.action) === 'THROW') {\n      return;\n    }\n    var owner = this._fragmentName;\n    switch (action) {\n      case 'THROW':\n        this._missingRequiredFields = {\n          action: action,\n          field: {\n            path: fieldPath,\n            owner: owner\n          }\n        };\n        return;\n      case 'LOG':\n        if (this._missingRequiredFields == null) {\n          this._missingRequiredFields = {\n            action: action,\n            fields: [{\n              path: fieldPath,\n              owner: owner\n            }]\n          };\n        } else {\n          this._missingRequiredFields = {\n            action: action,\n            fields: [].concat((0, _toConsumableArray2[\"default\"])(this._missingRequiredFields.fields), [{\n              path: fieldPath,\n              owner: owner\n            }])\n          };\n        }\n        return;\n      default:\n        action;\n    }\n  };\n  _proto._traverseSelections = function _traverseSelections(selections, record, data) {\n    for (var i = 0; i < selections.length; i++) {\n      var selection = selections[i];\n      switch (selection.kind) {\n        case REQUIRED_FIELD:\n          {\n            var fieldValue = this._readRequiredField(selection, record, data);\n            if (fieldValue == null) {\n              var action = selection.action;\n              if (action !== 'NONE') {\n                this._maybeReportUnexpectedNull(selection.path, action);\n              }\n              return false;\n            }\n            break;\n          }\n        case SCALAR_FIELD:\n          this._readScalar(selection, record, data);\n          break;\n        case LINKED_FIELD:\n          if (selection.plural) {\n            this._readPluralLink(selection, record, data);\n          } else {\n            this._readLink(selection, record, data);\n          }\n          break;\n        case CONDITION:\n          var conditionValue = Boolean(this._getVariableValue(selection.condition));\n          if (conditionValue === selection.passingValue) {\n            var hasExpectedData = this._traverseSelections(selection.selections, record, data);\n            if (!hasExpectedData) {\n              return false;\n            }\n          }\n          break;\n        case INLINE_FRAGMENT:\n          {\n            if (this._readInlineFragment(selection, record, data) === false) {\n              return false;\n            }\n            break;\n          }\n        case RELAY_LIVE_RESOLVER:\n        case RELAY_RESOLVER:\n          {\n            if (!RelayFeatureFlags.ENABLE_RELAY_RESOLVERS) {\n              throw new Error('Relay Resolver fields are not yet supported.');\n            }\n            this._readResolverField(selection, record, data);\n            break;\n          }\n        case FRAGMENT_SPREAD:\n          this._createFragmentPointer(selection, record, data);\n          break;\n        case ALIASED_FRAGMENT_SPREAD:\n          data[selection.name] = this._createAliasedFragmentSpread(selection, record);\n          break;\n        case ALIASED_INLINE_FRAGMENT_SPREAD:\n          {\n            var _fieldValue = this._readInlineFragment(selection.fragment, record, {});\n            if (_fieldValue === false) {\n              _fieldValue = null;\n            }\n            data[selection.name] = _fieldValue;\n            break;\n          }\n        case MODULE_IMPORT:\n          this._readModuleImport(selection, record, data);\n          break;\n        case INLINE_DATA_FRAGMENT_SPREAD:\n          this._createInlineDataOrResolverFragmentPointer(selection, record, data);\n          break;\n        case DEFER:\n        case CLIENT_EXTENSION:\n          {\n            var isMissingData = this._isMissingData;\n            var alreadyMissingClientEdges = this._missingClientEdges.length;\n            if (RelayFeatureFlags.ENABLE_CLIENT_EDGES) {\n              this._clientEdgeTraversalPath.push(null);\n            }\n            var _hasExpectedData = this._traverseSelections(selection.selections, record, data);\n            this._isMissingData = isMissingData || this._missingClientEdges.length > alreadyMissingClientEdges || this._missingLiveResolverFields.length > 0;\n            if (RelayFeatureFlags.ENABLE_CLIENT_EDGES) {\n              this._clientEdgeTraversalPath.pop();\n            }\n            if (!_hasExpectedData) {\n              return false;\n            }\n            break;\n          }\n        case STREAM:\n          {\n            var _hasExpectedData2 = this._traverseSelections(selection.selections, record, data);\n            if (!_hasExpectedData2) {\n              return false;\n            }\n            break;\n          }\n        case ACTOR_CHANGE:\n          this._readActorChange(selection, record, data);\n          break;\n        case CLIENT_EDGE_TO_CLIENT_OBJECT:\n        case CLIENT_EDGE_TO_SERVER_OBJECT:\n          if (RelayFeatureFlags.ENABLE_CLIENT_EDGES) {\n            this._readClientEdge(selection, record, data);\n          } else {\n            throw new Error('Client edges are not yet supported.');\n          }\n          break;\n        default:\n          selection;\n          !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader(): Unexpected ast kind `%s`.', selection.kind) : invariant(false) : void 0;\n      }\n    }\n    return true;\n  };\n  _proto._readRequiredField = function _readRequiredField(selection, record, data) {\n    switch (selection.field.kind) {\n      case SCALAR_FIELD:\n        return this._readScalar(selection.field, record, data);\n      case LINKED_FIELD:\n        if (selection.field.plural) {\n          return this._readPluralLink(selection.field, record, data);\n        } else {\n          return this._readLink(selection.field, record, data);\n        }\n      case RELAY_RESOLVER:\n        if (!RelayFeatureFlags.ENABLE_RELAY_RESOLVERS) {\n          throw new Error('Relay Resolver fields are not yet supported.');\n        }\n        return this._readResolverField(selection.field, record, data);\n      case RELAY_LIVE_RESOLVER:\n        if (!RelayFeatureFlags.ENABLE_RELAY_RESOLVERS) {\n          throw new Error('Relay Resolver fields are not yet supported.');\n        }\n        return this._readResolverField(selection.field, record, data);\n      case CLIENT_EDGE_TO_CLIENT_OBJECT:\n      case CLIENT_EDGE_TO_SERVER_OBJECT:\n        if (!RelayFeatureFlags.ENABLE_RELAY_RESOLVERS) {\n          throw new Error('Relay Resolver fields are not yet supported.');\n        }\n        return this._readClientEdge(selection.field, record, data);\n      default:\n        selection.field.kind;\n        !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader(): Unexpected ast kind `%s`.', selection.kind) : invariant(false) : void 0;\n    }\n  };\n  _proto._readResolverField = function _readResolverField(field, record, data) {\n    var _field$alias;\n    var parentRecordID = RelayModernRecord.getDataID(record);\n    var result = this._readResolverFieldImpl(field, parentRecordID);\n    var applicationName = (_field$alias = field.alias) !== null && _field$alias !== void 0 ? _field$alias : field.name;\n    data[applicationName] = result;\n    return result;\n  };\n  _proto._readResolverFieldImpl = function _readResolverFieldImpl(field, parentRecordID) {\n    var _this = this;\n    var fragment = field.fragment;\n    var snapshot;\n    var getDataForResolverFragment = function getDataForResolverFragment(singularReaderSelector) {\n      if (snapshot != null) {\n        return {\n          data: snapshot.data,\n          isMissingData: snapshot.isMissingData\n        };\n      }\n      snapshot = read(_this._recordSource, singularReaderSelector, _this._resolverCache);\n      return {\n        data: snapshot.data,\n        isMissingData: snapshot.isMissingData\n      };\n    };\n    var evaluate = function evaluate() {\n      if (fragment != null) {\n        var key = {\n          __id: parentRecordID,\n          __fragmentOwner: _this._owner,\n          __fragments: (0, _defineProperty2[\"default\"])({}, fragment.name, fragment.args ? getArgumentValues(fragment.args, _this._variables) : {})\n        };\n        var resolverContext = {\n          getDataForResolverFragment: getDataForResolverFragment\n        };\n        return withResolverContext(resolverContext, function () {\n          var _getResolverValue = getResolverValue(field, _this._variables, key),\n            resolverResult = _getResolverValue[0],\n            resolverError = _getResolverValue[1];\n          return {\n            resolverResult: resolverResult,\n            snapshot: snapshot,\n            error: resolverError\n          };\n        });\n      } else {\n        var _getResolverValue2 = getResolverValue(field, _this._variables, null),\n          resolverResult = _getResolverValue2[0],\n          _resolverError = _getResolverValue2[1];\n        return {\n          resolverResult: resolverResult,\n          snapshot: undefined,\n          error: _resolverError\n        };\n      }\n    };\n    var _this$_resolverCache$ = this._resolverCache.readFromCacheOrEvaluate(parentRecordID, field, this._variables, evaluate, getDataForResolverFragment),\n      result = _this$_resolverCache$[0],\n      seenRecord = _this$_resolverCache$[1],\n      resolverError = _this$_resolverCache$[2],\n      cachedSnapshot = _this$_resolverCache$[3],\n      suspenseID = _this$_resolverCache$[4],\n      updatedDataIDs = _this$_resolverCache$[5];\n    this._propogateResolverMetadata(field.path, cachedSnapshot, resolverError, seenRecord, suspenseID, updatedDataIDs);\n    return result;\n  };\n  _proto._propogateResolverMetadata = function _propogateResolverMetadata(fieldPath, cachedSnapshot, resolverError, seenRecord, suspenseID, updatedDataIDs) {\n    if (cachedSnapshot != null) {\n      if (cachedSnapshot.missingRequiredFields != null) {\n        this._addMissingRequiredFields(cachedSnapshot.missingRequiredFields);\n      }\n      if (cachedSnapshot.missingClientEdges != null) {\n        var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(cachedSnapshot.missingClientEdges),\n          _step2;\n        try {\n          for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n            var missing = _step2.value;\n            this._missingClientEdges.push(missing);\n          }\n        } catch (err) {\n          _iterator2.e(err);\n        } finally {\n          _iterator2.f();\n        }\n      }\n      if (cachedSnapshot.missingLiveResolverFields != null) {\n        this._isMissingData = this._isMissingData || cachedSnapshot.missingLiveResolverFields.length > 0;\n        var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])(cachedSnapshot.missingLiveResolverFields),\n          _step3;\n        try {\n          for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n            var missingResolverField = _step3.value;\n            this._missingLiveResolverFields.push(missingResolverField);\n          }\n        } catch (err) {\n          _iterator3.e(err);\n        } finally {\n          _iterator3.f();\n        }\n      }\n      var _iterator4 = (0, _createForOfIteratorHelper2[\"default\"])(cachedSnapshot.relayResolverErrors),\n        _step4;\n      try {\n        for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n          var error = _step4.value;\n          this._resolverErrors.push(error);\n        }\n      } catch (err) {\n        _iterator4.e(err);\n      } finally {\n        _iterator4.f();\n      }\n      this._isMissingData = this._isMissingData || cachedSnapshot.isMissingData;\n    }\n    if (resolverError) {\n      this._resolverErrors.push({\n        field: {\n          path: fieldPath,\n          owner: this._fragmentName\n        },\n        error: resolverError\n      });\n    }\n    if (seenRecord != null) {\n      this._seenRecords.add(seenRecord);\n    }\n    if (suspenseID != null) {\n      this._isMissingData = true;\n      this._missingLiveResolverFields.push({\n        path: \"\".concat(this._fragmentName, \".\").concat(fieldPath),\n        liveStateID: suspenseID\n      });\n    }\n    if (updatedDataIDs != null) {\n      var _iterator5 = (0, _createForOfIteratorHelper2[\"default\"])(updatedDataIDs),\n        _step5;\n      try {\n        for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n          var recordID = _step5.value;\n          this._updatedDataIDs.add(recordID);\n        }\n      } catch (err) {\n        _iterator5.e(err);\n      } finally {\n        _iterator5.f();\n      }\n    }\n  };\n  _proto._readClientEdge = function _readClientEdge(field, record, data) {\n    var _this2 = this;\n    var _backingField$alias;\n    var backingField = field.backingField;\n    !(backingField.kind !== 'ClientExtension') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Client extension client edges are not yet implemented.') : invariant(false) : void 0;\n    var applicationName = (_backingField$alias = backingField.alias) !== null && _backingField$alias !== void 0 ? _backingField$alias : backingField.name;\n    var backingFieldData = {};\n    this._traverseSelections([backingField], record, backingFieldData);\n    var clientEdgeResolverResponse = backingFieldData[applicationName];\n    if (clientEdgeResolverResponse == null || isSuspenseSentinel(clientEdgeResolverResponse)) {\n      data[applicationName] = clientEdgeResolverResponse;\n      return clientEdgeResolverResponse;\n    }\n    var validClientEdgeResolverResponse = assertValidClientEdgeResolverResponse(field, clientEdgeResolverResponse);\n    switch (validClientEdgeResolverResponse.kind) {\n      case 'PluralConcrete':\n        var storeIDs = getStoreIDsForPluralClientEdgeResolver(field, validClientEdgeResolverResponse.ids, this._resolverCache);\n        var validStoreIDs = storeIDs;\n        if (field.modelResolver != null) {\n          var modelResolver = field.modelResolver;\n          validStoreIDs = storeIDs.map(function (storeID) {\n            var model = _this2._readResolverFieldImpl(modelResolver, storeID);\n            return model != null ? storeID : null;\n          });\n        }\n        this._clientEdgeTraversalPath.push(null);\n        var edgeValues = this._readLinkedIds(field.linkedField, validStoreIDs, record, data);\n        this._clientEdgeTraversalPath.pop();\n        data[applicationName] = edgeValues;\n        return edgeValues;\n      case 'SingularConcrete':\n        var _getStoreIDAndTravers = getStoreIDAndTraversalPathSegmentForSingularClientEdgeResolver(field, validClientEdgeResolverResponse.id, this._resolverCache),\n          storeID = _getStoreIDAndTravers[0],\n          traversalPathSegment = _getStoreIDAndTravers[1];\n        if (field.modelResolver != null) {\n          var model = this._readResolverFieldImpl(field.modelResolver, storeID);\n          if (model == null) {\n            data[applicationName] = null;\n            return null;\n          }\n        }\n        this._clientEdgeTraversalPath.push(traversalPathSegment);\n        var prevData = data[applicationName];\n        !(prevData == null || typeof prevData === 'object') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader(): Expected data for field `%s` on record `%s` ' + 'to be an object, got `%s`.', applicationName, RelayModernRecord.getDataID(record), prevData) : invariant(false) : void 0;\n        var edgeValue = this._traverse(field.linkedField, storeID, prevData);\n        this._clientEdgeTraversalPath.pop();\n        data[applicationName] = edgeValue;\n        return edgeValue;\n      default:\n        validClientEdgeResolverResponse.kind;\n    }\n  };\n  _proto._readScalar = function _readScalar(field, record, data) {\n    var _field$alias2;\n    var applicationName = (_field$alias2 = field.alias) !== null && _field$alias2 !== void 0 ? _field$alias2 : field.name;\n    var storageKey = getStorageKey(field, this._variables);\n    var value = RelayModernRecord.getValue(record, storageKey);\n    if (value === null) {\n      this._maybeAddErrorResponseFields(record, storageKey);\n    } else if (value === undefined) {\n      this._markDataAsMissing();\n    }\n    data[applicationName] = value;\n    return value;\n  };\n  _proto._readLink = function _readLink(field, record, data) {\n    var _field$alias3;\n    var applicationName = (_field$alias3 = field.alias) !== null && _field$alias3 !== void 0 ? _field$alias3 : field.name;\n    var storageKey = getStorageKey(field, this._variables);\n    var linkedID = RelayModernRecord.getLinkedRecordID(record, storageKey);\n    if (linkedID == null) {\n      data[applicationName] = linkedID;\n      if (linkedID === null) {\n        this._maybeAddErrorResponseFields(record, storageKey);\n      } else if (linkedID === undefined) {\n        this._markDataAsMissing();\n      }\n      return linkedID;\n    }\n    var prevData = data[applicationName];\n    !(prevData == null || typeof prevData === 'object') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader(): Expected data for field `%s` on record `%s` ' + 'to be an object, got `%s`.', applicationName, RelayModernRecord.getDataID(record), prevData) : invariant(false) : void 0;\n    var value = this._traverse(field, linkedID, prevData);\n    data[applicationName] = value;\n    return value;\n  };\n  _proto._readActorChange = function _readActorChange(field, record, data) {\n    var _field$alias4;\n    var applicationName = (_field$alias4 = field.alias) !== null && _field$alias4 !== void 0 ? _field$alias4 : field.name;\n    var storageKey = getStorageKey(field, this._variables);\n    var externalRef = RelayModernRecord.getActorLinkedRecordID(record, storageKey);\n    if (externalRef == null) {\n      data[applicationName] = externalRef;\n      if (externalRef === undefined) {\n        this._markDataAsMissing();\n      } else if (externalRef === null) {\n        this._maybeAddErrorResponseFields(record, storageKey);\n      }\n      return data[applicationName];\n    }\n    var actorIdentifier = externalRef[0],\n      dataID = externalRef[1];\n    var fragmentRef = {};\n    this._createFragmentPointer(field.fragmentSpread, RelayModernRecord.fromObject({\n      __id: dataID\n    }), fragmentRef);\n    data[applicationName] = {\n      __fragmentRef: fragmentRef,\n      __viewer: actorIdentifier\n    };\n    return data[applicationName];\n  };\n  _proto._readPluralLink = function _readPluralLink(field, record, data) {\n    var storageKey = getStorageKey(field, this._variables);\n    var linkedIDs = RelayModernRecord.getLinkedRecordIDs(record, storageKey);\n    if (linkedIDs === null) {\n      this._maybeAddErrorResponseFields(record, storageKey);\n    }\n    return this._readLinkedIds(field, linkedIDs, record, data);\n  };\n  _proto._readLinkedIds = function _readLinkedIds(field, linkedIDs, record, data) {\n    var _this3 = this;\n    var _field$alias5;\n    var applicationName = (_field$alias5 = field.alias) !== null && _field$alias5 !== void 0 ? _field$alias5 : field.name;\n    if (linkedIDs == null) {\n      data[applicationName] = linkedIDs;\n      if (linkedIDs === undefined) {\n        this._markDataAsMissing();\n      }\n      return linkedIDs;\n    }\n    var prevData = data[applicationName];\n    !(prevData == null || Array.isArray(prevData)) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader(): Expected data for field `%s` on record `%s` ' + 'to be an array, got `%s`.', applicationName, RelayModernRecord.getDataID(record), prevData) : invariant(false) : void 0;\n    var linkedArray = prevData || [];\n    linkedIDs.forEach(function (linkedID, nextIndex) {\n      if (linkedID == null) {\n        if (linkedID === undefined) {\n          _this3._markDataAsMissing();\n        }\n        linkedArray[nextIndex] = linkedID;\n        return;\n      }\n      var prevItem = linkedArray[nextIndex];\n      !(prevItem == null || typeof prevItem === 'object') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader(): Expected data for field `%s` on record `%s` ' + 'to be an object, got `%s`.', applicationName, RelayModernRecord.getDataID(record), prevItem) : invariant(false) : void 0;\n      linkedArray[nextIndex] = _this3._traverse(field, linkedID, prevItem);\n    });\n    data[applicationName] = linkedArray;\n    return linkedArray;\n  };\n  _proto._readModuleImport = function _readModuleImport(moduleImport, record, data) {\n    var componentKey = getModuleComponentKey(moduleImport.documentName);\n    var component = RelayModernRecord.getValue(record, componentKey);\n    if (component == null) {\n      if (component === undefined) {\n        this._markDataAsMissing();\n      }\n      return;\n    }\n    this._createFragmentPointer({\n      kind: 'FragmentSpread',\n      name: moduleImport.fragmentName,\n      args: moduleImport.args\n    }, record, data);\n    data[FRAGMENT_PROP_NAME_KEY] = moduleImport.fragmentPropName;\n    data[MODULE_COMPONENT_KEY] = component;\n  };\n  _proto._createAliasedFragmentSpread = function _createAliasedFragmentSpread(namedFragmentSpread, record) {\n    var abstractKey = namedFragmentSpread.abstractKey;\n    if (abstractKey == null) {\n      var typeName = RelayModernRecord.getType(record);\n      if (typeName == null || typeName !== namedFragmentSpread.type) {\n        return null;\n      }\n    } else {\n      var implementsInterface = this._implementsInterface(record, abstractKey);\n      if (implementsInterface === false) {\n        return null;\n      } else if (implementsInterface == null) {\n        this._markDataAsMissing();\n        return undefined;\n      }\n    }\n    var fieldData = {};\n    this._createFragmentPointer(namedFragmentSpread.fragment, record, fieldData);\n    return RelayModernRecord.fromObject(fieldData);\n  };\n  _proto._readInlineFragment = function _readInlineFragment(inlineFragment, record, data) {\n    var abstractKey = inlineFragment.abstractKey;\n    if (abstractKey == null) {\n      var typeName = RelayModernRecord.getType(record);\n      if (typeName == null || typeName !== inlineFragment.type) {\n        return null;\n      } else {\n        var hasExpectedData = this._traverseSelections(inlineFragment.selections, record, data);\n        if (!hasExpectedData) {\n          return false;\n        }\n      }\n    } else {\n      var implementsInterface = this._implementsInterface(record, abstractKey);\n      var parentIsMissingData = this._isMissingData;\n      var parentIsWithinUnmatchedTypeRefinement = this._isWithinUnmatchedTypeRefinement;\n      this._isWithinUnmatchedTypeRefinement = parentIsWithinUnmatchedTypeRefinement || implementsInterface === false;\n      this._traverseSelections(inlineFragment.selections, record, data);\n      this._isWithinUnmatchedTypeRefinement = parentIsWithinUnmatchedTypeRefinement;\n      if (implementsInterface === false) {\n        this._isMissingData = parentIsMissingData;\n        return undefined;\n      } else if (implementsInterface == null) {\n        this._markDataAsMissing();\n        return null;\n      }\n    }\n    return data;\n  };\n  _proto._createFragmentPointer = function _createFragmentPointer(fragmentSpread, record, data) {\n    var fragmentPointers = data[FRAGMENTS_KEY];\n    if (fragmentPointers == null) {\n      fragmentPointers = data[FRAGMENTS_KEY] = {};\n    }\n    !(typeof fragmentPointers === 'object' && fragmentPointers != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader: Expected fragment spread data to be an object, got `%s`.', fragmentPointers) : invariant(false) : void 0;\n    if (data[ID_KEY] == null) {\n      data[ID_KEY] = RelayModernRecord.getDataID(record);\n    }\n    fragmentPointers[fragmentSpread.name] = getArgumentValues(fragmentSpread.args, this._variables, this._isWithinUnmatchedTypeRefinement);\n    data[FRAGMENT_OWNER_KEY] = this._owner;\n    if (RelayFeatureFlags.ENABLE_CLIENT_EDGES) {\n      if (this._clientEdgeTraversalPath.length > 0 && this._clientEdgeTraversalPath[this._clientEdgeTraversalPath.length - 1] !== null) {\n        data[CLIENT_EDGE_TRAVERSAL_PATH] = (0, _toConsumableArray2[\"default\"])(this._clientEdgeTraversalPath);\n      }\n    }\n  };\n  _proto._createInlineDataOrResolverFragmentPointer = function _createInlineDataOrResolverFragmentPointer(fragmentSpreadOrFragment, record, data) {\n    var fragmentPointers = data[FRAGMENTS_KEY];\n    if (fragmentPointers == null) {\n      fragmentPointers = data[FRAGMENTS_KEY] = {};\n    }\n    !(typeof fragmentPointers === 'object' && fragmentPointers != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReader: Expected fragment spread data to be an object, got `%s`.', fragmentPointers) : invariant(false) : void 0;\n    if (data[ID_KEY] == null) {\n      data[ID_KEY] = RelayModernRecord.getDataID(record);\n    }\n    var inlineData = {};\n    var parentFragmentName = this._fragmentName;\n    this._fragmentName = fragmentSpreadOrFragment.name;\n    var parentVariables = this._variables;\n    var argumentVariables = fragmentSpreadOrFragment.args ? getArgumentValues(fragmentSpreadOrFragment.args, this._variables) : {};\n    this._variables = RelayConcreteVariables.getFragmentVariables(fragmentSpreadOrFragment, this._owner.variables, argumentVariables);\n    this._traverseSelections(fragmentSpreadOrFragment.selections, record, inlineData);\n    this._variables = parentVariables;\n    this._fragmentName = parentFragmentName;\n    fragmentPointers[fragmentSpreadOrFragment.name] = inlineData;\n  };\n  _proto._addMissingRequiredFields = function _addMissingRequiredFields(additional) {\n    if (this._missingRequiredFields == null) {\n      this._missingRequiredFields = additional;\n      return;\n    }\n    if (this._missingRequiredFields.action === 'THROW') {\n      return;\n    }\n    if (additional.action === 'THROW') {\n      this._missingRequiredFields = additional;\n      return;\n    }\n    this._missingRequiredFields = {\n      action: 'LOG',\n      fields: [].concat((0, _toConsumableArray2[\"default\"])(this._missingRequiredFields.fields), (0, _toConsumableArray2[\"default\"])(additional.fields))\n    };\n  };\n  _proto._implementsInterface = function _implementsInterface(record, abstractKey) {\n    var typeName = RelayModernRecord.getType(record);\n    var typeRecord = this._recordSource.get(generateTypeID(typeName));\n    var implementsInterface = typeRecord != null ? RelayModernRecord.getValue(typeRecord, abstractKey) : null;\n    return implementsInterface;\n  };\n  return RelayReader;\n}();\nfunction getResolverValue(field, variables, fragmentKey) {\n  var resolverFunction = typeof field.resolverModule === 'function' ? field.resolverModule : field.resolverModule[\"default\"];\n  var resolverResult = null;\n  var resolverError = null;\n  try {\n    var resolverFunctionArgs = [];\n    if (field.fragment != null) {\n      resolverFunctionArgs.push(fragmentKey);\n    }\n    var args = field.args ? getArgumentValues(field.args, variables) : undefined;\n    resolverFunctionArgs.push(args);\n    resolverResult = resolverFunction.apply(null, resolverFunctionArgs);\n  } catch (e) {\n    if (e === RESOLVER_FRAGMENT_MISSING_DATA_SENTINEL) {\n      resolverResult = undefined;\n    } else {\n      resolverError = e;\n    }\n  }\n  return [resolverResult, resolverError];\n}\nfunction assertValidClientEdgeResolverResponse(field, clientEdgeResolverResponse) {\n  if (field.linkedField.plural) {\n    !Array.isArray(clientEdgeResolverResponse) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Expected plural Client Edge Relay Resolver to return an array containing IDs or objects with shape {id}.') : invariant(false) : void 0;\n    return {\n      kind: 'PluralConcrete',\n      ids: clientEdgeResolverResponse.map(function (response) {\n        return extractIdFromResponse(response, 'Expected this plural Client Edge Relay Resolver to return an array containing IDs or objects with shape {id}.');\n      })\n    };\n  } else {\n    return {\n      kind: 'SingularConcrete',\n      id: extractIdFromResponse(clientEdgeResolverResponse, 'Expected this Client Edge Relay Resolver to return an ID of type `string` or an object with shape {id}.')\n    };\n  }\n}\nfunction getStoreIDAndTraversalPathSegmentForSingularClientEdgeResolver(field, clientEdgeResolverResponse, resolverCache) {\n  if (field.kind === CLIENT_EDGE_TO_CLIENT_OBJECT) {\n    if (field.backingField.normalizationInfo == null) {\n      var concreteType = field.concreteType;\n      !(concreteType != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Expected at least one of backingField.normalizationInfo or field.concreteType to be non-null. ' + 'This indicates a bug in Relay.') : invariant(false) : void 0;\n      return [resolverCache.ensureClientRecord(clientEdgeResolverResponse, concreteType), null];\n    } else {\n      return [clientEdgeResolverResponse, null];\n    }\n  } else {\n    return [clientEdgeResolverResponse, {\n      readerClientEdge: field,\n      clientEdgeDestinationID: clientEdgeResolverResponse\n    }];\n  }\n}\nfunction getStoreIDsForPluralClientEdgeResolver(field, clientEdgeResolverResponse, resolverCache) {\n  if (field.kind === CLIENT_EDGE_TO_CLIENT_OBJECT) {\n    if (field.backingField.normalizationInfo == null) {\n      var concreteType = field.concreteType;\n      !(concreteType != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Expected at least one of backingField.normalizationInfo or field.concreteType to be non-null. ' + 'This indicates a bug in Relay.') : invariant(false) : void 0;\n      return clientEdgeResolverResponse.map(function (id) {\n        return resolverCache.ensureClientRecord(id, concreteType);\n      });\n    } else {\n      return clientEdgeResolverResponse;\n    }\n  } else {\n    !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Unexpected Client Edge to plural server type. This should be prevented by the compiler.') : invariant(false) : void 0;\n  }\n}\nfunction extractIdFromResponse(individualResponse, errorMessage) {\n  if (typeof individualResponse === 'string') {\n    return individualResponse;\n  } else if (typeof individualResponse === 'object' && individualResponse != null && typeof individualResponse.id === 'string') {\n    return individualResponse.id;\n  }\n  !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, errorMessage) : invariant(false) : void 0;\n}\nmodule.exports = {\n  read: read\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar RelayModernRecord = require('./RelayModernRecord');\nvar RelayRecordState = require('./RelayRecordState');\nvar EXISTENT = RelayRecordState.EXISTENT,\n  NONEXISTENT = RelayRecordState.NONEXISTENT,\n  UNKNOWN = RelayRecordState.UNKNOWN;\nvar RelayRecordSource = /*#__PURE__*/function () {\n  function RelayRecordSource(records) {\n    var _this = this;\n    this._records = new Map();\n    if (records != null) {\n      Object.keys(records).forEach(function (key) {\n        var object = records[key];\n        var record = RelayModernRecord.fromObject(object);\n        _this._records.set(key, record);\n      });\n    }\n  }\n  RelayRecordSource.create = function create(records) {\n    return new RelayRecordSource(records);\n  };\n  var _proto = RelayRecordSource.prototype;\n  _proto.clear = function clear() {\n    this._records = new Map();\n  };\n  _proto[\"delete\"] = function _delete(dataID) {\n    this._records.set(dataID, null);\n  };\n  _proto.get = function get(dataID) {\n    return this._records.get(dataID);\n  };\n  _proto.getRecordIDs = function getRecordIDs() {\n    return Array.from(this._records.keys());\n  };\n  _proto.getStatus = function getStatus(dataID) {\n    if (!this._records.has(dataID)) {\n      return UNKNOWN;\n    }\n    return this._records.get(dataID) == null ? NONEXISTENT : EXISTENT;\n  };\n  _proto.has = function has(dataID) {\n    return this._records.has(dataID);\n  };\n  _proto.remove = function remove(dataID) {\n    this._records[\"delete\"](dataID);\n  };\n  _proto.set = function set(dataID, record) {\n    this._records.set(dataID, record);\n  };\n  _proto.size = function size() {\n    return this._records.size;\n  };\n  _proto.toJSON = function toJSON() {\n    var obj = {};\n    var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(this._records),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var _step$value = _step.value,\n          key = _step$value[0],\n          record = _step$value[1];\n        obj[key] = RelayModernRecord.toJSON(record);\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n    return obj;\n  };\n  return RelayRecordSource;\n}();\nmodule.exports = RelayRecordSource;","'use strict';\n\nvar RelayRecordState = {\n  EXISTENT: 'EXISTENT',\n  NONEXISTENT: 'NONEXISTENT',\n  UNKNOWN: 'UNKNOWN'\n};\nmodule.exports = RelayRecordState;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar getOperation = require('../util/getOperation');\nvar RelayConcreteNode = require('../util/RelayConcreteNode');\nvar cloneRelayHandleSourceField = require('./cloneRelayHandleSourceField');\nvar getOutputTypeRecordIDs = require('./experimental-live-resolvers/getOutputTypeRecordIDs');\nvar _require = require('./RelayConcreteVariables'),\n  getLocalVariables = _require.getLocalVariables;\nvar RelayModernRecord = require('./RelayModernRecord');\nvar RelayStoreUtils = require('./RelayStoreUtils');\nvar _require2 = require('./TypeID'),\n  generateTypeID = _require2.generateTypeID;\nvar invariant = require('invariant');\nvar ACTOR_CHANGE = RelayConcreteNode.ACTOR_CHANGE,\n  CONDITION = RelayConcreteNode.CONDITION,\n  CLIENT_COMPONENT = RelayConcreteNode.CLIENT_COMPONENT,\n  CLIENT_EXTENSION = RelayConcreteNode.CLIENT_EXTENSION,\n  DEFER = RelayConcreteNode.DEFER,\n  FRAGMENT_SPREAD = RelayConcreteNode.FRAGMENT_SPREAD,\n  INLINE_FRAGMENT = RelayConcreteNode.INLINE_FRAGMENT,\n  LINKED_FIELD = RelayConcreteNode.LINKED_FIELD,\n  MODULE_IMPORT = RelayConcreteNode.MODULE_IMPORT,\n  LINKED_HANDLE = RelayConcreteNode.LINKED_HANDLE,\n  SCALAR_FIELD = RelayConcreteNode.SCALAR_FIELD,\n  SCALAR_HANDLE = RelayConcreteNode.SCALAR_HANDLE,\n  STREAM = RelayConcreteNode.STREAM,\n  TYPE_DISCRIMINATOR = RelayConcreteNode.TYPE_DISCRIMINATOR,\n  RELAY_RESOLVER = RelayConcreteNode.RELAY_RESOLVER,\n  RELAY_LIVE_RESOLVER = RelayConcreteNode.RELAY_LIVE_RESOLVER,\n  CLIENT_EDGE_TO_CLIENT_OBJECT = RelayConcreteNode.CLIENT_EDGE_TO_CLIENT_OBJECT;\nvar getStorageKey = RelayStoreUtils.getStorageKey,\n  getModuleOperationKey = RelayStoreUtils.getModuleOperationKey;\nfunction mark(recordSource, selector, references, operationLoader, shouldProcessClientComponents) {\n  var dataID = selector.dataID,\n    node = selector.node,\n    variables = selector.variables;\n  var marker = new RelayReferenceMarker(recordSource, variables, references, operationLoader, shouldProcessClientComponents);\n  marker.mark(node, dataID);\n}\nvar RelayReferenceMarker = /*#__PURE__*/function () {\n  function RelayReferenceMarker(recordSource, variables, references, operationLoader, shouldProcessClientComponents) {\n    this._operationLoader = operationLoader !== null && operationLoader !== void 0 ? operationLoader : null;\n    this._operationName = null;\n    this._recordSource = recordSource;\n    this._references = references;\n    this._variables = variables;\n    this._shouldProcessClientComponents = shouldProcessClientComponents;\n  }\n  var _proto = RelayReferenceMarker.prototype;\n  _proto.mark = function mark(node, dataID) {\n    if (node.kind === 'Operation' || node.kind === 'SplitOperation') {\n      this._operationName = node.name;\n    }\n    this._traverse(node, dataID);\n  };\n  _proto._traverse = function _traverse(node, dataID) {\n    this._references.add(dataID);\n    var record = this._recordSource.get(dataID);\n    if (record == null) {\n      return;\n    }\n    this._traverseSelections(node.selections, record);\n  };\n  _proto._getVariableValue = function _getVariableValue(name) {\n    !this._variables.hasOwnProperty(name) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReferenceMarker(): Undefined variable `%s`.', name) : invariant(false) : void 0;\n    return this._variables[name];\n  };\n  _proto._traverseSelections = function _traverseSelections(selections, record) {\n    var _this = this;\n    selections.forEach(function (selection) {\n      switch (selection.kind) {\n        case ACTOR_CHANGE:\n          _this._traverseLink(selection.linkedField, record);\n          break;\n        case LINKED_FIELD:\n          if (selection.plural) {\n            _this._traversePluralLink(selection, record);\n          } else {\n            _this._traverseLink(selection, record);\n          }\n          break;\n        case CONDITION:\n          var conditionValue = Boolean(_this._getVariableValue(selection.condition));\n          if (conditionValue === selection.passingValue) {\n            _this._traverseSelections(selection.selections, record);\n          }\n          break;\n        case INLINE_FRAGMENT:\n          if (selection.abstractKey == null) {\n            var typeName = RelayModernRecord.getType(record);\n            if (typeName != null && typeName === selection.type || typeName === RelayStoreUtils.ROOT_TYPE) {\n              _this._traverseSelections(selection.selections, record);\n            }\n          } else {\n            var _typeName = RelayModernRecord.getType(record);\n            var typeID = generateTypeID(_typeName);\n            _this._references.add(typeID);\n            _this._traverseSelections(selection.selections, record);\n          }\n          break;\n        case FRAGMENT_SPREAD:\n          var prevVariables = _this._variables;\n          _this._variables = getLocalVariables(_this._variables, selection.fragment.argumentDefinitions, selection.args);\n          _this._traverseSelections(selection.fragment.selections, record);\n          _this._variables = prevVariables;\n          break;\n        case LINKED_HANDLE:\n          var handleField = cloneRelayHandleSourceField(selection, selections, _this._variables);\n          if (handleField.plural) {\n            _this._traversePluralLink(handleField, record);\n          } else {\n            _this._traverseLink(handleField, record);\n          }\n          break;\n        case DEFER:\n        case STREAM:\n          _this._traverseSelections(selection.selections, record);\n          break;\n        case SCALAR_FIELD:\n        case SCALAR_HANDLE:\n          break;\n        case TYPE_DISCRIMINATOR:\n          {\n            var _typeName2 = RelayModernRecord.getType(record);\n            var _typeID = generateTypeID(_typeName2);\n            _this._references.add(_typeID);\n            break;\n          }\n        case MODULE_IMPORT:\n          _this._traverseModuleImport(selection, record);\n          break;\n        case CLIENT_EXTENSION:\n          _this._traverseSelections(selection.selections, record);\n          break;\n        case CLIENT_COMPONENT:\n          if (_this._shouldProcessClientComponents === false) {\n            break;\n          }\n          _this._traverseSelections(selection.fragment.selections, record);\n          break;\n        case RELAY_RESOLVER:\n          _this._traverseResolverField(selection, record);\n          break;\n        case RELAY_LIVE_RESOLVER:\n          _this._traverseResolverField(selection, record);\n          break;\n        case CLIENT_EDGE_TO_CLIENT_OBJECT:\n          _this._traverseClientEdgeToClientObject(selection, record);\n          break;\n        default:\n          selection;\n          !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReferenceMarker: Unknown AST node `%s`.', selection) : invariant(false) : void 0;\n      }\n    });\n  };\n  _proto._traverseClientEdgeToClientObject = function _traverseClientEdgeToClientObject(field, record) {\n    var dataID = this._traverseResolverField(field.backingField, record);\n    if (dataID == null) {\n      return;\n    }\n    var resolverRecord = this._recordSource.get(dataID);\n    if (resolverRecord == null) {\n      return;\n    }\n    if (field.backingField.isOutputType) {\n      var outputTypeRecordIDs = getOutputTypeRecordIDs(resolverRecord);\n      if (outputTypeRecordIDs != null) {\n        var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(outputTypeRecordIDs),\n          _step;\n        try {\n          for (_iterator.s(); !(_step = _iterator.n()).done;) {\n            var _dataID = _step.value;\n            this._references.add(_dataID);\n          }\n        } catch (err) {\n          _iterator.e(err);\n        } finally {\n          _iterator.f();\n        }\n      }\n    } else {\n      var linkedField = field.linkedField;\n      var concreteType = linkedField.concreteType;\n      if (concreteType == null) {\n        return;\n      }\n      if (linkedField.plural) {\n        var dataIDs = RelayModernRecord.getResolverLinkedRecordIDs(resolverRecord, concreteType);\n        if (dataIDs != null) {\n          var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(dataIDs),\n            _step2;\n          try {\n            for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n              var _dataID2 = _step2.value;\n              if (_dataID2 != null) {\n                this._traverse(linkedField, _dataID2);\n              }\n            }\n          } catch (err) {\n            _iterator2.e(err);\n          } finally {\n            _iterator2.f();\n          }\n        }\n      } else {\n        var _dataID3 = RelayModernRecord.getResolverLinkedRecordID(resolverRecord, concreteType);\n        if (_dataID3 != null) {\n          this._traverse(linkedField, _dataID3);\n        }\n      }\n    }\n  };\n  _proto._traverseResolverField = function _traverseResolverField(field, record) {\n    var storageKey = getStorageKey(field, this._variables);\n    var dataID = RelayModernRecord.getLinkedRecordID(record, storageKey);\n    if (dataID != null) {\n      this._references.add(dataID);\n    }\n    var fragment = field.fragment;\n    if (fragment != null) {\n      this._traverseSelections([fragment], record);\n    }\n    return dataID;\n  };\n  _proto._traverseModuleImport = function _traverseModuleImport(moduleImport, record) {\n    var _this$_operationName;\n    var operationLoader = this._operationLoader;\n    !(operationLoader !== null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReferenceMarker: Expected an operationLoader to be configured when using `@module`. ' + 'Could not load fragment `%s` in operation `%s`.', moduleImport.fragmentName, (_this$_operationName = this._operationName) !== null && _this$_operationName !== void 0 ? _this$_operationName : '(unknown)') : invariant(false) : void 0;\n    var operationKey = getModuleOperationKey(moduleImport.documentName);\n    var operationReference = RelayModernRecord.getValue(record, operationKey);\n    if (operationReference == null) {\n      return;\n    }\n    var normalizationRootNode = operationLoader.get(operationReference);\n    if (normalizationRootNode != null) {\n      var operation = getOperation(normalizationRootNode);\n      var prevVariables = this._variables;\n      this._variables = getLocalVariables(this._variables, operation.argumentDefinitions, moduleImport.args);\n      this._traverseSelections(operation.selections, record);\n      this._variables = prevVariables;\n    }\n  };\n  _proto._traverseLink = function _traverseLink(field, record) {\n    var storageKey = getStorageKey(field, this._variables);\n    var linkedID = RelayModernRecord.getLinkedRecordID(record, storageKey);\n    if (linkedID == null) {\n      return;\n    }\n    this._traverse(field, linkedID);\n  };\n  _proto._traversePluralLink = function _traversePluralLink(field, record) {\n    var _this2 = this;\n    var storageKey = getStorageKey(field, this._variables);\n    var linkedIDs = RelayModernRecord.getLinkedRecordIDs(record, storageKey);\n    if (linkedIDs == null) {\n      return;\n    }\n    linkedIDs.forEach(function (linkedID) {\n      if (linkedID != null) {\n        _this2._traverse(field, linkedID);\n      }\n    });\n  };\n  return RelayReferenceMarker;\n}();\nmodule.exports = {\n  mark: mark\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar _require = require('../multi-actor-environment/ActorUtils'),\n  ACTOR_IDENTIFIER_FIELD_NAME = _require.ACTOR_IDENTIFIER_FIELD_NAME,\n  getActorIdentifierFromPayload = _require.getActorIdentifierFromPayload;\nvar _require2 = require('../util/RelayConcreteNode'),\n  ACTOR_CHANGE = _require2.ACTOR_CHANGE,\n  CLIENT_COMPONENT = _require2.CLIENT_COMPONENT,\n  CLIENT_EDGE_TO_CLIENT_OBJECT = _require2.CLIENT_EDGE_TO_CLIENT_OBJECT,\n  CLIENT_EXTENSION = _require2.CLIENT_EXTENSION,\n  CONDITION = _require2.CONDITION,\n  DEFER = _require2.DEFER,\n  FRAGMENT_SPREAD = _require2.FRAGMENT_SPREAD,\n  INLINE_FRAGMENT = _require2.INLINE_FRAGMENT,\n  LINKED_FIELD = _require2.LINKED_FIELD,\n  LINKED_HANDLE = _require2.LINKED_HANDLE,\n  MODULE_IMPORT = _require2.MODULE_IMPORT,\n  RELAY_LIVE_RESOLVER = _require2.RELAY_LIVE_RESOLVER,\n  RELAY_RESOLVER = _require2.RELAY_RESOLVER,\n  SCALAR_FIELD = _require2.SCALAR_FIELD,\n  SCALAR_HANDLE = _require2.SCALAR_HANDLE,\n  STREAM = _require2.STREAM,\n  TYPE_DISCRIMINATOR = _require2.TYPE_DISCRIMINATOR;\nvar _require3 = require('./ClientID'),\n  generateClientID = _require3.generateClientID,\n  isClientID = _require3.isClientID;\nvar _require4 = require('./RelayConcreteVariables'),\n  getLocalVariables = _require4.getLocalVariables;\nvar _require5 = require('./RelayErrorTrie'),\n  buildErrorTrie = _require5.buildErrorTrie,\n  getErrorsByKey = _require5.getErrorsByKey,\n  getNestedErrorTrieByKey = _require5.getNestedErrorTrieByKey;\nvar RelayModernRecord = require('./RelayModernRecord');\nvar _require6 = require('./RelayModernSelector'),\n  createNormalizationSelector = _require6.createNormalizationSelector;\nvar _require7 = require('./RelayStoreUtils'),\n  ROOT_ID = _require7.ROOT_ID,\n  TYPENAME_KEY = _require7.TYPENAME_KEY,\n  getArgumentValues = _require7.getArgumentValues,\n  getHandleStorageKey = _require7.getHandleStorageKey,\n  getModuleComponentKey = _require7.getModuleComponentKey,\n  getModuleOperationKey = _require7.getModuleOperationKey,\n  getStorageKey = _require7.getStorageKey;\nvar _require8 = require('./TypeID'),\n  TYPE_SCHEMA_TYPE = _require8.TYPE_SCHEMA_TYPE,\n  generateTypeID = _require8.generateTypeID;\nvar areEqual = require(\"fbjs/lib/areEqual\");\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nfunction normalize(recordSource, selector, response, options, errors) {\n  var dataID = selector.dataID,\n    node = selector.node,\n    variables = selector.variables;\n  var normalizer = new RelayResponseNormalizer(recordSource, variables, options);\n  return normalizer.normalizeResponse(node, dataID, response, errors);\n}\nvar RelayResponseNormalizer = /*#__PURE__*/function () {\n  function RelayResponseNormalizer(recordSource, variables, options) {\n    this._actorIdentifier = options.actorIdentifier;\n    this._getDataId = options.getDataID;\n    this._handleFieldPayloads = [];\n    this._treatMissingFieldsAsNull = options.treatMissingFieldsAsNull;\n    this._incrementalPlaceholders = [];\n    this._isClientExtension = false;\n    this._isUnmatchedAbstractType = false;\n    this._followupPayloads = [];\n    this._path = options.path ? (0, _toConsumableArray2[\"default\"])(options.path) : [];\n    this._recordSource = recordSource;\n    this._variables = variables;\n    this._shouldProcessClientComponents = options.shouldProcessClientComponents;\n  }\n  var _proto = RelayResponseNormalizer.prototype;\n  _proto.normalizeResponse = function normalizeResponse(node, dataID, data, errors) {\n    var record = this._recordSource.get(dataID);\n    !record ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer(): Expected root record `%s` to exist.', dataID) : invariant(false) : void 0;\n    this._assignClientAbstractTypes(node);\n    this._errorTrie = buildErrorTrie(errors);\n    this._traverseSelections(node, record, data);\n    return {\n      errors: errors,\n      fieldPayloads: this._handleFieldPayloads,\n      incrementalPlaceholders: this._incrementalPlaceholders,\n      followupPayloads: this._followupPayloads,\n      source: this._recordSource,\n      isFinal: false\n    };\n  };\n  _proto._assignClientAbstractTypes = function _assignClientAbstractTypes(node) {\n    var clientAbstractTypes = node.clientAbstractTypes;\n    if (clientAbstractTypes != null) {\n      for (var _i = 0, _Object$keys = Object.keys(clientAbstractTypes); _i < _Object$keys.length; _i++) {\n        var abstractType = _Object$keys[_i];\n        var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(clientAbstractTypes[abstractType]),\n          _step;\n        try {\n          for (_iterator.s(); !(_step = _iterator.n()).done;) {\n            var concreteType = _step.value;\n            var typeID = generateTypeID(concreteType);\n            var typeRecord = this._recordSource.get(typeID);\n            if (typeRecord == null) {\n              typeRecord = RelayModernRecord.create(typeID, TYPE_SCHEMA_TYPE);\n              this._recordSource.set(typeID, typeRecord);\n            }\n            RelayModernRecord.setValue(typeRecord, abstractType, true);\n          }\n        } catch (err) {\n          _iterator.e(err);\n        } finally {\n          _iterator.f();\n        }\n      }\n    }\n  };\n  _proto._getVariableValue = function _getVariableValue(name) {\n    !this._variables.hasOwnProperty(name) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer(): Undefined variable `%s`.', name) : invariant(false) : void 0;\n    return this._variables[name];\n  };\n  _proto._getRecordType = function _getRecordType(data) {\n    var typeName = data[TYPENAME_KEY];\n    !(typeName != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer(): Expected a typename for record `%s`.', JSON.stringify(data, null, 2)) : invariant(false) : void 0;\n    return typeName;\n  };\n  _proto._traverseSelections = function _traverseSelections(node, record, data) {\n    for (var i = 0; i < node.selections.length; i++) {\n      var selection = node.selections[i];\n      switch (selection.kind) {\n        case SCALAR_FIELD:\n        case LINKED_FIELD:\n          this._normalizeField(selection, record, data);\n          break;\n        case CONDITION:\n          var conditionValue = Boolean(this._getVariableValue(selection.condition));\n          if (conditionValue === selection.passingValue) {\n            this._traverseSelections(selection, record, data);\n          }\n          break;\n        case FRAGMENT_SPREAD:\n          {\n            var prevVariables = this._variables;\n            this._variables = getLocalVariables(this._variables, selection.fragment.argumentDefinitions, selection.args);\n            this._traverseSelections(selection.fragment, record, data);\n            this._variables = prevVariables;\n            break;\n          }\n        case INLINE_FRAGMENT:\n          {\n            var abstractKey = selection.abstractKey;\n            if (abstractKey == null) {\n              var typeName = RelayModernRecord.getType(record);\n              if (typeName === selection.type) {\n                this._traverseSelections(selection, record, data);\n              }\n            } else {\n              var implementsInterface = data.hasOwnProperty(abstractKey);\n              var _typeName = RelayModernRecord.getType(record);\n              var typeID = generateTypeID(_typeName);\n              var typeRecord = this._recordSource.get(typeID);\n              if (typeRecord == null) {\n                typeRecord = RelayModernRecord.create(typeID, TYPE_SCHEMA_TYPE);\n                this._recordSource.set(typeID, typeRecord);\n              }\n              RelayModernRecord.setValue(typeRecord, abstractKey, implementsInterface);\n              if (implementsInterface) {\n                this._traverseSelections(selection, record, data);\n              }\n            }\n            break;\n          }\n        case TYPE_DISCRIMINATOR:\n          {\n            var _abstractKey = selection.abstractKey;\n            var _implementsInterface = data.hasOwnProperty(_abstractKey);\n            var _typeName2 = RelayModernRecord.getType(record);\n            var _typeID = generateTypeID(_typeName2);\n            var _typeRecord = this._recordSource.get(_typeID);\n            if (_typeRecord == null) {\n              _typeRecord = RelayModernRecord.create(_typeID, TYPE_SCHEMA_TYPE);\n              this._recordSource.set(_typeID, _typeRecord);\n            }\n            RelayModernRecord.setValue(_typeRecord, _abstractKey, _implementsInterface);\n            break;\n          }\n        case LINKED_HANDLE:\n        case SCALAR_HANDLE:\n          var args = selection.args ? getArgumentValues(selection.args, this._variables) : {};\n          var fieldKey = getStorageKey(selection, this._variables);\n          var handleKey = getHandleStorageKey(selection, this._variables);\n          this._handleFieldPayloads.push({\n            args: args,\n            dataID: RelayModernRecord.getDataID(record),\n            fieldKey: fieldKey,\n            handle: selection.handle,\n            handleKey: handleKey,\n            handleArgs: selection.handleArgs ? getArgumentValues(selection.handleArgs, this._variables) : {}\n          });\n          break;\n        case MODULE_IMPORT:\n          this._normalizeModuleImport(selection, record, data);\n          break;\n        case DEFER:\n          this._normalizeDefer(selection, record, data);\n          break;\n        case STREAM:\n          this._normalizeStream(selection, record, data);\n          break;\n        case CLIENT_EXTENSION:\n          var isClientExtension = this._isClientExtension;\n          this._isClientExtension = true;\n          this._traverseSelections(selection, record, data);\n          this._isClientExtension = isClientExtension;\n          break;\n        case CLIENT_COMPONENT:\n          if (this._shouldProcessClientComponents === false) {\n            break;\n          }\n          this._traverseSelections(selection.fragment, record, data);\n          break;\n        case ACTOR_CHANGE:\n          this._normalizeActorChange(selection, record, data);\n          break;\n        case RELAY_RESOLVER:\n          this._normalizeResolver(selection, record, data);\n          break;\n        case RELAY_LIVE_RESOLVER:\n          this._normalizeResolver(selection, record, data);\n          break;\n        case CLIENT_EDGE_TO_CLIENT_OBJECT:\n          this._normalizeResolver(selection.backingField, record, data);\n          break;\n        default:\n          selection;\n          !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer(): Unexpected ast kind `%s`.', selection.kind) : invariant(false) : void 0;\n      }\n    }\n  };\n  _proto._normalizeResolver = function _normalizeResolver(resolver, record, data) {\n    if (resolver.fragment != null) {\n      this._traverseSelections(resolver.fragment, record, data);\n    }\n  };\n  _proto._normalizeDefer = function _normalizeDefer(defer, record, data) {\n    var isDeferred = defer[\"if\"] === null || this._getVariableValue(defer[\"if\"]);\n    if (process.env.NODE_ENV !== \"production\") {\n      process.env.NODE_ENV !== \"production\" ? warning(typeof isDeferred === 'boolean', 'RelayResponseNormalizer: Expected value for @defer `if` argument to ' + 'be a boolean, got `%s`.', isDeferred) : void 0;\n    }\n    if (isDeferred === false) {\n      this._traverseSelections(defer, record, data);\n    } else {\n      this._incrementalPlaceholders.push({\n        kind: 'defer',\n        data: data,\n        label: defer.label,\n        path: (0, _toConsumableArray2[\"default\"])(this._path),\n        selector: createNormalizationSelector(defer, RelayModernRecord.getDataID(record), this._variables),\n        typeName: RelayModernRecord.getType(record),\n        actorIdentifier: this._actorIdentifier\n      });\n    }\n  };\n  _proto._normalizeStream = function _normalizeStream(stream, record, data) {\n    this._traverseSelections(stream, record, data);\n    var isStreamed = stream[\"if\"] === null || this._getVariableValue(stream[\"if\"]);\n    if (process.env.NODE_ENV !== \"production\") {\n      process.env.NODE_ENV !== \"production\" ? warning(typeof isStreamed === 'boolean', 'RelayResponseNormalizer: Expected value for @stream `if` argument ' + 'to be a boolean, got `%s`.', isStreamed) : void 0;\n    }\n    if (isStreamed === true) {\n      this._incrementalPlaceholders.push({\n        kind: 'stream',\n        label: stream.label,\n        path: (0, _toConsumableArray2[\"default\"])(this._path),\n        parentID: RelayModernRecord.getDataID(record),\n        node: stream,\n        variables: this._variables,\n        actorIdentifier: this._actorIdentifier\n      });\n    }\n  };\n  _proto._normalizeModuleImport = function _normalizeModuleImport(moduleImport, record, data) {\n    !(typeof data === 'object' && data) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer: Expected data for @module to be an object.') : invariant(false) : void 0;\n    var typeName = RelayModernRecord.getType(record);\n    var componentKey = getModuleComponentKey(moduleImport.documentName);\n    var componentReference = moduleImport.componentModuleProvider || data[componentKey];\n    RelayModernRecord.setValue(record, componentKey, componentReference !== null && componentReference !== void 0 ? componentReference : null);\n    var operationKey = getModuleOperationKey(moduleImport.documentName);\n    var operationReference = moduleImport.operationModuleProvider || data[operationKey];\n    RelayModernRecord.setValue(record, operationKey, operationReference !== null && operationReference !== void 0 ? operationReference : null);\n    if (operationReference != null) {\n      this._followupPayloads.push({\n        kind: 'ModuleImportPayload',\n        args: moduleImport.args,\n        data: data,\n        dataID: RelayModernRecord.getDataID(record),\n        operationReference: operationReference,\n        path: (0, _toConsumableArray2[\"default\"])(this._path),\n        typeName: typeName,\n        variables: this._variables,\n        actorIdentifier: this._actorIdentifier\n      });\n    }\n  };\n  _proto._normalizeField = function _normalizeField(selection, record, data) {\n    !(typeof data === 'object' && data) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'writeField(): Expected data for field `%s` to be an object.', selection.name) : invariant(false) : void 0;\n    var responseKey = selection.alias || selection.name;\n    var storageKey = getStorageKey(selection, this._variables);\n    var fieldValue = data[responseKey];\n    if (fieldValue == null) {\n      if (fieldValue === undefined) {\n        var isOptionalField = this._isClientExtension || this._isUnmatchedAbstractType;\n        if (isOptionalField) {\n          return;\n        } else if (!this._treatMissingFieldsAsNull) {\n          if (process.env.NODE_ENV !== \"production\") {\n            process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayResponseNormalizer: Payload did not contain a value ' + 'for field `%s: %s`. Check that you are parsing with the same ' + 'query that was used to fetch the payload.', responseKey, storageKey) : void 0;\n          }\n          return;\n        }\n      }\n      if (process.env.NODE_ENV !== \"production\") {\n        if (selection.kind === SCALAR_FIELD) {\n          this._validateConflictingFieldsWithIdenticalId(record, storageKey, null);\n        }\n      }\n      RelayModernRecord.setValue(record, storageKey, null);\n      var errorTrie = this._errorTrie;\n      if (errorTrie != null) {\n        var errors = getErrorsByKey(errorTrie, responseKey);\n        if (errors != null) {\n          RelayModernRecord.setErrors(record, storageKey, errors);\n        }\n      }\n      return;\n    }\n    if (selection.kind === SCALAR_FIELD) {\n      if (process.env.NODE_ENV !== \"production\") {\n        this._validateConflictingFieldsWithIdenticalId(record, storageKey, fieldValue);\n      }\n      RelayModernRecord.setValue(record, storageKey, fieldValue);\n    } else if (selection.kind === LINKED_FIELD) {\n      this._path.push(responseKey);\n      var oldErrorTrie = this._errorTrie;\n      this._errorTrie = oldErrorTrie == null ? null : getNestedErrorTrieByKey(oldErrorTrie, responseKey);\n      if (selection.plural) {\n        this._normalizePluralLink(selection, record, storageKey, fieldValue);\n      } else {\n        this._normalizeLink(selection, record, storageKey, fieldValue);\n      }\n      this._errorTrie = oldErrorTrie;\n      this._path.pop();\n    } else {\n      selection;\n      !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer(): Unexpected ast kind `%s` during normalization.', selection.kind) : invariant(false) : void 0;\n    }\n  };\n  _proto._normalizeActorChange = function _normalizeActorChange(selection, record, data) {\n    var _field$concreteType;\n    var field = selection.linkedField;\n    !(typeof data === 'object' && data) ? process.env.NODE_ENV !== \"production\" ? invariant(false, '_normalizeActorChange(): Expected data for field `%s` to be an object.', field.name) : invariant(false) : void 0;\n    var responseKey = field.alias || field.name;\n    var storageKey = getStorageKey(field, this._variables);\n    var fieldValue = data[responseKey];\n    if (fieldValue == null) {\n      if (fieldValue === undefined) {\n        var isOptionalField = this._isClientExtension || this._isUnmatchedAbstractType;\n        if (isOptionalField) {\n          return;\n        } else if (!this._treatMissingFieldsAsNull) {\n          if (process.env.NODE_ENV !== \"production\") {\n            process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayResponseNormalizer: Payload did not contain a value ' + 'for field `%s: %s`. Check that you are parsing with the same ' + 'query that was used to fetch the payload.', responseKey, storageKey) : void 0;\n          }\n          return;\n        }\n      }\n      RelayModernRecord.setValue(record, storageKey, null);\n      return;\n    }\n    var actorIdentifier = getActorIdentifierFromPayload(fieldValue);\n    if (actorIdentifier == null) {\n      if (process.env.NODE_ENV !== \"production\") {\n        process.env.NODE_ENV !== \"production\" ? warning(false, 'RelayResponseNormalizer: Payload did not contain a value ' + 'for field `%s`. Check that you are parsing with the same ' + 'query that was used to fetch the payload. Payload is `%s`.', ACTOR_IDENTIFIER_FIELD_NAME, JSON.stringify(fieldValue, null, 2)) : void 0;\n      }\n      RelayModernRecord.setValue(record, storageKey, null);\n      return;\n    }\n    var typeName = (_field$concreteType = field.concreteType) !== null && _field$concreteType !== void 0 ? _field$concreteType : this._getRecordType(fieldValue);\n    var nextID = this._getDataId(fieldValue, typeName) || RelayModernRecord.getLinkedRecordID(record, storageKey) || generateClientID(RelayModernRecord.getDataID(record), storageKey);\n    !(typeof nextID === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer: Expected id on field `%s` to be a string.', storageKey) : invariant(false) : void 0;\n    RelayModernRecord.setActorLinkedRecordID(record, storageKey, actorIdentifier, nextID);\n    this._followupPayloads.push({\n      kind: 'ActorPayload',\n      data: fieldValue,\n      dataID: nextID,\n      path: [].concat((0, _toConsumableArray2[\"default\"])(this._path), [responseKey]),\n      typeName: typeName,\n      variables: this._variables,\n      node: field,\n      actorIdentifier: actorIdentifier\n    });\n  };\n  _proto._normalizeLink = function _normalizeLink(field, record, storageKey, fieldValue) {\n    var _field$concreteType2;\n    !(typeof fieldValue === 'object' && fieldValue) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer: Expected data for field `%s` to be an object.', storageKey) : invariant(false) : void 0;\n    var nextID = this._getDataId(fieldValue, (_field$concreteType2 = field.concreteType) !== null && _field$concreteType2 !== void 0 ? _field$concreteType2 : this._getRecordType(fieldValue)) || RelayModernRecord.getLinkedRecordID(record, storageKey) || generateClientID(RelayModernRecord.getDataID(record), storageKey);\n    !(typeof nextID === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer: Expected id on field `%s` to be a string.', storageKey) : invariant(false) : void 0;\n    if (process.env.NODE_ENV !== \"production\") {\n      this._validateConflictingLinkedFieldsWithIdenticalId(RelayModernRecord.getLinkedRecordID(record, storageKey), nextID, storageKey);\n    }\n    RelayModernRecord.setLinkedRecordID(record, storageKey, nextID);\n    var nextRecord = this._recordSource.get(nextID);\n    if (!nextRecord) {\n      var typeName = field.concreteType || this._getRecordType(fieldValue);\n      nextRecord = RelayModernRecord.create(nextID, typeName);\n      this._recordSource.set(nextID, nextRecord);\n    } else if (process.env.NODE_ENV !== \"production\") {\n      this._validateRecordType(nextRecord, field, fieldValue);\n    }\n    this._traverseSelections(field, nextRecord, fieldValue);\n  };\n  _proto._normalizePluralLink = function _normalizePluralLink(field, record, storageKey, fieldValue) {\n    var _this = this;\n    !Array.isArray(fieldValue) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer: Expected data for field `%s` to be an array ' + 'of objects.', storageKey) : invariant(false) : void 0;\n    var prevIDs = RelayModernRecord.getLinkedRecordIDs(record, storageKey);\n    var nextIDs = [];\n    fieldValue.forEach(function (item, nextIndex) {\n      var _field$concreteType3;\n      if (item == null) {\n        nextIDs.push(item);\n        return;\n      }\n      _this._path.push(String(nextIndex));\n      var oldErrorTrie = _this._errorTrie;\n      _this._errorTrie = oldErrorTrie == null ? null : getNestedErrorTrieByKey(oldErrorTrie, nextIndex);\n      !(typeof item === 'object') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer: Expected elements for field `%s` to be ' + 'objects.', storageKey) : invariant(false) : void 0;\n      var nextID = _this._getDataId(item, (_field$concreteType3 = field.concreteType) !== null && _field$concreteType3 !== void 0 ? _field$concreteType3 : _this._getRecordType(item)) || prevIDs && prevIDs[nextIndex] || generateClientID(RelayModernRecord.getDataID(record), storageKey, nextIndex);\n      !(typeof nextID === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayResponseNormalizer: Expected id of elements of field `%s` to ' + 'be strings.', storageKey) : invariant(false) : void 0;\n      nextIDs.push(nextID);\n      var nextRecord = _this._recordSource.get(nextID);\n      if (!nextRecord) {\n        var typeName = field.concreteType || _this._getRecordType(item);\n        nextRecord = RelayModernRecord.create(nextID, typeName);\n        _this._recordSource.set(nextID, nextRecord);\n      } else if (process.env.NODE_ENV !== \"production\") {\n        _this._validateRecordType(nextRecord, field, item);\n      }\n      if (process.env.NODE_ENV !== \"production\") {\n        if (prevIDs) {\n          _this._validateConflictingLinkedFieldsWithIdenticalId(prevIDs[nextIndex], nextID, storageKey);\n        }\n      }\n      _this._traverseSelections(field, nextRecord, item);\n      _this._errorTrie = oldErrorTrie;\n      _this._path.pop();\n    });\n    RelayModernRecord.setLinkedRecordIDs(record, storageKey, nextIDs);\n  };\n  _proto._validateRecordType = function _validateRecordType(record, field, payload) {\n    var _field$concreteType4;\n    var typeName = (_field$concreteType4 = field.concreteType) !== null && _field$concreteType4 !== void 0 ? _field$concreteType4 : this._getRecordType(payload);\n    var dataID = RelayModernRecord.getDataID(record);\n    process.env.NODE_ENV !== \"production\" ? warning(isClientID(dataID) && dataID !== ROOT_ID || RelayModernRecord.getType(record) === typeName, 'RelayResponseNormalizer: Invalid record `%s`. Expected %s to be ' + 'consistent, but the record was assigned conflicting types `%s` ' + 'and `%s`. The GraphQL server likely violated the globally unique ' + 'id requirement by returning the same id for different objects.', dataID, TYPENAME_KEY, RelayModernRecord.getType(record), typeName) : void 0;\n  };\n  _proto._validateConflictingFieldsWithIdenticalId = function _validateConflictingFieldsWithIdenticalId(record, storageKey, fieldValue) {\n    if (process.env.NODE_ENV !== \"production\") {\n      var dataID = RelayModernRecord.getDataID(record);\n      var previousValue = RelayModernRecord.getValue(record, storageKey);\n      process.env.NODE_ENV !== \"production\" ? warning(storageKey === TYPENAME_KEY || previousValue === undefined || areEqual(previousValue, fieldValue), 'RelayResponseNormalizer: Invalid record. The record contains two ' + 'instances of the same id: `%s` with conflicting field, %s and its values: %s and %s. ' + 'If two fields are different but share ' + 'the same id, one field will overwrite the other.', dataID, storageKey, previousValue, fieldValue) : void 0;\n    }\n  };\n  _proto._validateConflictingLinkedFieldsWithIdenticalId = function _validateConflictingLinkedFieldsWithIdenticalId(prevID, nextID, storageKey) {\n    if (process.env.NODE_ENV !== \"production\") {\n      process.env.NODE_ENV !== \"production\" ? warning(prevID === undefined || prevID === nextID, 'RelayResponseNormalizer: Invalid record. The record contains ' + 'references to the conflicting field, %s and its id values: %s and %s. ' + 'We need to make sure that the record the field points ' + 'to remains consistent or one field will overwrite the other.', storageKey, prevID, nextID) : void 0;\n    }\n  };\n  return RelayResponseNormalizer;\n}();\nmodule.exports = {\n  normalize: normalize\n};","'use strict';\n\nvar deepFreeze = require('../util/deepFreeze');\nvar recycleNodesInto = require('../util/recycleNodesInto');\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar hasOverlappingIDs = require('./hasOverlappingIDs');\nvar hasSignificantOverlappingIDs = require('./hasSignificantOverlappingIDs');\nvar RelayReader = require('./RelayReader');\nvar RelayStoreSubscriptions = /*#__PURE__*/function () {\n  function RelayStoreSubscriptions(log, resolverCache) {\n    this._subscriptions = new Set();\n    this.__log = log;\n    this._resolverCache = resolverCache;\n  }\n  var _proto = RelayStoreSubscriptions.prototype;\n  _proto.subscribe = function subscribe(snapshot, callback) {\n    var _this = this;\n    var subscription = {\n      backup: null,\n      callback: callback,\n      snapshot: snapshot,\n      stale: false\n    };\n    var dispose = function dispose() {\n      _this._subscriptions[\"delete\"](subscription);\n    };\n    this._subscriptions.add(subscription);\n    return {\n      dispose: dispose\n    };\n  };\n  _proto.snapshotSubscriptions = function snapshotSubscriptions(source) {\n    var _this2 = this;\n    this._subscriptions.forEach(function (subscription) {\n      if (!subscription.stale) {\n        subscription.backup = subscription.snapshot;\n        return;\n      }\n      var snapshot = subscription.snapshot;\n      var backup = RelayReader.read(source, snapshot.selector, _this2._resolverCache);\n      var nextData = recycleNodesInto(snapshot.data, backup.data);\n      backup.data = nextData;\n      subscription.backup = backup;\n    });\n  };\n  _proto.restoreSubscriptions = function restoreSubscriptions() {\n    this._subscriptions.forEach(function (subscription) {\n      var backup = subscription.backup;\n      subscription.backup = null;\n      if (backup) {\n        if (backup.data !== subscription.snapshot.data) {\n          subscription.stale = true;\n        }\n        subscription.snapshot = {\n          data: subscription.snapshot.data,\n          isMissingData: backup.isMissingData,\n          missingClientEdges: backup.missingClientEdges,\n          missingLiveResolverFields: backup.missingLiveResolverFields,\n          seenRecords: backup.seenRecords,\n          selector: backup.selector,\n          missingRequiredFields: backup.missingRequiredFields,\n          relayResolverErrors: backup.relayResolverErrors,\n          errorResponseFields: backup.errorResponseFields\n        };\n      } else {\n        subscription.stale = true;\n      }\n    });\n  };\n  _proto.updateSubscriptions = function updateSubscriptions(source, updatedRecordIDs, updatedOwners, sourceOperation) {\n    var _this3 = this;\n    var hasUpdatedRecords = updatedRecordIDs.size !== 0;\n    this._subscriptions.forEach(function (subscription) {\n      var owner = _this3._updateSubscription(source, subscription, updatedRecordIDs, hasUpdatedRecords, sourceOperation);\n      if (owner != null) {\n        updatedOwners.push(owner);\n      }\n    });\n  };\n  _proto._updateSubscription = function _updateSubscription(source, subscription, updatedRecordIDs, hasUpdatedRecords, sourceOperation) {\n    var backup = subscription.backup,\n      callback = subscription.callback,\n      snapshot = subscription.snapshot,\n      stale = subscription.stale;\n    var hasOverlappingUpdates = hasUpdatedRecords && hasOverlappingIDs(snapshot.seenRecords, updatedRecordIDs);\n    if (!stale && !hasOverlappingUpdates) {\n      return;\n    }\n    var nextSnapshot = hasOverlappingUpdates || !backup ? RelayReader.read(source, snapshot.selector, this._resolverCache) : backup;\n    var nextData = recycleNodesInto(snapshot.data, nextSnapshot.data);\n    nextSnapshot = {\n      data: nextData,\n      isMissingData: nextSnapshot.isMissingData,\n      missingClientEdges: nextSnapshot.missingClientEdges,\n      missingLiveResolverFields: nextSnapshot.missingLiveResolverFields,\n      seenRecords: nextSnapshot.seenRecords,\n      selector: nextSnapshot.selector,\n      missingRequiredFields: nextSnapshot.missingRequiredFields,\n      relayResolverErrors: nextSnapshot.relayResolverErrors,\n      errorResponseFields: nextSnapshot.errorResponseFields\n    };\n    if (process.env.NODE_ENV !== \"production\") {\n      deepFreeze(nextSnapshot);\n    }\n    subscription.snapshot = nextSnapshot;\n    subscription.stale = false;\n    if (nextSnapshot.data !== snapshot.data) {\n      if (this.__log && RelayFeatureFlags.ENABLE_NOTIFY_SUBSCRIPTION) {\n        this.__log({\n          name: 'store.notify.subscription',\n          sourceOperation: sourceOperation,\n          snapshot: snapshot,\n          nextSnapshot: nextSnapshot\n        });\n      }\n      callback(nextSnapshot);\n      return snapshot.selector.owner;\n    }\n    if (RelayFeatureFlags.ENABLE_LOOSE_SUBSCRIPTION_ATTRIBUTION && (stale || hasSignificantOverlappingIDs(snapshot.seenRecords, updatedRecordIDs))) {\n      return snapshot.selector.owner;\n    }\n  };\n  return RelayStoreSubscriptions;\n}();\nmodule.exports = RelayStoreSubscriptions;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar getRelayHandleKey = require('../util/getRelayHandleKey');\nvar RelayConcreteNode = require('../util/RelayConcreteNode');\nvar stableCopy = require('../util/stableCopy');\nvar invariant = require('invariant');\nvar VARIABLE = RelayConcreteNode.VARIABLE,\n  LITERAL = RelayConcreteNode.LITERAL,\n  OBJECT_VALUE = RelayConcreteNode.OBJECT_VALUE,\n  LIST_VALUE = RelayConcreteNode.LIST_VALUE;\nvar ERRORS_KEY = '__errors';\nvar MODULE_COMPONENT_KEY_PREFIX = '__module_component_';\nvar MODULE_OPERATION_KEY_PREFIX = '__module_operation_';\nfunction getArgumentValue(arg, variables) {\n  if (arg.kind === VARIABLE) {\n    return getStableVariableValue(arg.variableName, variables);\n  } else if (arg.kind === LITERAL) {\n    return arg.value;\n  } else if (arg.kind === OBJECT_VALUE) {\n    var value = {};\n    arg.fields.forEach(function (field) {\n      value[field.name] = getArgumentValue(field, variables);\n    });\n    return value;\n  } else if (arg.kind === LIST_VALUE) {\n    var _value = [];\n    arg.items.forEach(function (item) {\n      item != null ? _value.push(getArgumentValue(item, variables)) : null;\n    });\n    return _value;\n  }\n}\nfunction getArgumentValues(args, variables, isWithinUnmatchedTypeRefinement) {\n  var values = {};\n  if (isWithinUnmatchedTypeRefinement) {\n    values[RelayStoreUtils.FRAGMENT_POINTER_IS_WITHIN_UNMATCHED_TYPE_REFINEMENT] = true;\n  }\n  if (args) {\n    args.forEach(function (arg) {\n      values[arg.name] = getArgumentValue(arg, variables);\n    });\n  }\n  return values;\n}\nfunction getHandleStorageKey(handleField, variables) {\n  var dynamicKey = handleField.dynamicKey,\n    handle = handleField.handle,\n    key = handleField.key,\n    name = handleField.name,\n    args = handleField.args,\n    filters = handleField.filters;\n  var handleName = getRelayHandleKey(handle, key, name);\n  var filterArgs = null;\n  if (args && filters && args.length !== 0 && filters.length !== 0) {\n    filterArgs = args.filter(function (arg) {\n      return filters.indexOf(arg.name) > -1;\n    });\n  }\n  if (dynamicKey) {\n    filterArgs = filterArgs != null ? [dynamicKey].concat((0, _toConsumableArray2[\"default\"])(filterArgs)) : [dynamicKey];\n  }\n  if (filterArgs === null) {\n    return handleName;\n  } else {\n    return formatStorageKey(handleName, getArgumentValues(filterArgs, variables));\n  }\n}\nfunction getStorageKey(field, variables) {\n  if (field.storageKey) {\n    return field.storageKey;\n  }\n  var args = getArguments(field);\n  var name = field.name;\n  return args && args.length !== 0 ? formatStorageKey(name, getArgumentValues(args, variables)) : name;\n}\nfunction getArguments(field) {\n  if (field.kind === 'RelayResolver' || field.kind === 'RelayLiveResolver') {\n    var _field$fragment2;\n    if (field.args == null) {\n      var _field$fragment;\n      return (_field$fragment = field.fragment) === null || _field$fragment === void 0 ? void 0 : _field$fragment.args;\n    }\n    if (((_field$fragment2 = field.fragment) === null || _field$fragment2 === void 0 ? void 0 : _field$fragment2.args) == null) {\n      return field.args;\n    }\n    return field.args.concat(field.fragment.args);\n  }\n  var args = typeof field.args === 'undefined' ? undefined : field.args;\n  return args;\n}\nfunction getStableStorageKey(name, args) {\n  return formatStorageKey(name, stableCopy(args));\n}\nfunction formatStorageKey(name, argValues) {\n  if (!argValues) {\n    return name;\n  }\n  var values = [];\n  for (var argName in argValues) {\n    if (argValues.hasOwnProperty(argName)) {\n      var value = argValues[argName];\n      if (value != null) {\n        var _JSON$stringify;\n        values.push(argName + ':' + ((_JSON$stringify = JSON.stringify(value)) !== null && _JSON$stringify !== void 0 ? _JSON$stringify : 'undefined'));\n      }\n    }\n  }\n  return values.length === 0 ? name : name + \"(\".concat(values.join(','), \")\");\n}\nfunction getStableVariableValue(name, variables) {\n  !variables.hasOwnProperty(name) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'getVariableValue(): Undefined variable `%s`.', name) : invariant(false) : void 0;\n  return stableCopy(variables[name]);\n}\nfunction getModuleComponentKey(documentName) {\n  return \"\".concat(MODULE_COMPONENT_KEY_PREFIX).concat(documentName);\n}\nfunction getModuleOperationKey(documentName) {\n  return \"\".concat(MODULE_OPERATION_KEY_PREFIX).concat(documentName);\n}\nvar RelayStoreUtils = {\n  ACTOR_IDENTIFIER_KEY: '__actorIdentifier',\n  CLIENT_EDGE_TRAVERSAL_PATH: '__clientEdgeTraversalPath',\n  FRAGMENTS_KEY: '__fragments',\n  FRAGMENT_OWNER_KEY: '__fragmentOwner',\n  FRAGMENT_POINTER_IS_WITHIN_UNMATCHED_TYPE_REFINEMENT: '$isWithinUnmatchedTypeRefinement',\n  FRAGMENT_PROP_NAME_KEY: '__fragmentPropName',\n  MODULE_COMPONENT_KEY: '__module_component',\n  ERRORS_KEY: ERRORS_KEY,\n  ID_KEY: '__id',\n  REF_KEY: '__ref',\n  REFS_KEY: '__refs',\n  ROOT_ID: 'client:root',\n  ROOT_TYPE: '__Root',\n  TYPENAME_KEY: '__typename',\n  INVALIDATED_AT_KEY: '__invalidated_at',\n  RELAY_RESOLVER_VALUE_KEY: '__resolverValue',\n  RELAY_RESOLVER_INVALIDATION_KEY: '__resolverValueMayBeInvalid',\n  RELAY_RESOLVER_SNAPSHOT_KEY: '__resolverSnapshot',\n  RELAY_RESOLVER_ERROR_KEY: '__resolverError',\n  RELAY_RESOLVER_OUTPUT_TYPE_RECORD_IDS: '__resolverOutputTypeRecordIDs',\n  formatStorageKey: formatStorageKey,\n  getArgumentValue: getArgumentValue,\n  getArgumentValues: getArgumentValues,\n  getHandleStorageKey: getHandleStorageKey,\n  getStorageKey: getStorageKey,\n  getStableStorageKey: getStableStorageKey,\n  getModuleComponentKey: getModuleComponentKey,\n  getModuleOperationKey: getModuleOperationKey\n};\nmodule.exports = RelayStoreUtils;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar recycleNodesInto = require('../util/recycleNodesInto');\nvar _require = require('../util/RelayConcreteNode'),\n  RELAY_LIVE_RESOLVER = _require.RELAY_LIVE_RESOLVER;\nvar RelayFeatureFlags = require('../util/RelayFeatureFlags');\nvar shallowFreeze = require('../util/shallowFreeze');\nvar _require2 = require('./ClientID'),\n  generateClientID = _require2.generateClientID;\nvar RelayModernRecord = require('./RelayModernRecord');\nvar _require3 = require('./RelayStoreUtils'),\n  RELAY_RESOLVER_ERROR_KEY = _require3.RELAY_RESOLVER_ERROR_KEY,\n  RELAY_RESOLVER_INVALIDATION_KEY = _require3.RELAY_RESOLVER_INVALIDATION_KEY,\n  RELAY_RESOLVER_SNAPSHOT_KEY = _require3.RELAY_RESOLVER_SNAPSHOT_KEY,\n  RELAY_RESOLVER_VALUE_KEY = _require3.RELAY_RESOLVER_VALUE_KEY,\n  getStorageKey = _require3.getStorageKey;\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nvar emptySet = new Set();\nvar NoopResolverCache = /*#__PURE__*/function () {\n  function NoopResolverCache() {}\n  var _proto = NoopResolverCache.prototype;\n  _proto.readFromCacheOrEvaluate = function readFromCacheOrEvaluate(recordID, field, variables, evaluate, getDataForResolverFragment) {\n    !(field.kind !== RELAY_LIVE_RESOLVER) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'This store does not support Live Resolvers') : invariant(false) : void 0;\n    var _evaluate = evaluate(),\n      resolverResult = _evaluate.resolverResult,\n      snapshot = _evaluate.snapshot,\n      error = _evaluate.error;\n    return [resolverResult, undefined, error, snapshot, undefined, undefined];\n  };\n  _proto.invalidateDataIDs = function invalidateDataIDs(updatedDataIDs) {};\n  _proto.ensureClientRecord = function ensureClientRecord(id, typeName) {\n    !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Client Edges to Client Objects are not supported in this version of Relay Store') : invariant(false) : void 0;\n  };\n  _proto.notifyUpdatedSubscribers = function notifyUpdatedSubscribers(updatedDataIDs) {};\n  return NoopResolverCache;\n}();\nfunction addDependencyEdge(edges, from, to) {\n  var set = edges.get(from);\n  if (!set) {\n    set = new Set();\n    edges.set(from, set);\n  }\n  set.add(to);\n}\nvar RecordResolverCache = /*#__PURE__*/function () {\n  function RecordResolverCache(getRecordSource) {\n    this._resolverIDToRecordIDs = new Map();\n    this._recordIDToResolverIDs = new Map();\n    this._getRecordSource = getRecordSource;\n  }\n  var _proto2 = RecordResolverCache.prototype;\n  _proto2.readFromCacheOrEvaluate = function readFromCacheOrEvaluate(recordID, field, variables, evaluate, getDataForResolverFragment) {\n    var recordSource = this._getRecordSource();\n    var record = recordSource.get(recordID);\n    !(record != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'We expect record to exist in the store.') : invariant(false) : void 0;\n    var storageKey = getStorageKey(field, variables);\n    var linkedID = RelayModernRecord.getLinkedRecordID(record, storageKey);\n    var linkedRecord = linkedID == null ? null : recordSource.get(linkedID);\n    if (linkedRecord == null || this._isInvalid(linkedRecord, getDataForResolverFragment)) {\n      var _linkedID;\n      linkedID = (_linkedID = linkedID) !== null && _linkedID !== void 0 ? _linkedID : generateClientID(recordID, storageKey);\n      linkedRecord = RelayModernRecord.create(linkedID, '__RELAY_RESOLVER__');\n      var evaluationResult = evaluate();\n      if (RelayFeatureFlags.ENABLE_SHALLOW_FREEZE_RESOLVER_VALUES) {\n        shallowFreeze(evaluationResult.resolverResult);\n      }\n      RelayModernRecord.setValue(linkedRecord, RELAY_RESOLVER_VALUE_KEY, evaluationResult.resolverResult);\n      RelayModernRecord.setValue(linkedRecord, RELAY_RESOLVER_SNAPSHOT_KEY, evaluationResult.snapshot);\n      RelayModernRecord.setValue(linkedRecord, RELAY_RESOLVER_ERROR_KEY, evaluationResult.error);\n      recordSource.set(linkedID, linkedRecord);\n      var currentRecord = recordSource.get(recordID);\n      !(currentRecord != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Expected the parent record to still be in the record source.') : invariant(false) : void 0;\n      var nextRecord = RelayModernRecord.clone(currentRecord);\n      RelayModernRecord.setLinkedRecordID(nextRecord, storageKey, linkedID);\n      recordSource.set(recordID, nextRecord);\n      if (field.fragment != null) {\n        var _evaluationResult$sna;\n        var fragmentStorageKey = getStorageKey(field.fragment, variables);\n        var resolverID = generateClientID(recordID, fragmentStorageKey);\n        addDependencyEdge(this._resolverIDToRecordIDs, resolverID, linkedID);\n        addDependencyEdge(this._recordIDToResolverIDs, recordID, resolverID);\n        var seenRecordIds = (_evaluationResult$sna = evaluationResult.snapshot) === null || _evaluationResult$sna === void 0 ? void 0 : _evaluationResult$sna.seenRecords;\n        if (seenRecordIds != null) {\n          var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(seenRecordIds),\n            _step;\n          try {\n            for (_iterator.s(); !(_step = _iterator.n()).done;) {\n              var seenRecordID = _step.value;\n              addDependencyEdge(this._recordIDToResolverIDs, seenRecordID, resolverID);\n            }\n          } catch (err) {\n            _iterator.e(err);\n          } finally {\n            _iterator.f();\n          }\n        }\n      }\n    }\n    var answer = RelayModernRecord.getValue(linkedRecord, RELAY_RESOLVER_VALUE_KEY);\n    var snapshot = RelayModernRecord.getValue(linkedRecord, RELAY_RESOLVER_SNAPSHOT_KEY);\n    var error = RelayModernRecord.getValue(linkedRecord, RELAY_RESOLVER_ERROR_KEY);\n    return [answer, linkedID, error, snapshot, undefined, undefined];\n  };\n  _proto2.invalidateDataIDs = function invalidateDataIDs(updatedDataIDs) {\n    var recordSource = this._getRecordSource();\n    var visited = new Set();\n    var recordsToVisit = Array.from(updatedDataIDs);\n    while (recordsToVisit.length) {\n      var recordID = recordsToVisit.pop();\n      updatedDataIDs.add(recordID);\n      var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])((_this$_recordIDToReso = this._recordIDToResolverIDs.get(recordID)) !== null && _this$_recordIDToReso !== void 0 ? _this$_recordIDToReso : emptySet),\n        _step2;\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var _this$_recordIDToReso;\n          var fragment = _step2.value;\n          if (!visited.has(fragment)) {\n            var _iterator3 = (0, _createForOfIteratorHelper2[\"default\"])((_this$_resolverIDToRe = this._resolverIDToRecordIDs.get(fragment)) !== null && _this$_resolverIDToRe !== void 0 ? _this$_resolverIDToRe : emptySet),\n              _step3;\n            try {\n              for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                var _this$_resolverIDToRe;\n                var anotherRecordID = _step3.value;\n                this._markInvalidatedResolverRecord(anotherRecordID, recordSource, updatedDataIDs);\n                if (!visited.has(anotherRecordID)) {\n                  recordsToVisit.push(anotherRecordID);\n                }\n              }\n            } catch (err) {\n              _iterator3.e(err);\n            } finally {\n              _iterator3.f();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n    }\n  };\n  _proto2._markInvalidatedResolverRecord = function _markInvalidatedResolverRecord(dataID, recordSource, updatedDataIDs) {\n    var record = recordSource.get(dataID);\n    if (!record) {\n      process.env.NODE_ENV !== \"production\" ? warning(false, 'Expected a resolver record with ID %s, but it was missing.', dataID) : void 0;\n      return;\n    }\n    var nextRecord = RelayModernRecord.clone(record);\n    RelayModernRecord.setValue(nextRecord, RELAY_RESOLVER_INVALIDATION_KEY, true);\n    recordSource.set(dataID, nextRecord);\n  };\n  _proto2._isInvalid = function _isInvalid(record, getDataForResolverFragment) {\n    if (!RelayModernRecord.getValue(record, RELAY_RESOLVER_INVALIDATION_KEY)) {\n      return false;\n    }\n    var snapshot = RelayModernRecord.getValue(record, RELAY_RESOLVER_SNAPSHOT_KEY);\n    var originalInputs = snapshot === null || snapshot === void 0 ? void 0 : snapshot.data;\n    var readerSelector = snapshot === null || snapshot === void 0 ? void 0 : snapshot.selector;\n    if (originalInputs == null || readerSelector == null) {\n      process.env.NODE_ENV !== \"production\" ? warning(false, 'Expected previous inputs and reader selector on resolver record with ID %s, but they were missing.', RelayModernRecord.getDataID(record)) : void 0;\n      return true;\n    }\n    var _getDataForResolverFr = getDataForResolverFragment(readerSelector),\n      latestValues = _getDataForResolverFr.data;\n    var recycled = recycleNodesInto(originalInputs, latestValues);\n    if (recycled !== originalInputs) {\n      return true;\n    }\n    return false;\n  };\n  _proto2.ensureClientRecord = function ensureClientRecord(id, typename) {\n    !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Client Edges to Client Objects are not supported in this version of Relay Store') : invariant(false) : void 0;\n  };\n  _proto2.notifyUpdatedSubscribers = function notifyUpdatedSubscribers(updatedDataIDs) {\n    !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Processing @outputType records is not supported in this version of Relay Store') : invariant(false) : void 0;\n  };\n  return RecordResolverCache;\n}();\nmodule.exports = {\n  NoopResolverCache: NoopResolverCache,\n  RecordResolverCache: RecordResolverCache\n};","'use strict';\n\nvar _require = require('../query/GraphQLTag'),\n  getFragment = _require.getFragment;\nvar _require2 = require('./RelayModernSelector'),\n  getSelector = _require2.getSelector;\nvar invariant = require('invariant');\nvar contextStack = [];\nfunction withResolverContext(context, cb) {\n  contextStack.push(context);\n  try {\n    return cb();\n  } finally {\n    contextStack.pop();\n  }\n}\nfunction readFragment(fragmentInput, fragmentKey) {\n  if (!contextStack.length) {\n    throw new Error('readFragment should be called only from within a Relay Resolver function.');\n  }\n  var context = contextStack[contextStack.length - 1];\n  var fragmentNode = getFragment(fragmentInput);\n  var fragmentSelector = getSelector(fragmentNode, fragmentKey);\n  !(fragmentSelector != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, \"Expected a selector for the fragment of the resolver \".concat(fragmentNode.name, \", but got null.\")) : invariant(false) : void 0;\n  !(fragmentSelector.kind === 'SingularReaderSelector') ? process.env.NODE_ENV !== \"production\" ? invariant(false, \"Expected a singular reader selector for the fragment of the resolver \".concat(fragmentNode.name, \", but it was plural.\")) : invariant(false) : void 0;\n  var _context$getDataForRe = context.getDataForResolverFragment(fragmentSelector, fragmentKey),\n    data = _context$getDataForRe.data,\n    isMissingData = _context$getDataForRe.isMissingData;\n  if (isMissingData) {\n    throw RESOLVER_FRAGMENT_MISSING_DATA_SENTINEL;\n  }\n  return data;\n}\nvar RESOLVER_FRAGMENT_MISSING_DATA_SENTINEL = {};\nmodule.exports = {\n  readFragment: readFragment,\n  withResolverContext: withResolverContext,\n  RESOLVER_FRAGMENT_MISSING_DATA_SENTINEL: RESOLVER_FRAGMENT_MISSING_DATA_SENTINEL\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar inspect = function inspect() {};\nif (process.env.NODE_ENV !== \"production\") {\n  var formattersInstalled = false;\n  var installDevtoolFormatters = function installDevtoolFormatters() {\n    var _window$devtoolsForma;\n    if (formattersInstalled) {\n      return;\n    }\n    formattersInstalled = true;\n    if (window.devtoolsFormatters == null) {\n      window.devtoolsFormatters = [];\n    }\n    if (!Array.isArray(window.devtoolsFormatters)) {\n      return;\n    }\n    console.info('Make sure to select \"Enable custom formatters\" in the Chrome ' + 'Developer Tools settings, tab \"Preferences\" under the \"Console\" ' + 'section.');\n    (_window$devtoolsForma = window.devtoolsFormatters).push.apply(_window$devtoolsForma, (0, _toConsumableArray2[\"default\"])(createFormatters()));\n  };\n  var createFormatters = function createFormatters() {\n    var listStyle = {\n      style: 'list-style-type: none; padding: 0; margin: 0 0 0 12px; font-style: normal'\n    };\n    var keyStyle = {\n      style: 'rgb(136, 19, 145)'\n    };\n    var nullStyle = {\n      style: 'color: #777'\n    };\n    var reference = function reference(object, config) {\n      return object == null ? ['span', nullStyle, 'undefined'] : ['object', {\n        object: object,\n        config: config\n      }];\n    };\n    var renderRecordHeader = function renderRecordHeader(record) {\n      return ['span', {\n        style: 'font-style: italic'\n      }, record.__typename, ['span', nullStyle, ' {id: \"', record.__id, '\", …}']];\n    };\n    var isRecord = function isRecord(o) {\n      return o != null && typeof o.__id === 'string';\n    };\n    var RecordEntry = function RecordEntry(key, value) {\n      this.key = key;\n      this.value = value;\n    };\n    var renderRecordEntries = function renderRecordEntries(record) {\n      var children = Object.keys(record).map(function (key) {\n        return ['li', {}, ['object', {\n          object: new RecordEntry(key, record[key])\n        }]];\n      });\n      return ['ol', listStyle].concat((0, _toConsumableArray2[\"default\"])(children));\n    };\n    var recordFormatter = {\n      header: function header(obj) {\n        if (!isRecord(obj)) {\n          return null;\n        }\n        return renderRecordHeader(obj);\n      },\n      hasBody: function hasBody(obj) {\n        return true;\n      },\n      body: function body(obj) {\n        return renderRecordEntries(obj);\n      }\n    };\n    var recordEntryFormatter = {\n      header: function header(obj) {\n        if (obj instanceof RecordEntry) {\n          var value = isRecord(obj.value) ? renderRecordHeader(obj.value) : reference(obj.value);\n          return ['span', keyStyle, obj.key, ': ', value];\n        }\n        return null;\n      },\n      hasBody: function hasBody(obj) {\n        return isRecord(obj.value);\n      },\n      body: function body(obj) {\n        return renderRecordEntries(obj.value);\n      }\n    };\n    return [recordFormatter, recordEntryFormatter];\n  };\n  var getWrappedRecord = function getWrappedRecord(source, dataID) {\n    var record = source.get(dataID);\n    if (record == null) {\n      return record;\n    }\n    return new Proxy((0, _objectSpread2[\"default\"])({}, record), {\n      get: function get(target, prop) {\n        var value = target[prop];\n        if (value == null) {\n          return value;\n        }\n        if (typeof value === 'object') {\n          if (typeof value.__ref === 'string') {\n            return getWrappedRecord(source, value.__ref);\n          }\n          if (Array.isArray(value.__refs)) {\n            return value.__refs.map(function (ref) {\n              return getWrappedRecord(source, ref);\n            });\n          }\n        }\n        return value;\n      }\n    });\n  };\n  inspect = function inspect(environment, dataID) {\n    installDevtoolFormatters();\n    return getWrappedRecord(environment.getStore().getSource(), dataID !== null && dataID !== void 0 ? dataID : 'client:root');\n  };\n}\nmodule.exports = {\n  inspect: inspect\n};","'use strict';\n\nvar PREFIX = 'client:__type:';\nvar TYPE_SCHEMA_TYPE = '__TypeSchema';\nfunction generateTypeID(typeName) {\n  return PREFIX + typeName;\n}\nfunction isTypeID(id) {\n  return id.indexOf(PREFIX) === 0;\n}\nmodule.exports = {\n  generateTypeID: generateTypeID,\n  isTypeID: isTypeID,\n  TYPE_SCHEMA_TYPE: TYPE_SCHEMA_TYPE\n};","'use strict';\n\nvar _require = require('./ClientID'),\n  generateClientID = _require.generateClientID;\nvar _require2 = require('./RelayStoreUtils'),\n  ROOT_ID = _require2.ROOT_ID;\nvar VIEWER_ID = generateClientID(ROOT_ID, 'viewer');\nvar VIEWER_TYPE = 'Viewer';\nmodule.exports = {\n  VIEWER_ID: VIEWER_ID,\n  VIEWER_TYPE: VIEWER_TYPE\n};","'use strict';\n\nvar _require = require('../util/RelayConcreteNode'),\n  LINKED_FIELD = _require.LINKED_FIELD;\nvar _require2 = require('./RelayStoreUtils'),\n  getHandleStorageKey = _require2.getHandleStorageKey;\nvar areEqual = require(\"fbjs/lib/areEqual\");\nvar invariant = require('invariant');\nfunction cloneRelayHandleSourceField(handleField, selections, variables) {\n  var sourceField = selections.find(function (source) {\n    return source.kind === LINKED_FIELD && source.name === handleField.name && source.alias === handleField.alias && areEqual(source.args, handleField.args);\n  });\n  !(sourceField && sourceField.kind === LINKED_FIELD) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'cloneRelayHandleSourceField: Expected a corresponding source field for ' + 'handle `%s`.', handleField.handle) : invariant(false) : void 0;\n  var handleKey = getHandleStorageKey(handleField, variables);\n  return {\n    kind: 'LinkedField',\n    alias: sourceField.alias,\n    name: handleKey,\n    storageKey: handleKey,\n    args: null,\n    concreteType: sourceField.concreteType,\n    plural: sourceField.plural,\n    selections: sourceField.selections\n  };\n}\nmodule.exports = cloneRelayHandleSourceField;","'use strict';\n\nvar _require = require('../util/RelayConcreteNode'),\n  SCALAR_FIELD = _require.SCALAR_FIELD;\nvar _require2 = require('./RelayStoreUtils'),\n  getHandleStorageKey = _require2.getHandleStorageKey;\nvar areEqual = require(\"fbjs/lib/areEqual\");\nvar invariant = require('invariant');\nfunction cloneRelayScalarHandleSourceField(handleField, selections, variables) {\n  var sourceField = selections.find(function (source) {\n    return source.kind === SCALAR_FIELD && source.name === handleField.name && source.alias === handleField.alias && areEqual(source.args, handleField.args);\n  });\n  !(sourceField && sourceField.kind === SCALAR_FIELD) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'cloneRelayScalarHandleSourceField: Expected a corresponding source field for ' + 'handle `%s`.', handleField.handle) : invariant(false) : void 0;\n  var handleKey = getHandleStorageKey(handleField, variables);\n  return {\n    kind: 'ScalarField',\n    alias: sourceField.alias,\n    name: handleKey,\n    storageKey: handleKey,\n    args: null\n  };\n}\nmodule.exports = cloneRelayScalarHandleSourceField;","'use strict';\n\nvar RelayModernFragmentSpecResolver = require('./RelayModernFragmentSpecResolver');\nvar warning = require(\"fbjs/lib/warning\");\nfunction createFragmentSpecResolver(context, containerName, fragments, props, rootIsQueryRenderer, callback) {\n  if (process.env.NODE_ENV !== \"production\") {\n    var fragmentNames = Object.keys(fragments);\n    fragmentNames.forEach(function (fragmentName) {\n      var propValue = props[fragmentName];\n      process.env.NODE_ENV !== \"production\" ? warning(propValue !== undefined, 'createFragmentSpecResolver: Expected prop `%s` to be supplied to `%s`, but ' + 'got `undefined`. Pass an explicit `null` if this is intentional.', fragmentName, containerName) : void 0;\n    });\n  }\n  return new RelayModernFragmentSpecResolver(context, fragments, props, callback, rootIsQueryRenderer);\n}\nmodule.exports = createFragmentSpecResolver;","'use strict';\n\nvar invariant = require('invariant');\nvar relayContext;\nvar firstReact;\nfunction createRelayContext(react) {\n  if (!relayContext) {\n    relayContext = react.createContext(null);\n    if (process.env.NODE_ENV !== \"production\") {\n      relayContext.displayName = 'RelayContext';\n    }\n    firstReact = react;\n  }\n  !(react === firstReact) ? process.env.NODE_ENV !== \"production\" ? invariant(false, '[createRelayContext]: You are passing a different instance of React', react.version) : invariant(false) : void 0;\n  return relayContext;\n}\nmodule.exports = createRelayContext;","'use strict';\n\nvar _require = require('./ViewerPattern'),\n  VIEWER_ID = _require.VIEWER_ID,\n  VIEWER_TYPE = _require.VIEWER_TYPE;\nfunction defaultGetDataID(fieldValue, typeName) {\n  if (typeName === VIEWER_TYPE) {\n    return fieldValue.id == null ? VIEWER_ID : fieldValue.id;\n  }\n  return fieldValue.id;\n}\nmodule.exports = defaultGetDataID;","'use strict';\n\nvar defaultRelayFieldLogger = function defaultRelayFieldLogger(event) {\n  if (process.env.NODE_ENV !== \"production\" && event.kind === 'missing_field.log') {\n    throw new Error('Relay Environment Configuration Error (dev only): `@required(action: LOG)` requires that the Relay Environment be configured with a `relayFieldLogger`.');\n  }\n};\nmodule.exports = defaultRelayFieldLogger;","'use strict';\n\nvar LIVE_RESOLVER_SUSPENSE_SENTINEL = Object.freeze({\n  __LIVE_RESOLVER_SUSPENSE_SENTINEL: true\n});\nfunction suspenseSentinel() {\n  return LIVE_RESOLVER_SUSPENSE_SENTINEL;\n}\nfunction isSuspenseSentinel(value) {\n  return value === LIVE_RESOLVER_SUSPENSE_SENTINEL;\n}\nmodule.exports = {\n  isSuspenseSentinel: isSuspenseSentinel,\n  suspenseSentinel: suspenseSentinel\n};","'use strict';\n\nvar RelayModernRecord = require('../RelayModernRecord');\nvar _require = require('../RelayStoreUtils'),\n  RELAY_RESOLVER_OUTPUT_TYPE_RECORD_IDS = _require.RELAY_RESOLVER_OUTPUT_TYPE_RECORD_IDS;\nvar invariant = require('invariant');\nfunction getOutputTypeRecordIDs(record) {\n  var maybeOutputTypeRecordIDs = RelayModernRecord.getValue(record, RELAY_RESOLVER_OUTPUT_TYPE_RECORD_IDS);\n  if (maybeOutputTypeRecordIDs == null) {\n    return null;\n  }\n  !(maybeOutputTypeRecordIDs instanceof Set) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'getOutputTypeRecordIDs: Expected the `%s` field on record `%s` to be of type Set. Instead, it is a %s.', RELAY_RESOLVER_OUTPUT_TYPE_RECORD_IDS, typeof maybeOutputTypeRecordIDs) : invariant(false) : void 0;\n  return maybeOutputTypeRecordIDs;\n}\nmodule.exports = getOutputTypeRecordIDs;","'use strict';\n\nvar ITERATOR_KEY = Symbol.iterator;\nfunction hasOverlappingIDs(seenRecords, updatedRecordIDs) {\n  var iterator = seenRecords[ITERATOR_KEY]();\n  var next = iterator.next();\n  while (!next.done) {\n    var key = next.value;\n    if (updatedRecordIDs.has(key)) {\n      return true;\n    }\n    next = iterator.next();\n  }\n  return false;\n}\nmodule.exports = hasOverlappingIDs;","'use strict';\n\nvar _require = require('./RelayStoreUtils'),\n  ROOT_ID = _require.ROOT_ID;\nvar _require2 = require('./ViewerPattern'),\n  VIEWER_ID = _require2.VIEWER_ID;\nvar ITERATOR_KEY = Symbol.iterator;\nfunction hasSignificantOverlappingIDs(seenRecords, updatedRecordIDs) {\n  var iterator = seenRecords[ITERATOR_KEY]();\n  var next = iterator.next();\n  while (!next.done) {\n    var key = next.value;\n    if (updatedRecordIDs.has(key) && key !== ROOT_ID && key !== VIEWER_ID) {\n      return true;\n    }\n    next = iterator.next();\n  }\n  return false;\n}\nmodule.exports = hasSignificantOverlappingIDs;","'use strict';\n\nfunction isRelayModernEnvironment(environment) {\n  return Boolean(environment && environment['@@RelayModernEnvironment']);\n}\nmodule.exports = isRelayModernEnvironment;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar _RelayModernRecord = _interopRequireDefault(require(\"./RelayModernRecord\"));\nvar _RelayRecordSource = _interopRequireDefault(require(\"./RelayRecordSource\"));\nvar _RelayResponseNormalizer = _interopRequireDefault(require(\"./RelayResponseNormalizer\"));\nfunction normalizeResponse(response, selector, typeName, options) {\n  var _response$extensions;\n  var data = response.data,\n    errors = response.errors;\n  var source = _RelayRecordSource[\"default\"].create();\n  var record = _RelayModernRecord[\"default\"].create(selector.dataID, typeName);\n  source.set(selector.dataID, record);\n  var relayPayload = _RelayResponseNormalizer[\"default\"].normalize(source, selector, data, options, errors);\n  return (0, _objectSpread2[\"default\"])((0, _objectSpread2[\"default\"])({}, relayPayload), {}, {\n    isFinal: ((_response$extensions = response.extensions) === null || _response$extensions === void 0 ? void 0 : _response$extensions.is_final) === true\n  });\n}\nmodule.exports = normalizeResponse;","'use strict';\n\nvar _require = require('../query/GraphQLTag'),\n  getInlineDataFragment = _require.getInlineDataFragment;\nvar _require2 = require('./RelayStoreUtils'),\n  FRAGMENTS_KEY = _require2.FRAGMENTS_KEY;\nvar invariant = require('invariant');\nfunction readInlineData(fragment, fragmentRef) {\n  var _fragmentRef$FRAGMENT;\n  var inlineDataFragment = getInlineDataFragment(fragment);\n  if (fragmentRef == null) {\n    return fragmentRef;\n  }\n  !(typeof fragmentRef === 'object') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'readInlineData(): Expected an object, got `%s`.', typeof fragmentRef) : invariant(false) : void 0;\n  var inlineData = (_fragmentRef$FRAGMENT = fragmentRef[FRAGMENTS_KEY]) === null || _fragmentRef$FRAGMENT === void 0 ? void 0 : _fragmentRef$FRAGMENT[inlineDataFragment.name];\n  !(inlineData != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'readInlineData(): Expected fragment `%s` to be spread in the parent ' + 'fragment.', inlineDataFragment.name) : invariant(false) : void 0;\n  return inlineData;\n}\nmodule.exports = readInlineData;","'use strict';\n\nvar RelayDeclarativeMutationConfig = require('../mutations/RelayDeclarativeMutationConfig');\nvar _require = require('../query/GraphQLTag'),\n  getRequest = _require.getRequest;\nvar _require2 = require('../store/RelayModernOperationDescriptor'),\n  createOperationDescriptor = _require2.createOperationDescriptor;\nvar _require3 = require('../store/RelayModernSelector'),\n  createReaderSelector = _require3.createReaderSelector;\nvar warning = require(\"fbjs/lib/warning\");\nfunction requestSubscription(environment, config) {\n  var subscription = getRequest(config.subscription);\n  if (subscription.params.operationKind !== 'subscription') {\n    throw new Error('requestSubscription: Must use Subscription operation');\n  }\n  var configs = config.configs,\n    onCompleted = config.onCompleted,\n    onError = config.onError,\n    onNext = config.onNext,\n    variables = config.variables,\n    cacheConfig = config.cacheConfig;\n  var operation = createOperationDescriptor(subscription, variables, cacheConfig);\n  process.env.NODE_ENV !== \"production\" ? warning(!(config.updater && configs), 'requestSubscription: Expected only one of `updater` and `configs` to be provided') : void 0;\n  var _ref = configs ? RelayDeclarativeMutationConfig.convert(configs, subscription, null, config.updater) : config,\n    updater = _ref.updater;\n  var sub = environment.executeSubscription({\n    operation: operation,\n    updater: updater\n  }).subscribe({\n    next: function next(responses) {\n      if (onNext != null) {\n        var selector = operation.fragment;\n        var nextID;\n        if (Array.isArray(responses)) {\n          var _responses$, _responses$$extension;\n          nextID = (_responses$ = responses[0]) === null || _responses$ === void 0 ? void 0 : (_responses$$extension = _responses$.extensions) === null || _responses$$extension === void 0 ? void 0 : _responses$$extension.__relay_subscription_root_id;\n        } else {\n          var _responses$extensions;\n          nextID = (_responses$extensions = responses.extensions) === null || _responses$extensions === void 0 ? void 0 : _responses$extensions.__relay_subscription_root_id;\n        }\n        if (typeof nextID === 'string') {\n          selector = createReaderSelector(selector.node, nextID, selector.variables, selector.owner);\n        }\n        var data = environment.lookup(selector).data;\n        onNext(data);\n      }\n    },\n    error: onError,\n    complete: onCompleted\n  });\n  return {\n    dispose: sub.unsubscribe\n  };\n}\nmodule.exports = requestSubscription;","'use strict';\n\nvar RelayConcreteNode = {\n  ACTOR_CHANGE: 'ActorChange',\n  CONDITION: 'Condition',\n  CLIENT_COMPONENT: 'ClientComponent',\n  CLIENT_EDGE_TO_SERVER_OBJECT: 'ClientEdgeToServerObject',\n  CLIENT_EDGE_TO_CLIENT_OBJECT: 'ClientEdgeToClientObject',\n  CLIENT_EXTENSION: 'ClientExtension',\n  DEFER: 'Defer',\n  CONNECTION: 'Connection',\n  FRAGMENT: 'Fragment',\n  FRAGMENT_SPREAD: 'FragmentSpread',\n  INLINE_DATA_FRAGMENT_SPREAD: 'InlineDataFragmentSpread',\n  INLINE_DATA_FRAGMENT: 'InlineDataFragment',\n  INLINE_FRAGMENT: 'InlineFragment',\n  LINKED_FIELD: 'LinkedField',\n  LINKED_HANDLE: 'LinkedHandle',\n  LITERAL: 'Literal',\n  LIST_VALUE: 'ListValue',\n  LOCAL_ARGUMENT: 'LocalArgument',\n  MODULE_IMPORT: 'ModuleImport',\n  ALIASED_FRAGMENT_SPREAD: 'AliasedFragmentSpread',\n  ALIASED_INLINE_FRAGMENT_SPREAD: 'AliasedInlineFragmentSpread',\n  RELAY_RESOLVER: 'RelayResolver',\n  RELAY_LIVE_RESOLVER: 'RelayLiveResolver',\n  REQUIRED_FIELD: 'RequiredField',\n  OBJECT_VALUE: 'ObjectValue',\n  OPERATION: 'Operation',\n  REQUEST: 'Request',\n  ROOT_ARGUMENT: 'RootArgument',\n  SCALAR_FIELD: 'ScalarField',\n  SCALAR_HANDLE: 'ScalarHandle',\n  SPLIT_OPERATION: 'SplitOperation',\n  STREAM: 'Stream',\n  TYPE_DISCRIMINATOR: 'TypeDiscriminator',\n  UPDATABLE_QUERY: 'UpdatableQuery',\n  VARIABLE: 'Variable'\n};\nmodule.exports = RelayConcreteNode;","'use strict';\n\nmodule.exports = {\n  DEFAULT_HANDLE_KEY: ''\n};","'use strict';\n\nfunction createError(type, name, messageFormat) {\n  for (var _len = arguments.length, messageParams = new Array(_len > 3 ? _len - 3 : 0), _key = 3; _key < _len; _key++) {\n    messageParams[_key - 3] = arguments[_key];\n  }\n  var index = 0;\n  var message = messageFormat.replace(/%s/g, function () {\n    return String(messageParams[index++]);\n  });\n  var err = new Error(message);\n  var error = Object.assign(err, {\n    name: name,\n    messageFormat: messageFormat,\n    messageParams: messageParams,\n    type: type,\n    taalOpcodes: [2, 2]\n  });\n  if (error.stack === undefined) {\n    try {\n      throw error;\n    } catch (_unused) {}\n  }\n  return error;\n}\nmodule.exports = {\n  create: function create(name, messageFormat) {\n    for (var _len2 = arguments.length, messageParams = new Array(_len2 > 2 ? _len2 - 2 : 0), _key2 = 2; _key2 < _len2; _key2++) {\n      messageParams[_key2 - 2] = arguments[_key2];\n    }\n    return createError.apply(void 0, ['error', name, messageFormat].concat(messageParams));\n  },\n  createWarning: function createWarning(name, messageFormat) {\n    for (var _len3 = arguments.length, messageParams = new Array(_len3 > 2 ? _len3 - 2 : 0), _key3 = 2; _key3 < _len3; _key3++) {\n      messageParams[_key3 - 2] = arguments[_key3];\n    }\n    return createError.apply(void 0, ['warn', name, messageFormat].concat(messageParams));\n  }\n};","'use strict';\n\nvar RelayFeatureFlags = {\n  ENABLE_CLIENT_EDGES: false,\n  ENABLE_VARIABLE_CONNECTION_KEY: false,\n  ENABLE_RELAY_RESOLVERS: false,\n  ENABLE_GETFRAGMENTIDENTIFIER_OPTIMIZATION: false,\n  ENABLE_FRIENDLY_QUERY_NAME_GQL_URL: false,\n  ENABLE_LOAD_QUERY_REQUEST_DEDUPING: true,\n  ENABLE_DO_NOT_WRAP_LIVE_QUERY: false,\n  ENABLE_NOTIFY_SUBSCRIPTION: false,\n  BATCH_ASYNC_MODULE_UPDATES_FN: null,\n  ENABLE_CONTAINERS_SUBSCRIBE_ON_COMMIT: false,\n  MAX_DATA_ID_LENGTH: null,\n  STRING_INTERN_LEVEL: 0,\n  LOG_MISSING_RECORDS_IN_PROD: false,\n  ENABLE_LOOSE_SUBSCRIPTION_ATTRIBUTION: false,\n  ENABLE_OPERATION_TRACKER_OPTIMISTIC_UPDATES: false,\n  ENABLE_RELAY_OPERATION_TRACKER_SUSPENSE: false,\n  ENABLE_FIELD_ERROR_HANDLING: false,\n  ENABLE_FIELD_ERROR_HANDLING_THROW_BY_DEFAULT: false,\n  ENABLE_FIELD_ERROR_HANDLING_CATCH_DIRECTIVE: false,\n  ENABLE_SHALLOW_FREEZE_RESOLVER_VALUES: true,\n  ENABLE_STRICT_EQUAL_SELECTORS: false\n};\nmodule.exports = RelayFeatureFlags;","'use strict';\n\nvar profileHandlersByName = {};\nvar defaultProfiler = {\n  stop: function stop() {}\n};\nvar RelayProfiler = {\n  profile: function profile(name, state) {\n    var handlers = profileHandlersByName[name];\n    if (handlers && handlers.length > 0) {\n      var stopHandlers = [];\n      for (var ii = handlers.length - 1; ii >= 0; ii--) {\n        var stopHandler = handlers[ii](name, state);\n        stopHandlers.unshift(stopHandler);\n      }\n      return {\n        stop: function stop(error) {\n          stopHandlers.forEach(function (stopHandler) {\n            return stopHandler(error);\n          });\n        }\n      };\n    }\n    return defaultProfiler;\n  },\n  attachProfileHandler: function attachProfileHandler(name, handler) {\n    if (!profileHandlersByName.hasOwnProperty(name)) {\n      profileHandlersByName[name] = [];\n    }\n    profileHandlersByName[name].push(handler);\n  },\n  detachProfileHandler: function detachProfileHandler(name, handler) {\n    if (profileHandlersByName.hasOwnProperty(name)) {\n      removeFromArray(profileHandlersByName[name], handler);\n    }\n  }\n};\nfunction removeFromArray(array, element) {\n  var index = array.indexOf(element);\n  if (index !== -1) {\n    array.splice(index, 1);\n  }\n}\nmodule.exports = RelayProfiler;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar RelayObservable = require('../network/RelayObservable');\nvar invariant = require('invariant');\nvar RelayReplaySubject = /*#__PURE__*/function () {\n  function RelayReplaySubject() {\n    var _this = this;\n    (0, _defineProperty2[\"default\"])(this, \"_complete\", false);\n    (0, _defineProperty2[\"default\"])(this, \"_events\", []);\n    (0, _defineProperty2[\"default\"])(this, \"_sinks\", new Set());\n    (0, _defineProperty2[\"default\"])(this, \"_subscription\", []);\n    this._observable = RelayObservable.create(function (sink) {\n      _this._sinks.add(sink);\n      var events = _this._events;\n      for (var i = 0; i < events.length; i++) {\n        if (sink.closed) {\n          break;\n        }\n        var event = events[i];\n        switch (event.kind) {\n          case 'complete':\n            sink.complete();\n            break;\n          case 'error':\n            sink.error(event.error);\n            break;\n          case 'next':\n            sink.next(event.data);\n            break;\n          default:\n            event.kind;\n            !false ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'RelayReplaySubject: Unknown event kind `%s`.', event.kind) : invariant(false) : void 0;\n        }\n      }\n      return function () {\n        _this._sinks[\"delete\"](sink);\n      };\n    });\n  }\n  var _proto = RelayReplaySubject.prototype;\n  _proto.complete = function complete() {\n    if (this._complete === true) {\n      return;\n    }\n    this._complete = true;\n    this._events.push({\n      kind: 'complete'\n    });\n    this._sinks.forEach(function (sink) {\n      return sink.complete();\n    });\n  };\n  _proto.error = function error(_error) {\n    if (this._complete === true) {\n      return;\n    }\n    this._complete = true;\n    this._events.push({\n      kind: 'error',\n      error: _error\n    });\n    this._sinks.forEach(function (sink) {\n      return sink.error(_error);\n    });\n  };\n  _proto.next = function next(data) {\n    if (this._complete === true) {\n      return;\n    }\n    this._events.push({\n      kind: 'next',\n      data: data\n    });\n    this._sinks.forEach(function (sink) {\n      return sink.next(data);\n    });\n  };\n  _proto.subscribe = function subscribe(observer) {\n    var subscription = this._observable.subscribe(observer);\n    this._subscription.push(subscription);\n    return subscription;\n  };\n  _proto.unsubscribe = function unsubscribe() {\n    var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(this._subscription),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var subscription = _step.value;\n        subscription.unsubscribe();\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n    this._subscription = [];\n  };\n  _proto.getObserverCount = function getObserverCount() {\n    return this._sinks.size;\n  };\n  return RelayReplaySubject;\n}();\nmodule.exports = RelayReplaySubject;","'use strict';\n\nvar internTable = new Map();\nvar nextIndex = 1;\nvar digits = initDigitTable();\nvar INTERN_PREFIX = '\\t';\nvar ESCAPE_PREFIX = '\\v';\nfunction initDigitTable() {\n  var digits = new Set();\n  for (var i = 0; i < 10; ++i) {\n    digits.add(i.toString());\n  }\n  return digits;\n}\nfunction escape(str) {\n  if (str[0] === INTERN_PREFIX && digits.has(str[1]) || str[0] === ESCAPE_PREFIX) {\n    return ESCAPE_PREFIX + str;\n  }\n  return str;\n}\nfunction intern(str, limit) {\n  if (limit == null || str.length < limit) {\n    return escape(str);\n  }\n  var internedString = internTable.get(str);\n  if (internedString != null) {\n    return internedString;\n  }\n  internedString = INTERN_PREFIX + nextIndex++;\n  internTable.set(str, internedString);\n  return internedString;\n}\nmodule.exports = {\n  intern: intern\n};","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar _require = require('../store/RelayStoreUtils'),\n  getModuleComponentKey = _require.getModuleComponentKey,\n  getModuleOperationKey = _require.getModuleOperationKey;\nfunction createPayloadFor3DField(name, operation, component, response) {\n  var data = (0, _objectSpread2[\"default\"])({}, response);\n  data[getModuleComponentKey(name)] = component;\n  data[getModuleOperationKey(name)] = operation;\n  return data;\n}\nmodule.exports = createPayloadFor3DField;","'use strict';\n\nfunction deepFreeze(object) {\n  if (!shouldBeFrozen(object)) {\n    return object;\n  }\n  Object.freeze(object);\n  Object.getOwnPropertyNames(object).forEach(function (name) {\n    var property = object[name];\n    if (property && typeof property === 'object' && !Object.isFrozen(property)) {\n      deepFreeze(property);\n    }\n  });\n  return object;\n}\nfunction shouldBeFrozen(value) {\n  return value != null && (Array.isArray(value) || typeof value === 'object' && value.constructor === Object);\n}\nmodule.exports = deepFreeze;","'use strict';\n\nvar id = 100000;\nfunction generateID() {\n  return id++;\n}\nmodule.exports = generateID;","'use strict';\n\nvar _require = require('../store/RelayModernSelector'),\n  getDataIDsFromFragment = _require.getDataIDsFromFragment,\n  getSelector = _require.getSelector,\n  getVariablesFromFragment = _require.getVariablesFromFragment;\nvar isEmptyObject = require('./isEmptyObject');\nvar RelayFeatureFlags = require('./RelayFeatureFlags');\nvar stableCopy = require('./stableCopy');\nvar _require2 = require('./StringInterner'),\n  intern = _require2.intern;\nfunction getFragmentIdentifier(fragmentNode, fragmentRef) {\n  var selector = getSelector(fragmentNode, fragmentRef);\n  var fragmentOwnerIdentifier = selector == null ? 'null' : selector.kind === 'SingularReaderSelector' ? selector.owner.identifier : '[' + selector.selectors.map(function (sel) {\n    return sel.owner.identifier;\n  }).join(',') + ']';\n  var fragmentVariables = getVariablesFromFragment(fragmentNode, fragmentRef);\n  var dataIDs = getDataIDsFromFragment(fragmentNode, fragmentRef);\n  if (RelayFeatureFlags.ENABLE_GETFRAGMENTIDENTIFIER_OPTIMIZATION) {\n    var ids = typeof dataIDs === 'undefined' ? 'missing' : dataIDs == null ? 'null' : Array.isArray(dataIDs) ? '[' + dataIDs.join(',') + ']' : dataIDs;\n    ids = RelayFeatureFlags.STRING_INTERN_LEVEL <= 1 ? ids : intern(ids, RelayFeatureFlags.MAX_DATA_ID_LENGTH);\n    return fragmentOwnerIdentifier + '/' + fragmentNode.name + '/' + (fragmentVariables == null || isEmptyObject(fragmentVariables) ? '{}' : JSON.stringify(stableCopy(fragmentVariables))) + '/' + ids;\n  } else {\n    var _JSON$stringify;\n    var _ids = (_JSON$stringify = JSON.stringify(dataIDs)) !== null && _JSON$stringify !== void 0 ? _JSON$stringify : 'missing';\n    _ids = RelayFeatureFlags.STRING_INTERN_LEVEL <= 1 ? _ids : intern(_ids, RelayFeatureFlags.MAX_DATA_ID_LENGTH);\n    return fragmentOwnerIdentifier + '/' + fragmentNode.name + '/' + JSON.stringify(stableCopy(fragmentVariables)) + '/' + _ids;\n  }\n}\nmodule.exports = getFragmentIdentifier;","'use strict';\n\nvar _require = require('./RelayConcreteNode'),\n  REQUEST = _require.REQUEST,\n  SPLIT_OPERATION = _require.SPLIT_OPERATION;\nfunction getOperation(node) {\n  switch (node.kind) {\n    case REQUEST:\n      return node.operation;\n    case SPLIT_OPERATION:\n    default:\n      return node;\n  }\n}\nmodule.exports = getOperation;","'use strict';\n\nvar getRefetchMetadata = require('./getRefetchMetadata');\nvar invariant = require('invariant');\nfunction getPaginationMetadata(fragmentNode, componentDisplayName) {\n  var _fragmentNode$metadat, _fragmentNode$metadat2;\n  var _getRefetchMetadata = getRefetchMetadata(fragmentNode, componentDisplayName),\n    paginationRequest = _getRefetchMetadata.refetchableRequest,\n    refetchMetadata = _getRefetchMetadata.refetchMetadata;\n  var paginationMetadata = refetchMetadata.connection;\n  !(paginationMetadata != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getPaginationMetadata(): Expected fragment `%s` to include a ' + 'connection when using `%s`. Did you forget to add a @connection ' + 'directive to the connection field in the fragment?', componentDisplayName, fragmentNode.name) : invariant(false) : void 0;\n  var connectionPathInFragmentData = paginationMetadata.path;\n  var connectionMetadata = ((_fragmentNode$metadat = (_fragmentNode$metadat2 = fragmentNode.metadata) === null || _fragmentNode$metadat2 === void 0 ? void 0 : _fragmentNode$metadat2.connection) !== null && _fragmentNode$metadat !== void 0 ? _fragmentNode$metadat : [])[0];\n  !(connectionMetadata != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getPaginationMetadata(): Expected fragment `%s` to include a ' + 'connection when using `%s`. Did you forget to add a @connection ' + 'directive to the connection field in the fragment?', componentDisplayName, fragmentNode.name) : invariant(false) : void 0;\n  var identifierInfo = refetchMetadata.identifierInfo;\n  !((identifierInfo === null || identifierInfo === void 0 ? void 0 : identifierInfo.identifierField) == null || typeof identifierInfo.identifierField === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getRefetchMetadata(): Expected `identifierField` to be a string.') : invariant(false) : void 0;\n  return {\n    connectionPathInFragmentData: connectionPathInFragmentData,\n    identifierField: identifierInfo === null || identifierInfo === void 0 ? void 0 : identifierInfo.identifierField,\n    paginationRequest: paginationRequest,\n    paginationMetadata: paginationMetadata,\n    stream: connectionMetadata.stream === true\n  };\n}\nmodule.exports = getPaginationMetadata;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _objectSpread4 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread2\"));\nvar invariant = require('invariant');\nvar warning = require(\"fbjs/lib/warning\");\nfunction getPaginationVariables(direction, count, cursor, baseVariables, extraVariables, paginationMetadata) {\n  var _objectSpread3;\n  var backwardMetadata = paginationMetadata.backward,\n    forwardMetadata = paginationMetadata.forward;\n  if (direction === 'backward') {\n    var _objectSpread2;\n    !(backwardMetadata != null && backwardMetadata.count != null && backwardMetadata.cursor != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: Expected backward pagination metadata to be available. ' + \"If you're seeing this, this is likely a bug in Relay.\") : invariant(false) : void 0;\n    process.env.NODE_ENV !== \"production\" ? warning(!extraVariables.hasOwnProperty(backwardMetadata.cursor), 'Relay: `UNSTABLE_extraVariables` provided by caller should not ' + 'contain cursor variable `%s`. This variable is automatically ' + 'determined by Relay.', backwardMetadata.cursor) : void 0;\n    process.env.NODE_ENV !== \"production\" ? warning(!extraVariables.hasOwnProperty(backwardMetadata.count), 'Relay: `UNSTABLE_extraVariables` provided by caller should not ' + 'contain count variable `%s`. This variable is automatically ' + 'determined by Relay.', backwardMetadata.count) : void 0;\n    var _paginationVariables = (0, _objectSpread4[\"default\"])((0, _objectSpread4[\"default\"])((0, _objectSpread4[\"default\"])({}, baseVariables), extraVariables), {}, (_objectSpread2 = {}, (0, _defineProperty2[\"default\"])(_objectSpread2, backwardMetadata.cursor, cursor), (0, _defineProperty2[\"default\"])(_objectSpread2, backwardMetadata.count, count), _objectSpread2));\n    if (forwardMetadata && forwardMetadata.cursor) {\n      _paginationVariables[forwardMetadata.cursor] = null;\n    }\n    if (forwardMetadata && forwardMetadata.count) {\n      _paginationVariables[forwardMetadata.count] = null;\n    }\n    return _paginationVariables;\n  }\n  !(forwardMetadata != null && forwardMetadata.count != null && forwardMetadata.cursor != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: Expected forward pagination metadata to be available. ' + \"If you're seeing this, this is likely a bug in Relay.\") : invariant(false) : void 0;\n  process.env.NODE_ENV !== \"production\" ? warning(!extraVariables.hasOwnProperty(forwardMetadata.cursor), 'Relay: `UNSTABLE_extraVariables` provided by caller should not ' + 'contain cursor variable `%s`. This variable is automatically ' + 'determined by Relay.', forwardMetadata.cursor) : void 0;\n  process.env.NODE_ENV !== \"production\" ? warning(!extraVariables.hasOwnProperty(forwardMetadata.count), 'Relay: `UNSTABLE_extraVariables` provided by caller should not ' + 'contain count variable `%s`. This variable is automatically ' + 'determined by Relay.', forwardMetadata.count) : void 0;\n  var paginationVariables = (0, _objectSpread4[\"default\"])((0, _objectSpread4[\"default\"])((0, _objectSpread4[\"default\"])({}, baseVariables), extraVariables), {}, (_objectSpread3 = {}, (0, _defineProperty2[\"default\"])(_objectSpread3, forwardMetadata.cursor, cursor), (0, _defineProperty2[\"default\"])(_objectSpread3, forwardMetadata.count, count), _objectSpread3));\n  if (backwardMetadata && backwardMetadata.cursor) {\n    paginationVariables[backwardMetadata.cursor] = null;\n  }\n  if (backwardMetadata && backwardMetadata.count) {\n    paginationVariables[backwardMetadata.count] = null;\n  }\n  return paginationVariables;\n}\nmodule.exports = getPaginationVariables;","'use strict';\n\nvar _require = require('../query/fetchQueryInternal'),\n  getPromiseForActiveRequest = _require.getPromiseForActiveRequest;\nfunction getPendingOperationsForFragment(environment, fragmentNode, fragmentOwner) {\n  var _pendingOperations$ma, _pendingOperations;\n  var pendingOperations = [];\n  var promise = getPromiseForActiveRequest(environment, fragmentOwner);\n  if (promise != null) {\n    pendingOperations = [fragmentOwner];\n  } else {\n    var _result$pendingOperat, _result$promise;\n    var result = environment.getOperationTracker().getPendingOperationsAffectingOwner(fragmentOwner);\n    pendingOperations = (_result$pendingOperat = result === null || result === void 0 ? void 0 : result.pendingOperations) !== null && _result$pendingOperat !== void 0 ? _result$pendingOperat : [];\n    promise = (_result$promise = result === null || result === void 0 ? void 0 : result.promise) !== null && _result$promise !== void 0 ? _result$promise : null;\n  }\n  if (!promise) {\n    return null;\n  }\n  var pendingOperationName = (_pendingOperations$ma = (_pendingOperations = pendingOperations) === null || _pendingOperations === void 0 ? void 0 : _pendingOperations.map(function (op) {\n    return op.node.params.name;\n  }).join(',')) !== null && _pendingOperations$ma !== void 0 ? _pendingOperations$ma : null;\n  if (pendingOperationName == null || pendingOperationName.length === 0) {\n    pendingOperationName = 'Unknown pending operation';\n  }\n  var fragmentName = fragmentNode.name;\n  var promiseDisplayName = pendingOperationName === fragmentName ? \"Relay(\".concat(pendingOperationName, \")\") : \"Relay(\".concat(pendingOperationName, \":\").concat(fragmentName, \")\");\n  promise.displayName = promiseDisplayName;\n  environment.__log({\n    name: 'pendingoperation.found',\n    fragment: fragmentNode,\n    fragmentOwner: fragmentOwner,\n    pendingOperations: pendingOperations\n  });\n  return {\n    promise: promise,\n    pendingOperations: pendingOperations\n  };\n}\nmodule.exports = getPendingOperationsForFragment;","'use strict';\n\nvar invariant = require('invariant');\nfunction getRefetchMetadata(fragmentNode, componentDisplayName) {\n  var _fragmentNode$metadat, _fragmentNode$metadat2;\n  !(((_fragmentNode$metadat = fragmentNode.metadata) === null || _fragmentNode$metadat === void 0 ? void 0 : _fragmentNode$metadat.plural) !== true) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getRefetchMetadata(): Expected fragment `%s` not to be plural when using ' + '`%s`. Remove `@relay(plural: true)` from fragment `%s` ' + 'in order to use it with `%s`.', fragmentNode.name, componentDisplayName, fragmentNode.name, componentDisplayName) : invariant(false) : void 0;\n  var refetchMetadata = (_fragmentNode$metadat2 = fragmentNode.metadata) === null || _fragmentNode$metadat2 === void 0 ? void 0 : _fragmentNode$metadat2.refetch;\n  !(refetchMetadata != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getRefetchMetadata(): Expected fragment `%s` to be refetchable when using `%s`. ' + 'Did you forget to add a @refetchable directive to the fragment?', componentDisplayName, fragmentNode.name) : invariant(false) : void 0;\n  var refetchableRequest = refetchMetadata.operation[\"default\"] ? refetchMetadata.operation[\"default\"] : refetchMetadata.operation;\n  var fragmentRefPathInResponse = refetchMetadata.fragmentPathInResult;\n  !(typeof refetchableRequest !== 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getRefetchMetadata(): Expected refetch query to be an ' + \"operation and not a string when using `%s`. If you're seeing this, \" + 'this is likely a bug in Relay.', componentDisplayName) : invariant(false) : void 0;\n  var identifierInfo = refetchMetadata.identifierInfo;\n  if (identifierInfo != null) {\n    !(identifierInfo.identifierField == null || typeof identifierInfo.identifierField === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getRefetchMetadata(): Expected `identifierField` to be a string.') : invariant(false) : void 0;\n    !(identifierInfo.identifierQueryVariableName == null || typeof identifierInfo.identifierQueryVariableName === 'string') ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: getRefetchMetadata(): Expected `identifierQueryVariableName` to be a string.') : invariant(false) : void 0;\n  }\n  return {\n    fragmentRefPathInResponse: fragmentRefPathInResponse,\n    identifierInfo: identifierInfo,\n    refetchableRequest: refetchableRequest,\n    refetchMetadata: refetchMetadata\n  };\n}\nmodule.exports = getRefetchMetadata;","'use strict';\n\nvar _require = require('./RelayDefaultHandleKey'),\n  DEFAULT_HANDLE_KEY = _require.DEFAULT_HANDLE_KEY;\nvar invariant = require('invariant');\nfunction getRelayHandleKey(handleName, key, fieldName) {\n  if (key && key !== DEFAULT_HANDLE_KEY) {\n    return \"__\".concat(key, \"_\").concat(handleName);\n  }\n  !(fieldName != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'getRelayHandleKey: Expected either `fieldName` or `key` in `handle` to be provided') : invariant(false) : void 0;\n  return \"__\".concat(fieldName, \"_\").concat(handleName);\n}\nmodule.exports = getRelayHandleKey;","'use strict';\n\nvar stableCopy = require('./stableCopy');\nvar invariant = require('invariant');\nfunction getRequestIdentifier(parameters, variables) {\n  var requestID = parameters.cacheID != null ? parameters.cacheID : parameters.id;\n  !(requestID != null) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'getRequestIdentifier: Expected request `%s` to have either a ' + 'valid `id` or `cacheID` property', parameters.name) : invariant(false) : void 0;\n  return requestID + JSON.stringify(stableCopy(variables));\n}\nmodule.exports = getRequestIdentifier;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar invariant = require('invariant');\nfunction getValueAtPath(data, path) {\n  var result = data;\n  var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(path),\n    _step;\n  try {\n    for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var key = _step.value;\n      if (result == null) {\n        return null;\n      }\n      if (typeof key === 'number') {\n        !Array.isArray(result) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: Expected an array when extracting value at path. ' + \"If you're seeing this, this is likely a bug in Relay.\") : invariant(false) : void 0;\n        result = result[key];\n      } else {\n        !(typeof result === 'object' && !Array.isArray(result)) ? process.env.NODE_ENV !== \"production\" ? invariant(false, 'Relay: Expected an object when extracting value at path. ' + \"If you're seeing this, this is likely a bug in Relay.\") : invariant(false) : void 0;\n        result = result[key];\n      }\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n  return result;\n}\nmodule.exports = getValueAtPath;","'use strict';\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\")[\"default\"];\nvar _createForOfIteratorHelper2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createForOfIteratorHelper\"));\nvar _RelayErrorTrie = require(\"../store/RelayErrorTrie\");\nvar _RelayFeatureFlags = _interopRequireDefault(require(\"./RelayFeatureFlags\"));\nfunction handlePotentialSnapshotErrors(environment, missingRequiredFields, relayResolverErrors, errorResponseFields) {\n  var _iterator = (0, _createForOfIteratorHelper2[\"default\"])(relayResolverErrors),\n    _step;\n  try {\n    for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var resolverError = _step.value;\n      environment.relayFieldLogger({\n        kind: 'relay_resolver.error',\n        owner: resolverError.field.owner,\n        fieldPath: resolverError.field.path,\n        error: resolverError.error\n      });\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n  if (_RelayFeatureFlags[\"default\"].ENABLE_FIELD_ERROR_HANDLING && errorResponseFields != null) {\n    if (errorResponseFields != null) {\n      var _iterator2 = (0, _createForOfIteratorHelper2[\"default\"])(errorResponseFields),\n        _step2;\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var fieldError = _step2.value;\n          var path = fieldError.path,\n            owner = fieldError.owner,\n            error = fieldError.error;\n          environment.relayFieldLogger({\n            kind: 'relay_field_payload.error',\n            owner: owner,\n            fieldPath: path,\n            error: error\n          });\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n    }\n    if (_RelayFeatureFlags[\"default\"].ENABLE_FIELD_ERROR_HANDLING_THROW_BY_DEFAULT) {\n      throw new _RelayErrorTrie.RelayFieldError(\"Relay: Unexpected response payload - this object includes an errors property in which you can access the underlying errors\", errorResponseFields.map(function (_ref) {\n        var path = _ref.path,\n          owner = _ref.owner,\n          error = _ref.error;\n        return error;\n      }));\n    }\n  }\n  if (missingRequiredFields != null) {\n    switch (missingRequiredFields.action) {\n      case 'THROW':\n        {\n          var _missingRequiredField = missingRequiredFields.field,\n            _path = _missingRequiredField.path,\n            _owner = _missingRequiredField.owner;\n          environment.relayFieldLogger({\n            kind: 'missing_field.throw',\n            owner: _owner,\n            fieldPath: _path\n          });\n          throw new Error(\"Relay: Missing @required value at path '\".concat(_path, \"' in '\").concat(_owner, \"'.\"));\n        }\n      case 'LOG':\n        missingRequiredFields.fields.forEach(function (_ref2) {\n          var path = _ref2.path,\n            owner = _ref2.owner;\n          environment.relayFieldLogger({\n            kind: 'missing_field.log',\n            owner: owner,\n            fieldPath: path\n          });\n        });\n        break;\n      default:\n        {\n          missingRequiredFields.action;\n        }\n    }\n  }\n}\nmodule.exports = handlePotentialSnapshotErrors;","'use strict';\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nfunction isEmptyObject(obj) {\n  for (var _key in obj) {\n    if (hasOwnProperty.call(obj, _key)) {\n      return false;\n    }\n  }\n  return true;\n}\nmodule.exports = isEmptyObject;","'use strict';\n\nfunction isPromise(p) {\n  return !!p && typeof p.then === 'function';\n}\nmodule.exports = isPromise;","'use strict';\n\nfunction isScalarAndEqual(valueA, valueB) {\n  return valueA === valueB && (valueA === null || typeof valueA !== 'object');\n}\nmodule.exports = isScalarAndEqual;","'use strict';\n\nfunction recycleNodesInto(prevData, nextData) {\n  return recycleNodesIntoImpl(prevData, nextData, true);\n}\nfunction recycleNodesIntoImpl(prevData, nextData, canMutate) {\n  if (prevData === nextData || typeof prevData !== 'object' || !prevData || prevData.constructor !== Object && !Array.isArray(prevData) || typeof nextData !== 'object' || !nextData || nextData.constructor !== Object && !Array.isArray(nextData)) {\n    return nextData;\n  }\n  var canRecycle = false;\n  var prevArray = Array.isArray(prevData) ? prevData : null;\n  var nextArray = Array.isArray(nextData) ? nextData : null;\n  if (prevArray && nextArray) {\n    var canMutateNext = canMutate && !Object.isFrozen(nextArray);\n    canRecycle = nextArray.reduce(function (wasEqual, nextItem, ii) {\n      var prevValue = prevArray[ii];\n      var nextValue = recycleNodesIntoImpl(prevValue, nextItem, canMutateNext);\n      if (nextValue !== nextArray[ii] && canMutateNext) {\n        nextArray[ii] = nextValue;\n      }\n      return wasEqual && nextValue === prevArray[ii];\n    }, true) && prevArray.length === nextArray.length;\n  } else if (!prevArray && !nextArray) {\n    var prevObject = prevData;\n    var nextObject = nextData;\n    var prevKeys = Object.keys(prevObject);\n    var nextKeys = Object.keys(nextObject);\n    var _canMutateNext = canMutate && !Object.isFrozen(nextObject);\n    canRecycle = nextKeys.reduce(function (wasEqual, key) {\n      var prevValue = prevObject[key];\n      var nextValue = recycleNodesIntoImpl(prevValue, nextObject[key], _canMutateNext);\n      if (nextValue !== nextObject[key] && _canMutateNext) {\n        nextObject[key] = nextValue;\n      }\n      return wasEqual && nextValue === prevObject[key];\n    }, true) && prevKeys.length === nextKeys.length;\n  }\n  return canRecycle ? prevData : nextData;\n}\nmodule.exports = recycleNodesInto;","'use strict';\n\nfunction registerEnvironmentWithDevTools(environment) {\n  var _global = typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : undefined;\n  var devToolsHook = _global && _global.__RELAY_DEVTOOLS_HOOK__;\n  if (devToolsHook) {\n    devToolsHook.registerEnvironment(environment);\n  }\n}\nmodule.exports = registerEnvironmentWithDevTools;","'use strict';\n\nvar resolvedPromise = Promise.resolve();\nfunction resolveImmediate(callback) {\n  resolvedPromise.then(callback)[\"catch\"](throwNext);\n}\nfunction throwNext(error) {\n  setTimeout(function () {\n    throw error;\n  }, 0);\n}\nmodule.exports = resolveImmediate;","'use strict';\n\nmodule.exports = function shallowFreeze(value) {\n  if (typeof value === 'object' && value != null && (Array.isArray(value) || value.constructor === Object)) {\n    Object.freeze(value);\n  }\n};","'use strict';\n\nfunction stableCopy(value) {\n  if (!value || typeof value !== 'object') {\n    return value;\n  }\n  if (Array.isArray(value)) {\n    return value.map(stableCopy);\n  }\n  var keys = Object.keys(value).sort();\n  var stable = {};\n  for (var i = 0; i < keys.length; i++) {\n    stable[keys[i]] = stableCopy(value[keys[i]]);\n  }\n  return stable;\n}\nmodule.exports = stableCopy;","'use strict';\n\nvar _window, _window$performance;\nvar isPerformanceNowAvailable = typeof window !== 'undefined' && typeof ((_window = window) === null || _window === void 0 ? void 0 : (_window$performance = _window.performance) === null || _window$performance === void 0 ? void 0 : _window$performance.now) === 'function';\nfunction currentTimestamp() {\n  if (isPerformanceNowAvailable) {\n    return window.performance.now();\n  }\n  return Date.now();\n}\nfunction withDuration(cb) {\n  var startTime = currentTimestamp();\n  var result = cb();\n  return [currentTimestamp() - startTime, result];\n}\nmodule.exports = withDuration;","'use strict';\n\nvar areEqual = require(\"fbjs/lib/areEqual\");\nvar warning = require(\"fbjs/lib/warning\");\nvar WEAKMAP_SUPPORTED = typeof WeakMap === 'function';\nvar debugCache = WEAKMAP_SUPPORTED ? new WeakMap() : new Map();\nfunction withProvidedVariables(userSuppliedVariables, providedVariables) {\n  if (providedVariables != null) {\n    var operationVariables = {};\n    Object.assign(operationVariables, userSuppliedVariables);\n    Object.keys(providedVariables).forEach(function (varName) {\n      var providerFunction = providedVariables[varName].get;\n      var providerResult = providerFunction();\n      if (!debugCache.has(providerFunction)) {\n        debugCache.set(providerFunction, providerResult);\n        operationVariables[varName] = providerResult;\n      } else {\n        var cachedResult = debugCache.get(providerFunction);\n        if (process.env.NODE_ENV !== \"production\") {\n          process.env.NODE_ENV !== \"production\" ? warning(areEqual(providerResult, cachedResult), 'Relay: Expected function `%s` for provider `%s` to be a pure function, ' + 'but got conflicting return values `%s` and `%s`', providerFunction.name, varName, providerResult, cachedResult) : void 0;\n        }\n        operationVariables[varName] = cachedResult;\n      }\n    });\n    return operationVariables;\n  } else {\n    return userSuppliedVariables;\n  }\n}\nwithProvidedVariables.tests_only_resetDebugCache = process.env.NODE_ENV !== \"production\" ? function () {\n  debugCache = WEAKMAP_SUPPORTED ? new WeakMap() : new Map();\n} : undefined;\nmodule.exports = withProvidedVariables;","import { bench, group, run, summary } from \"mitata\";\nimport { createCachebay as createCachebayClient } from \"../../cachebay/src/core/client\";\nimport { InMemoryCache } from \"@apollo/client/cache\";\nimport { relayStylePagination } from \"@apollo/client/utilities\";\nimport { Environment, Network, RecordSource, Store, createOperationDescriptor } from \"relay-runtime\";\nimport type { ConcreteRequest } from \"relay-runtime\";\nimport RelayWriteQuery from \"../src/__generated__/relayWriteQueryDefRelayWriteQuery.graphql\";\nimport { makeResponse, buildPages, CACHEBAY_QUERY, APOLLO_QUERY } from \"./utils\";\n\nlet __sink = 0;\n\nconst sink = (o: any) => {\n  __sink ^= (o?.users?.edges?.length ?? 0) | 0;\n};\n\nconst createCachebay = () => {\n  return createCachebayClient({\n    transport: {\n      http: async () => ({ data: {} }),\n    },\n  });\n}\n\nconst createApolloCache = (resultCaching = false) => {\n  return new InMemoryCache({\n    resultCaching,\n\n    typePolicies: {\n      Query: {\n        fields: {\n          users: relayStylePagination(),\n        },\n      },\n\n      User: {\n        keyFields: [\"id\"],\n\n        fields: {\n          posts: relayStylePagination(),\n        },\n      },\n\n      Post: {\n        keyFields: [\"id\"],\n\n        fields: {\n          comments: relayStylePagination(),\n        },\n      },\n\n      Comment: {\n        keyFields: [\"id\"],\n      },\n    },\n  });\n}\n\nconst createRelayEnvironment = () => {\n  return new Environment({ network: Network.create(() => Promise.resolve({ data: {} })), store: new Store(new RecordSource()) });\n}\n\nsummary(() => {\n  const TOTAL_USERS = 500;\n  const USERS_PAGE_SIZE = 10;\n  const pages = buildPages(makeResponse({ users: TOTAL_USERS, posts: 5, comments: 3 }), USERS_PAGE_SIZE);\n\n  const getLabel = () => {\n    return `${TOTAL_USERS} users (${pages.length} pages of ${USERS_PAGE_SIZE})`;\n  };\n\n  group(\"materializeDocument\", () => {\n    bench(`cachebay.materializeDocument:canonical(${getLabel()})`, function* () {\n      yield {\n        [0]() {\n          const cachebay = createCachebay();\n\n          for (let i = 0; i < pages.length; i++) {\n            cachebay.writeQuery({ query: CACHEBAY_QUERY, variables: pages[i].variables, data: pages[i].data });\n\n            cachebay.__internals.documents.materializeDocument({ document: `query JIT { LFG }`, variables: {}, canonical: true, force: true });\n          }\n\n          return cachebay;\n        },\n        bench(cachebay) {\n          const result = cachebay.__internals.documents.materializeDocument({ document: CACHEBAY_QUERY, variables: { first: USERS_PAGE_SIZE, after: null }, canonical: true, fingerprint: false, force: false });\n          //sink(result.data);\n        },\n      };\n    });\n\n    bench(`cachebay.materializeDocument:canonical:fingerprint(${getLabel()})`, function* () {\n      yield {\n        [0]() {\n          const cachebay = createCachebay();\n\n          for (let i = 0; i < pages.length; i++) {\n            cachebay.writeQuery({ query: CACHEBAY_QUERY, variables: pages[i].variables, data: pages[i].data });\n\n            cachebay.__internals.documents.materializeDocument({ document: `query JIT { LFG }`, variables: {}, canonical: true, force: true });\n          }\n\n          return cachebay;\n        },\n        bench(cachebay) {\n          const result = cachebay.__internals.documents.materializeDocument({ document: CACHEBAY_QUERY, variables: { first: USERS_PAGE_SIZE, after: null }, canonical: true, fingerprint: true, force: false });\n          //sink(result.data);\n        },\n      };\n    });\n\n    bench(`apollo.readQuery(${getLabel()})`, function* () {\n      yield {\n        [0]() {\n          const apollo = createApolloCache(false);\n\n          for (let i = 0; i < pages.length; i++) {\n            apollo.writeQuery({ query: APOLLO_QUERY, variables: pages[i].variables, data: pages[i].data });\n          }\n\n          return apollo;\n        },\n        bench(apollo) {\n          const result = apollo.readQuery({ query: APOLLO_QUERY, variables: { first: USERS_PAGE_SIZE, after: null } });\n          sink(result);\n        },\n      };\n    });\n\n    bench(`relay.lookup(${getLabel()})`, function* () {\n      yield {\n        [0]() {\n          const relay = createRelayEnvironment();\n\n          for (let i = 0; i < pages.length; i++) {\n            relay.commitPayload(createOperationDescriptor(RelayWriteQuery as ConcreteRequest, pages[i].variables), pages[i].data);\n          }\n\n          return relay;\n        },\n        bench(relay) {\n          const result = relay.lookup(createOperationDescriptor(RelayWriteQuery as ConcreteRequest, { first: USERS_PAGE_SIZE, after: null }).fragment);\n          sink(result.data);\n        },\n      };\n    });\n  });\n});\n\n(globalThis as any).__bench_sink = __sink;\n\nawait run();\n","import { gql } from \"graphql-tag\";\n\n// For fair perf (strip dev-only code in your lib if you gate by NODE_ENV)\n// process.env.NODE_ENV = \"production\"; // Set via environment variable instead\n\n// -----------------------------------------------------------------------------\n// Deterministic fixtures\n// -----------------------------------------------------------------------------\nfunction likeCount(i: number, j: number) {\n  return ((i * 131 + j * 977) % 100) | 0;\n}\n\nexport type ResponseShape = {\n  __typename: \"Query\";\n  users: {\n    __typename: \"UserConnection\";\n    edges: Array<{\n      __typename: \"UserEdge\";\n      cursor: string;\n      node: {\n        __typename: \"User\";\n        id: string;\n        name: string;\n        avatar: string;\n        posts: {\n          __typename: \"PostConnection\";\n          edges: Array<{\n            __typename: \"PostEdge\";\n            cursor: string;\n            node: {\n              __typename: \"Post\";\n              id: string;\n              title: string;\n              likeCount: number;\n              comments: {\n                __typename: \"CommentConnection\";\n                edges: Array<{\n                  __typename: \"CommentEdge\";\n                  cursor: string;\n                  node: {\n                    __typename: \"Comment\";\n                    id: string;\n                    text: string;\n                    author: {\n                      __typename: \"User\";\n                      id: string;\n                      name: string;\n                    };\n                  };\n                }>;\n                pageInfo: { __typename: \"PageInfo\"; hasNextPage: boolean };\n              };\n            };\n          }>;\n          pageInfo: { __typename: \"PageInfo\"; hasNextPage: boolean };\n        };\n      };\n    }>;\n    pageInfo: {\n      __typename: \"PageInfo\";\n      endCursor: string | null;\n      hasNextPage: boolean;\n    };\n  };\n};\n\nexport function makeResponse({\n  users = 10,\n  posts = 5,\n  comments = 3,\n}: {\n  users: number;\n  posts: number;\n  comments: number;\n}): ResponseShape {\n  return {\n    __typename: \"Query\",\n    users: {\n      __typename: \"UserConnection\",\n      edges: Array.from({ length: users }, (_, i) => ({\n        __typename: \"UserEdge\",\n        cursor: \"u\" + (i + 1),\n        node: {\n          __typename: \"User\",\n          id: \"u\" + (i + 1),\n          name: \"User \" + (i + 1),\n          avatar: `https://i.pravatar.cc/150?u=${i + 1}`,\n          posts: {\n            __typename: \"PostConnection\",\n            edges: Array.from({ length: posts }, (_, j) => ({\n              __typename: \"PostEdge\",\n              cursor: \"p\" + (j + 1),\n              node: {\n                __typename: \"Post\",\n                id: `p-${i + 1}-${j + 1}`,\n                title: `Post ${j + 1} by User ${i + 1}`,\n                likeCount: likeCount(i + 1, j + 1),\n                comments: {\n                  __typename: \"CommentConnection\",\n                  edges: Array.from({ length: comments }, (_, k) => ({\n                    __typename: \"CommentEdge\",\n                    cursor: \"c\" + (k + 1),\n                    node: {\n                      __typename: \"Comment\",\n                      id: `c-${i + 1}-${j + 1}-${k + 1}`,\n                      text: `Comment ${k + 1} on Post ${j + 1}`,\n                      author: {\n                        __typename: \"User\",\n                        id: \"u\" + ((k % users) + 1),\n                        name: \"User \" + ((k % users) + 1),\n                      },\n                    },\n                  })),\n                  pageInfo: {\n                    __typename: \"PageInfo\",\n                    endCursor: comments > 0 ? \"c\" + comments : null,\n                    hasNextPage: false\n                  },\n                },\n              },\n            })),\n            pageInfo: {\n              __typename: \"PageInfo\",\n              endCursor: posts > 0 ? \"p\" + posts : null,\n              hasNextPage: false\n            },\n          },\n        },\n      })),\n      pageInfo: {\n        __typename: \"PageInfo\",\n        endCursor: users > 0 ? \"u\" + users : null,\n        hasNextPage: false,\n      },\n    },\n  };\n}\n\n// -----------------------------------------------------------------------------\n// Helpers: paginate once, reuse everywhere\n// -----------------------------------------------------------------------------\nexport type Page = {\n  data: ResponseShape;\n  after: string | null;\n  variables: { first: number; after: string | null };\n};\n\nexport const buildPages = (all: ResponseShape, pageSize: number): Page[] => {\n  const edges = all.users.edges;\n  const pages: Page[] = [];\n  const total = edges.length;\n\n  for (let start = 0, pageIdx = 0; start < total; start += pageSize, pageIdx++) {\n    const end = Math.min(start + pageSize, total);\n    const pageEdges = edges.slice(start, end);\n    const endCursor = pageEdges.length ? pageEdges[pageEdges.length - 1].cursor : null;\n    const after = pageIdx === 0 ? null : pages[pageIdx - 1].data.users.pageInfo.endCursor;\n\n    const pageData: ResponseShape = {\n      __typename: \"Query\",\n      users: {\n        __typename: \"UserConnection\",\n        edges: pageEdges,\n        pageInfo: {\n          __typename: \"PageInfo\",\n          endCursor,\n          hasNextPage: end < total,\n        },\n      },\n    };\n\n    Object.freeze(pageData); // prevent accidental mutation\n    pages.push({\n      data: pageData,\n      after,\n      variables: { first: pageSize, after },\n    });\n  }\n\n  return pages;\n}\n\n// -----------------------------------------------------------------------------\n// GraphQL Queries\n// -----------------------------------------------------------------------------\n\n// ---- Cachebay query: explicit keys for nested connections ----\nexport const CACHEBAY_QUERY = gql`\n  query Users($first: Int!, $after: String) {\n    users(first: $first, after: $after) @connection {\n      edges {\n        cursor\n        node {\n          id\n          name\n          avatar\n          posts(first: 5, after: null) @connection(key: \"posts\") {\n            edges {\n              cursor\n              node {\n                id\n                title\n                likeCount\n                comments(first: 3, after: null) @connection(key: \"comments\") {\n                  edges {\n                    cursor\n                    node { id text author { id name } }\n                  }\n                  pageInfo { hasNextPage }\n                }\n              }\n            }\n            pageInfo { hasNextPage }\n          }\n        }\n      }\n      pageInfo { endCursor hasNextPage }\n    }\n  }\n`;\n\n// ---- Apollo query: same selection (no directives) ----\nexport const APOLLO_QUERY = gql`\n  query Users($first: Int!, $after: String) {\n    users(first: $first, after: $after) {\n      edges {\n        cursor\n        node {\n          id\n          name\n          avatar\n          posts(first: 5, after: null) {\n            edges {\n              cursor\n              node {\n                id\n                title\n                likeCount\n                comments(first: 3, after: null) {\n                  edges {\n                    cursor\n                    node { id text author { id name } }\n                  }\n                  pageInfo { hasNextPage }\n                }\n              }\n            }\n            pageInfo { hasNextPage }\n          }\n        }\n      }\n      pageInfo { endCursor hasNextPage }\n    }\n  }\n`;\n","import {\n  Kind,\n  parse,\n  print,\n  visit,\n  type DocumentNode,\n  type FragmentDefinitionNode,\n  type OperationDefinitionNode,\n  type SelectionSetNode,\n  type FieldNode,\n} from \"graphql\";\nimport { lowerSelectionSet } from \"./lowering/flatten\";\nimport { isCachePlan, buildFieldKey, buildConnectionKey, buildConnectionCanonicalKey } from \"./utils\";\nimport type { CachePlan, PlanField } from \"./types\";\nimport { fingerprintPlan, hashFingerprint } from \"./fingerprint\";\nimport { collectVarsFromSelectionSet, makeMaskedVarsKeyFn } from \"./variables\";\n\n/** Build a Map of fragment name -> fragment definition for lowering. */\nconst indexFragments = (doc: DocumentNode): Map<string, FragmentDefinitionNode> => {\n  const m = new Map<string, FragmentDefinitionNode>();\n  for (let i = 0; i < doc.definitions.length; i++) {\n    const d = doc.definitions[i];\n    if (d.kind === Kind.FRAGMENT_DEFINITION) {\n      m.set(d.name.value, d as FragmentDefinitionNode);\n    }\n  }\n  return m;\n};\n\nconst indexByResponseKey = (\n  fields: PlanField[] | null | undefined,\n): Map<string, PlanField> | undefined => {\n  if (!fields || fields.length === 0) return undefined;\n  const m = new Map<string, PlanField>();\n  for (let i = 0; i < fields.length; i++) m.set(fields[i].responseKey, fields[i]);\n  return m;\n};\n\nconst opRootTypename = (op: OperationDefinitionNode): string => {\n  switch (op.operation) {\n    case \"query\": return \"Query\";\n    case \"mutation\": return \"Mutation\";\n    case \"subscription\": return \"Subscription\";\n    default: return \"Query\";\n  }\n};\n\n/**\n * Compute plan metadata: id, varMask, makeVarsKey, windowArgs.\n * This walks the lowered plan to collect window args and combines with\n * variables collected from the original AST.\n */\nconst computePlanMetadata = (\n  root: PlanField[],\n  selectionSet: SelectionSetNode,\n  fragmentsByName: Map<string, FragmentDefinitionNode>,\n  operation: string,\n  rootTypename: string,\n): {\n  id: number;\n  varMask: { strict: string[]; canonical: string[] };\n  makeVarsKey: (mode: \"strict\" | \"canonical\", vars: Record<string, any>) => string;\n  makeSignature: (mode: \"strict\" | \"canonical\", vars: Record<string, any>) => string;\n  windowArgs: Set<string>;\n  selectionFingerprint: string;\n} => {\n  // 1. Compute stable fingerprint and hash it to get numeric ID\n  const selectionFingerprint = fingerprintPlan(root, operation, rootTypename);\n  const id = hashFingerprint(selectionFingerprint);\n\n  // 2. Collect all variables from the AST\n  const strictVars = collectVarsFromSelectionSet(selectionSet, fragmentsByName);\n\n  // 3. Collect window args from connection fields\n  const windowArgs = new Set<string>();\n  const walkFields = (fields: PlanField[]): void => {\n    for (const field of fields) {\n      if (field.isConnection && field.pageArgs) {\n        for (const arg of field.pageArgs) {\n          windowArgs.add(arg);\n        }\n      }\n      if (field.selectionSet) {\n        walkFields(field.selectionSet);\n      }\n    }\n  };\n  walkFields(root);\n\n  // 4. Compute canonical vars (strict minus window args)\n  const canonicalVars = new Set<string>();\n  for (const v of strictVars) {\n    if (!windowArgs.has(v)) {\n      canonicalVars.add(v);\n    }\n  }\n\n  // 5. Build masks and precompiled key function\n  const strictMask = Array.from(strictVars);\n  const canonicalMask = Array.from(canonicalVars);\n  const internalMakeVarsKey = makeMaskedVarsKeyFn(strictMask, canonicalMask);\n\n  // 6. Build public API with canonical boolean\n  const makeVarsKey = (canonical: boolean, vars: Record<string, any>): string => {\n    const mode = canonical ? \"canonical\" : \"strict\";\n    return internalMakeVarsKey(mode, vars);\n  };\n\n  const makeSignature = (canonical: boolean, vars: Record<string, any>): string => {\n    const mode = canonical ? \"canonical\" : \"strict\";\n    return `${id}|${mode}|${internalMakeVarsKey(mode, vars)}`;\n  };\n\n  // 7. Build blazing fast getDependencies\n  // Collect connection fields and fields with arguments for dependency tracking\n  type DepField = { field: PlanField; isConnection: boolean; parentTypename: string };\n  const depFields: DepField[] = [];\n\n  const collectDepFields = (fields: PlanField[], parentTypename: string): void => {\n    for (const field of fields) {\n      // Collect connections and fields with arguments\n      if (field.isConnection || field.expectedArgNames.length > 0) {\n        depFields.push({ field, isConnection: field.isConnection, parentTypename });\n      }\n\n      // Recurse into children with the field's typename as parent\n      if (field.selectionSet) {\n        const childParent = field.typeName || parentTypename;\n        collectDepFields(field.selectionSet, childParent);\n      }\n    }\n  };\n  collectDepFields(root, rootTypename);\n\n  // Build getDependencies function - returns dependency keys for graph watching\n  const getDependencies = (canonical: boolean, vars: Record<string, any>): Set<string> => {\n    const deps = new Set<string>();\n\n    // Iterate collected fields and build dependency keys using optimized utility functions\n    for (let i = 0; i < depFields.length; i++) {\n      const { field, isConnection, parentTypename } = depFields[i];\n\n      // Determine parentId: use \"@\" for root (Query/Mutation), otherwise use typename\n      const parentId = parentTypename === rootTypename ? \"@\" : parentTypename;\n\n      if (isConnection) {\n        // For connections: use canonical (filters only) or strict (with pagination) based on mode\n        const key = canonical ? buildConnectionCanonicalKey(field, parentId, vars) : buildConnectionKey(field, parentId, vars);\n        deps.add(key);\n      } else{\n        // For regular fields with arguments: use buildFieldKey\n        const key = buildFieldKey(field, vars);\n        deps.add(key);\n      }\n    }\n\n    return deps;\n  };\n\n  return {\n    id,\n    varMask: { strict: strictMask, canonical: canonicalMask },\n    makeVarsKey,\n    makeSignature,\n    getDependencies,\n    windowArgs,\n    selectionFingerprint,\n  };\n};\n\n/* ────────────────────────────────────────────────────────────────────────── */\n/* Sanitizer: add __typename (except at op root), strip @connection           */\n/* ────────────────────────────────────────────────────────────────────────── */\n\nfunction ensureTypename(ss: SelectionSetNode): SelectionSetNode {\n  const has = ss.selections.some(\n    s => s.kind === Kind.FIELD && s.name.value === \"__typename\",\n  );\n  if (has) return ss;\n\n  const typenameField: FieldNode = { kind: Kind.FIELD, name: { kind: Kind.NAME, value: \"__typename\" } };\n  const newSelections = new Array(ss.selections.length + 1);\n  for (let i = 0; i < ss.selections.length; i++) {\n    newSelections[i] = ss.selections[i];\n  }\n  newSelections[ss.selections.length] = typenameField;\n\n  return { kind: ss.kind, selections: newSelections };\n}\n\n/** Recursively add __typename to all selection sets (for fragments) */\nfunction ensureTypenameRecursive(ss: SelectionSetNode): SelectionSetNode {\n  // First add __typename to this level\n  const withTypename = ensureTypename(ss);\n\n  // Then recursively process all field selections\n  let hasChanges = false;\n  const selections = new Array(withTypename.selections.length);\n  for (let i = 0; i < withTypename.selections.length; i++) {\n    const sel = withTypename.selections[i];\n    if (sel.kind === Kind.FIELD && sel.selectionSet) {\n      const newSelectionSet = ensureTypenameRecursive(sel.selectionSet);\n      if (newSelectionSet !== sel.selectionSet) {\n        selections[i] = { kind: sel.kind, name: sel.name, alias: sel.alias, arguments: sel.arguments, directives: sel.directives, selectionSet: newSelectionSet };\n        hasChanges = true;\n      } else {\n        selections[i] = sel;\n      }\n    } else if (sel.kind === Kind.INLINE_FRAGMENT && sel.selectionSet) {\n      const newSelectionSet = ensureTypenameRecursive(sel.selectionSet);\n      if (newSelectionSet !== sel.selectionSet) {\n        selections[i] = { kind: sel.kind, typeCondition: sel.typeCondition, directives: sel.directives, selectionSet: newSelectionSet };\n        hasChanges = true;\n      } else {\n        selections[i] = sel;\n      }\n    } else {\n      selections[i] = sel;\n    }\n  }\n\n  if (!hasChanges && selections === withTypename.selections) {\n    return withTypename;\n  }\n\n  return { kind: withTypename.kind, selections };\n}\n\n/** Add __typename to nested selections but NOT at root level (for operations) */\nfunction ensureTypenameNested(ss: SelectionSetNode): SelectionSetNode {\n  // Don't add __typename at this level (root), only to nested selections\n  let hasChanges = false;\n  const selections = new Array(ss.selections.length);\n  for (let i = 0; i < ss.selections.length; i++) {\n    const sel = ss.selections[i];\n    if (sel.kind === Kind.FIELD && sel.selectionSet) {\n      const newSelectionSet = ensureTypenameRecursive(sel.selectionSet);\n      if (newSelectionSet !== sel.selectionSet) {\n        selections[i] = { kind: sel.kind, name: sel.name, alias: sel.alias, arguments: sel.arguments, directives: sel.directives, selectionSet: newSelectionSet };\n        hasChanges = true;\n      } else {\n        selections[i] = sel;\n      }\n    } else if (sel.kind === Kind.INLINE_FRAGMENT && sel.selectionSet) {\n      const newSelectionSet = ensureTypenameRecursive(sel.selectionSet);\n      if (newSelectionSet !== sel.selectionSet) {\n        selections[i] = { kind: sel.kind, typeCondition: sel.typeCondition, directives: sel.directives, selectionSet: newSelectionSet };\n        hasChanges = true;\n      } else {\n        selections[i] = sel;\n      }\n    } else {\n      selections[i] = sel;\n    }\n  }\n\n  if (!hasChanges) {\n    return ss;\n  }\n\n  return { kind: ss.kind, selections };\n}\n\n/** Create a network-safe copy: strip @connection directives. __typename is already added during compilation. Returns a string ready to send to server. */\nfunction buildNetworkQuery(doc: DocumentNode): string {\n  const cleaned = visit(doc, {\n    Field: {\n      enter(node) {\n        if (!node.directives || node.directives.length === 0) {\n          return node;\n        }\n\n        const directives = (node.directives || []).filter(d => d.name.value !== \"connection\");\n        if (directives.length === node.directives.length) {\n          return node; // No @connection found, return as-is\n        }\n\n        // Avoid spread operator - create new object directly\n        return {\n          kind: node.kind,\n          name: node.name,\n          alias: node.alias,\n          arguments: node.arguments,\n          directives: directives.length > 0 ? directives : undefined,\n          selectionSet: node.selectionSet,\n        };\n      },\n    },\n  });\n\n  return print(cleaned);\n}\n\n/* ────────────────────────────────────────────────────────────────────────── */\n/* Public: compilePlan(document)                                             */\n/* ────────────────────────────────────────────────────────────────────────── */\n\n/**\n * Compile to a flat cache plan plus a network-safe DocumentNode.\n * - If called with a precompiled plan → returned as-is (pass-through).\n * - If called with a string → parsed to DocumentNode first.\n * - If the document contains an OperationDefinition → compiled as an operation.\n * - Else if it has one or more FragmentDefinitions:\n *    - with a single fragment → compiled as that fragment\n *    - with multiple fragments → requires opts.fragmentName to select\n */\nexport const compilePlan = (\n  documentOrStringOrPlan: string | DocumentNode | CachePlan,\n  opts?: { fragmentName?: string },\n): CachePlan => {\n  // Precompiled plan? done.\n  if (isCachePlan(documentOrStringOrPlan)) {\n    return documentOrStringOrPlan;\n  }\n\n  // String? parse first.\n  const document: DocumentNode =\n    typeof documentOrStringOrPlan === \"string\"\n      ? parse(documentOrStringOrPlan)\n      : (documentOrStringOrPlan as DocumentNode);\n\n  const fragmentsByName = indexFragments(document);\n\n  // Operation path\n  const operation = document.definitions.find(\n    (d): d is OperationDefinitionNode => d.kind === Kind.OPERATION_DEFINITION,\n  );\n\n  if (operation) {\n    const rootTypename = opRootTypename(operation);\n\n    const selectionWithTypename = ensureTypenameNested(operation.selectionSet);\n\n    // Lower the selection set (it still has @connection) so we retain metadata\n    const root = lowerSelectionSet(selectionWithTypename, rootTypename, fragmentsByName);\n    const rootSelectionMap = indexByResponseKey(root);\n\n    // Build network-safe doc with __typename added to operation and all fragments\n    // Just need to strip @connection directives\n    // Avoid spread operators for performance\n    const operationWithTypename: OperationDefinitionNode = {\n      kind: operation.kind,\n      operation: operation.operation,\n      name: operation.name,\n      variableDefinitions: operation.variableDefinitions,\n      directives: operation.directives,\n      selectionSet: selectionWithTypename,\n    };\n\n    const newDefinitions = new Array(document.definitions.length);\n    for (let i = 0; i < document.definitions.length; i++) {\n      const d = document.definitions[i];\n      if (d.kind === Kind.OPERATION_DEFINITION) {\n        newDefinitions[i] = operationWithTypename;\n      } else if (d.kind === Kind.FRAGMENT_DEFINITION) {\n        const fragWithTypename = ensureTypenameRecursive(d.selectionSet);\n        newDefinitions[i] = {\n          kind: d.kind,\n          name: d.name,\n          typeCondition: d.typeCondition,\n          directives: d.directives,\n          selectionSet: fragWithTypename,\n        };\n      } else {\n        newDefinitions[i] = d;\n      }\n    }\n\n    const docWithTypename: DocumentNode = {\n      kind: document.kind,\n      definitions: newDefinitions,\n    };\n\n    const networkQuery = buildNetworkQuery(docWithTypename);\n\n    // Compute plan metadata (id, varMask, makeVarsKey, windowArgs)\n    const metadata = computePlanMetadata(\n      root,\n      operation.selectionSet,\n      fragmentsByName,\n      operation.operation,\n      rootTypename,\n    );\n\n    return {\n      kind: \"CachePlan\",\n      operation: operation.operation,   // \"query\" | \"mutation\" | \"subscription\"\n      rootTypename,\n      root,\n      rootSelectionMap,\n      networkQuery,\n      id: metadata.id,\n      varMask: metadata.varMask,\n      makeVarsKey: metadata.makeVarsKey,\n      makeSignature: metadata.makeSignature,\n      getDependencies: metadata.getDependencies,\n      windowArgs: metadata.windowArgs,\n      selectionFingerprint: metadata.selectionFingerprint,\n    };\n  }\n\n  // Fragment path (single or multiple)\n  const fragmentDefs = document.definitions.filter(\n    (d): d is FragmentDefinitionNode => d.kind === Kind.FRAGMENT_DEFINITION,\n  );\n\n  if (fragmentDefs.length >= 1) {\n    let frag: FragmentDefinitionNode | undefined;\n\n    if (fragmentDefs.length === 1) {\n      frag = fragmentDefs[0];\n    } else {\n      if (!opts?.fragmentName) {\n        const names = fragmentDefs.map(f => f.name.value).join(\", \");\n        throw new Error(\n          `compilePlan: document contains multiple fragments [${names}]; ` +\n          'pass { fragmentName: \"<one-of>\" }',\n        );\n      }\n      frag = fragmentDefs.find(f => f.name.value === opts.fragmentName);\n      if (!frag) {\n        const names = fragmentDefs.map(f => f.name.value).join(\", \");\n        throw new Error(\n          `compilePlan: fragment \"${opts.fragmentName}\" not found. ` +\n          `Available: [${names}]`,\n        );\n      }\n    }\n\n    const parentTypename = frag.typeCondition.name.value;\n\n    // For fragments, ensure __typename is in ALL selections recursively (unlike operations where we skip root __typename)\n    const fragSelectionWithTypename = ensureTypenameRecursive(frag.selectionSet);\n    const root = lowerSelectionSet(fragSelectionWithTypename, parentTypename, fragmentsByName);\n    const rootSelectionMap = indexByResponseKey(root);\n\n    // Build network-safe doc with __typename added to ALL fragments\n    // Just need to strip @connection directives\n    const newDefinitions = new Array(document.definitions.length);\n    for (let i = 0; i < document.definitions.length; i++) {\n      const d = document.definitions[i];\n      if (d.kind === Kind.FRAGMENT_DEFINITION) {\n        const fragWithTypename = ensureTypenameRecursive(d.selectionSet);\n        newDefinitions[i] = {\n          kind: d.kind,\n          name: d.name,\n          typeCondition: d.typeCondition,\n          directives: d.directives,\n          selectionSet: fragWithTypename,\n        };\n      } else {\n        newDefinitions[i] = d;\n      }\n    }\n\n    const docWithTypename: DocumentNode = {\n      kind: document.kind,\n      definitions: newDefinitions,\n    };\n\n    const networkQuery = buildNetworkQuery(docWithTypename);\n\n    // Compute plan metadata (id, varMask, makeVarsKey, windowArgs)\n    const metadata = computePlanMetadata(\n      root,\n      frag.selectionSet,\n      fragmentsByName,\n      \"fragment\",\n      parentTypename,\n    );\n\n    return {\n      kind: \"CachePlan\",\n      operation: \"fragment\",\n      rootTypename: parentTypename,\n      root,\n      rootSelectionMap,\n      networkQuery,\n      id: metadata.id,\n      varMask: metadata.varMask,\n      makeVarsKey: metadata.makeVarsKey,\n      makeSignature: metadata.makeSignature,\n      getDependencies: metadata.getDependencies,\n      windowArgs: metadata.windowArgs,\n      selectionFingerprint: metadata.selectionFingerprint,\n    };\n  }\n\n  throw new Error(\"compilePlan: document has no OperationDefinition.\");\n};\n","import type { PlanField } from \"./types\";\n\n/**\n * Fast 32-bit FNV-1a hash for strings.\n * Produces stable numeric IDs from selection fingerprints.\n */\nconst fnv1a32 = (str: string): number => {\n  let hash = 2166136261; // FNV offset basis\n  for (let i = 0; i < str.length; i++) {\n    hash ^= str.charCodeAt(i);\n    hash = Math.imul(hash, 16777619); // FNV prime\n  }\n  return hash >>> 0; // unsigned 32-bit\n};\n\n/**\n * Build a stable fingerprint for a field subtree.\n * Includes: responseKey, fieldName, typeCondition, isConnection, arg names (not values),\n * and recursively child selections.\n */\nexport const fingerprintField = (field: PlanField, argNames: string[]): string => {\n  const parts: string[] = [\n    field.responseKey,\n    field.fieldName,\n  ];\n\n  if (field.typeCondition) {\n    parts.push(`@${field.typeCondition}`);\n  }\n\n  if (field.isConnection) {\n    parts.push(\"@connection\");\n  }\n\n  if (argNames.length > 0) {\n    // Sort arg names for stability\n    parts.push(`(${argNames.slice().sort().join(\",\")})`);\n  }\n\n  if (field.selectionSet && field.selectionSet.length > 0) {\n    // Sort children by responseKey, then fieldName for order-insensitive fingerprints\n    const sortedChildren = field.selectionSet.slice().sort((a, b) => {\n      const cmp = a.responseKey.localeCompare(b.responseKey);\n      return cmp !== 0 ? cmp : a.fieldName.localeCompare(b.fieldName);\n    });\n    const childFingerprints = sortedChildren.map(child => child.selId || \"\");\n    parts.push(`{${childFingerprints.join(\",\")}}`)\n  }\n\n  return parts.join(\":\");\n};\n\n/**\n * Build a stable fingerprint for the entire plan root.\n * This is the basis for plan.id.\n * Includes operation and rootTypename to prevent collisions between different roots.\n */\nexport const fingerprintPlan = (\n  root: PlanField[],\n  operation: string,\n  rootTypename: string,\n): string => {\n  // Sort root fields by responseKey, then fieldName for order-insensitive fingerprints\n  const sortedRoot = root.slice().sort((a, b) => {\n    const cmp = a.responseKey.localeCompare(b.responseKey);\n    return cmp !== 0 ? cmp : a.fieldName.localeCompare(b.fieldName);\n  });\n  const rootFingerprints = sortedRoot.map(field => field.selId || \"\");\n  return `${operation}:${rootTypename}:[${rootFingerprints.join(\",\")}]`;\n};\n\n/**\n * Compute a stable numeric ID from a fingerprint string.\n */\nexport const hashFingerprint = (fingerprint: string): number => {\n  return fnv1a32(fingerprint);\n};\n","export type { PlanField, CachePlan } from \"./types\";\nexport { isCachePlan } from \"./utils\";\nexport { compilePlan } from \"./compile\";\n","import {\n  Kind,\n  type SelectionSetNode,\n  type FieldNode,\n  type FragmentDefinitionNode,\n  type InlineFragmentNode,\n  type FragmentSpreadNode,\n  type ValueNode,\n} from \"graphql\";\nimport type { PlanField } from \"../types\";\nimport { fingerprintField } from \"../fingerprint\";\nimport { collectFieldVars } from \"../variables\";\n\n/* ────────────────────────────────────────────────────────────────────────── */\n/* helpers                                                                   */\n/* ────────────────────────────────────────────────────────────────────────── */\n\nconst indexByResponseKey = (fields: PlanField[] | null | undefined): Map<string, PlanField> | undefined => {\n  if (!fields || fields.length === 0) return undefined;\n  const m = new Map<string, PlanField>();\n  for (let i = 0; i < fields.length; i++) m.set(fields[i].responseKey, fields[i]);\n  return m;\n};\n\n/** infer child parent typename from inline fragments / spreads when unambiguous */\nconst inferChildParentTypename = (\n  selectionSet: SelectionSetNode,\n  defaultParent: string,\n  fragmentsByName: Map<string, FragmentDefinitionNode>,\n): string => {\n  const typeNames = new Set<string>();\n  for (const sel of selectionSet.selections) {\n    if (sel.kind === Kind.INLINE_FRAGMENT && sel.typeCondition) {\n      typeNames.add(sel.typeCondition.name.value);\n    } else if (sel.kind === Kind.FRAGMENT_SPREAD) {\n      const frag = fragmentsByName.get(sel.name.value);\n      if (frag) typeNames.add(frag.typeCondition.name.value);\n    }\n  }\n  return typeNames.size === 1 ? Array.from(typeNames)[0]! : defaultParent;\n};\n\n/** resolve a ValueNode to JS (vars is a flat dictionary) */\nconst valueToJS = (node: ValueNode, vars?: Record<string, any>): any => {\n  switch (node.kind) {\n    case Kind.NULL: return null;\n    case Kind.INT:\n    case Kind.FLOAT: return Number(node.value);\n    case Kind.STRING: return node.value;\n    case Kind.BOOLEAN: return node.value;\n    case Kind.ENUM: return node.value;\n    case Kind.LIST: return node.values.map(v => valueToJS(v, vars));\n    case Kind.OBJECT: {\n      const o: Record<string, any> = {};\n      for (const f of node.fields) o[f.name.value] = valueToJS(f.value, vars);\n      return o;\n    }\n    case Kind.VARIABLE: return vars ? vars[node.name.value] : undefined;\n    default: return undefined;\n  }\n};\n\n/** compile argument resolver from field arguments */\nconst compileArgBuilder = (args: readonly any[] | undefined): {\n  buildArgs: (vars: Record<string, any>) => Record<string, any>;\n  expectedArgNames: string[];\n} => {\n  const entries = (args || []).map(a => [a.name.value, a.value as ValueNode]) as Array<[string, ValueNode]>;\n  const expectedArgNames = entries.map(([k]) => k);\n\n  const buildArgs = (vars: Record<string, any>) => {\n    if (!entries.length) return {};\n    const out: Record<string, any> = {};\n    for (let i = 0; i < entries.length; i++) {\n      const [k, v] = entries[i];\n      const val = valueToJS(v, vars);\n      if (val !== undefined) out[k] = val;\n    }\n    return out;\n  };\n\n  return { buildArgs, expectedArgNames };\n};\n\n/**\n * Fast stringify for common primitive types (avoids JSON.stringify overhead)\n */\nconst fastStringify = (value: any): string => {\n  const type = typeof value;\n  if (type === \"string\") return '\"' + value + '\"';\n  if (type === \"number\") return String(value);\n  if (type === \"boolean\") return value ? \"true\" : \"false\";\n  if (value === null) return \"null\";\n  // Fallback to JSON.stringify for arrays/objects\n  return JSON.stringify(value);\n};\n\n/**\n * Compile a fast stringifyArgs function using precomputed arg order.\n * This avoids the need for stableStringify by iterating args in a fixed order.\n * Optimized with pre-stringified arg names and fast primitive stringification.\n */\nconst compileStringifyArgs = (\n  buildArgs: (vars: Record<string, any>) => Record<string, any>,\n  expectedArgNames: string[],\n): (vars: Record<string, any>) => string => {\n  if (expectedArgNames.length === 0) {\n    return () => \"\";\n  }\n\n  // Pre-stringify arg names at compile time (only once)\n  const stringifiedArgNames = expectedArgNames.map(name => '\"' + name + '\":');\n\n  return (vars: Record<string, any>) => {\n    const args = buildArgs(vars);\n    const parts: string[] = [];\n\n    for (let i = 0; i < expectedArgNames.length; i++) {\n      const value = args[expectedArgNames[i]];\n      if (value !== undefined) {\n        parts.push(stringifiedArgNames[i] + fastStringify(value));\n      }\n    }\n\n    return \"{\" + parts.join(\",\") + \"}\";\n  };\n};\n\n/** read @connection(key, filters, mode) on a field */\nconst parseConnectionDirective = (field: FieldNode): {\n  isConnection: boolean;\n  key?: string;\n  filters?: string[];\n  mode?: \"infinite\" | \"page\";\n} => {\n  if (!field.directives) return { isConnection: false };\n  const dir = field.directives.find(d => d.name.value === \"connection\");\n  if (!dir) return { isConnection: false };\n\n  let key: string | undefined;\n  let filters: string[] | undefined;\n  let mode: \"infinite\" | \"page\" | undefined;\n\n  for (const arg of dir.arguments || []) {\n    const name = arg.name.value;\n    if (name === \"key\") {\n      const v = valueToJS(arg.value);\n      if (typeof v === \"string\" && v.trim()) key = v.trim();\n    } else if (name === \"filters\") {\n      const v = valueToJS(arg.value);\n      if (Array.isArray(v)) {\n        filters = v.map(s => String(s)).filter(Boolean);\n      }\n    } else if (name === \"mode\") {\n      const v = String(valueToJS(arg.value));\n      if (v === \"infinite\" || v === \"page\") mode = v;\n    }\n  }\n\n  return {\n    isConnection: true,\n    key,\n    filters,\n    // ✅ default to \"infinite\"\n    mode: mode ?? \"infinite\",\n  };\n};\n\n/* ────────────────────────────────────────────────────────────────────────── */\n/* main lowering                                                              */\n/* ────────────────────────────────────────────────────────────────────────── */\n\n/**\n * Lower a GraphQL SelectionSet into PlanField[].\n * `guardType` is the active inline-fragment/fragment-spread type condition to apply\n * to produced fields (so runtime can skip mismatched implementors).\n */\nexport const lowerSelectionSet = (\n  selectionSet: SelectionSetNode | null | undefined,\n  parentTypename: string,\n  fragmentsByName: Map<string, FragmentDefinitionNode>,\n  guardType?: string, // ← NEW\n): PlanField[] => {\n  if (!selectionSet) return [];\n\n  const out: PlanField[] = [];\n\n  for (const sel of selectionSet.selections) {\n    // Field\n    if (sel.kind === Kind.FIELD) {\n      const fieldNode = sel as FieldNode;\n      const responseKey = fieldNode.alias?.value || fieldNode.name.value;\n      const fieldName = fieldNode.name.value;\n\n      // child plan\n      let childPlan: PlanField[] | null = null;\n      let childMap: Map<string, PlanField> | undefined;\n      if (fieldNode.selectionSet) {\n        const childParent = inferChildParentTypename(fieldNode.selectionSet, parentTypename, fragmentsByName);\n        // propagate current guardType down the tree\n        childPlan = lowerSelectionSet(fieldNode.selectionSet, childParent, fragmentsByName, guardType);\n        childMap = indexByResponseKey(childPlan);\n      }\n\n      // args\n      const { buildArgs, expectedArgNames } = compileArgBuilder(fieldNode.arguments || []);\n      const stringifyArgs = compileStringifyArgs(buildArgs, expectedArgNames);\n\n      // connection directive (+ defaults)\n      let isConnection = false;\n      let connectionKey: string | undefined;\n      let connectionFilters: string[] | undefined;\n      let connectionMode: \"infinite\" | \"page\" | undefined;\n      let pageArgs: string[] | undefined;\n\n      if (fieldNode.directives?.some(d => d.name.value === \"connection\")) {\n        const meta = parseConnectionDirective(fieldNode);\n        isConnection = meta.isConnection;\n        connectionKey = meta.key || fieldName;\n\n        // If filters not provided: infer from field args excluding pagination args.\n        const paginationArgs = new Set([\"first\", \"last\", \"after\", \"before\"]);\n        if (meta.filters && meta.filters.length > 0) {\n          connectionFilters = meta.filters.slice();\n        } else {\n          connectionFilters = (fieldNode.arguments || [])\n            .map(a => a.name.value)\n            .filter(n => !paginationArgs.has(n));\n        }\n\n        connectionMode = meta.mode || \"infinite\"; // meta already defaults; keep for clarity\n\n        // Collect window/pagination args for this connection\n        pageArgs = (fieldNode.arguments || [])\n          .map(a => a.name.value)\n          .filter(n => paginationArgs.has(n));\n      }\n\n      // Collect arg names and vars for fingerprinting\n      const { argNames } = collectFieldVars(fieldNode);\n\n      // Build the field object first (without selId)\n      const planField: PlanField = {\n        responseKey,\n        fieldName,\n        selectionSet: childPlan,\n        selectionMap: childMap,\n        buildArgs,\n        stringifyArgs,\n        expectedArgNames,\n        isConnection,\n        connectionKey,\n        connectionFilters,\n        connectionMode,\n        typeCondition: guardType,\n        pageArgs,\n      };\n\n      // Compute stable fingerprint for this field subtree\n      planField.selId = fingerprintField(planField, argNames);\n\n      out.push(planField);\n      continue;\n    }\n\n    // Inline fragment\n    if (sel.kind === Kind.INLINE_FRAGMENT) {\n      const ifrag = sel as InlineFragmentNode;\n      const nextParent = ifrag.typeCondition ? ifrag.typeCondition.name.value : parentTypename;\n\n      // If the fragment has a type condition, it *becomes* the active guard for its subtree.\n      const nextGuard = ifrag.typeCondition ? ifrag.typeCondition.name.value : guardType;\n\n      const lowered = lowerSelectionSet(ifrag.selectionSet, nextParent, fragmentsByName, nextGuard);\n      for (let i = 0; i < lowered.length; i++) out.push(lowered[i]);\n      continue;\n    }\n\n    // Fragment spread\n    if (sel.kind === Kind.FRAGMENT_SPREAD) {\n      const spread = sel as FragmentSpreadNode;\n      const frag = fragmentsByName.get(spread.name.value);\n      if (!frag) continue;\n\n      const nextParent = frag.typeCondition.name.value;\n      const nextGuard = frag.typeCondition.name.value; // spreads always carry a type condition\n\n      const lowered = lowerSelectionSet(frag.selectionSet, nextParent, fragmentsByName, nextGuard);\n      for (let i = 0; i < lowered.length; i++) out.push(lowered[i]);\n      continue;\n    }\n  }\n\n  return out;\n};\n","import type { CachePlan, PlanField } from \"./types\";\n\nexport const isCachePlan = (v: any): v is CachePlan => {\n  return v && typeof v === \"object\" && v.kind === \"CachePlan\";\n};\n\n// Connection pagination fields (Relay spec)\nconst CONNECTION_FIELDS = new Set([\"first\", \"last\", \"after\", \"before\"]);\nconst ROOT_ID = \"@\";\n\n/**\n * Stable JSON stringify with sorted keys for consistent output.\n */\nconst stableStringify = (object: any): string => {\n  const walk = (object: any): any => {\n    if (object === null || typeof object !== \"object\") {\n      return object;\n    }\n\n    if (Array.isArray(object)) {\n      return object.map(walk);\n    }\n\n    const result: Record<string, any> = {};\n    const keys = Object.keys(object).sort();\n    for (let i = 0; i < keys.length; i++) {\n      const key = keys[i];\n      result[key] = walk(object[key]);\n    }\n\n    return result;\n  };\n\n  try {\n    return JSON.stringify(walk(object));\n  } catch {\n    return \"\";\n  }\n};\n\n/**\n * Build a field link key used on a record snapshot, e.g.:\n *   user({\"id\":\"u1\"})\n *\n * NOTE: `field.stringifyArgs(vars)` expects RAW variables; it internally runs the compiled\n * `buildArgs` to map variable names → field-arg names and drops undefined.\n */\nexport const buildFieldKey = (field: PlanField, variables: Record<string, any>): string => {\n  const args = field.stringifyArgs(variables);\n  return args === \"\" || args === \"{}\" ? field.fieldName : `${field.fieldName}(${args})`;\n};\n\n/**\n * Build a connection key for a specific page, e.g.:\n *   @.posts({\"category\":\"tech\",\"first\":10,\"after\":\"c1\"})\n *   @.User:u1.posts({\"first\":10,\"after\":\"p2\"})\n */\nexport const buildConnectionKey = (\n  field: PlanField,\n  parentId: string,\n  variables: Record<string, any>,\n): string => {\n  // parentId can be \"@\", \"Type:id\", \"Type:id.container\", or already absolute like \"@.X.Y\"\n  const base = parentId[0] === ROOT_ID ? parentId : `${ROOT_ID}.${parentId}`;\n  return `${base}.${field.fieldName}(${field.stringifyArgs(variables)})`;\n};\n\n/**\n * Build the canonical connection key (filters-only identity) under the `@connection.` namespace, e.g.:\n *   @connection.posts({\"category\":\"tech\"})\n *   @connection.User:u1.posts({\"category\":\"tech\",\"sort\":\"hot\"})\n *\n * - Uses `field.connectionKey` (directive key) when available; falls back to the field name.\n * - If `field.connectionFilters` is present, use only those arg names (when present in args).\n * - Otherwise, include all non-pagination args derived from `buildArgs(vars)`.\n */\nexport const buildConnectionCanonicalKey = (\n  field: PlanField,\n  parentId: string,\n  variables: Record<string, any>,\n): string => {\n  const allArgs = field.buildArgs(variables) || {};\n  const identity: Record<string, any> = {};\n\n  // Compiler always sets connectionFilters as an array (explicit or inferred)\n  // Note: Explicit filters from @connection directive could include pagination fields,\n  // so we must filter them out here\n  if (field.connectionFilters) {\n    for (let i = 0; i < field.connectionFilters.length; i++) {\n      const name = field.connectionFilters[i];\n      if (CONNECTION_FIELDS.has(name)) continue; // Skip pagination fields\n      if (name in allArgs) identity[name] = allArgs[name];\n    }\n  }\n\n  const keyPart = field.connectionKey || field.fieldName; // prefer directive key; fallback to field\n  const parentPart = parentId === ROOT_ID ? \"@connection.\" : `@connection.${parentId}.`;\n  return `${parentPart}${keyPart}(${stableStringify(identity)})`;\n};\n","import {\n  Kind,\n  type ValueNode,\n  type SelectionSetNode,\n  type FieldNode,\n  type InlineFragmentNode,\n  type FragmentSpreadNode,\n  type FragmentDefinitionNode,\n} from \"graphql\";\nimport type { PlanField } from \"./types\";\n\n/**\n * Extract all variable names referenced in a ValueNode (recursively).\n */\nconst collectVarsFromValue = (node: ValueNode, out: Set<string>): void => {\n  switch (node.kind) {\n    case Kind.VARIABLE:\n      out.add(node.name.value);\n      break;\n    case Kind.LIST:\n      for (const v of node.values) collectVarsFromValue(v, out);\n      break;\n    case Kind.OBJECT:\n      for (const f of node.fields) collectVarsFromValue(f.value, out);\n      break;\n  }\n};\n\n/**\n * Collect all variable names used in arguments for a single field.\n * Returns both the full set and the arg names (for fingerprinting).\n */\nexport const collectFieldVars = (\n  fieldNode: { arguments?: readonly any[] },\n): { vars: Set<string>; argNames: string[] } => {\n  const vars = new Set<string>();\n  const argNames: string[] = [];\n\n  if (fieldNode.arguments) {\n    for (const arg of fieldNode.arguments) {\n      argNames.push(arg.name.value);\n      collectVarsFromValue(arg.value as ValueNode, vars);\n    }\n  }\n\n  return { vars, argNames };\n};\n\n/**\n * Recursively collect all variables used in a PlanField tree.\n * Also collects window args from connection fields.\n */\nexport const collectPlanVars = (\n  fields: PlanField[],\n): { strictVars: Set<string>; windowArgs: Set<string> } => {\n  const strictVars = new Set<string>();\n  const windowArgs = new Set<string>();\n\n  const walk = (field: PlanField): void => {\n    // Collect vars from this field's args (already compiled, but we need the raw AST)\n    // Since we don't have the raw AST here, we'll rely on the field's pageArgs\n    // which were computed during lowering.\n\n    if (field.isConnection && field.pageArgs) {\n      for (const arg of field.pageArgs) {\n        windowArgs.add(arg);\n      }\n    }\n\n    if (field.selectionSet) {\n      for (const child of field.selectionSet) {\n        walk(child);\n      }\n    }\n  };\n\n  for (const field of fields) {\n    walk(field);\n  }\n\n  return { strictVars, windowArgs };\n};\n\n/**\n * Collect all variable names from a SelectionSet AST (recursively).\n * This walks the raw AST before lowering.\n */\nexport const collectVarsFromSelectionSet = (\n  selectionSet: SelectionSetNode,\n  fragmentsByName: Map<string, FragmentDefinitionNode>,\n  visited = new Set<string>(),\n): Set<string> => {\n  const vars = new Set<string>();\n\n  for (const sel of selectionSet.selections) {\n    if (sel.kind === Kind.FIELD) {\n      const field = sel as FieldNode;\n      if (field.arguments) {\n        for (const arg of field.arguments) {\n          collectVarsFromValue(arg.value as ValueNode, vars);\n        }\n      }\n      if (field.selectionSet) {\n        const childVars = collectVarsFromSelectionSet(field.selectionSet, fragmentsByName, visited);\n        for (const v of childVars) vars.add(v);\n      }\n    } else if (sel.kind === Kind.INLINE_FRAGMENT) {\n      const ifrag = sel as InlineFragmentNode;\n      const childVars = collectVarsFromSelectionSet(ifrag.selectionSet, fragmentsByName, visited);\n      for (const v of childVars) vars.add(v);\n    } else if (sel.kind === Kind.FRAGMENT_SPREAD) {\n      const spread = sel as FragmentSpreadNode;\n      const fragName = spread.name.value;\n      if (!visited.has(fragName)) {\n        visited.add(fragName);\n        const frag = fragmentsByName.get(fragName);\n        if (frag) {\n          const childVars = collectVarsFromSelectionSet(frag.selectionSet, fragmentsByName, visited);\n          for (const v of childVars) vars.add(v);\n        }\n      }\n    }\n  }\n\n  return vars;\n};\n\n/**\n * Build a precompiled function that extracts masked variables and returns a stable key.\n * This is ultra-fast at runtime: just pick keys, sort, and stringify.\n */\nexport const makeMaskedVarsKeyFn = (\n  strictMask: string[],\n  canonicalMask: string[],\n): ((mode: \"strict\" | \"canonical\", vars: Record<string, any>) => string) => {\n  // Pre-sort masks for stable output\n  const strictSorted = strictMask.slice().sort();\n  const canonicalSorted = canonicalMask.slice().sort();\n\n  return (mode: \"strict\" | \"canonical\", vars: Record<string, any>): string => {\n    const mask = mode === \"strict\" ? strictSorted : canonicalSorted;\n    if (mask.length === 0) return \"{}\";\n\n    const pairs: string[] = [];\n    for (let i = 0; i < mask.length; i++) {\n      const k = mask[i];\n      if (k in vars) {\n        const v = vars[k];\n        pairs.push(`${JSON.stringify(k)}:${JSON.stringify(v)}`);\n      }\n    }\n\n    return `{${pairs.join(\",\")}}`;\n  };\n};\n","import { buildConnectionCanonicalKey } from \"../compiler/utils\";\nimport type { GraphInstance } from \"./graph\";\nimport type { PlanField } from \"../compiler\";\nimport type { OptimisticInstance } from \"./optimistic\";\n\nexport type CanonicalDependencies = {\n  graph: GraphInstance;\n  optimistic: OptimisticInstance;\n};\n\nexport type CanonicalInstance = ReturnType<typeof createCanonical>;\n\ntype CursorIndex = { [cursor: string]: number };\n\n/**\n * Creates the canonical connection manager that merges paginated data\n * using Relay-style splice-based merging with cursor relationships.\n * Highly optimized for large lists (thousands of items).\n */\nexport const createCanonical = ({ graph, optimistic }: CanonicalDependencies) => {\n  /**\n   * Helper to get cursor index key for a canonical key.\n   */\n  const getCursorIndexKey = (canonicalKey: string): string => {\n    return `${canonicalKey}::cursorIndex`;\n  };\n\n  /**\n   * Reads cursor index from graph.\n   */\n  const readCursorIndex = (canonicalKey: string): CursorIndex => {\n    const index = graph.getRecord(getCursorIndexKey(canonicalKey));\n    return (index as CursorIndex) || {};\n  };\n\n  /**\n   * Writes cursor index to graph.\n   */\n  const writeCursorIndex = (canonicalKey: string, index: CursorIndex): void => {\n    graph.putRecord(getCursorIndexKey(canonicalKey), index);\n  };\n\n  /**\n   * Gets cursor from an edge.\n   */\n  const getEdgeCursor = (edgeRef: string): string | null => {\n    const edge = graph.getRecord(edgeRef);\n    return edge?.cursor || null;\n  };\n\n  /**\n   * Builds a cursor-to-index map for O(1) lookups.\n   */\n  const buildCursorIndex = (edgeRefs: string[]): CursorIndex => {\n    const index: CursorIndex = {};\n    for (let i = 0; i < edgeRefs.length; i++) {\n      const cursor = getEdgeCursor(edgeRefs[i]);\n      if (cursor) {\n        index[cursor] = i;\n      }\n    }\n    return index;\n  };\n\n  /**\n   * Finds cursor position using index (O(1)) or fallback to scan (O(N)).\n   */\n  const findCursorIndex = (edgeRefs: string[], cursor: string, cursorIndex?: CursorIndex): number => {\n    // Try index first (O(1))\n    if (cursorIndex && cursor in cursorIndex) {\n      return cursorIndex[cursor];\n    }\n\n    // Fallback to linear scan (O(N))\n    for (let i = 0; i < edgeRefs.length; i++) {\n      if (getEdgeCursor(edgeRefs[i]) === cursor) {\n        return i;\n      }\n    }\n    return -1;\n  };\n\n  /**\n   * Extracts extra fields from connection (everything except edges, pageInfo, __typename).\n   */\n  const getExtras = (connection: Record<string, any>): Record<string, any> => {\n    const extras: Record<string, any> = {};\n    const keys = Object.keys(connection || {});\n\n    for (let i = 0; i < keys.length; i++) {\n      const key = keys[i];\n      if (key === \"edges\" || key === \"pageInfo\" || key === \"__typename\") {\n        continue;\n      }\n      extras[key] = connection[key];\n    }\n\n    return extras;\n  };\n\n  /**\n   * Detects cursor role from variables (O(1) with buildArgs).\n   */\n  const detectCursorRole = (field: PlanField, variables: Record<string, any>): { after: string | null; before: string | null; isLeader: boolean } => {\n    const args = field.buildArgs ? (field.buildArgs(variables) || {}) : (variables || {});\n\n    const after: string | null = args.after ?? null;\n    const before: string | null = args.before ?? null;\n    const isLeader = !after && !before;\n\n    return { after, before, isLeader };\n  };\n\n  /**\n   * Ensures canonical record exists (prevents undefined reads).\n   */\n  const ensureCanonical = (canonicalKey: string): void => {\n    if (graph.getRecord(canonicalKey)) {\n      return;\n    }\n\n    const pageInfoKey = `${canonicalKey}.pageInfo`;\n    graph.putRecord(pageInfoKey, {\n      __typename: \"PageInfo\",\n      startCursor: null,\n      endCursor: null,\n      hasPreviousPage: false,\n      hasNextPage: false,\n    });\n\n    graph.putRecord(canonicalKey, {\n      __typename: \"Connection\",\n      edges: { __refs: [] },\n      pageInfo: { __ref: pageInfoKey },\n    });\n\n    writeCursorIndex(canonicalKey, {});\n  };\n\n  /**\n   * Merges incoming page into canonical using Relay-style splice logic.\n   * Handles forward (after), backward (before), and leader (reset) pagination.\n   */\n  const updateConnection = (args: {\n    field: PlanField;\n    parentId: string;\n    variables: Record<string, any>;\n    normalizedPage: Record<string, any>;\n  }): void => {\n    const { field, parentId, variables, normalizedPage } = args;\n    const canonicalKey = buildConnectionCanonicalKey(field, parentId, variables);\n\n    ensureCanonical(canonicalKey);\n\n    const incomingEdgeRefs = (normalizedPage.edges?.__refs as string[]) || [];\n\n    // Page mode: replace entire canonical with incoming page\n    if (field.connectionMode === \"page\") {\n      const pageInfoRef = normalizedPage.pageInfo?.__ref;\n      const pageInfoData = pageInfoRef ? graph.getRecord(pageInfoRef) : null;\n\n      const pageInfoKey = `${canonicalKey}.pageInfo`;\n      graph.putRecord(pageInfoKey, {\n        __typename: pageInfoData?.__typename || \"PageInfo\",\n        startCursor: pageInfoData?.startCursor ?? null,\n        endCursor: pageInfoData?.endCursor ?? null,\n        hasPreviousPage: !!pageInfoData?.hasPreviousPage,\n        hasNextPage: !!pageInfoData?.hasNextPage,\n      });\n\n      graph.putRecord(canonicalKey, {\n        __typename: normalizedPage.__typename || \"Connection\",\n        edges: { __refs: incomingEdgeRefs },\n        pageInfo: { __ref: pageInfoKey },\n        ...getExtras(normalizedPage),\n      });\n\n      writeCursorIndex(canonicalKey, buildCursorIndex(incomingEdgeRefs));\n      optimistic.replayOptimistic({ connections: [canonicalKey] });\n      return;\n    }\n\n    // Infinite mode: merge using cursor relationships\n    const { after, before, isLeader } = detectCursorRole(field, variables);\n\n    // Cache existing data\n    const existing = graph.getRecord(canonicalKey);\n    const existingEdges = (existing?.edges?.__refs as string[]) || [];\n    const existingCursorIndex = readCursorIndex(canonicalKey);\n\n    const incomingPageInfo = graph.getRecord(normalizedPage.pageInfo?.__ref) || {};\n\n    // Determine splice indices (no array allocations yet)\n    let prefixEnd = 0;\n    let suffixStart = 0;\n    let isPureAppend = false;\n    let isPurePrepend = false;\n\n    if (isLeader) {\n      // Leader: reset everything (discard all existing edges)\n      prefixEnd = 0;\n      suffixStart = existingEdges.length; // Start suffix past the end = no suffix\n    } else if (after) {\n      const idx = findCursorIndex(existingEdges, after, existingCursorIndex);\n      if (idx >= 0) {\n        prefixEnd = idx + 1;\n        suffixStart = existingEdges.length;\n        isPureAppend = idx === existingEdges.length - 1;\n      } else {\n        // Cursor not found - append to end\n        prefixEnd = existingEdges.length;\n        suffixStart = existingEdges.length;\n        isPureAppend = true;\n      }\n    } else if (before) {\n      const idx = findCursorIndex(existingEdges, before, existingCursorIndex);\n      if (idx >= 0) {\n        prefixEnd = 0;\n        suffixStart = idx;\n        isPurePrepend = idx === 0;\n      } else {\n        // Cursor not found - prepend to start\n        prefixEnd = 0;\n        suffixStart = 0;\n        isPurePrepend = true;\n      }\n    }\n\n    // Calculate total size and preallocate\n    const prefixLen = prefixEnd;\n    const suffixLen = existingEdges.length - suffixStart;\n    const totalLen = prefixLen + incomingEdgeRefs.length + suffixLen;\n    const mergedEdges = new Array<string>(totalLen);\n\n    // Copy ranges directly into preallocated array\n    let writePos = 0;\n\n    for (let i = 0; i < prefixEnd; i++) {\n      mergedEdges[writePos++] = existingEdges[i];\n    }\n\n    for (let i = 0; i < incomingEdgeRefs.length; i++) {\n      mergedEdges[writePos++] = incomingEdgeRefs[i];\n    }\n\n    for (let i = suffixStart; i < existingEdges.length; i++) {\n      mergedEdges[writePos++] = existingEdges[i];\n    }\n\n    // Build or update cursor index (copy-on-write optimization)\n    let newCursorIndex: CursorIndex = existingCursorIndex;\n    let copied = false;\n\n    const ensureCopy = () => {\n      if (!copied) {\n        newCursorIndex = { ...existingCursorIndex };\n        copied = true;\n      }\n    };\n\n    if (isPureAppend && Object.keys(existingCursorIndex).length > 0) {\n      // Incremental append: extend existing index\n      let pos = existingEdges.length;\n      for (let i = 0; i < incomingEdgeRefs.length; i++) {\n        const cursor = getEdgeCursor(incomingEdgeRefs[i]);\n        if (cursor) {\n          ensureCopy();\n          newCursorIndex[cursor] = pos++;\n        }\n      }\n    } else if (isPurePrepend && Object.keys(existingCursorIndex).length > 0) {\n      // Incremental prepend: shift existing indices\n      newCursorIndex = {};\n      copied = true;\n      const shift = incomingEdgeRefs.length;\n\n      const existingKeys = Object.keys(existingCursorIndex);\n      for (let i = 0; i < existingKeys.length; i++) {\n        const key = existingKeys[i];\n        newCursorIndex[key] = existingCursorIndex[key] + shift;\n      }\n\n      for (let i = 0; i < incomingEdgeRefs.length; i++) {\n        const cursor = getEdgeCursor(incomingEdgeRefs[i]);\n        if (cursor) {\n          newCursorIndex[cursor] = i;\n        }\n      }\n    } else {\n      // General case: rebuild full index\n      newCursorIndex = {};\n      copied = true;\n      for (let i = 0; i < mergedEdges.length; i++) {\n        const cursor = getEdgeCursor(mergedEdges[i]);\n        if (cursor) {\n          newCursorIndex[cursor] = i;\n        }\n      }\n    }\n\n    // Write cursor index only if changed\n    if (copied) {\n      writeCursorIndex(canonicalKey, newCursorIndex);\n    }\n\n    // Build pageInfo\n    const existingPageInfo = graph.getRecord(existing?.pageInfo?.__ref) || {};\n\n    // Extract boundary fields from incoming\n    const { hasPreviousPage, hasNextPage, startCursor, endCursor, __typename, ...incomingPageInfoExtras } = incomingPageInfo;\n\n    // Start from existing, apply incoming extras\n    const pageInfo: any = {\n      __typename,\n      ...existingPageInfo,\n      ...incomingPageInfoExtras,\n    };\n\n    // Track if boundaries changed\n    let boundariesChanged = false;\n\n    // Override boundary fields based on position (Relay logic)\n    if (prefixLen === 0) {\n      if (hasPreviousPage !== undefined) {\n        const newVal = !!hasPreviousPage;\n        if (pageInfo.hasPreviousPage !== newVal) {\n          pageInfo.hasPreviousPage = newVal;\n          boundariesChanged = true;\n        }\n      }\n      if (startCursor !== undefined) {\n        if (pageInfo.startCursor !== startCursor) {\n          pageInfo.startCursor = startCursor;\n          boundariesChanged = true;\n        }\n      }\n    }\n\n    if (suffixLen === 0) {\n      if (hasNextPage !== undefined) {\n        const newVal = !!hasNextPage;\n        if (pageInfo.hasNextPage !== newVal) {\n          pageInfo.hasNextPage = newVal;\n          boundariesChanged = true;\n        }\n      }\n      if (endCursor !== undefined) {\n        if (pageInfo.endCursor !== endCursor) {\n          pageInfo.endCursor = endCursor;\n          boundariesChanged = true;\n        }\n      }\n    }\n\n    // Fallback: infer cursors from edges if missing\n    if (pageInfo.startCursor == null && mergedEdges.length > 0) {\n      const firstEdgeCursor = getEdgeCursor(mergedEdges[0]);\n      if (firstEdgeCursor) {\n        pageInfo.startCursor = firstEdgeCursor;\n        boundariesChanged = true;\n      }\n    }\n\n    if (pageInfo.endCursor == null && mergedEdges.length > 0) {\n      const lastEdgeCursor = getEdgeCursor(mergedEdges[mergedEdges.length - 1]);\n      if (lastEdgeCursor) {\n        pageInfo.endCursor = lastEdgeCursor;\n        boundariesChanged = true;\n      }\n    }\n\n    // Ensure pageInfo has required fields\n    pageInfo.__typename = pageInfo.__typename || \"PageInfo\";\n    pageInfo.startCursor = pageInfo.startCursor ?? null;\n    pageInfo.endCursor = pageInfo.endCursor ?? null;\n    pageInfo.hasPreviousPage = !!pageInfo.hasPreviousPage;\n    pageInfo.hasNextPage = !!pageInfo.hasNextPage;\n\n    // Write pageInfo only if changed\n    const pageInfoKey = `${canonicalKey}.pageInfo`;\n\n    if (boundariesChanged || !existingPageInfo) {\n      graph.putRecord(pageInfoKey, pageInfo);\n    }\n\n    // Merge extra fields (incoming overrides existing)\n    const existingExtras = existing ? getExtras(existing) : {};\n    const incomingConnectionExtras = getExtras(normalizedPage);\n\n    // Write canonical\n    graph.putRecord(canonicalKey, {\n      __typename: normalizedPage.__typename || existing?.__typename || \"Connection\",\n      edges: { __refs: mergedEdges },\n      pageInfo: { __ref: pageInfoKey },\n      ...existingExtras,\n      ...incomingConnectionExtras,\n    });\n\n    optimistic.replayOptimistic({ connections: [canonicalKey] });\n  };\n\n  return {\n    updateConnection,\n  };\n};\n","import { createInspect } from \"./inspect\";\nimport { createSSR } from \"./ssr\";\nimport { createCanonical } from \"./canonical\";\nimport { createDocuments } from \"./documents\";\nimport { createFragments } from \"./fragments\";\nimport { createGraph } from \"./graph\";\nimport { createOptimistic } from \"./optimistic\";\nimport { createPlanner } from \"./planner\";\nimport { createQueries } from \"./queries\";\nimport { createOperations } from \"./operations\";\nimport type { CachebayOptions } from \"./types\";\n\n/**\n * Main Cachebay instance type\n * Framework-agnostic GraphQL cache client with Relay support\n *\n * @public\n * @example\n * ```typescript\n * import { createCachebay } from 'cachebay';\n *\n * const cachebay = createCachebay({\n *   transport: {\n *     http: async (ctx) => {\n *       const res = await fetch('/graphql', {\n *         method: 'POST',\n *         body: JSON.stringify({ query: ctx.query, variables: ctx.variables })\n *       });\n *       return res.json();\n *     }\n *   }\n * });\n *\n * // Read from cache\n * const user = cachebay.readFragment({\n *   id: 'User:123',\n *   fragment: USER_FRAGMENT\n * });\n *\n * const result = await cachebay.executeQuery({\n *   query: GET_USER_QUERY,\n *   variables: { id: '123' },\n *   cachePolicy: 'cache-first'\n * });\n * ```\n */\nexport type CachebayInstance = {\n  /**\n   * Serialize cache state for SSR\n   * @returns Serializable snapshot of the cache\n   */\n  dehydrate: () => Record<string, unknown>;\n\n  /**\n   * Restore cache state from SSR snapshot\n   * @param input - Snapshot object or function that emits snapshot\n   */\n  hydrate: (input: Record<string, unknown> | ((emit: (snapshot: Record<string, unknown>) => void) => void)) => void;\n\n  /**\n   * Check if currently in SSR hydration window\n   * @returns true if within hydration timeout, false otherwise\n   */\n  isHydrating: () => boolean;\n\n  /**\n   * Generate stable cache key for an object\n   * @param obj - GraphQL object with __typename and id\n   * @returns Cache key string (typename:id) or null if not identifiable\n   */\n  identify: (obj: Record<string, unknown>) => string | null;\n\n  /**\n   * Read fragment data from cache reactively\n   * @template TData - Expected fragment data type\n   * @param args - Fragment read arguments\n   * @returns Reactive fragment data or undefined\n   */\n  readFragment: <TData = unknown>(args: {\n    id: string;\n    fragment: unknown;\n    fragmentName?: string;\n    variables?: Record<string, unknown>;\n  }) => TData | undefined;\n\n  /**\n   * Write fragment data into cache\n   * @template TData - Fragment data type\n   * @param args - Fragment write arguments\n   */\n  writeFragment: <TData = unknown>(args: {\n    id: string;\n    fragment: unknown;\n    fragmentName?: string;\n    data: TData;\n    variables?: Record<string, unknown>;\n  }) => void;\n\n  /**\n   * Watch fragment reactively (returns unsubscribe handle)\n   */\n  watchFragment: ReturnType<typeof createFragments>[\"watchFragment\"];\n\n  /**\n   * Read query from cache (sync)\n   */\n  readQuery: ReturnType<typeof createQueries>[\"readQuery\"];\n\n  /**\n   * Write query to cache (sync, triggers reactive updates)\n   */\n  writeQuery: ReturnType<typeof createQueries>[\"writeQuery\"];\n\n  /**\n   * Watch query reactively (returns unsubscribe handle)\n   */\n  watchQuery: ReturnType<typeof createQueries>[\"watchQuery\"];\n\n  /**\n   * Apply optimistic updates with transaction support\n   */\n  modifyOptimistic: ReturnType<typeof createOptimistic>[\"modifyOptimistic\"];\n\n  /**\n   * Execute a GraphQL query (always hits network, writes to cache)\n   */\n  executeQuery: ReturnType<typeof createOperations>[\"executeQuery\"];\n\n  /**\n   * Execute a GraphQL mutation (always hits network, writes to cache)\n   */\n  executeMutation: ReturnType<typeof createOperations>[\"executeMutation\"];\n\n  /**\n   * Execute a GraphQL subscription (returns observable, writes to cache)\n   */\n  executeSubscription: ReturnType<typeof createOperations>[\"executeSubscription\"];\n\n  /**\n   * Get compiled query plan\n   */\n  getPlan: ReturnType<typeof createOperations>[\"getPlan\"];\n\n  /**\n   * Debug inspection API for cache internals\n   */\n  inspect: ReturnType<typeof createInspect>;\n\n  /**\n   * Internal APIs for testing and debugging\n   * @internal\n   */\n  __internals: {\n    graph: ReturnType<typeof createGraph>;\n    planner: ReturnType<typeof createPlanner>;\n    canonical: ReturnType<typeof createCanonical>;\n    documents: ReturnType<typeof createDocuments>;\n    fragments: ReturnType<typeof createFragments>;\n    queries: ReturnType<typeof createQueries>;\n    operations: ReturnType<typeof createOperations>;\n    ssr: ReturnType<typeof createSSR>;\n    inspect: ReturnType<typeof createInspect>;\n  };\n};\n\n/**\n * Create a new Cachebay cache instance\n * @param options - Configuration options for the cache\n * @returns Configured cache instance with Villus plugin interface\n */\nexport function createCachebay(options: CachebayOptions): CachebayInstance {\n  // Validate transport configuration\n  if (!options.transport) {\n    throw new Error(\n      \"Cachebay: 'transport' is required. Please provide a transport object with 'http' function.\\n\" +\n      \"Example:\\n\" +\n      \"  createCachebay({\\n\" +\n      \"    transport: {\\n\" +\n      \"      http: async (context) => { /* HTTP implementation */ },\\n\" +\n      \"      ws: async (context) => { /* WebSocket implementation (optional) */ }\\n\" +\n      \"    }\\n\" +\n      \"  })\"\n    );\n  }\n\n  if (typeof options.transport.http !== \"function\") {\n    throw new Error(\n      \"Cachebay: 'transport.http' must be a function.\\n\" +\n      \"Expected: async (context: HttpContext) => Promise<OperationResult>\"\n    );\n  }\n\n  if (options.transport.ws && typeof options.transport.ws !== \"function\") {\n    throw new Error(\n      \"Cachebay: 'transport.ws' must be a function if provided.\\n\" +\n      \"Expected: async (context: WsContext) => Promise<ObservableLike<OperationResult>>\"\n    );\n  }\n\n  const planner = createPlanner();\n\n  let documents: ReturnType<typeof createDocuments>;\n  let queries: ReturnType<typeof createQueries>;\n  let fragments: ReturnType<typeof createFragments>;\n\n  const graph = createGraph({\n    keys: options.keys || {},\n    interfaces: options.interfaces || {},\n    onChange: (touchedIds) => {\n      queries.propagateData(touchedIds);\n      fragments.propagateData(touchedIds);\n    },\n  });\n\n  // Now create subsystems with graph\n  const optimistic = createOptimistic({ graph });\n  const ssr = createSSR({ hydrationTimeout: options.hydrationTimeout }, { graph });\n  const canonical = createCanonical({ graph, optimistic });\n  documents = createDocuments({ graph, planner, canonical });\n  fragments = createFragments({ graph, planner, documents });\n\n  // Create queries first\n  queries = createQueries({\n    documents,\n    planner,\n  });\n\n  // Operations (always created since transport is required)\n  const operations = createOperations(\n    {\n      cachePolicy: options.cachePolicy,\n      transport: options.transport,\n      suspensionTimeout: options.suspensionTimeout,\n      onQueryError: (signature, error) => {\n        // Propagate errors to queries, which will notify watchers\n        queries.propagateError(signature, error);\n      },\n      onQueryData: queries.handleQueryExecuted,\n    },\n    { planner, documents, ssr }\n  );\n\n  const inspect = createInspect({ graph, optimistic });\n\n  const cache = {} as CachebayInstance;\n\n  cache.identify = graph.identify;\n\n  // Fragments API\n  cache.readFragment = fragments.readFragment;\n  cache.writeFragment = fragments.writeFragment;\n  cache.watchFragment = fragments.watchFragment;\n\n  // Queries API\n  cache.readQuery = queries.readQuery;\n  cache.writeQuery = queries.writeQuery;\n  cache.watchQuery = queries.watchQuery;\n\n  // Optimistic API\n  cache.modifyOptimistic = optimistic.modifyOptimistic;\n\n  // Operations API\n  cache.executeQuery = operations.executeQuery;\n  cache.executeMutation = operations.executeMutation;\n  cache.executeSubscription = operations.executeSubscription;\n\n  // Inspect (debug)\n  cache.inspect = inspect;\n\n  // SSR API\n  cache.dehydrate = ssr.dehydrate;\n  cache.hydrate = ssr.hydrate;\n  cache.isHydrating = ssr.isHydrating;\n\n  // Planner\n  cache.getPlan = planner.getPlan;\n\n  // Internals for tests\n  cache.__internals = {\n    graph,\n    optimistic,\n    planner,\n    canonical,\n    documents,\n    fragments,\n    queries,\n    operations,\n    ssr,\n    inspect,\n  };\n\n  return cache;\n}\n","/**\n * Core constants used throughout the cache system\n */\n\nexport const ROOT_ID = \"@\";\n\nexport const ID_FIELD = \"id\";\n\nexport const TYPENAME_FIELD = \"__typename\";\n\nexport const IDENTITY_FIELDS = new Set([\"__typename\", \"id\"]);\n\nexport const CONNECTION_FIELDS = new Set([\"first\", \"last\", \"after\", \"before\"]);\n","import { fingerprintNodes } from \"./utils\";\nimport { buildFieldKey, buildConnectionKey, buildConnectionCanonicalKey } from \"../compiler/utils\";\nimport { ROOT_ID } from \"./constants\";\nimport { __DEV__ } from \"./instrumentation\";\nimport type { CachePlan, PlanField } from \"../compiler\";\nimport type { CanonicalInstance } from \"./canonical\";\nimport type { GraphInstance } from \"./graph\";\nimport type { PlannerInstance } from \"./planner\";\nimport type { DocumentNode } from \"graphql\";\nimport { WeakStringMap } from \"./utils\";\n\n/**\n * Dependencies required by documents instance\n */\nexport type DocumentsDependencies = {\n  graph: GraphInstance;\n  planner: PlannerInstance;\n  canonical: CanonicalInstance;\n};\n\nexport const ENTITY_MISSING = \"entity-missing\";\nexport const ROOT_LINK_MISSING = \"root-link-missing\";\nexport const FIELD_LINK_MISSING = \"field-link-missing\";\nexport const CONNECTION_MISSING = \"connection-missing\";\nexport const PAGE_INFO_MISSING = \"pageinfo-missing\";\nexport const EDGE_NODE_MISSING = \"edge-node-missing\";\nexport const SCALAR_MISSING = \"scalar-missing\";\nexport const FINGERPRINT_KEY = \"__version\";\n\n/**\n * Represents a cache miss during materialization\n * Used for debugging incomplete reads in development mode\n */\nexport type Miss =\n  | { kind: typeof ENTITY_MISSING; at: string; id: string }\n  | { kind: typeof ROOT_LINK_MISSING; at: string; fieldKey: string }\n  | { kind: typeof FIELD_LINK_MISSING; at: string; parentId: string; fieldKey: string }\n  | { kind: typeof CONNECTION_MISSING; at: string; mode: \"strict\" | \"canonical\"; parentId: string; canonicalKey: string; strictKey: string; hasCanonical: boolean; hasStrict: boolean; }\n  | { kind: typeof PAGE_INFO_MISSING; at: string; pageId: string }\n  | { kind: typeof EDGE_NODE_MISSING; at: string; edgeId: string }\n  | { kind: typeof SCALAR_MISSING; at: string; parentId: string; fieldKey: string };\n\n/**\n * Options for normalizing a document into cache\n */\nexport type NormalizeDocumentOptions = {\n  document: DocumentNode | CachePlan;\n  variables?: Record<string, any>;\n  data: any;\n  rootId?: string;\n};\n\n/**\n * Result of normalizing a document (void for now, may add stats later)\n */\nexport type NormalizeDocumentResult = void;\n\n/**\n * Options for materializing a document from cache\n */\nexport type MaterializeDocumentOptions = {\n  document: DocumentNode | CachePlan;\n  variables?: Record<string, any>;\n  canonical?: boolean;\n  entityId?: string;\n  fingerprint?: boolean;\n  force?: boolean;\n};\n\n/**\n * Result of materializing a document from cache\n */\nexport type MaterializeDocumentResult = {\n  data: any;\n  dependencies: Set<string>;\n  source: \"canonical\" | \"strict\" | \"none\";\n  ok: {\n    strict: boolean;\n    canonical: boolean;\n    miss?: Miss[];\n    strictSignature?: string;      // Strict signature for this materialization\n    canonicalSignature?: string;   // Canonical signature for this materialization\n  };\n  hot: boolean; // true if result came from materializeCache, false if computed\n};\n\n/**\n * Documents instance type\n */\nexport type DocumentsInstance = ReturnType<typeof createDocuments>;\n\n\n/**\n * Create documents instance for normalization and materialization\n * Handles writing GraphQL responses to cache and reading them back\n */\nexport const createDocuments = (deps: DocumentsDependencies) => {\n  const { graph, planner, canonical } = deps;\n\n  /**\n   * WeakMap cache for materialized documents\n   * Key: DocumentNode or CachePlan object\n   * Value: Map of signature -> MaterializeDocumentResult\n   */\n  const materializeCache = new WeakStringMap();\n\n  /**\n   * Helper to build materialize cache key\n   * For regular queries: use precomputed signature + fingerprint flag\n   * For entityId queries: prefix with entityId to ensure separate cache entries\n   */\n  const getMaterializeCacheKey = (options: {\n    signature: string;\n    fingerprint: boolean;\n    entityId?: string;\n  }): string => {\n    const { signature, fingerprint, entityId } = options;\n    const fpFlag = fingerprint ? \"f\" : \"n\";\n\n    return entityId\n      ? `entity:${entityId}|${fpFlag}|${signature}`\n      : `${fpFlag}|${signature}`;\n  };\n\n  /**\n   * Normalize a GraphQL response into the cache\n   * Writes entities, connections, and links to the graph store\n   */\n  const normalizeDocument = (options: NormalizeDocumentOptions) => {\n    const { document, variables = {}, data, rootId } = options;\n\n    const put = (id: string, patch: Record<string, any>) => {\n      graph.putRecord(id, patch);\n    };\n\n    const plan = planner.getPlan(document);\n    const startId = rootId ?? ROOT_ID;\n    const shouldLink = (startId !== ROOT_ID) || (plan.operation === \"query\");\n\n    if (startId === ROOT_ID) {\n      put(ROOT_ID, { id: ROOT_ID, __typename: ROOT_ID });\n    }\n\n    type Frame = {\n      parentId: string;\n      fields?: readonly PlanField[];\n      fieldsMap?: Map<string, PlanField>;\n      insideConnection: boolean;\n      pageKey: string | null;\n    };\n\n    const connectionPages = [];\n\n    const initialFrame = {\n      parentId: startId,\n      fields: plan.root,\n      fieldsMap: plan.rootSelectionMap ?? new Map(),\n      insideConnection: false,\n      pageKey: null,\n    };\n\n    const writeScalar = (parentId: string, field: PlanField, value: any) => {\n      const fieldKey = buildFieldKey(field, variables);\n      put(parentId, { [fieldKey]: value });\n    };\n\n    const linkTo = (parentId: string, field: PlanField, targetId: string) => {\n      if (!shouldLink) {\n        return;\n      }\n      const fieldKey = buildFieldKey(field, variables);\n      put(parentId, { [fieldKey]: { __ref: targetId } });\n    };\n\n    const normalizeObjectFields = (obj: any, frame: Frame) => {\n      const keys = Object.keys(obj);\n\n      for (let i = 0; i < keys.length; i++) {\n        const responseKey = keys[i];\n        const value = obj[responseKey];\n        const field = frame.fieldsMap?.get(responseKey);\n\n        normalizeValue(value, responseKey, field, frame);\n      }\n    };\n\n    const normalizeEdgesArray = (pageKey: string, edges: any[], edgesField: PlanField | undefined, parentFrame: Frame) => {\n      const refs = new Array(edges.length);\n\n      for (let i = 0; i < edges.length; i++) {\n        refs[i] = `${pageKey}.edges.${i}`;\n      }\n\n      put(pageKey, { edges: { __refs: refs } });\n\n      if (!edgesField?.selectionSet) {\n        return;\n      }\n\n      const edgesSel = edgesField.selectionSet;\n      const edgesSelMap = edgesField.selectionMap;\n\n      for (let idx = 0; idx < edges.length; idx++) {\n        const edgeKey = `${pageKey}.edges.${idx}`;\n        const edgeObj = edges[idx];\n        const edgePatch = {};\n\n        if (edgeObj && edgeObj.__typename) {\n          edgePatch.__typename = edgeObj.__typename;\n        }\n\n        const nodeObj = edgeObj?.node;\n\n        if (nodeObj && typeof nodeObj === \"object\") {\n          const nodeId = graph.identify(nodeObj);\n\n          if (nodeId) {\n            edgePatch.node = { __ref: nodeId };\n          }\n        }\n\n        put(edgeKey, edgePatch);\n\n        const edgeFrame = {\n          parentId: edgeKey,\n          fields: edgesSel,\n          fieldsMap: edgesSelMap,\n          insideConnection: true,\n          pageKey,\n        };\n\n        if (edgeObj && typeof edgeObj === \"object\") {\n          normalizeObjectFields(edgeObj, edgeFrame);\n        }\n      }\n    };\n\n    const normalizeConnection = (value: any, field: PlanField, frame: Frame) => {\n      const pageKey = buildConnectionKey(field, frame.parentId, variables);\n      const fieldKey = buildFieldKey(field, variables);\n      const pageRecord = {};\n\n      if (value?.__typename) {\n        pageRecord.__typename = value.__typename;\n      }\n\n      if (value && typeof value === \"object\") {\n        const keys = Object.keys(value);\n\n        for (let i = 0; i < keys.length; i++) {\n          const key = keys[i];\n\n          if (key === \"__typename\" || key === \"edges\" || key === \"pageInfo\") {\n            continue;\n          }\n\n          const fieldValue = value[key];\n          const isScalarLike = fieldValue === null || typeof fieldValue !== \"object\";\n          const isInlineObject = fieldValue && typeof fieldValue === \"object\" && !fieldValue.__typename;\n\n          if (isScalarLike || Array.isArray(fieldValue) || isInlineObject) {\n            pageRecord[key] = fieldValue;\n          }\n        }\n      }\n\n      put(pageKey, pageRecord);\n\n      if (shouldLink) {\n        put(frame.parentId, { [fieldKey]: { __ref: pageKey } });\n        connectionPages.push({ field, parentId: frame.parentId, pageKey });\n      }\n\n      const pageInfoObj = value?.pageInfo;\n\n      if (pageInfoObj && typeof pageInfoObj === \"object\") {\n        const pageInfoKey = `${pageKey}.pageInfo`;\n\n        put(pageKey, { pageInfo: { __ref: pageInfoKey } });\n\n        if (pageInfoObj.__typename) {\n          put(pageInfoKey, { __typename: pageInfoObj.__typename });\n        } else {\n          put(pageInfoKey, {});\n        }\n      }\n\n      const nextFrame = {\n        parentId: pageKey,\n        fields: field.selectionSet,\n        fieldsMap: field.selectionMap,\n        insideConnection: true,\n        pageKey,\n      };\n\n      if (value && typeof value === \"object\") {\n        normalizeObjectFields(value, nextFrame);\n      }\n    };\n\n    const normalizeArrayOfObjectsWithSelection = (arr: any[], field: PlanField, frame: Frame) => {\n      const fieldKey = buildFieldKey(field, variables);\n      const baseKey = `${frame.parentId}.${fieldKey}`;\n      const refs = new Array(arr.length);\n\n      for (let i = 0; i < arr.length; i++) {\n        const item = arr[i];\n        const entityId = (item && typeof item === \"object\") ? graph.identify(item) : null;\n        const itemKey = entityId ?? `${baseKey}.${i}`;\n\n        if (item && typeof item === \"object\") {\n          if (item.__typename) {\n            put(itemKey, { __typename: item.__typename });\n          } else {\n            put(itemKey, {});\n          }\n        }\n\n        refs[i] = itemKey;\n      }\n\n      put(frame.parentId, { [fieldKey]: { __refs: refs } });\n\n      if (!field.selectionSet) {\n        return;\n      }\n\n      for (let i = 0; i < arr.length; i++) {\n        const val = arr[i];\n\n        if (!val || typeof val !== \"object\") {\n          continue;\n        }\n\n        const entityId = graph.identify(val);\n        const itemKey = entityId ?? `${baseKey}.${i}`;\n\n        const itemFrame = {\n          parentId: itemKey,\n          fields: field.selectionSet,\n          fieldsMap: field.selectionMap,\n          insideConnection: false,\n          pageKey: baseKey,\n        };\n\n        normalizeObjectFields(val, itemFrame);\n      }\n    };\n\n    const normalizeArray = (arr: any[], responseKey: string | number, field: PlanField | undefined, frame: Frame) => {\n      if (frame.insideConnection && responseKey === \"edges\" && typeof frame.pageKey === \"string\") {\n        normalizeEdgesArray(frame.pageKey, arr, field, frame);\n        return;\n      }\n\n      if (field && field.selectionSet) {\n        normalizeArrayOfObjectsWithSelection(arr, field, frame);\n        return;\n      }\n\n      if (field && !field.selectionSet) {\n        const fieldKey = buildFieldKey(field, variables);\n        const out = new Array(arr.length);\n\n        for (let i = 0; i < arr.length; i++) {\n          out[i] = arr[i];\n        }\n\n        put(frame.parentId, { [fieldKey]: out });\n      }\n    };\n\n    const normalizeInlineContainer = (obj: any, field: PlanField, frame: Frame) => {\n      const containerFieldKey = buildFieldKey(field, variables);\n      const containerKey = `${frame.parentId}.${containerFieldKey}`;\n\n      if (obj?.__typename) {\n        put(containerKey, { __typename: obj.__typename });\n      } else {\n        put(containerKey, {});\n      }\n\n      if (shouldLink) {\n        put(frame.parentId, { [containerFieldKey]: { __ref: containerKey } });\n      }\n\n      if (frame.insideConnection && containerFieldKey === \"pageInfo\" && frame.pageKey) {\n        put(frame.pageKey, { pageInfo: { __ref: containerKey } });\n      }\n\n      const nextFrame = {\n        parentId: containerKey,\n        fields: field.selectionSet,\n        fieldsMap: field.selectionMap,\n        insideConnection: frame.insideConnection,\n        pageKey: frame.pageKey,\n      };\n\n      normalizeObjectFields(obj, nextFrame);\n    };\n\n    const normalizeEntityObject = (obj: any, field: PlanField | undefined, frame: Frame) => {\n      const entityId = graph.identify(obj);\n\n      if (!entityId) {\n        return false;\n      }\n\n      if (obj.__typename) {\n        put(entityId, { __typename: obj.__typename });\n      } else {\n        put(entityId, {});\n      }\n\n      if (field && !(frame.insideConnection && field.responseKey === \"node\")) {\n        linkTo(frame.parentId, field, entityId);\n      }\n\n      const fromNode = !!field && field.responseKey === \"node\";\n      const nextFrame = {\n        parentId: entityId,\n        fields: field?.selectionSet,\n        fieldsMap: field?.selectionMap,\n        insideConnection: fromNode ? false : frame.insideConnection,\n        pageKey: fromNode ? null : frame.pageKey,\n      };\n\n      normalizeObjectFields(obj, nextFrame);\n\n      return true;\n    };\n\n    const normalizeValue = (value: any, responseKey: string | number, field: PlanField | undefined, frame: Frame) => {\n      if (Array.isArray(value)) {\n        normalizeArray(value, responseKey, field, frame);\n        return;\n      }\n\n      if (value && typeof value === \"object\") {\n        if (field && !field.selectionSet) {\n          writeScalar(frame.parentId, field, value);\n          return;\n        }\n\n        if (field && (field as any).isConnection) {\n          normalizeConnection(value, field, frame);\n          return;\n        }\n\n        if (normalizeEntityObject(value, field, frame)) {\n          return;\n        }\n\n        if (field && field.selectionSet) {\n          normalizeInlineContainer(value, field, frame);\n          return;\n        }\n\n        return;\n      }\n\n      if (typeof responseKey === \"string\" && field && !field.selectionSet) {\n        writeScalar(frame.parentId, field, value);\n      }\n    };\n\n    if (data && typeof data === \"object\") {\n      normalizeObjectFields(data, initialFrame);\n    }\n\n    if (connectionPages.length > 0) {\n      for (let i = 0; i < connectionPages.length; i++) {\n        const { field, parentId, pageKey } = connectionPages[i];\n        const normalizedPage = graph.getRecord(pageKey);\n\n        if (!normalizedPage) {\n          continue;\n        }\n\n        canonical.updateConnection({\n          field,\n          parentId,\n          variables,\n          pageKey,\n          normalizedPage,\n        });\n      }\n    }\n  };\n\n  /**\n   * Materialize a document from cache\n   * Reads normalized data and reconstructs the GraphQL response shape\n   *\n   * @param options.force - If false (default), returns cached result if available. If true, always re-materializes.\n   */\n  const materializeDocument = (options: MaterializeDocumentOptions): MaterializeDocumentResult => {\n    const { document, variables = {}, canonical = true, entityId, fingerprint = true, force = false } = options;\n\n    // Get plan once at the start\n    const plan = planner.getPlan(document);\n\n    const strictSignature = plan.makeSignature(false, variables);\n    const canonicalSignature = canonical ? plan.makeSignature(true, variables) : undefined;\n    const cacheKey = getMaterializeCacheKey({ signature: canonical ? canonicalSignature! : strictSignature, fingerprint, entityId });\n\n    if (!force) {\n      let cached = materializeCache.get(cacheKey);\n\n      if (cached) {\n        cached.hot = true;\n\n        return cached;\n      }\n    }\n\n    graph.flush();\n\n    const dependencies = new Set();\n\n    const touch = (id: string) => {\n      dependencies.add(id);\n    };\n\n    let strictOK = true;\n    let canonicalOK = true;\n\n    const misses = [];\n    const miss = __DEV__ ? (m: Miss) => { misses.push(m); } : (_: Miss) => { };\n    const addPath = __DEV__\n      ? (base: string, seg: string) => (base ? base + \".\" + seg : seg)\n      : (_base: string, _seg: string) => \"\";\n\n    const selectionAppliesToRuntime = (field: any, runtimeType: string | undefined): boolean => {\n      const one = field.typeCondition || field.onType || field.typeName;\n\n      if (one != null) {\n        if (runtimeType == null) return true;\n        if (runtimeType === one) return true;\n        return graph.getImplementers(one).has(runtimeType);\n      }\n\n      const many = field.typeConditions || field.onTypes || field.typeNames;\n\n      if (Array.isArray(many)) {\n        if (runtimeType == null) return true;\n        for (let i = 0; i < many.length; i++) {\n          const expected = many[i];\n          if (runtimeType === expected || graph.getImplementers(expected).has(runtimeType)) {\n            return true;\n          }\n        }\n        return false;\n      }\n\n      return true;\n    };\n\n    const setFingerprint = (obj: any, fp: number) => {\n      if (!fingerprint) {\n        return;\n      }\n\n      if (Array.isArray(obj)) {\n        Object.defineProperty(obj, FINGERPRINT_KEY, {\n          value: fp,\n          writable: true,\n          enumerable: false,\n          configurable: true,\n        });\n      } else {\n        obj[FINGERPRINT_KEY] = fp;\n      }\n    };\n\n    const getFingerprint = (obj: any) => {\n      if (!fingerprint) {\n        return undefined;\n      }\n      return obj[FINGERPRINT_KEY];\n    };\n\n    const readScalar = (record: any, field: PlanField, out: any, outKey: string, parentId: string, path: string) => {\n      if (field.fieldName === \"__typename\") {\n        const typeName = record ? (record as any).__typename : undefined;\n        out[outKey] = typeName;\n        return;\n      }\n\n      const storeKey = buildFieldKey(field, variables);\n      const value = record ? (record as any)[storeKey] : undefined;\n\n      if (value === undefined && __DEV__) {\n        miss({ kind: SCALAR_MISSING, at: path, parentId, fieldKey: storeKey });\n      }\n\n      out[outKey] = value;\n    };\n\n    const readPageInfo = (pageInfoId: string, field: PlanField, outConn: any, path: string) => {\n      touch(pageInfoId);\n\n      const record = graph.getRecord(pageInfoId) || {};\n      const selection = field.selectionSet || [];\n      const outPageInfo: any = {};\n\n      for (let i = 0; i < selection.length; i++) {\n        const f = selection[i];\n\n        if (f.selectionSet) {\n          continue;\n        }\n\n        readScalar(record, f, outPageInfo, f.responseKey, pageInfoId, addPath(path, f.responseKey));\n      }\n\n      outConn.pageInfo = outPageInfo;\n\n      const pageInfoVersion = graph.getVersion(pageInfoId);\n\n      setFingerprint(outPageInfo, pageInfoVersion);\n\n      return pageInfoVersion;\n    };\n\n    const readEntity = (id: string, field: PlanField, out: any, path: string) => {\n      touch(id);\n\n      const record = graph.getRecord(id);\n      if (!record) {\n        strictOK = false;\n        canonicalOK = false;\n        miss({ kind: ENTITY_MISSING, at: path, id });\n      }\n\n      const snapshot = record || {};\n\n      if ((snapshot as any).__typename !== undefined) {\n        out.__typename = (snapshot as any).__typename;\n      }\n\n      const runtimeType = (snapshot as any).__typename as string | undefined;\n      const selection = field.selectionSet || [];\n      const childFingerprints = [];\n\n      for (let i = 0; i < selection.length; i++) {\n        const childField = selection[i];\n        const outKey = childField.responseKey;\n\n        if (!selectionAppliesToRuntime(childField, runtimeType)) {\n          continue;\n        }\n\n        if ((childField as any).isConnection) {\n          readConnection(id, childField, out, outKey, addPath(path, outKey));\n          const connObj = out[outKey];\n          if (connObj && typeof connObj === \"object\") {\n            const fp = getFingerprint(connObj);\n            if (fp !== undefined) childFingerprints.push(fp);\n          }\n          continue;\n        }\n\n        if (childField.selectionSet && childField.selectionSet.length) {\n          const storeKey = buildFieldKey(childField, variables);\n          const link = (snapshot as any)[storeKey];\n\n          if (link != null && Array.isArray(link.__refs)) {\n            const refs = link.__refs;\n            const outArray = new Array(refs.length);\n\n            out[outKey] = outArray;\n\n            const arrayFingerprints = [];\n\n            for (let j = 0; j < refs.length; j++) {\n              const childOut: any = {};\n              outArray[j] = childOut;\n              readEntity(refs[j], childField, childOut, addPath(path, outKey + \"[\" + j + \"]\"));\n              const fp = getFingerprint(childOut);\n\n              if (fp !== undefined) {\n                arrayFingerprints.push(fp);\n              }\n            }\n\n            if (arrayFingerprints.length > 0) {\n              const arrayFp = fingerprintNodes(0, arrayFingerprints);\n              setFingerprint(outArray, arrayFp);\n              childFingerprints.push(arrayFp);\n            }\n\n            continue;\n          }\n\n          if (!link || !link.__ref) {\n            out[outKey] = link === null ? null : undefined;\n            strictOK = false;\n            canonicalOK = false;\n            miss({ kind: FIELD_LINK_MISSING, at: addPath(path, outKey), parentId: id, fieldKey: storeKey });\n            continue;\n          }\n\n          const childId = link.__ref as string;\n          const childOut: any = {};\n          out[outKey] = childOut;\n          readEntity(childId, childField, childOut, addPath(path, outKey));\n          const fp = getFingerprint(childOut);\n          if (fp !== undefined) childFingerprints.push(fp);\n          continue;\n        }\n\n        readScalar(snapshot, childField, out, outKey, id, addPath(path, outKey));\n      }\n\n      if (Array.isArray(field.selectionSet) && field.selectionSet.length) {\n        for (let i = 0; i < field.selectionSet.length; i++) {\n          const pf = field.selectionSet[i];\n\n          if (pf.selectionSet) {\n            continue;\n          }\n          if (out[pf.responseKey] !== undefined) {\n            continue;\n          }\n\n          const storeKey = buildFieldKey(pf, variables);\n\n          if (snapshot && storeKey in (snapshot as any)) {\n            out[pf.responseKey] = (snapshot as any)[storeKey];\n          }\n        }\n      }\n\n      const entityVersion = graph.getVersion(id);\n\n      const finalFingerprint = childFingerprints.length > 0 ? fingerprintNodes(entityVersion, childFingerprints) : entityVersion;\n\n      setFingerprint(out, finalFingerprint);\n    };\n\n    const readEdge = (edgeId: string, field: PlanField, outArray: any[], index: number, path: string) => {\n      const record = graph.getRecord(edgeId) || {};\n      const outEdge: any = {};\n      outArray[index] = outEdge;\n\n      if ((record as any).__typename !== undefined) {\n        outEdge.__typename = (record as any).__typename;\n      }\n\n      const selection = field.selectionSet || [];\n      const nodePlan = (field as any).selectionMap ? (field as any).selectionMap.get(\"node\") : undefined;\n\n      let nodeFingerprint;\n\n      for (let i = 0; i < selection.length; i++) {\n        const f = selection[i];\n        const outKey = f.responseKey;\n\n        if (outKey === \"node\") {\n          const nlink = (record as any).node;\n\n          if (!nlink || !nlink.__ref) {\n            outEdge.node = nlink === null ? null : undefined;\n            strictOK = false;\n            canonicalOK = false;\n            miss({ kind: EDGE_NODE_MISSING, at: addPath(path, \"node\"), edgeId });\n          } else {\n            const nodeId = nlink.__ref as string;\n            const nodeOut: any = {};\n            outEdge.node = nodeOut;\n            readEntity(nodeId, nodePlan as PlanField, nodeOut, addPath(path, \"node\"));\n            nodeFingerprint = getFingerprint(nodeOut);\n          }\n        } else if (!f.selectionSet) {\n          readScalar(record, f, outEdge, outKey, edgeId, addPath(path, outKey));\n        }\n      }\n\n      const edgeVersion = graph.getVersion(edgeId);\n\n      const finalFingerprint = nodeFingerprint !== undefined ? fingerprintNodes(edgeVersion, [nodeFingerprint]) : edgeVersion;\n\n      setFingerprint(outEdge, finalFingerprint);\n    };\n\n    const readConnection = (parentId: string, field: PlanField, out: any, outKey: string, path: string) => {\n      const canonicalKey = buildConnectionCanonicalKey(field, parentId, variables);\n      const strictKey = buildConnectionKey(field, parentId, variables);\n\n      if (canonical) {\n        touch(canonicalKey);\n      } else {\n        touch(strictKey);\n      }\n\n      const pageCanonical = graph.getRecord(canonicalKey);\n      const pageStrict = graph.getRecord(strictKey);\n\n      canonicalOK &&= !!pageCanonical;\n      strictOK &&= !!pageStrict;\n\n      const requestedOK = canonical ? !!pageCanonical : !!pageStrict;\n\n      const conn: any = { edges: [], pageInfo: {} };\n      out[outKey] = conn;\n\n      if (!requestedOK) {\n        miss({\n          kind: CONNECTION_MISSING,\n          at: path,\n          mode: canonical ? \"canonical\" : \"strict\",\n          parentId,\n          canonicalKey,\n          strictKey,\n          hasCanonical: !!pageCanonical,\n          hasStrict: !!pageStrict,\n        });\n        return;\n      }\n\n      const baseIsCanonical = canonical === true;\n      const page = (baseIsCanonical ? pageCanonical : pageStrict) as any;\n      const baseKey = baseIsCanonical ? canonicalKey : strictKey;\n\n      const selMap = (field as any).selectionMap;\n\n      if (!selMap || selMap.size === 0) {\n        return;\n      }\n\n      let pageInfoFingerprint;\n      const edgeFingerprints = [];\n\n      for (const [responseKey, childField] of selMap) {\n        if (responseKey === \"pageInfo\") {\n          const pageInfoLink = page.pageInfo;\n\n          if (pageInfoLink && pageInfoLink.__ref) {\n            pageInfoFingerprint = readPageInfo(pageInfoLink.__ref as string, childField, conn, addPath(path, \"pageInfo\"));\n          } else {\n            conn.pageInfo = {};\n            strictOK = false;\n            canonicalOK = false;\n            miss({ kind: PAGE_INFO_MISSING, at: addPath(path, \"pageInfo\"), pageId: baseKey + \".pageInfo\" });\n          }\n          continue;\n        }\n\n        if (responseKey === \"edges\") {\n          const refs = page.edges.__refs;\n          const outArr = new Array(refs.length);\n          conn.edges = outArr;\n\n          for (let i = 0; i < refs.length; i++) {\n            readEdge(refs[i], childField, outArr, i, addPath(path, \"edges[\" + i + \"]\"));\n\n            const edge = outArr[i];\n\n            if (edge) {\n              const fp = getFingerprint(edge);\n              if (fp !== undefined) edgeFingerprints.push(fp);\n            }\n          }\n\n          if (edgeFingerprints.length > 0) {\n            const edgesArrayFp = fingerprintNodes(0, edgeFingerprints);\n            setFingerprint(outArr, edgesArrayFp);\n          }\n\n          continue;\n        }\n\n        if (!childField.selectionSet) {\n          readScalar(page, childField, conn, childField.responseKey, baseKey, addPath(path, childField.responseKey));\n          continue;\n        }\n\n        if ((childField as any).isConnection) {\n          readConnection(baseKey, childField, conn, childField.responseKey, addPath(path, childField.responseKey));\n          continue;\n        }\n\n        const link = page[buildFieldKey(childField, variables)];\n\n        if (link != null && Array.isArray(link.__refs)) {\n          const refs = link.__refs;\n          const outArray = new Array(refs.length);\n          conn[childField.responseKey] = outArray;\n\n          for (let j = 0; j < refs.length; j++) {\n            const childOut: any = {};\n            outArray[j] = childOut;\n            readEntity(refs[j], childField, childOut, addPath(path, childField.responseKey + \"[\" + j + \"]\"));\n          }\n\n          continue;\n        }\n\n        if (!link || !link.__ref) {\n          conn[childField.responseKey] = link === null ? null : undefined;\n          strictOK = false;\n          canonicalOK = false;\n          miss({\n            kind: FIELD_LINK_MISSING,\n            at: addPath(path, childField.responseKey),\n            parentId: baseKey,\n            fieldKey: buildFieldKey(childField, variables),\n          });\n          continue;\n        }\n\n        const childId = link.__ref as string;\n        const childOut: any = {};\n        conn[childField.responseKey] = childOut;\n        readEntity(childId, childField, childOut, addPath(path, childField.responseKey));\n      }\n\n      const pageVersion = graph.getVersion(baseKey);\n\n      const connChildren = [];\n      if (pageInfoFingerprint !== undefined) {\n        connChildren.push(pageInfoFingerprint);\n      }\n      if (edgeFingerprints.length > 0) {\n        connChildren.push(fingerprintNodes(0, edgeFingerprints));\n      }\n\n      const connFingerprint = connChildren.length > 0\n        ? fingerprintNodes(pageVersion, connChildren)\n        : pageVersion;\n      setFingerprint(conn, connFingerprint);\n    };\n\n    const data = {};\n\n    if (entityId) {\n      const synthetic = { selectionSet: plan.root, selectionMap: plan.rootSelectionMap } as unknown as PlanField;\n      readEntity(entityId, synthetic, data, entityId);\n    } else {\n      const rootRecord = graph.getRecord(ROOT_ID) || {};\n      const rootSelection = plan.root;\n\n      for (let i = 0; i < rootSelection.length; i++) {\n        const field = rootSelection[i];\n        const path = addPath(ROOT_ID, field.responseKey);\n\n        if ((field as any).isConnection) {\n          readConnection(ROOT_ID, field, data, field.responseKey, path);\n          continue;\n        }\n\n        if (field.selectionSet && field.selectionSet.length) {\n          const fieldKey = buildFieldKey(field, variables);\n          touch(ROOT_ID + \".\" + fieldKey);\n\n          const link = (rootRecord as any)[fieldKey];\n\n          if (!link || !link.__ref) {\n            data[field.responseKey] = link === null ? null : undefined;\n            strictOK = false;\n            canonicalOK = false;\n            miss({ kind: ROOT_LINK_MISSING, at: path, fieldKey });\n          } else {\n            const childId = link.__ref as string;\n            const childOut: any = {};\n            data[field.responseKey] = childOut;\n            readEntity(childId, field, childOut, addPath(path, childId));\n          }\n        } else {\n          readScalar(rootRecord, field, data, field.responseKey, ROOT_ID, path);\n        }\n      }\n    }\n\n    const requestedOK = canonical ? canonicalOK : strictOK;\n    const rootFingerprints = [];\n    if (entityId) {\n      const fp = getFingerprint(data);\n      if (fp !== undefined) rootFingerprints.push(fp);\n    } else {\n      for (let i = 0; i < plan.root.length; i++) {\n        const field = plan.root[i];\n        const value = data[field.responseKey];\n        if (value && typeof value === \"object\") {\n          const fp = getFingerprint(value);\n          if (fp !== undefined) rootFingerprints.push(fp);\n        }\n      }\n    }\n\n    if (requestedOK && rootFingerprints.length > 0) {\n      const rootFingerprint = fingerprintNodes(0, rootFingerprints);\n      setFingerprint(data, rootFingerprint);\n    }\n\n    // Create result object (either \"none\" or with data)\n    const result: MaterializeDocumentResult = !requestedOK\n      ? {\n          data: undefined,\n          dependencies,\n          source: \"none\",\n          ok: {\n            strict: strictOK,\n            canonical: canonicalOK,\n            miss: __DEV__ ? misses : undefined,\n            strictSignature,\n            canonicalSignature,\n          },\n          hot: false,\n        }\n      : {\n          data,\n          dependencies,\n          source: canonical ? \"canonical\" : \"strict\",\n          ok: {\n            strict: strictOK,\n            canonical: canonicalOK,\n            miss: __DEV__ ? misses : undefined,\n            strictSignature,\n            canonicalSignature,\n          },\n          hot: false,\n        };\n\n    materializeCache.set(cacheKey, result);\n\n    return result;\n  };\n\n  return {\n    normalizeDocument,\n    materializeDocument,\n  };\n};\n","import type { GraphQLError } from \"graphql\";\n\n/**\n * Custom error types for cachebay\n */\n\n/**\n * Error thrown when cache-only policy is used but no cached data exists\n */\nexport class CacheMissError extends Error {\n  constructor(message = 'Cache miss: no data available for cache-only query') {\n    super(message);\n    this.name = 'CacheMissError';\n  }\n}\n\n/**\n * Error returned when a query response arrives after a newer request\n * for the same query+variables has been initiated.\n * This is expected behavior and should be ignored by consumers.\n */\nexport class StaleResponseError extends Error {\n  constructor(message = 'Response ignored: newer request in flight') {\n    super(message);\n    this.name = 'StaleResponseError';\n  }\n}\n\n/**\n * Generate error message from network and GraphQL errors\n */\nconst generateErrorMessage = (networkError?: Error, graphqlErrors?: GraphQLError[]) => {\n  let error = \"\";\n  if (networkError !== undefined) {\n    return (error = `[Network] ${networkError.message}`);\n  }\n\n  if (graphqlErrors !== undefined) {\n    for (let i = 0; i < graphqlErrors.length; i++) {\n      error += `[GraphQL] ${graphqlErrors[i].message}\\n`;\n    }\n  }\n\n  return error.trim();\n};\n\n/**\n * CombinedError - handles both network and GraphQL errors\n */\nexport class CombinedError extends Error {\n  public name: \"CombinedError\";\n  public message: string;\n  public response: any;\n  public networkError?: Error;\n  public graphqlErrors?: GraphQLError[];\n\n  constructor({\n    response,\n    networkError,\n    graphqlErrors,\n  }: {\n    response?: any;\n    networkError?: Error;\n    graphqlErrors?: GraphQLError[];\n  }) {\n    const message = generateErrorMessage(networkError, graphqlErrors);\n    super(message);\n\n    this.name = \"CombinedError\";\n    this.response = response;\n    this.message = message;\n    this.networkError = networkError;\n    this.graphqlErrors = graphqlErrors;\n  }\n\n  toString() {\n    return this.message;\n  }\n}\n","import type { CachePlan } from \"@/src/compiler\";\nimport type { GraphInstance } from \"./graph\";\nimport type { PlannerInstance } from \"./planner\";\nimport type { DocumentsInstance } from \"./documents\";\nimport type { DocumentNode } from \"graphql\";\nimport { CacheMissError } from \"./errors\";\nimport { recycleSnapshots } from \"./utils\";\n\nexport type FragmentsDependencies = {\n  graph: GraphInstance;\n  planner: PlannerInstance;\n  documents: DocumentsInstance;\n};\n\nexport type ReadFragmentArgs<TData = unknown> = {\n  id: string;\n  fragment: DocumentNode | CachePlan;\n  fragmentName?: string;\n  variables?: Record<string, unknown>;\n};\n\nexport type WatchFragmentOptions = {\n  id: string;\n  fragment: DocumentNode | CachePlan;\n  fragmentName?: string;\n  variables?: Record<string, unknown>;\n  onData: (data: any) => void;\n  onError?: (error: Error) => void;\n  /** Emit initial data immediately (default: true) */\n  immediate?: boolean;\n};\n\nexport type WatchFragmentHandle = {\n  unsubscribe: () => void;\n  update: (options: { id?: string; variables?: Record<string, unknown>; immediate?: boolean }) => void;\n};\n\nexport type WriteFragmentArgs<TData = unknown> = {\n  id: string;\n  fragment: DocumentNode | CachePlan;\n  fragmentName?: string;\n  data: TData;\n  variables?: Record<string, unknown>;\n};\n\nexport const createFragments = ({ graph, planner, documents }: FragmentsDependencies) => {\n  // --- Watchers (same shape and batching strategy as queries) ---\n  type WatcherState = {\n    id: string;\n    fragment: DocumentNode | CachePlan;\n    fragmentName?: string;\n    variables: Record<string, unknown>;\n    onData: (data: any) => void;\n    onError?: (error: Error) => void;\n    deps: Set<string>;\n    lastData: any | undefined;\n  };\n\n  const watchers = new Map<number, WatcherState>();\n  const depIndex = new Map<string, Set<number>>();\n  let watcherSeq = 1;\n\n  let pendingTouched = new Set<string>();\n  let flushScheduled = false;\n\n  const scheduleFlush = () => {\n    if (flushScheduled) return;\n    flushScheduled = true;\n    queueMicrotask(() => {\n      flushScheduled = false;\n      if (pendingTouched.size === 0) return;\n\n      const touched = Array.from(pendingTouched);\n      pendingTouched.clear();\n\n      const affected = new Set<number>();\n      for (const id of touched) {\n        const ws = depIndex.get(id);\n        if (ws) for (const k of ws) affected.add(k);\n      }\n      if (affected.size === 0) return;\n\n      for (const k of affected) {\n        const w = watchers.get(k);\n        if (!w) continue;\n\n        const result = documents.materializeDocument({\n          document: planner.getPlan(w.fragment, { fragmentName: w.fragmentName }),\n          variables: w.variables as Record<string, any>,\n          canonical: true,  // Always use canonical mode\n          entityId: w.id,\n          fingerprint: true,\n          force: true, // Always force in propagateData - data changed\n        });\n\n        updateWatcherDeps(k, result.dependencies);\n\n        if (result.source !== \"none\") {\n          const recycled = recycleSnapshots(w.lastData, result.data);\n          if (recycled !== w.lastData) {\n            w.lastData = recycled;\n            try {\n              w.onData(recycled);\n            } catch (e) {\n              w.onError?.(e as Error);\n            }\n          }\n        }\n        // Don't call onError for cache miss - entity might be deleted or not loaded yet\n      }\n    });\n  };\n\n  const propagateData = (touched: Set<string>) => {\n    for (const value of touched) {\n      pendingTouched.add(value);\n    }\n\n    scheduleFlush();\n  };\n\n  const updateWatcherDeps = (watcherId: number, nextDepsArr: string[]) => {\n    const watcher = watchers.get(watcherId);\n    if (!watcher) return;\n\n    const old = watcher.deps;\n    const next = new Set(nextDepsArr);\n\n    // fast path: identical\n    if (old.size === next.size) {\n      let same = true;\n      for (const d of old) if (!next.has(d)) { same = false; break; }\n      if (same) return;\n    }\n\n    for (const d of old) {\n      const set = depIndex.get(d);\n      if (set) {\n        set.delete(watcherId);\n        if (set.size === 0) depIndex.delete(d);\n      }\n    }\n\n    for (const d of next) {\n      let set = depIndex.get(d);\n      if (!set) depIndex.set(d, (set = new Set()));\n      set.add(watcherId);\n    }\n\n    watcher.deps = next;\n  };\n\n  // --- Public API ---\n\n  const readFragment = <T = any>({\n    id,\n    fragment,\n    fragmentName,\n    variables = {},\n  }: ReadFragmentArgs): T | null => {\n    const result = documents.materializeDocument({\n      document: planner.getPlan(fragment, { fragmentName }),\n      variables: variables as Record<string, any>,\n      canonical: true,  // Always use canonical mode\n      entityId: id,\n      fingerprint: true, // Include version fingerprints\n      force: true, // Always read fresh data (rare operation, not hot path)\n    });\n\n    if (result.source !== \"none\") {\n      return result.data as T;\n    }\n    return null;\n  };\n\n  const writeFragment = ({\n    id,\n    fragment,\n    fragmentName,\n    data,\n    variables = {},\n  }: WriteFragmentArgs): void => {\n    const plan = planner.getPlan(fragment, { fragmentName });\n    documents.normalizeDocument({\n      document: plan,\n      variables: variables as Record<string, any>,\n      data,\n      // write \"under\" this entity and create links to connection pages\n      rootId: id,\n    });\n  };\n\n  const watchFragment = ({\n    id,\n    fragment,\n    fragmentName,\n    variables = {},\n    onData,\n    onError,\n    immediate = true,\n  }: WatchFragmentOptions): WatchFragmentHandle => {\n    const watcherId = watcherSeq++;\n\n    const watcher: WatcherState = {\n      id,\n      fragment,\n      fragmentName,\n      variables: variables || {},\n      onData,\n      onError,\n      deps: new Set(),\n      lastData: undefined,\n    };\n    watchers.set(watcherId, watcher);\n\n    const initial = documents.materializeDocument({\n      document: planner.getPlan(fragment, { fragmentName }),\n      variables: variables as Record<string, any>,\n      canonical: true,  // Always use canonical mode\n      entityId: id,\n      fingerprint: true,\n    });\n\n    updateWatcherDeps(watcherId, initial.dependencies);\n\n    if (initial.source !== \"none\") {\n      watcher.lastData = recycleSnapshots(undefined, initial.data);\n      if (immediate) {\n        try {\n          onData(initial.data);\n        } catch (e) {\n          onError?.(e as Error);\n        }\n      }\n    }\n    // Don't call onError for initial cache miss - entity might not be loaded yet\n\n    return {\n      unsubscribe: () => {\n        const w = watchers.get(watcherId);\n        if (!w) return;\n        for (const d of w.deps) {\n          const set = depIndex.get(d);\n          if (set) {\n            set.delete(watcherId);\n            if (set.size === 0) depIndex.delete(d);\n          }\n        }\n        watchers.delete(watcherId);\n      },\n\n      update: ({ id: newId, variables: newVariables, immediate = true }) => {\n        const w = watchers.get(watcherId);\n        if (!w) return;\n\n        // Update watcher state\n        if (newId !== undefined) w.id = newId;\n        if (newVariables !== undefined) w.variables = newVariables;\n\n        // If immediate, materialize and emit synchronously\n        if (immediate) {\n          const res = documents.materializeDocument({\n            document: planner.getPlan(w.fragment, { fragmentName: w.fragmentName }),\n            variables: w.variables as Record<string, any>,\n            canonical: true,\n            entityId: w.id,\n            fingerprint: true,\n            force: false, // Use cache - propagateData already updated it\n          });\n\n          updateWatcherDeps(watcherId, res.dependencies);\n\n          if (res.source !== \"none\") {\n            // recycleSnapshots automatically preserves object identity for unchanged parts\n            const recycled = recycleSnapshots(w.lastData, res.data);\n            // Only emit if data actually changed\n            if (recycled !== w.lastData) {\n              w.lastData = recycled;\n              try {\n                w.onData(recycled);\n              } catch (e) {\n                w.onError?.(e as Error);\n              }\n            }\n          }\n          // No else - watchers simply don't emit on cache miss, entity might not be loaded yet\n        }\n      },\n    };\n  };\n\n  return {\n    readFragment,\n    writeFragment,\n    watchFragment,\n    propagateData,\n  };\n};\n","import { ID_FIELD, TYPENAME_FIELD, IDENTITY_FIELDS, ROOT_ID } from \"./constants\";\nimport { isObject, isDataDeepEqual } from \"./utils\";\n\nconst EMPTY_SET: ReadonlySet<string> = new Set();\n\n/**\n * Configuration options for graph store\n */\nexport type GraphOptions = {\n  /** Custom key functions for entity identification by typename */\n  keys?: Record<string, (obj: Record<string, unknown>) => string | null>;\n  /** Interface to implementation mappings */\n  interfaces?: Record<string, string[]>;\n  /** Callback fired when records change (required for reactivity) */\n  onChange: (recordIds: Set<string>) => void;\n};\n\n/**\n * Graph store instance type\n */\nexport type GraphInstance = ReturnType<typeof createGraph>;\n\n/**\n * Diff field changes and track what changed\n * Uses deep equality for objects/arrays to avoid false positives from JSON.parse\n * @private\n */\nconst commitChanges = (currentSnapshot: Record<string, any>, partialSnapshot: Record<string, any>): boolean => {\n  let hasChanges = false;\n\n  for (let i = 0, fields = Object.keys(partialSnapshot); i < fields.length; i++) {\n    const fieldName = fields[i];\n    const incomingValue = partialSnapshot[fieldName];\n\n    if (incomingValue === undefined) {\n      continue;\n    }\n\n    if (fieldName === ID_FIELD) {\n      const normalizedId = incomingValue ? String(incomingValue) : null;\n\n      if (currentSnapshot[ID_FIELD] === normalizedId) {\n        continue;\n      }\n\n      currentSnapshot[ID_FIELD] = normalizedId;\n      hasChanges = true;\n      continue;\n    }\n\n    const currentValue = currentSnapshot[fieldName];\n\n    // Fast path: reference equality (handles primitives and same object references)\n    if (currentValue === incomingValue) {\n      continue;\n    }\n\n    // Only use deep equality for objects/arrays to avoid false positives from JSON.parse\n    if (typeof incomingValue === 'object' && incomingValue !== null &&\n      typeof currentValue === 'object' && currentValue !== null) {\n      if (isDataDeepEqual(currentValue, incomingValue)) {\n        continue;\n      }\n    }\n\n    currentSnapshot[fieldName] = incomingValue;\n    hasChanges = true;\n  }\n\n  return hasChanges;\n};\n\n/**\n * Identity manager for entity key generation and interface resolution\n * Handles typename mapping, key parsing, and custom key functions\n * @private\n */\nclass IdentityManager {\n  private keyStore = new Map<string, [string, string | undefined]>();\n  private interfaceStore = new Map<string, string>();\n  private keyers = new Map<string, (obj: any) => string | null>();\n\n  constructor(config: { keys: Record<string, (obj: any) => string | null>; interfaces?: Record<string, string[]> }) {\n    for (const [typename, keyFunction] of Object.entries(config.keys || {})) {\n      this.keyers.set(typename, keyFunction);\n    }\n\n    if (config.interfaces) {\n      const interfaces = Object.keys(config.interfaces);\n\n      for (let i = 0; i < interfaces.length; i++) {\n        const interfaceTypename = interfaces[i];\n        const implementors = config.interfaces[interfaceTypename] || [];\n\n        for (let j = 0; j < implementors.length; j++) {\n          this.interfaceStore.set(implementors[j], interfaceTypename);\n        }\n      }\n    }\n  }\n\n  getCanonicalTypename(typename: string): string {\n    return this.interfaceStore.get(typename) || typename;\n  }\n\n  parseKey(key: string): [string, string | undefined] {\n    const cached = this.keyStore.get(key);\n\n    if (cached) {\n      return cached;\n    }\n\n    const parsed = key.split(\":\", 2) as [string, string | undefined];\n\n    this.keyStore.set(key, parsed);\n\n    return parsed;\n  }\n\n  stringifyKey(object: any): string | null {\n    if (!isObject(object)) {\n      return null;\n    }\n\n    const typename = this.getCanonicalTypename(object[TYPENAME_FIELD]) || object[TYPENAME_FIELD];\n\n    if (!typename) {\n      return null;\n    }\n\n    const id = this.keyers.get(typename)?.(object) ?? object[ID_FIELD];\n\n    if (id === undefined || id === null) {\n      return null;\n    }\n\n    return `${typename}:${id}`;\n  }\n\n  clear(): void {\n    this.keyStore.clear();\n  }\n}\n\n/**\n * Create a normalized graph store\n * @param options - Configuration for keys and interfaces\n * @returns Graph store instance with CRUD and read methods\n */\nexport const createGraph = (options: GraphOptions = {}) => {\n  const { onChange = () => { } } = options;\n\n  const identityManager = new IdentityManager({ keys: options.keys || {}, interfaces: options.interfaces || {} });\n  const implementersMap = new Map<string, ReadonlySet<string>>();\n  const recordStore = new Map<string, Record<string, any>>();\n  const recordVersionStore = new Map<string, number>();\n  const pendingChanges = new Set<string>();\n\n  let isFlushing = false;\n  let versionClock = 0;\n\n  for (const name in options.interfaces) {\n    const implementors = options.interfaces[name];\n\n    if (Array.isArray(implementors) && implementors.length > 0) {\n      implementersMap.set(name, new Set(implementors));\n    } else {\n      implementersMap.set(name, EMPTY_SET);\n    }\n  }\n\n  const notifyChange = (recordId: string) => {\n    const shouldSchedule = pendingChanges.size === 0;\n\n    pendingChanges.add(recordId);\n\n    if (shouldSchedule) {\n      queueMicrotask(flush);\n    }\n  };\n\n  /**\n   * Get implementers for a given interface\n   */\n  const getImplementers = (interfaceName: string): ReadonlySet<string> => {\n    return implementersMap.get(interfaceName) || EMPTY_SET;\n  };\n\n  /**\n   * Get stable key for object using configured resolvers\n   */\n  const identify = (object: any): string | null => {\n    return identityManager.stringifyKey(object);\n  };\n\n  /**\n   * Get raw record data by ID\n   */\n  const getRecord = (recordId: string): Record<string, any> | undefined => {\n    return recordStore.get(recordId);\n  };\n\n  /**\n   * Update record with partial data, undefined values are ignored\n   */\n  const putRecord = (recordId: string, partialSnapshot: Record<string, any>): void => {\n    const currentSnapshot = recordStore.get(recordId) || {};\n\n    const hasChanges = commitChanges(currentSnapshot, partialSnapshot); // NOTE: Don't destructure for performance\n\n    if (!hasChanges) {\n      return;\n    }\n\n    versionClock++;\n\n    recordStore.set(recordId, currentSnapshot);\n    recordVersionStore.set(recordId, versionClock);\n\n    if (recordId === ROOT_ID) {\n      for (let i = 0, keys = Object.keys(partialSnapshot); i < keys.length; i++) {\n        const key = keys[i];\n\n        notifyChange(`${recordId}.${key}`);\n      }\n    }\n\n    notifyChange(recordId);\n  };\n\n  /**\n   * Delete record from store\n   */\n  const removeRecord = (recordId: string): void => {\n    recordStore.delete(recordId);\n    recordVersionStore.delete(recordId);\n\n    notifyChange(recordId);\n  };\n\n  /**\n  * Get version of record\n  */\n  const getVersion = (recordId: string): number => {\n    return recordVersionStore.get(recordId) || 0;\n  };\n\n  /**\n   * Flush pending onChange notifications immediately (for sync reads after writes)\n   */\n\n  const flush = () => {\n    if (isFlushing) {\n      return;\n    }\n\n    if (pendingChanges.size === 0) {\n      return;\n    }\n\n    isFlushing = true;\n\n    try {\n      onChange(pendingChanges);\n      pendingChanges.clear();\n    } finally {\n      isFlushing = false;\n    }\n  };\n\n  /**\n   * Get all record IDs\n   */\n  const keys = () => {\n    return Array.from(recordStore.keys());\n  };\n\n  /**\n   * Clear all data\n   */\n  const clear = () => {\n    recordStore.clear();\n    recordVersionStore.clear();\n  };\n\n  /**\n   * Debug inspection of current state\n   */\n  const inspect = () => {\n    const records: Record<string, any> = {};\n\n    for (const [recordId, currentSnapshot] of recordStore.entries()) {\n      records[recordId] = currentSnapshot;\n    }\n\n    return {\n      records,\n\n      options: {\n        keys: options.keys || {},\n        interfaces: options.interfaces || {},\n      },\n    };\n  };\n\n  return {\n    getImplementers,\n    identify,\n    putRecord,\n    getRecord,\n    removeRecord,\n    getVersion,\n    flush,\n    keys,\n    clear,\n    inspect,\n  };\n};\n","import { ROOT_ID } from \"../core/constants\";\nimport { buildConnectionCanonicalKey } from \"../compiler/utils\";\nimport type { GraphInstance } from \"../core/graph\";\nimport type { OptimisticInstance } from \"../core/optimistic\";\n\n/**\n * Inspect API instance type\n */\nexport type InspectAPI = ReturnType<typeof createInspect>;\n\n/**\n * Parent selector for connection filtering\n */\ntype ParentSelector =\n  | \"@\"\n  | \"Query\"\n  | string\n  | { __typename: string; id: string | number };\n\n/**\n * Filter criteria for connection inspection\n */\ntype ConnectionFilter = {\n  /** Match only pages under this parent. Omit to match any parent. */\n  parent?: ParentSelector;\n\n  /** Field name (e.g. \"projects\", \"posts\") to match. */\n  key?: string;\n\n  /** Predicate over the raw argument string inside '(...)'. */\n  argsFn?: (rawArgs: string) => boolean;\n};\n\nconst PAGINATION_ARGS = new Set([\n  \"first\",\n  \"last\",\n  \"after\",\n  \"before\",\n  \"offset\",\n  \"limit\",\n  \"page\",\n  \"cursor\",\n]);\n\n/* ────────────────────────────────────────────────────────────────────────────\n * Small helpers (allocation-lean)\n * -------------------------------------------------------------------------- */\n\nconst isRootRecord = (id: string): boolean => {\n  return id === \"@\";\n};\n\nconst isEdgeRecord = (id: string): boolean => {\n  return id.includes(\".edges.\");\n};\n\nconst isPageRecord = (id: string): boolean => {\n  return id.startsWith(\"@.\") && !isEdgeRecord(id);\n};\n\nconst parentId = (parent?: ParentSelector): string => {\n  if (!parent || parent === \"Query\" || parent === \"@\") {\n    return \"\";\n  }\n  if (typeof parent === \"string\") {\n    return parent;\n  }\n  return `${parent.__typename}:${String(parent.id)}`;\n};\n\n/** Root pages: '@.<field>(...)' → last '.' before '(' is exactly index 1. */\nconst isPageUnderParent = (pageKey: string, p?: ParentSelector): boolean => {\n  if (!isPageRecord(pageKey)) {\n    return false;\n  }\n\n  const pid = parentId(p);\n\n  if (!pid) {\n    const paren = pageKey.indexOf(\"(\");\n    const stop = paren >= 0 ? paren : pageKey.length;\n    const lastDot = pageKey.lastIndexOf(\".\", stop);\n    return lastDot === 1;\n  }\n\n  return pageKey.startsWith(`@.${pid}.`);\n};\n\nconst fieldOf = (pageKey: string): string | null => {\n  const paren = pageKey.indexOf(\"(\");\n  const end = paren >= 0 ? paren : pageKey.length;\n\n  const dot = pageKey.lastIndexOf(\".\", end);\n  if (dot < 0) {\n    return null;\n  }\n\n  return pageKey.slice(dot + 1, end);\n};\n\nconst argsOf = (pageKey: string): string => {\n  const i = pageKey.indexOf(\"(\");\n  if (i < 0) {\n    return \"\";\n  }\n\n  const j = pageKey.lastIndexOf(\")\");\n  if (j <= i) {\n    return \"\";\n  }\n\n  return pageKey.slice(i + 1, j).trim();\n};\n\n/** Parse filters from raw '(...)' JSON; drop pagination args. */\nconst parseFilters = (raw: string): Record<string, any> => {\n  if (!raw) {\n    return {};\n  }\n\n  try {\n    const src = JSON.parse(raw) as Record<string, any>;\n    const out: Record<string, any> = {};\n\n    const keys = Object.keys(src);\n    for (let i = 0; i < keys.length; i++) {\n      const k = keys[i];\n      if (!PAGINATION_ARGS.has(k)) {\n        out[k] = src[k];\n      }\n    }\n\n    return out;\n  } catch {\n    // Non-JSON args are ignored for inspection; return empty to be safe.\n    return {};\n  }\n};\n\nconst unique = <T,>(xs: T[]): T[] => {\n  if (xs.length < 2) {\n    return xs;\n  }\n  return Array.from(new Set(xs));\n};\n\n/* ────────────────────────────────────────────────────────────────────────────\n * Public API\n * -------------------------------------------------------------------------- */\n\n/**\n * Create debug inspection API for cache internals\n * Provides methods to inspect entities, connections, and optimistic state\n * @param deps - Required dependencies (graph, optimistic)\n * @returns Inspect API with record, entityKeys, connectionKeys, config, and optimistic methods\n */\nexport const createInspect = ({ graph, optimistic }: { graph: GraphInstance, optimistic: OptimisticInstance }) => {\n  const getRecord = (id: string): any => {\n    return graph.getRecord(id);\n  };\n\n  /**\n   * List entity record ids (excludes root, pages, edges). Optional typename filter.\n   * @param typename Optional typename prefix to filter, e.g. \"User\".\n   */\n  const getEntityKeys = (typename?: string): string[] => {\n    const all = graph.keys();\n    const out: string[] = [];\n\n    for (let i = 0; i < all.length; i++) {\n      const k = all[i];\n\n      if (isRootRecord(k) || isPageRecord(k) || isEdgeRecord(k)) {\n        continue;\n      }\n      if (typename && !k.startsWith(typename + \":\")) {\n        continue;\n      }\n\n      out.push(k);\n    }\n\n    return out;\n  };\n\n  /**\n   * List canonical @connection keys for pages that match the filter.\n   * Pagination args are removed; remaining args become the connection filters.\n   */\n  const getConnectionKeys = (opts: ConnectionFilter = {}): string[] => {\n    const all = graph.keys();\n    const results: string[] = [];\n\n    const wantField = opts.key;\n    const testArgs = opts.argsFn;\n    const hasParentFilter = opts.parent !== undefined;\n\n    for (let i = 0; i < all.length; i++) {\n      const k = all[i];\n\n      if (!isPageRecord(k)) {\n        continue;\n      }\n\n      if (hasParentFilter && !isPageUnderParent(k, opts.parent)) {\n        continue;\n      }\n\n      if (wantField) {\n        const f = fieldOf(k);\n        if (f !== wantField) {\n          continue;\n        }\n      }\n\n      if (testArgs) {\n        const raw = argsOf(k);\n        if (!testArgs(raw)) {\n          continue;\n        }\n      }\n\n      // Convert page key → canonical connection key using the shared builder.\n      const paren = k.indexOf(\"(\");\n      const end = paren >= 0 ? paren : k.length;\n      const lastDot = k.lastIndexOf(\".\", end);\n\n      const hasParent = lastDot > 1;\n      const parentStr = hasParent ? k.slice(2, lastDot) : ROOT_ID;\n      const fieldName = k.slice(lastDot + 1, end);\n\n      const filters = parseFilters(argsOf(k));\n      const filterKeys = Object.keys(filters);\n\n      const canonical = buildConnectionCanonicalKey(\n        { fieldName, buildArgs: (v: any) => v || {}, connectionFilters: filterKeys } as any,\n        parentStr,\n        filters,\n      );\n\n      results.push(canonical);\n    }\n\n    return unique(results);\n  };\n\n  /** Return the graph creation options (keys, interfaces). */\n  const config = () => {\n    const snap = (graph as any).inspect?.();\n\n    return snap?.options ?? { keys: {}, interfaces: {} };\n  };\n\n  return {\n    getRecord,\n    getEntityKeys,\n    getConnectionKeys,\n    config,\n    optimistic: () => optimistic.inspect(),\n  };\n};\n","/**\n * Development mode flag - computed once at module load.\n * Tree-shaken in production builds.\n */\nexport const __DEV__ = process.env.NODE_ENV === 'development';\n","import type { DocumentNode, GraphQLError } from \"graphql\";\nimport { print } from \"graphql\";\nimport type { PlannerInstance } from \"./planner\";\nimport type { DocumentsInstance } from \"./documents\";\nimport type { SSRInstance } from \"./ssr\";\nimport { __DEV__ } from \"./instrumentation\";\nimport { StaleResponseError, CombinedError, CacheMissError } from \"./errors\";\n\n/**\n * Types\n */\n\n/**\n * GraphQL query variables\n *\n * @public\n * @example\n * ```typescript\n * const variables: QueryVariables = {\n *   id: \"123\",\n *   first: 10,\n *   after: \"cursor\"\n * };\n * ```\n */\nexport type QueryVariables = Record<string, any>;\n\n/**\n * Cache policy determines how the cache interacts with the network\n *\n * @public\n * - `cache-first`: Return cached data if available, otherwise fetch from network\n * - `cache-only`: Only return cached data, never fetch from network (throws if not cached)\n * - `network-only`: Always fetch from network, ignore cache\n * - `cache-and-network`: Return cached data immediately, then fetch from network and update\n *\n * @example\n * ```typescript\n * const policy: CachePolicy = \"cache-first\";\n *\n * // Or use constants\n * import { CACHE_POLICIES } from 'cachebay';\n * const policy = CACHE_POLICIES.CACHE_FIRST;\n * ```\n */\nexport type CachePolicy = \"cache-and-network\" | \"network-only\" | \"cache-first\" | \"cache-only\";\n\nexport const CACHE_AND_NETWORK = \"cache-and-network\" as const;\nexport const NETWORK_ONLY = \"network-only\" as const;\nexport const CACHE_FIRST = \"cache-first\" as const;\nexport const CACHE_ONLY = \"cache-only\" as const;\n\n/**\n * Valid cache policies\n */\nconst VALID_CACHE_POLICIES: readonly CachePolicy[] = [\n  \"cache-and-network\",\n  \"network-only\",\n  \"cache-first\",\n  \"cache-only\",\n] as const;\n\n/**\n * Validate and normalize cache policy\n * In dev: throws on invalid policy\n * In prod: warns and returns default policy\n */\nfunction validateCachePolicy(policy: any, defaultPolicy: CachePolicy = 'cache-first'): CachePolicy {\n  if (!policy) {\n    return defaultPolicy;\n  }\n\n  if (VALID_CACHE_POLICIES.includes(policy as CachePolicy)) {\n    return policy as CachePolicy;\n  }\n\n  const errorMessage = `Invalid cache policy: \"${policy}\". Valid policies are: ${VALID_CACHE_POLICIES.join(', ')}`;\n\n  if (__DEV__) {\n    throw new Error(errorMessage);\n  } else {\n    console.warn(`[cachebay] ${errorMessage}. Falling back to \"${defaultPolicy}\".`);\n    return defaultPolicy;\n  }\n}\n\n/**\n * GraphQL operation configuration\n *\n * @public\n * @template TData - Expected data type returned from the operation\n * @template TVars - Variables type for the operation\n * @example\n * ```typescript\n * const operation: Operation<{ user: User }, { id: string }> = {\n *   query: gql`query GetUser($id: ID!) { user(id: $id) { id name } }`,\n *   variables: { id: \"123\" },\n *   cachePolicy: \"cache-first\"\n * };\n * ```\n */\nexport interface Operation<TData = any, TVars = QueryVariables> {\n  /** GraphQL query string or DocumentNode */\n  query: string | DocumentNode;\n  /** Variables for the GraphQL operation */\n  variables?: TVars;\n  /** Cache policy for this operation */\n  cachePolicy?: CachePolicy;\n  /** Callback when data is successfully fetched/read */\n  onSuccess?: (data: TData) => void;\n  /** Callback when an error occurs */\n  onError?: (error: CombinedError) => void;\n  /** Callback for cached data (called synchronously before Promise resolves for cache hits) */\n  onCachedData?: (data: TData) => void;\n}\n\n// CombinedError is now imported from ./errors\n\n/**\n * Result of a GraphQL operation\n *\n * @public\n * @template TData - Type of data returned\n * @example\n * ```typescript\n * const result: OperationResult<{ user: User }> = {\n *   data: { user: { id: \"123\", name: \"Alice\" } },\n *   error: null,\n *   meta: { source: 'cache' }\n * };\n * ```\n */\nexport interface OperationResult<TData = any> {\n  /** Operation data if successful, null if error */\n  data: TData | null;\n  /** Error if operation failed, null if successful */\n  error: CombinedError | null;\n  /** Metadata about the operation result */\n  meta?: {\n    /** Source of the data: 'cache' for cached data, 'network' for fresh network data */\n    source?: 'cache' | 'network';\n  };\n}\n\nexport interface ObserverLike<T> {\n  next: (value: T) => void;\n  error: (err: any) => void;\n  complete?: () => void;\n}\n\nexport interface Unsubscribable {\n  unsubscribe: () => void;\n}\n\nexport interface ObservableLike<T> {\n  subscribe(observer: Partial<ObserverLike<T>>): Unsubscribable;\n}\n\nexport interface HttpTransport {\n  (context: HttpContext): Promise<OperationResult>;\n}\n\nexport interface WsTransport {\n  (context: WsContext): Promise<ObservableLike<OperationResult>>;\n}\n\n/**\n * Transport layer for GraphQL operations\n * Provides HTTP transport (required) and WebSocket transport (optional)\n *\n * @public\n * @example\n * ```typescript\n * const transport: Transport = {\n *   http: async (ctx) => {\n *     const res = await fetch('/graphql', {\n *       method: 'POST',\n *       headers: { 'Content-Type': 'application/json' },\n *       body: JSON.stringify({\n *         query: ctx.query,\n *         variables: ctx.variables\n *       })\n *     });\n *     return res.json();\n *   },\n *   ws: async (ctx) => {\n *     // WebSocket implementation for subscriptions\n *     return createWebSocketObservable(ctx);\n *   }\n * };\n * ```\n */\nexport interface Transport {\n  /** HTTP transport for queries and mutations (required) */\n  http: HttpTransport;\n  /** WebSocket transport for subscriptions (optional) */\n  ws?: WsTransport;\n}\n\nexport interface HttpContext {\n  query: string | DocumentNode;\n  variables?: QueryVariables;\n  operationType: \"query\" | \"mutation\";\n  compiledQuery: any; // CachePlan from planner\n}\n\nexport interface WsContext {\n  query: string | DocumentNode;\n  variables?: QueryVariables;\n  operationType: \"subscription\";\n  compiledQuery: any; // CachePlan from planner\n}\n\n/**\n * Operations\n */\n\nexport interface OperationsOptions {\n  transport: Transport;\n  suspensionTimeout?: number;\n  onQueryError?: (signature: string, error: CombinedError) => void;\n  onQueryData?: (event: {\n    signature: string;\n    data: any;\n    dependencies: Set<string>;\n    cachePolicy: CachePolicy;\n  }) => void;\n  cachePolicy?: CachePolicy;\n}\n\nexport interface OperationsDependencies {\n  planner: PlannerInstance;\n  documents: DocumentsInstance;\n  ssr: SSRInstance;\n}\n\nexport const createOperations = (\n  { transport, suspensionTimeout = 1000, onQueryError, onQueryData, cachePolicy: defaultCachePolicy }: OperationsOptions,\n  { planner, documents, ssr }: OperationsDependencies\n) => {\n  // Track query epochs to prevent stale responses from notifying watchers\n  // Key: query signature, Value: current epoch number\n  const queryEpochs = new Map<string, number>();\n\n  // Suspension tracking: last terminal emit time per query signature\n  const lastEmitBySig = new Map<string, number>();\n\n  // No need for error tracking maps - just call onQueryError callback\n\n  /**\n   * Check if we're within the suspension window for a query signature\n   */\n  const isWithinSuspension = (signature: string): boolean => {\n    const last = lastEmitBySig.get(signature);\n    return last != null && performance.now() - last <= suspensionTimeout;\n  };\n\n  /**\n   * Mark a query signature as having emitted (for suspension tracking)\n   */\n  const markEmitted = (signature: string): void => {\n    lastEmitBySig.set(signature, performance.now());\n  };\n\n  /**\n   * Execute a GraphQL query with suspension and hydration support\n   */\n  const executeQuery = async <TData = any, TVars = QueryVariables>({\n    query,\n    variables = {},\n    cachePolicy,\n    onSuccess,\n    onError,\n    onCachedData,\n  }: Operation<TData, TVars>): Promise<OperationResult<TData>> => {\n    // Validate and normalize cache policy\n    const rawPolicy = cachePolicy ?? defaultCachePolicy;\n    const effectiveCachePolicy = validateCachePolicy(rawPolicy, 'network-only');\n    const plan = planner.getPlan(query);\n    const signature = plan.makeSignature(true, variables);  // Always canonical\n\n    // Read from cache using documents directly\n    // Always read cache during SSR hydration, even for network-only\n    let cached;\n    if (effectiveCachePolicy !== 'network-only' || ssr.isHydrating()) {\n      cached = documents.materializeDocument({\n        document: query,\n        variables,\n        canonical: true,\n        fingerprint: true,\n        force: false,\n      });\n    }\n\n    const performRequest = async () => {\n      try {\n        const currentEpoch = (queryEpochs.get(signature) || 0) + 1;\n\n        queryEpochs.set(signature, currentEpoch);\n\n        // Network fetch\n        const context: HttpContext = {\n          query: plan.networkQuery, // Use the pre-compiled network-safe query string\n          variables,\n          operationType: \"query\",\n          compiledQuery: plan,\n        };\n\n        const result = await transport.http(context);\n\n        const isStale = queryEpochs.get(signature) !== currentEpoch;\n\n        // If stale, return null data with StaleResponseError wrapped in CombinedError\n        if (isStale) {\n          throw new StaleResponseError();\n        }\n\n        // Write result to cache if we have data (even with partial errors)\n        // This matches Relay/Apollo behavior: partial data is still useful\n        if (result.data) {\n          documents.normalizeDocument({\n            document: query,\n            variables,\n            data: result.data,\n          });\n\n          // Read back from cache to get normalized/materialized data\n          // This ensures the same reference as watchQuery would emit\n          const cachedAfterWrite = documents.materializeDocument({\n            document: query,\n            variables,\n            canonical: true,\n            fingerprint: true, // Get dependencies for watcher tracking\n            force: true,\n          });\n\n          // Notify watchers about query execution with data and dependencies\n          onQueryData?.({\n            signature,\n            data: cachedAfterWrite.data,\n            dependencies: cachedAfterWrite.dependencies,\n            cachePolicy: effectiveCachePolicy,\n          });\n\n          // Validate that we can materialize the data we just wrote\n          if (cachedAfterWrite.source === \"none\") {\n            if (__DEV__ && cachedAfterWrite.ok.miss) {\n              console.error(\n                '[cachebay] Failed to materialize query after network response.\\n' +\n                'This usually means the response is missing required fields.\\n' +\n                'Missing data:',\n                cachedAfterWrite.ok.miss\n              );\n            }\n            return {\n              data: null,\n              error: new CombinedError({\n                networkError: new Error(\n                  'Failed to materialize query after write. ' +\n                  'The response may be missing required fields like __typename or id.'\n                ),\n              }),\n            };\n          }\n\n          markEmitted(signature);\n\n          const successResult = {\n            data: cachedAfterWrite.data as TData,\n            error: result.error || null,\n            meta: { source: 'network' as const },\n          };\n          onSuccess?.(successResult.data);\n          return successResult;\n        }\n\n        // Mark as emitted for suspension tracking\n        markEmitted(signature);\n\n        // If we have an error but no data, propagate the error\n        if (result.error) {\n          const combinedError = result.error instanceof CombinedError\n            ? result.error\n            : new CombinedError({ networkError: result.error as Error });\n\n          onError?.(combinedError);\n          onQueryError?.(signature, combinedError);\n        }\n\n        return result as OperationResult<TData>;\n      } catch (error) {\n        const combinedError = new CombinedError({ networkError: error as Error });\n\n        // Only notify error callbacks if not a stale response\n        // Stale errors should be silently dropped\n        if (!(error instanceof StaleResponseError)) {\n          onError?.(combinedError);\n          onQueryError?.(signature, combinedError);\n        }\n\n        return {\n          data: null,\n          error: combinedError,\n        };\n      }\n    };\n\n    // SSR hydration or suspension window: return cached data if available\n    if (ssr.isHydrating() || isWithinSuspension(signature)) {\n      if (cached && cached.source !== \"none\") {\n        // Call onCachedData for SSR/suspension to set data synchronously\n        onCachedData?.(cached.data as TData);\n\n        const result = { data: cached.data as TData, error: null };\n        onSuccess?.(result.data);\n        return result;\n      }\n    }\n\n    // Call onCachedData synchronously for all cache policies (except network-only) when we have cached data\n    // This prevents loading flash by setting data before first render\n    if (effectiveCachePolicy !== 'network-only' && cached && cached.data) {\n      onCachedData?.(cached.data as TData);\n    }\n\n    if (effectiveCachePolicy === 'cache-only') {\n      if (!cached || cached.source === \"none\") {\n        const error = new CombinedError({ networkError: new CacheMissError() });\n        onError?.(error);\n\n        // Notify error callback\n        onQueryError?.(signature, error);\n\n        return { data: null, error };\n      }\n\n      // Notify watchers about cache-only hit with data and dependencies\n      onQueryData?.({\n        signature,\n        data: cached.data,\n        dependencies: cached.dependencies,\n        cachePolicy: effectiveCachePolicy,\n      });\n\n      const result = { data: cached.data as TData, error: null };\n      onSuccess?.(result.data);\n      return result;\n    }\n\n    if (effectiveCachePolicy === 'cache-first') {\n      if (cached && cached.ok.canonical && cached.ok.strict) {\n        // Check if strict signature matches (pagination args haven't changed)\n        // If strictSignature is present and matches, return cached data\n        // If strictSignature doesn't match, fetch from network (pagination changed)\n        const strictSignature = plan.makeSignature(false, variables);\n        const strictMatches = cached.ok.strictSignature === strictSignature;\n        \n        if (strictMatches) {\n          // Strict match: pagination args haven't changed, return cached data\n          onQueryData?.({\n            signature,\n            data: cached.data,\n            dependencies: cached.dependencies,\n            cachePolicy: effectiveCachePolicy,\n          });\n\n          const result = { data: cached.data as TData, error: null };\n          onSuccess?.(result.data);\n          return result;\n        }\n        // No strict match: pagination args changed, fall through to network fetch\n      }\n    }\n\n    if (effectiveCachePolicy === 'cache-and-network') {\n      if (cached && cached.ok.canonical) {\n        // Notify watchers so lastData is set (prevents duplicate emission if network data is same)\n        onQueryData?.({\n          signature,\n          data: cached.data,\n          dependencies: cached.dependencies,\n          cachePolicy: effectiveCachePolicy,\n        });\n\n        // Return the network request Promise (resolves with fresh network data)\n        return performRequest();\n      }\n    }\n\n    return performRequest();\n  };\n\n  /**\n   * Execute a GraphQL mutation\n   */\n  const executeMutation = async <TData = any, TVars = QueryVariables>({\n    query,\n    variables,\n    ...restOptions\n  }: Operation<TData, TVars>): Promise<OperationResult<TData>> => {\n    const vars = variables || ({} as TVars);\n    const compiledQuery = planner.getPlan(query);\n\n    const context: HttpContext = {\n      query,\n      variables: vars,\n      operationType: \"mutation\",\n      compiledQuery,\n    };\n\n    try {\n      const result = await transport.http(context);\n\n      // Write successful mutation result to cache\n      if (result.data && !result.error) {\n        documents.normalizeDocument({\n          document: query,\n          variables: vars,\n          data: result.data,\n        });\n      }\n\n      return result as OperationResult<TData>;\n    } catch (err) {\n      return {\n        data: null,\n        error: new CombinedError({\n          networkError: err as Error,\n        }),\n      };\n    }\n  };\n\n  /**\n   * Execute a GraphQL subscription - returns observable that writes data to cache\n   */\n  const executeSubscription = async <TData = any, TVars = QueryVariables>({\n    query,\n    variables,\n  }: Operation<TData, TVars>): Promise<ObservableLike<OperationResult<TData>>> => {\n    if (!transport.ws) {\n      throw new Error(\n        \"WebSocket transport is not configured. Please provide 'transport.ws' in createCachebay options to use subscriptions.\"\n      );\n    }\n\n    const vars = variables || ({} as TVars);\n    const plan = planner.getPlan(query);\n\n    const context: WsContext = {\n      query: plan.networkQuery,\n      variables: vars,\n      operationType: \"subscription\",\n      compiledQuery: plan,\n    };\n\n    try {\n      const observable = await transport.ws(context);\n\n      // Wrap observable to write incoming data to cache\n      return {\n        subscribe(observer: Partial<ObserverLike<OperationResult<TData>>>) {\n          return observable.subscribe({\n            next: (result: OperationResult<TData>) => {\n              // Write successful subscription data to cache\n              if (result.data && !result.error) {\n                documents.normalizeDocument({\n                  document: query,\n                  variables: vars,\n                  data: result.data,\n                });\n              }\n\n              // Forward to observer\n              if (observer.next) {\n                observer.next(result);\n              }\n            },\n            error: (err: any) => {\n              // Forward error to observer\n              if (observer.error) {\n                observer.error(err);\n              }\n            },\n            complete: () => {\n              // Forward completion to observer\n              if (observer.complete) {\n                observer.complete();\n              }\n            },\n          });\n        },\n      };\n    } catch (err) {\n      return {\n        subscribe(observer: Partial<ObserverLike<OperationResult<TData>>>) {\n          if (observer.error) {\n            observer.error(err);\n          }\n          return { unsubscribe: () => { } };\n        },\n      };\n    }\n  };\n\n  return {\n    executeQuery,\n    executeMutation,\n    executeSubscription,\n  };\n};\n\nexport type OperationsInstance = ReturnType<typeof createOperations>;\n","import { ROOT_ID } from \"./constants\";\nimport { buildConnectionCanonicalKey } from \"../compiler/utils\";\nimport type { GraphInstance } from \"./graph\";\n\ntype OptimisticDependencies = { graph: GraphInstance };\n\nconst ENTITY_WRITE = Symbol(\"EntityWrite\");\nconst ENTITY_DELETE = Symbol(\"EntityDelete\");\nconst CONNECTION_ADD_NODE = Symbol(\"ConnectionAddNode\");\nconst CONNECTION_REMOVE_NODE = Symbol(\"ConnectionRemoveNode\");\nconst CONNECTION_PATCH = Symbol(\"ConnectionPatch\");\nconst EDGE_INDEX_REGEX = /\\.edges:(\\d+)$/;\n\ntype EntityOp =\n  | { kind: typeof ENTITY_WRITE; recordId: string; patch: Record<string, any>; policy: \"merge\" | \"replace\" }\n  | { kind: typeof ENTITY_DELETE; recordId: string };\n\ntype ConnectionOp =\n  | {\n    kind: typeof CONNECTION_ADD_NODE;\n    connectionKey: string;\n    entityKey: string;\n    meta?: any;\n    position: \"start\" | \"end\" | \"before\" | \"after\";\n    anchor?: string | null;\n  }\n  | { kind: typeof CONNECTION_REMOVE_NODE; connectionKey: string; entityKey: string }\n  | { kind: typeof CONNECTION_PATCH; connectionKey: string; patch: Record<string, any> };\n\ntype Layer = {\n  id: number;\n  entityOps: EntityOp[];\n  connectionOps: ConnectionOp[];\n  touched: Set<string>;\n  localBase: Map<string, any | null>;\n  builder: (tx: BuilderInstance, ctx: BuilderContext) => void;\n};\n\ntype ConnectionArgs = {\n  parent: \"Query\" | string | { __typename?: string; id?: any };\n  key: string;\n  filters?: Record<string, any>;\n};\n\ntype EntityRef = string | { __typename?: string; id?: any };\n\ntype PatchInput = Record<string, any> | ((prev: any) => Record<string, any>);\n\ntype ConnectionAPI = {\n  addNode: (\n    node: any,\n    opts?: { position?: \"start\" | \"end\" | \"before\" | \"after\"; anchor?: EntityRef; edge?: Record<string, any> },\n  ) => void;\n  removeNode: (ref: EntityRef) => void;\n  patch: (patchOrFn: PatchInput) => void;\n  key: string;\n};\n\ntype BuilderInstance = {\n  patch: (target: EntityRef, patchOrFn: PatchInput, opts?: { mode?: \"merge\" | \"replace\" }) => void;\n  delete: (target: EntityRef) => void;\n  connection: (argsOrKey: ConnectionArgs | string) => ConnectionAPI;\n};\n\ntype BuilderContext = {\n  phase: \"optimistic\" | \"commit\";\n  data?: any;\n};\n\nexport type OptimisticTransaction = {\n  commit: (data?: any) => void;\n  revert: () => void;\n};\n\nconst cloneJSON = <T,>(value: T): T => {\n  return JSON.parse(JSON.stringify(value));\n};\n\nconst parseRecordId = (recordId: string): { typename?: string; id?: string } => {\n  const colonIndex = recordId.indexOf(\":\");\n\n  if (colonIndex < 0) {\n    return {};\n  }\n\n  return {\n    typename: recordId.slice(0, colonIndex) || undefined,\n    id: recordId.slice(colonIndex + 1) || undefined,\n  };\n};\n\nconst isCanonicalKey = (id: string): boolean => {\n  return id.startsWith(\"@connection.\");\n};\n\nconst extractEdgeMeta = (meta: any): any => {\n  if (!meta || typeof meta !== \"object\") {\n    return undefined;\n  }\n\n  const result: any = {};\n\n  for (const key in meta) {\n    if (key !== \"cursor\") {\n      result[key] = meta[key];\n    }\n  }\n\n  return Object.keys(result).length > 0 ? result : undefined;\n};\n\nconst getCursorIndexKey = (canonicalKey: string): string => {\n  return `${canonicalKey}::cursorIndex`;\n};\n\nconst readCursorIndex = (graph: GraphInstance, canonicalKey: string): Record<string, number> => {\n  const index = graph.getRecord(getCursorIndexKey(canonicalKey));\n  return (index as Record<string, number>) || {};\n};\n\nconst writeCursorIndex = (graph: GraphInstance, canonicalKey: string, index: Record<string, number>): void => {\n  graph.putRecord(getCursorIndexKey(canonicalKey), index);\n};\n\nconst writeCursorIndexPatch = (graph: GraphInstance, canonicalKey: string, patch: Record<string, number | undefined>): void => {\n  graph.putRecord(getCursorIndexKey(canonicalKey), patch);\n};\n\nconst getEdgeCursor = (graph: GraphInstance, edgeRef: string): string | null => {\n  const edge = graph.getRecord(edgeRef);\n  return edge?.cursor || null;\n};\n\nconst shiftCursorIndicesAfter = (graph: GraphInstance, canonicalKey: string, fromPosition: number, shift: number): void => {\n  if (shift === 0) {\n    return;\n  }\n\n  const cursorIndex = readCursorIndex(graph, canonicalKey);\n  const keys = Object.keys(cursorIndex);\n\n  if (keys.length === 0) {\n    return;\n  }\n\n  const patch: Record<string, number> = {};\n  let hasChanges = false;\n\n  for (let i = 0; i < keys.length; i++) {\n    const cursor = keys[i];\n    const pos = cursorIndex[cursor];\n\n    if (pos >= fromPosition) {\n      patch[cursor] = pos + shift;\n      hasChanges = true;\n    }\n  }\n\n  if (hasChanges) {\n    writeCursorIndexPatch(graph, canonicalKey, patch);\n  }\n};\n\nconst addCursorToIndex = (graph: GraphInstance, canonicalKey: string, cursor: string, position: number): void => {\n  const cursorIndex = readCursorIndex(graph, canonicalKey);\n\n  if (cursor in cursorIndex) {\n    return;\n  }\n\n  writeCursorIndexPatch(graph, canonicalKey, { [cursor]: position });\n};\n\nconst removeCursorFromIndex = (graph: GraphInstance, canonicalKey: string, cursor: string): void => {\n  const cursorIndex = readCursorIndex(graph, canonicalKey);\n\n  if (!(cursor in cursorIndex)) {\n    return;\n  }\n\n  graph.putRecord(getCursorIndexKey(canonicalKey), { [cursor]: undefined });\n};\n\nconst getEdgeRefs = (canonical: any): string[] => {\n  const edgesField = canonical?.edges;\n\n  if (!edgesField || typeof edgesField !== \"object\") {\n    return [];\n  }\n\n  return Array.isArray(edgesField.__refs) ? edgesField.__refs : [];\n};\n\nconst setEdgeRefs = (canonical: any, refs: string[]): void => {\n  if (!canonical.edges || typeof canonical.edges !== \"object\") {\n    canonical.edges = { __refs: refs };\n  } else {\n    canonical.edges.__refs = refs;\n  }\n};\n\nconst shallowCopy = (source: any): any => {\n  const result: any = {};\n\n  for (const key in source) {\n    result[key] = source[key];\n  }\n\n  return result;\n};\n\n// === Edge key counter (avoids O(n) scans for next index) ===\n\nconst getEdgeCounterKey = (canonicalKey: string): string => {\n  return `${canonicalKey}::edgeCounter`;\n};\n\nconst readEdgeCounter = (graph: GraphInstance, canonicalKey: string): number => {\n  const rec = graph.getRecord(getEdgeCounterKey(canonicalKey));\n  // Store as object { value } to align with patch semantics of putRecord\n  if (rec && typeof rec === \"object\" && typeof (rec as any).value === \"number\") {\n    return (rec as any).value as number;\n  }\n  return 0;\n};\n\nconst nextEdgeIndex = (graph: GraphInstance, canonicalKey: string): number => {\n  const next = readEdgeCounter(graph, canonicalKey) + 1;\n  graph.putRecord(getEdgeCounterKey(canonicalKey), { value: next });\n  return next;\n};\n\n// Kept for back-compat in case it's ever called elsewhere.\n// Now falls back to regex scan ONLY if no counter is present.\nconst findNextEdgeIndex = (canonical: any, graph?: GraphInstance, canonicalKey?: string): number => {\n  if (graph && canonicalKey) {\n    return nextEdgeIndex(graph, canonicalKey);\n  }\n\n  const refs = getEdgeRefs(canonical);\n\n  if (refs.length === 0) {\n    return 0;\n  }\n\n  let maxIndex = -1;\n\n  for (let i = 0; i < refs.length; i++) {\n    const match = refs[i]?.match(EDGE_INDEX_REGEX);\n\n    if (match) {\n      const number = Number(match[1]);\n\n      if (!Number.isNaN(number) && number > maxIndex) {\n        maxIndex = number;\n      }\n    }\n  }\n\n  return maxIndex + 1;\n};\n\nconst findEdgeByNode = (graph: GraphInstance, refs: string[], entityKey: string): number => {\n  for (let i = 0; i < refs.length; i++) {\n    const edge = graph.getRecord(refs[i]);\n\n    if (edge?.node?.__ref === entityKey) {\n      return i;\n    }\n  }\n\n  return -1;\n};\n\nconst findAnchorIndex = (graph: GraphInstance, refs: string[], anchorKey: string): number => {\n  for (let i = 0; i < refs.length; i++) {\n    const edge = graph.getRecord(refs[i]);\n\n    if (edge?.node?.__ref === anchorKey) {\n      return i;\n    }\n  }\n\n  const anchorId = anchorKey.includes(\":\") ? anchorKey.slice(anchorKey.indexOf(\":\") + 1) : anchorKey;\n\n  for (let i = 0; i < refs.length; i++) {\n    const edge = graph.getRecord(refs[i]);\n    const nodeKey = edge?.node?.__ref;\n\n    if (!nodeKey) {\n      continue;\n    }\n\n    const node = graph.getRecord(nodeKey);\n\n    if (node?.id != null && String(node.id) === String(anchorId)) {\n      return i;\n    }\n  }\n\n  return -1;\n};\n\nconst insertEdge = (\n  graph: GraphInstance,\n  canonicalKey: string,\n  canonical: any,\n  entityKey: string,\n  edgeMeta: any,\n  position: \"start\" | \"end\" | \"before\" | \"after\",\n  anchorKey?: string | null,\n): void => {\n  const refs = getEdgeRefs(canonical);\n  const existingIndex = findEdgeByNode(graph, refs, entityKey);\n\n  if (existingIndex >= 0) {\n    if (edgeMeta) {\n      graph.putRecord(refs[existingIndex]!, shallowCopy(edgeMeta));\n    }\n    return;\n  }\n\n  // Use O(1) counter instead of scanning existing refs\n  const edgeIndex = findNextEdgeIndex(canonical, graph, canonicalKey);\n  const edgeKey = `${canonicalKey}.edges.${edgeIndex}`;\n  const nodeType = entityKey.split(\":\")[0]?.trim() || \"\";\n  const edgeTypename = nodeType ? `${nodeType}Edge` : \"Edge\";\n\n  const edgeRecord: any = {\n    __typename: edgeTypename,\n    node: { __ref: entityKey },\n  };\n\n  if (edgeMeta) {\n    for (const key in edgeMeta) {\n      edgeRecord[key] = edgeMeta[key];\n    }\n  }\n\n  graph.putRecord(edgeKey, edgeRecord);\n\n  const newRefs = [...refs];\n  let insertPosition: number;\n\n  if (position === \"start\") {\n    newRefs.unshift(edgeKey);\n    insertPosition = 0;\n  } else if (position === \"end\") {\n    newRefs.push(edgeKey);\n    insertPosition = newRefs.length - 1;\n  } else {\n    const insertAt = anchorKey ? findAnchorIndex(graph, refs, anchorKey) : -1;\n\n    if (insertAt < 0) {\n      if (position === \"before\") {\n        newRefs.unshift(edgeKey);\n        insertPosition = 0;\n      } else {\n        newRefs.push(edgeKey);\n        insertPosition = newRefs.length - 1;\n      }\n    } else {\n      insertPosition = position === \"before\" ? insertAt : insertAt + 1;\n      newRefs.splice(insertPosition, 0, edgeKey);\n    }\n  }\n\n  setEdgeRefs(canonical, newRefs);\n\n  const cursor = getEdgeCursor(graph, edgeKey);\n  if (cursor) {\n    if (insertPosition < refs.length) {\n      shiftCursorIndicesAfter(graph, canonicalKey, insertPosition, 1);\n    }\n    addCursorToIndex(graph, canonicalKey, cursor, insertPosition);\n  } else if (insertPosition < refs.length) {\n    shiftCursorIndicesAfter(graph, canonicalKey, insertPosition, 1);\n  }\n};\n\nconst removeEdge = (graph: GraphInstance, canonicalKey: string, canonical: any, entityKey: string): boolean => {\n  const refs = getEdgeRefs(canonical);\n\n  for (let i = 0; i < refs.length; i++) {\n    const edge = graph.getRecord(refs[i]);\n\n    if (edge?.node?.__ref === entityKey) {\n      const newRefs = [...refs];\n      newRefs.splice(i, 1);\n      setEdgeRefs(canonical, newRefs);\n\n      const cursor = getEdgeCursor(graph, refs[i]);\n      if (cursor) {\n        removeCursorFromIndex(graph, canonicalKey, cursor);\n      }\n      shiftCursorIndicesAfter(graph, canonicalKey, i + 1, -1);\n\n      return true;\n    }\n  }\n\n  return false;\n};\n\nconst createEmptyCanonical = (canonicalKey: string): any => {\n  return {\n    __typename: \"Connection\",\n    edges: { __refs: [] },\n    pageInfo: { __ref: `${canonicalKey}.pageInfo` },\n  };\n};\n\nconst cloneCanonical = (canonical: any): any => {\n  return {\n    __typename: canonical.__typename,\n    edges: { __refs: [...getEdgeRefs(canonical)] },\n    pageInfo: canonical.pageInfo || {},\n  };\n};\n\nconst ensurePageInfo = (graph: GraphInstance, canonicalKey: string): void => {\n  const pageInfoKey = `${canonicalKey}.pageInfo`;\n  if (!graph.getRecord(pageInfoKey)) {\n    graph.putRecord(pageInfoKey, { __typename: \"PageInfo\" });\n  }\n};\n\nconst patchPageInfo = (graph: GraphInstance, canonical: any, pageInfoPatch: any): void => {\n  const pageInfoRef = canonical.pageInfo?.__ref;\n\n  if (!pageInfoRef) {\n    return;\n  }\n\n  const current = graph.getRecord(pageInfoRef) || {};\n  const updated = shallowCopy(current);\n\n  for (const key in pageInfoPatch) {\n    updated[key] = pageInfoPatch[key];\n  }\n\n  graph.putRecord(pageInfoRef, updated);\n};\n\nconst writeEntity = (graph: GraphInstance, recordId: string, patch: Record<string, any>, policy: \"merge\" | \"replace\"): void => {\n  const prevRecord = graph.getRecord(recordId);\n  const { typename, id } = parseRecordId(recordId);\n\n  if (policy === \"replace\" || !prevRecord) {\n    const nextTypename = (patch.__typename as string) ?? typename ?? prevRecord?.__typename;\n    const nextId = (patch.id != null ? String(patch.id) : undefined) ?? id ?? prevRecord?.id;\n    const record = shallowCopy(patch);\n\n    if (record.__typename === undefined && nextTypename) {\n      record.__typename = nextTypename;\n    }\n\n    if (record.id === undefined && nextId) {\n      record.id = nextId;\n    }\n\n    graph.putRecord(recordId, record);\n  } else {\n    graph.putRecord(recordId, patch);\n  }\n};\n\nconst deleteEntity = (graph: GraphInstance, recordId: string): void => {\n  graph.removeRecord(recordId);\n};\n\nconst restoreEntity = (graph: GraphInstance, recordId: string, snapshot: any | null): void => {\n  if (snapshot === null) {\n    graph.removeRecord(recordId);\n    return;\n  }\n\n  const current = graph.getRecord(recordId);\n\n  if (current) {\n    const deletions: Record<string, any> = {};\n\n    for (const key in current) {\n      if (!(key in snapshot)) {\n        deletions[key] = undefined;\n      }\n    }\n\n    if (Object.keys(deletions).length > 0) {\n      graph.putRecord(recordId, deletions);\n    }\n  }\n\n  graph.putRecord(recordId, snapshot);\n};\n\nconst captureBaseline = (layer: Layer, graph: GraphInstance, recordId: string): void => {\n  if (layer.touched.has(recordId)) {\n    return;\n  }\n\n  layer.touched.add(recordId);\n\n  if (!layer.localBase.has(recordId)) {\n    const snapshot = graph.getRecord(recordId);\n    layer.localBase.set(recordId, snapshot ? cloneJSON(snapshot) : null);\n  }\n};\n\nconst applyEntityOp = (graph: GraphInstance, op: EntityOp): void => {\n  if (op.kind === ENTITY_WRITE) {\n    writeEntity(graph, op.recordId, op.patch, op.policy);\n  } else {\n    deleteEntity(graph, op.recordId);\n  }\n};\n\nconst applyConnectionOp = (graph: GraphInstance, op: ConnectionOp): void => {\n  let canonical = graph.getRecord(op.connectionKey);\n\n  if (!canonical || typeof canonical !== \"object\") {\n    canonical = createEmptyCanonical(op.connectionKey);\n    if (op.kind !== CONNECTION_REMOVE_NODE) {\n      ensurePageInfo(graph, op.connectionKey);\n    }\n  } else {\n    canonical = cloneCanonical(canonical);\n  }\n\n  if (op.kind === CONNECTION_ADD_NODE) {\n    insertEdge(graph, op.connectionKey, canonical, op.entityKey, op.meta, op.position, op.anchor);\n  } else if (op.kind === CONNECTION_REMOVE_NODE) {\n    removeEdge(graph, op.connectionKey, canonical, op.entityKey);\n  } else {\n    if (op.patch.pageInfo) {\n      patchPageInfo(graph, canonical, op.patch.pageInfo);\n    }\n\n    for (const key in op.patch) {\n      if (key !== \"pageInfo\") {\n        canonical[key] = op.patch[key];\n      }\n    }\n  }\n\n  graph.putRecord(op.connectionKey, canonical);\n};\n\nconst recordOp = (layer: Layer, graph: GraphInstance, op: EntityOp | ConnectionOp): void => {\n  const recordId = \"recordId\" in op ? op.recordId : op.connectionKey;\n  captureBaseline(layer, graph, recordId);\n\n  if (\"recordId\" in op) {\n    applyEntityOp(graph, op);\n  } else {\n    applyConnectionOp(graph, op);\n  }\n};\n\nconst revertEntities = (layer: Layer, graph: GraphInstance): void => {\n  for (const [recordId, snapshot] of layer.localBase) {\n    if (!isCanonicalKey(recordId)) {\n      restoreEntity(graph, recordId, snapshot);\n    }\n  }\n};\n\nconst revertConnectionOp = (layer: Layer, graph: GraphInstance, op: ConnectionOp): void => {\n  let canonical = graph.getRecord(op.connectionKey);\n\n  if (!canonical || typeof canonical !== \"object\") {\n    canonical = createEmptyCanonical(op.connectionKey);\n  } else {\n    canonical = cloneCanonical(canonical);\n  }\n\n  if (op.kind === CONNECTION_ADD_NODE) {\n    removeEdge(graph, op.connectionKey, canonical, op.entityKey);\n    graph.putRecord(op.connectionKey, canonical);\n    return;\n  }\n\n  if (op.kind === CONNECTION_REMOVE_NODE) {\n    const baseline = layer.localBase.get(op.connectionKey) || {};\n    const baseRefs = getEdgeRefs(baseline);\n\n    let edgeRef: string | null = null;\n\n    for (let i = 0; i < baseRefs.length; i++) {\n      const edge = graph.getRecord(baseRefs[i]);\n      if (edge?.node?.__ref === op.entityKey) {\n        edgeRef = baseRefs[i];\n        break;\n      }\n    }\n\n    if (edgeRef) {\n      const wantIndex = baseRefs.indexOf(edgeRef);\n      const currentRefs = getEdgeRefs(canonical);\n\n      if (!currentRefs.includes(edgeRef)) {\n        const newRefs = [...currentRefs];\n        const insertPosition = Math.max(0, Math.min(wantIndex, newRefs.length));\n        newRefs.splice(insertPosition, 0, edgeRef);\n        setEdgeRefs(canonical, newRefs);\n\n        const cursor = getEdgeCursor(graph, edgeRef);\n        if (cursor) {\n          if (insertPosition < currentRefs.length) {\n            shiftCursorIndicesAfter(graph, op.connectionKey, insertPosition, 1);\n          }\n          addCursorToIndex(graph, op.connectionKey, cursor, insertPosition);\n        } else if (insertPosition < currentRefs.length) {\n          shiftCursorIndicesAfter(graph, op.connectionKey, insertPosition, 1);\n        }\n      }\n    } else {\n      insertEdge(graph, op.connectionKey, canonical, op.entityKey, undefined, \"end\", null);\n    }\n\n    graph.putRecord(op.connectionKey, canonical);\n    return;\n  }\n\n  if (op.kind === CONNECTION_PATCH) {\n    const baseline = layer.localBase.get(op.connectionKey) || {};\n\n    if (op.patch.pageInfo) {\n      const pageInfoRef = canonical.pageInfo?.__ref;\n\n      if (pageInfoRef) {\n        const basePageInfo = baseline.pageInfo?.__ref ? graph.getRecord(baseline.pageInfo.__ref) || {} : {};\n        const current = graph.getRecord(pageInfoRef) || {};\n        const updated = shallowCopy(current);\n\n        for (const key in op.patch.pageInfo) {\n          const baseValue = basePageInfo[key];\n\n          if (baseValue === undefined) {\n            delete updated[key];\n          } else {\n            updated[key] = baseValue;\n          }\n        }\n\n        graph.putRecord(pageInfoRef, updated);\n      }\n    }\n\n    for (const key in op.patch) {\n      if (key === \"pageInfo\") {\n        continue;\n      }\n\n      const baseValue = baseline[key];\n      if (baseValue === undefined) {\n        delete canonical[key];\n      } else {\n        canonical[key] = baseValue;\n      }\n    }\n\n    graph.putRecord(op.connectionKey, canonical);\n  }\n};\n\nconst revertConnections = (layer: Layer, graph: GraphInstance): void => {\n  for (let i = layer.connectionOps.length - 1; i >= 0; i--) {\n    revertConnectionOp(layer, graph, layer.connectionOps[i]);\n  }\n};\n\nexport const createOptimistic = ({ graph }: OptimisticDependencies) => {\n  const pending = new Set<Layer>();\n  let nextLayerId = 1;\n\n  const resolveParentId = (parent: \"Query\" | string | { __typename?: string; id?: any }): string => {\n    if (typeof parent === \"string\") {\n      return parent === \"Query\" ? ROOT_ID : parent;\n    }\n\n    if (parent === \"Query\") {\n      return ROOT_ID;\n    }\n\n    return graph.identify(parent) || ROOT_ID;\n  };\n\n  const createBuilder = (layer: Layer, recording: boolean): BuilderInstance => {\n    const ensureEntity = (node: any): string | null => {\n      const entityKey = graph.identify(node);\n\n      if (!entityKey) {\n        return null;\n      }\n\n      // Avoid no-op writes (perf): if node only has __typename/id, skip the merge\n      const patch: any = {};\n      for (const key in node) {\n        if (key !== \"__typename\" && key !== \"id\") {\n          patch[key] = node[key];\n        }\n      }\n      const hasFields = Object.keys(patch).length > 0;\n\n      const op: EntityOp = { kind: ENTITY_WRITE, recordId: entityKey, patch, policy: \"merge\" };\n\n      if (recording) {\n        if (hasFields) {\n          layer.entityOps.push(op);\n          recordOp(layer, graph, op);\n        }\n      } else {\n        if (hasFields) {\n          writeEntity(graph, entityKey, patch, \"merge\");\n        }\n      }\n\n      return entityKey;\n    };\n\n    const resolveAnchor = (anchor?: string | { __typename: string; id: any } | null): string | null => {\n      if (!anchor) {\n        return null;\n      }\n\n      return typeof anchor === \"string\" ? anchor : graph.identify(anchor) || null;\n    };\n\n    return {\n      patch(target, patchOrFn, opts) {\n        const recordId = typeof target === \"string\" ? target : graph.identify(target);\n        if (!recordId) {\n          return;\n        }\n\n        const previous = graph.getRecord(recordId) || {};\n        const delta = typeof patchOrFn === \"function\" ? patchOrFn(cloneJSON(previous)) : patchOrFn;\n\n        if (!delta || typeof delta !== \"object\") {\n          return;\n        }\n\n        // Skip empty patch objects\n        let hasAny = false;\n        for (const _ in delta) {\n          hasAny = true;\n          break;\n        }\n        if (!hasAny) {\n          return;\n        }\n\n        const mode = opts?.mode ?? \"merge\";\n        const patch = shallowCopy(delta);\n        const op: EntityOp = { kind: ENTITY_WRITE, recordId, patch, policy: mode };\n\n        if (recording) {\n          layer.entityOps.push(op);\n          recordOp(layer, graph, op);\n        } else {\n          writeEntity(graph, recordId, patch, mode);\n        }\n      },\n\n      delete(target) {\n        const recordId = typeof target === \"string\" ? target : graph.identify(target);\n        if (!recordId) {\n          return;\n        }\n\n        const op: EntityOp = { kind: ENTITY_DELETE, recordId };\n\n        if (recording) {\n          layer.entityOps.push(op);\n          recordOp(layer, graph, op);\n        } else {\n          deleteEntity(graph, recordId);\n        }\n      },\n\n      connection(input) {\n        let canonicalKey: string;\n\n        if (typeof input === \"string\") {\n          canonicalKey = input;\n        } else {\n          const parent = resolveParentId(input.parent);\n          const filters = input.filters || {};\n          const filterKeys = Object.keys(filters);\n\n          canonicalKey = buildConnectionCanonicalKey(\n            {\n              fieldName: input.key,\n              buildArgs: (v: any) => v || {},\n              connectionFilters: filterKeys,\n            } as any,\n            parent,\n            filters,\n          );\n        }\n\n        return {\n          addNode(node, opts = {}) {\n            const entityKey = ensureEntity(node);\n            if (!entityKey) {\n              return;\n            }\n\n            const meta = extractEdgeMeta(opts.edge);\n            const position = opts.position ?? \"end\";\n            const anchor = resolveAnchor(opts.anchor);\n\n            const op: ConnectionOp = {\n              kind: CONNECTION_ADD_NODE,\n              connectionKey: canonicalKey,\n              entityKey,\n              meta,\n              position,\n              anchor,\n            };\n\n            if (recording) {\n              layer.connectionOps.push(op);\n              recordOp(layer, graph, op);\n            } else {\n              applyConnectionOp(graph, op);\n            }\n          },\n\n          removeNode(ref) {\n            const entityKey = typeof ref === \"string\" ? ref : graph.identify(ref);\n            if (!entityKey) {\n              return;\n            }\n\n            const op: ConnectionOp = { kind: CONNECTION_REMOVE_NODE, connectionKey: canonicalKey, entityKey };\n\n            if (recording) {\n              layer.connectionOps.push(op);\n              recordOp(layer, graph, op);\n            } else {\n              applyConnectionOp(graph, op);\n            }\n          },\n\n          patch(patchOrFn) {\n            const previous = graph.getRecord(canonicalKey) || {};\n            const delta = typeof patchOrFn === \"function\" ? patchOrFn(cloneJSON(previous)) : patchOrFn;\n\n            if (!delta || typeof delta !== \"object\") {\n              return;\n            }\n\n            // Skip empty patch objects\n            let hasAny = false;\n            for (const _ in delta) {\n              hasAny = true;\n              break;\n            }\n            if (!hasAny) {\n              return;\n            }\n\n            const patch = shallowCopy(delta);\n            const op: ConnectionOp = { kind: CONNECTION_PATCH, connectionKey: canonicalKey, patch };\n\n            if (recording) {\n              layer.connectionOps.push(op);\n              recordOp(layer, graph, op);\n            } else {\n              applyConnectionOp(graph, op);\n            }\n          },\n\n          key: canonicalKey,\n        };\n      },\n    };\n  };\n\n  const modifyOptimistic = (builder: (tx: BuilderInstance, ctx: BuilderContext) => void): OptimisticTransaction => {\n    const layer: Layer = {\n      id: nextLayerId++,\n      entityOps: [],\n      connectionOps: [],\n      touched: new Set(),\n      localBase: new Map(),\n      builder,\n    };\n\n    pending.add(layer);\n\n    builder(createBuilder(layer, true), { phase: \"optimistic\" });\n\n    return {\n      commit(data?: any) {\n        revertEntities(layer, graph);\n        revertConnections(layer, graph);\n\n        layer.localBase.clear();\n        layer.entityOps.length = 0;\n        layer.connectionOps.length = 0;\n        layer.touched.clear();\n\n        layer.builder(createBuilder(layer, false), { phase: \"commit\", data });\n        pending.delete(layer);\n      },\n\n      revert() {\n        if (!pending.delete(layer)) {\n          return;\n        }\n\n        revertEntities(layer, graph);\n        revertConnections(layer, graph);\n\n        layer.localBase.clear();\n        layer.entityOps.length = 0;\n        layer.connectionOps.length = 0;\n        layer.touched.clear();\n      },\n    };\n  };\n\n  const replayOptimistic = (hint?: { connections?: string[]; entities?: string[] }): { added: string[]; removed: string[] } => {\n    const connectionScope = hint?.connections ? new Set(hint.connections) : null;\n    const entityScope = hint?.entities ? new Set(hint.entities) : null;\n\n    const added: string[] = [];\n    const removed: string[] = [];\n\n    const sortedLayers = Array.from(pending).sort((a, b) => a.id - b.id);\n\n    for (const layer of sortedLayers) {\n      for (const op of layer.entityOps) {\n        if (entityScope && !entityScope.has(op.recordId)) {\n          continue;\n        }\n        applyEntityOp(graph, op);\n      }\n\n      for (const op of layer.connectionOps) {\n        if (connectionScope && !connectionScope.has(op.connectionKey)) {\n          continue;\n        }\n\n        if (op.kind === CONNECTION_ADD_NODE) {\n          added.push(op.entityKey);\n        } else if (op.kind === CONNECTION_REMOVE_NODE) {\n          removed.push(op.entityKey);\n        }\n\n        applyConnectionOp(graph, op);\n      }\n    }\n\n    return { added, removed };\n  };\n\n  const inspect = (): { total: number; layers: any[] } => {\n    const sortedLayers = Array.from(pending).sort((a, b) => a.id - b.id);\n    const layers: any[] = [];\n\n    for (const layer of sortedLayers) {\n      const entityOps: any[] = [];\n\n      for (const op of layer.entityOps) {\n        entityOps.push(shallowCopy(op));\n      }\n\n      const connectionOps: any[] = [];\n\n      for (const op of layer.connectionOps) {\n        connectionOps.push(shallowCopy(op));\n      }\n\n      const touched: string[] = [];\n\n      for (const key of layer.touched) {\n        touched.push(key);\n      }\n\n      const localBaseKeys: string[] = [];\n      const localBase: Record<string, any> = {};\n\n      for (const [key, value] of layer.localBase) {\n        localBaseKeys.push(key);\n        localBase[key] = cloneJSON(value);\n      }\n\n      layers.push({\n        id: layer.id,\n        entityOps,\n        connectionOps,\n        touched,\n        localBaseKeys,\n        localBase,\n      });\n    }\n\n    return { total: layers.length, layers };\n  };\n\n  return { modifyOptimistic, replayOptimistic, inspect };\n};\n\nexport type OptimisticInstance = ReturnType<typeof createOptimistic>;\n","import { compilePlan, isCachePlan, type CachePlan } from \"../compiler\";\nimport type { DocumentNode } from \"graphql\";\n\nexport type PlannerInstance = ReturnType<typeof createPlanner>;\n\ntype GetPlanOpts = { fragmentName?: string };\n\nexport const createPlanner = () => {\n  // Cache for DocumentNode → (fragmentName|\"\" → plan)\n  const docCache = new WeakMap<DocumentNode, Map<string, CachePlan>>();\n  // Cache for string docs → key = doc + \"::\" + fragmentName\n  const strCache = new Map<string, CachePlan>();\n\n  const getPlan = (\n    docOrPlan: DocumentNode | CachePlan | string,\n    opts?: GetPlanOpts,\n  ): CachePlan => {\n    // Already compiled? just return it\n    if (isCachePlan(docOrPlan)) return docOrPlan as CachePlan;\n\n    const fragKey = opts?.fragmentName ?? \"\";\n\n    if (typeof docOrPlan === \"string\") {\n      const key = `${docOrPlan}::${fragKey}`;\n      const hit = strCache.get(key);\n      if (hit) return hit;\n\n      const plan = compilePlan(docOrPlan, opts ?? {});\n      strCache.set(key, plan);\n      return plan;\n    }\n\n    // DocumentNode path\n    let inner = docCache.get(docOrPlan);\n    if (!inner) {\n      inner = new Map<string, CachePlan>();\n      docCache.set(docOrPlan, inner);\n    }\n\n    const hit = inner.get(fragKey);\n    if (hit) return hit;\n\n    const plan = compilePlan(docOrPlan, opts ?? {});\n    inner.set(fragKey, plan);\n    return plan;\n  };\n\n  return { getPlan };\n};\n","// src/core/queries.ts\nimport type { DocumentsInstance } from \"./documents\";\nimport type { PlannerInstance } from \"./planner\";\nimport { recycleSnapshots } from \"./utils\";\nimport type { DocumentNode } from \"graphql\";\n\nexport type QueriesDependencies = {\n  documents: DocumentsInstance;\n  planner: PlannerInstance;\n};\n\nexport type ReadQueryOptions = {\n  query: DocumentNode | string;\n  variables?: Record<string, any>;\n};\n\nexport type WriteQueryOptions = {\n  query: DocumentNode | string;\n  variables?: Record<string, any>;\n  data: any;\n};\n\nexport type WatchQueryOptions = {\n  query: DocumentNode | string;\n  variables?: Record<string, any>;\n  onData: (data: any) => void;\n  onError?: (error: Error) => void;\n  /** Emit initial data immediately (default: true) */\n  immediate?: boolean;\n};\n\nexport type WatchQueryHandle = {\n  unsubscribe: () => void;\n  /** Update variables. If immediate=true, materializes and emits immediately. */\n  update: (options: { variables?: Record<string, any>; immediate?: boolean }) => void;\n};\n\nexport type QueriesInstance = ReturnType<typeof createQueries>;\n\nexport const createQueries = ({ documents, planner }: QueriesDependencies) => {\n\n  // --- Watcher state & indices ---\n  type WatcherState = {\n    query: DocumentNode | string;\n    variables: Record<string, any>;\n    signature: string;  // Query signature for error tracking\n    onData: (data: any) => void;\n    onError?: (error: Error) => void;\n    deps: Set<string>;\n    lastData: any | undefined;\n    skipNextPropagate?: boolean; // Flag to skip next propagateData emission (coalescing)\n  };\n\n  const watchers = new Map<number, WatcherState>();\n  const depIndex = new Map<string, Set<number>>();\n  const signatureToWatchers = new Map<string, Set<number>>(); // Multiple watchers per signature\n  let watcherSeq = 1;\n\n  // --- Batched broadcasting ---\n  let pendingTouched = new Set<string>();\n  let flushScheduled = false;\n\n  const scheduleFlush = () => {\n    if (flushScheduled) {\n      return;\n    }\n    flushScheduled = true;\n\n    queueMicrotask(() => {\n      flushScheduled = false;\n      if (pendingTouched.size === 0) {\n        return;\n      }\n\n      const touched = Array.from(pendingTouched);\n      pendingTouched.clear();\n\n      const affected = new Set<number>();\n      for (const id of touched) {\n        const ws = depIndex.get(id);\n        if (ws) {\n          for (const k of ws) affected.add(k);\n        }\n      }\n\n      if (affected.size === 0) {\n        return;\n      }\n\n      for (const k of affected) {\n        const w = watchers.get(k);\n        if (!w) continue;\n\n        // Skip if recently emitted by handleQueryExecuted (coalescing)\n        if (w.skipNextPropagate) {\n          continue;\n        }\n\n        const result = documents.materializeDocument({\n          document: w.query,\n          variables: w.variables,\n          canonical: true, // Always canonical for watchers\n          fingerprint: true,\n          force: true,\n        });\n\n        // Always refresh deps so missing -> fulfilled transitions trigger\n        updateWatcherDependencies(k, result.dependencies);\n\n        if (result.source === \"none\") {\n          continue;\n        }\n\n        const recycled = recycleSnapshots(w.lastData, result.data);\n        if (recycled !== w.lastData) {\n          w.lastData = recycled;\n          try {\n            w.onData(recycled);\n          } catch (e) {\n            w.onError?.(e as Error);\n          }\n        }\n      }\n    });\n  };\n\n  /**\n   * Propagate data changes to watchers tracking the given dependencies\n   */\n  const propagateData = (touched: Set<string>) => {\n    for (const value of touched) {\n      pendingTouched.add(value);\n    }\n\n    scheduleFlush();\n  };\n\n  /**\n   * Propagate error to all watchers with the given signature\n   */\n  const propagateError = (signature: string, error: Error) => {\n    // Find all watchers with this signature\n    const watcherSet = signatureToWatchers.get(signature);\n    if (!watcherSet) return;\n\n    for (const watcherId of watcherSet) {\n      const watcher = watchers.get(watcherId);\n      if (watcher?.onError) {\n        watcher.onError(error);\n      }\n    }\n  };\n\n  // --- Dep index maintenance ---\n  const updateWatcherDependencies = (watcherId: number, nextDeps: Set<string>) => {\n    const watcher = watchers.get(watcherId);\n    if (!watcher) return;\n\n    const old = watcher.deps;\n    const next = nextDeps;\n\n    // fast path\n    if (old.size === next.size) {\n      let same = true;\n      for (const d of old) if (!next.has(d)) { same = false; break; }\n      if (same) return;\n    }\n\n    // remove old\n    for (const d of old) {\n      if (!next.has(d)) {\n        const set = depIndex.get(d);\n        if (set) {\n          set.delete(watcherId);\n          if (set.size === 0) depIndex.delete(d);\n        }\n      }\n    }\n\n    // add new\n    for (const d of next) {\n      if (!old.has(d)) {\n        let set = depIndex.get(d);\n        if (!set) depIndex.set(d, (set = new Set()));\n        set.add(watcherId);\n      }\n    }\n\n    watcher.deps = next;\n  };\n\n  // --- Public API ---\n\n  const readQuery = <T = any>({\n    query,\n    variables = {},\n  }: ReadQueryOptions): T | null => {\n    const result = documents.materializeDocument({\n      document: query,\n      variables,\n      canonical: true,  // Always use canonical mode\n      fingerprint: true, // Include version fingerprints\n      force: true, // Always read fresh data (rare operation, not hot path)\n    });\n\n    if (result.source !== \"none\") {\n      return result.data as T;\n    }\n    return null;\n  };\n\n  const writeQuery = ({\n    query,\n    variables = {},\n    data,\n  }: WriteQueryOptions): void => {\n    documents.normalizeDocument({\n      document: query,\n      variables,\n      data,\n    });\n  };\n\n  const watchQuery = ({\n    query,\n    variables = {},\n    onData,\n    onError,\n    immediate = true,\n  }: WatchQueryOptions): WatchQueryHandle => {\n    const watcherId = watcherSeq++;\n\n    // Generate signature for error tracking (always canonical)\n    const plan = planner.getPlan(query);\n    const signature = plan.makeSignature(true, variables);\n\n    const watcher: WatcherState = {\n      query,\n      variables,\n      signature,\n      onData,\n      onError,\n      deps: new Set(),\n      lastData: undefined,\n    };\n    watchers.set(watcherId, watcher);\n\n    // Add to signature → watchers mapping (multiple watchers per signature)\n    let watcherSet = signatureToWatchers.get(signature);\n    if (!watcherSet) {\n      watcherSet = new Set();\n      signatureToWatchers.set(signature, watcherSet);\n    }\n    watcherSet.add(watcherId);\n\n    // If immediate, materialize synchronously to get initial data\n    if (immediate) {\n      const initial = documents.materializeDocument({\n        document: query,\n        variables,\n        canonical: true,\n        fingerprint: true,\n        force: false,\n      });\n\n      // Track deps even if initial data is missing\n      updateWatcherDependencies(watcherId, initial.dependencies);\n\n      if (initial.source !== \"none\") {\n        watcher.lastData = initial.data;\n        try {\n          onData(initial.data);\n        } catch (e) {\n          onError?.(e as Error);\n        }\n      }\n      // No else - watchers simply don't emit on cache miss, they wait for data\n    } else {\n      // Even with immediate: false, register basic dependencies from query plan\n      // This ensures the watcher is notified when entities are added to the cache\n      // Use canonical mode to match the signature mode (watchers use canonical signatures)\n      const basicDeps = plan.getDependencies(true, variables);\n      updateWatcherDependencies(watcherId, basicDeps);\n    }\n\n    return {\n      unsubscribe: () => {\n        const w = watchers.get(watcherId);\n        if (!w) return;\n\n        // Remove from dep index\n        for (const d of w.deps) {\n          const set = depIndex.get(d);\n          if (set) {\n            set.delete(watcherId);\n            if (set.size === 0) depIndex.delete(d);\n          }\n        }\n\n        // Remove from signature → watchers mapping\n        const watcherSet = signatureToWatchers.get(w.signature);\n        if (watcherSet) {\n          watcherSet.delete(watcherId);\n          if (watcherSet.size === 0) {\n            signatureToWatchers.delete(w.signature);\n          }\n        }\n\n        watchers.delete(watcherId);\n      },\n\n      update: ({ variables: newVariables = {}, immediate = true }) => {\n        const w = watchers.get(watcherId);\n        if (!w) return;\n\n        // Update watcher state\n        w.variables = newVariables;\n        const plan = planner.getPlan(w.query);\n        const newSignature = plan.makeSignature(true, newVariables);\n\n        // Update signature mapping if signature changed\n        if (w.signature !== newSignature) {\n          // Remove from old signature set\n          const oldSet = signatureToWatchers.get(w.signature);\n          if (oldSet) {\n            oldSet.delete(watcherId);\n            if (oldSet.size === 0) {\n              signatureToWatchers.delete(w.signature);\n            }\n          }\n\n          // Add to new signature set\n          w.signature = newSignature;\n          let newSet = signatureToWatchers.get(newSignature);\n          if (!newSet) {\n            newSet = new Set();\n            signatureToWatchers.set(newSignature, newSet);\n          }\n          newSet.add(watcherId);\n        }\n\n        // If immediate, materialize and emit synchronously\n        if (immediate) {\n          const res = documents.materializeDocument({\n            document: w.query,\n            variables: newVariables,\n            canonical: true,\n            fingerprint: true,\n            force: false,\n          });\n\n          updateWatcherDependencies(watcherId, res.dependencies);\n\n          if (res.source !== \"none\") {\n            // recycleSnapshots automatically preserves object identity for unchanged parts\n            const recycled = recycleSnapshots(w.lastData, res.data);\n            // Only emit if data actually changed\n            if (recycled !== w.lastData) {\n              w.lastData = recycled;\n              try {\n                w.onData(recycled);\n              } catch (e) {\n                w.onError?.(e as Error);\n              }\n            }\n          }\n          // No else - watchers simply don't emit on cache miss, they wait for data\n        }\n      },\n    };\n  };\n\n  /**\n   * Callback handler from operations - updates watcher dependencies and directly emits data\n   * Handles multiple watchers per signature\n   */\n  const handleQueryExecuted = ({ signature, data, dependencies }: {\n    signature: string;\n    data: any;\n    dependencies: Set<string>;\n    cachePolicy: string;\n  }) => {\n    // Find all watchers with this signature\n    const watcherSet = signatureToWatchers.get(signature);\n    if (!watcherSet) return;\n\n    // Emit to all watchers with this signature\n    for (const watcherId of watcherSet) {\n      const w = watchers.get(watcherId);\n      if (!w) continue;\n\n      // Update dependencies\n      updateWatcherDependencies(watcherId, dependencies);\n\n      // Directly emit data to watcher (avoid redundant materialize)\n      // recycleSnapshots to preserve object identity\n      const recycled = recycleSnapshots(w.lastData, data);\n      if (recycled !== w.lastData) {\n        w.lastData = recycled;\n\n        // Set flag to skip next propagateData emission (coalescing)\n        // This prevents double emission when normalize triggers graph.onChange\n        w.skipNextPropagate = true;\n\n        Promise.resolve().then(() => {\n          w.skipNextPropagate = false;\n        });\n\n        try {\n          w.onData(recycled);\n        } catch (e) {\n          if (w.onError) {\n            w.onError(e as Error);\n          }\n        }\n      }\n    }\n  };\n\n  return {\n    readQuery,\n    writeQuery,\n    watchQuery,\n    propagateData,\n    propagateError,\n    handleQueryExecuted, // Expose for operations to call\n  };\n};\n","import type { GraphInstance } from \"../core/graph\";\n\ntype Deps = { graph: GraphInstance };\n\n/**\n * Serializable snapshot of graph state for SSR\n */\ntype GraphSnapshot = {\n  /** Array of [recordId, snapshot] entries; JSON-safe */\n  records: Array<[string, Record<string, unknown>]>;\n};\n\n/**\n * JSON-only deep clone for snapshots\n * @private\n */\nconst cloneJSON = <T,>(data: T): T => JSON.parse(JSON.stringify(data));\n\n/**\n * SSR instance type\n */\nexport type SSRInstance = ReturnType<typeof createSSR>;\n\n/**\n * Configuration options for SSR\n */\ntype SSROptions = {\n  /** Timeout in ms for hydration window (default: 100) */\n  hydrationTimeout?: number;\n};\n\n/**\n * Create SSR de/hydration layer for graph store\n * @param options - SSR configuration\n * @param deps - Required dependencies (graph)\n * @returns SSR instance with dehydrate, hydrate, and isHydrating methods\n */\nexport const createSSR = (options: SSROptions = {}, { graph }: Deps) => {\n  let hydrating = false;\n  const { hydrationTimeout = 100 } = options;\n\n  /** Serialize all graph records. */\n  const dehydrate = (): GraphSnapshot => {\n    const ids = graph.keys();\n    const out: Array<[string, any]> = new Array(ids.length);\n    for (let i = 0; i < ids.length; i++) {\n      const id = ids[i];\n      const snap = graph.getRecord(id);\n      out[i] = [id, snap != null ? cloneJSON(snap) : undefined];\n    }\n    return { records: out };\n  };\n\n  /**\n   * Hydrate a snapshot into the graph.\n   * - input can be a plain snapshot or a function that emits it (stream-friendly)\n   * - clears the graph first, then restores records\n   * - `isHydrating()` is true until the next microtask\n   */\n  const hydrate = (\n    input: GraphSnapshot | ((emit: (snapshot: GraphSnapshot) => void) => void),\n  ) => {\n    const run = (snapshot: GraphSnapshot) => {\n      if (!snapshot || !Array.isArray(snapshot.records)) return;\n\n      graph.clear();\n\n      for (let i = 0; i < snapshot.records.length; i++) {\n        const entry = snapshot.records[i];\n        if (!entry) continue;\n        const [id, snap] = entry;\n        if (!id || !snap || typeof snap !== \"object\") continue;\n        graph.putRecord(id, snap);\n      }\n    };\n\n    if (hydrationTimeout !== 0) {\n      hydrating = true;\n\n      setTimeout(() => { hydrating = false; }, hydrationTimeout);\n    }\n\n    if (typeof input === \"function\") {\n      input((s) => run(s));\n    } else {\n      run(input);\n    }\n  };\n\n  return {\n    dehydrate,\n    hydrate,\n    isHydrating: () => hydrating,\n  };\n};\n","export class WeakStringMap {\n  constructor() {\n    this.objectToKey = new WeakMap();       // object -> string\n    this.keyToRef = new Map();              // string -> WeakRef(object)\n    this.registry = new FinalizationRegistry((key) => {\n      // Object was GC'd; drop the stale string->ref mapping\n      this.keyToRef.delete(key);\n    });\n  }\n\n  set(key, obj) {\n    // If this object was previously bound to another key, clear that old key.\n    const oldKey = this.objectToKey.get(obj);\n    if (oldKey && oldKey !== key) {\n      this.keyToRef.delete(oldKey);\n    }\n\n    // If this key was previously bound to another object, unlink it.\n    const prevRef = this.keyToRef.get(key);\n    const prevObj = prevRef?.deref();\n    if (prevObj && prevObj !== obj) {\n      this.objectToKey.delete(prevObj);\n      this.registry.unregister(prevObj);\n    }\n\n    this.objectToKey.set(obj, key);\n    this.keyToRef.set(key, new WeakRef(obj));\n\n    // Use the object itself as the unregister token (we don't keep a strong ref to it).\n    this.registry.register(obj, key, obj);\n  }\n\n  get(key) {\n    const ref = this.keyToRef.get(key);\n    if (!ref) {\n      return undefined;\n    }\n    const obj = ref.deref();\n    if (!obj) {\n      // Stale entry; prune eagerly.\n      this.keyToRef.delete(key);\n    }\n    return obj;\n  }\n\n  has(key) {\n    const ref = this.keyToRef.get(key);\n    if (!ref) {\n      return false;\n    }\n    const obj = ref.deref();\n    if (!obj) {\n      this.keyToRef.delete(key);\n      return false;\n    }\n    return true;\n  }\n\n  delete(key) {\n    const ref = this.keyToRef.get(key);\n    if (!ref) {\n      return false;\n    }\n    this.keyToRef.delete(key);\n\n    const obj = ref.deref();\n    if (obj) {\n      this.objectToKey.delete(obj);\n      this.registry.unregister(obj);\n    }\n    return true;\n  }\n\n  // Optional helper: retrieve the string key by object.\n  keyOf(obj) {\n    return this.objectToKey.get(obj);\n  }\n\n  // Optional: sweep all keys and prune any now-stale refs.\n  prune() {\n    for (const [k, ref] of this.keyToRef) {\n      if (!ref.deref()) {\n        this.keyToRef.delete(k);\n      }\n    }\n  }\n}\n\nexport const isObject = (value: any): value is Record<string, any> => {\n  return value !== null && typeof value === \"object\";\n};\n\n/**\n * Deep equality comparison for JSON data structures (normalized cache data).\n * Optimized for common patterns: __ref objects, __refs arrays, primitives.\n * Not a true deep equal - designed specifically for cache comparison.\n */\nexport const isDataDeepEqual = (a: any, b: any): boolean => {\n  // Fast path: reference equality (includes null === null, undefined === undefined)\n  if (a === b) return true;\n\n  // null and undefined are different values\n  if (a == null || b == null) return false;\n\n  // Fast path: different types (string vs number, etc)\n  const typeA = typeof a;\n  const typeB = typeof b;\n  if (typeA !== typeB) return false;\n\n  // Fast path: primitives (already handled by a === b above, but helps V8 optimize)\n  if (typeA !== 'object') return false;\n\n  // Special case: __ref objects (very common in normalized cache)\n  if (a.__ref !== undefined && b.__ref !== undefined) {\n    return a.__ref === b.__ref;\n  }\n\n  // Special case: __refs arrays (single-level array of refs, no recursion needed)\n  if (Array.isArray(a.__refs) && Array.isArray(b.__refs)) {\n    if (a.__refs.length !== b.__refs.length) return false;\n    for (let i = 0; i < a.__refs.length; i++) {\n      if (a.__refs[i] !== b.__refs[i]) return false;\n    }\n    return true;\n  }\n\n  // Fast path: array vs non-array\n  const isArrayA = Array.isArray(a);\n  const isArrayB = Array.isArray(b);\n  if (isArrayA !== isArrayB) return false;\n\n  // Arrays\n  if (isArrayA) {\n    if (a.length !== b.length) return false;\n    for (let i = 0; i < a.length; i++) {\n      if (!isDataDeepEqual(a[i], b[i])) return false;\n    }\n    return true;\n  }\n\n  // Objects - check key count first (fast rejection)\n  const keysA = Object.keys(a);\n  const keysB = Object.keys(b);\n  if (keysA.length !== keysB.length) return false;\n\n  // Compare object properties\n  for (let i = 0; i < keysA.length; i++) {\n    const key = keysA[i];\n    if (!isDataDeepEqual(a[key], b[key])) return false;\n  }\n\n  return true;\n};\n\nexport const hasTypename = (value: any): boolean => {\n  return !!(value && typeof value === \"object\" && typeof value.__typename === \"string\");\n};\n\nexport const stableStringify = (object: any): string => {\n  const walk = (object: any): any => {\n    if (!isObject(object)) {\n      return object;\n    }\n\n    if (Array.isArray(object)) {\n      return object.map(walk);\n    }\n\n    const result: Record<string, any> = {};\n\n    for (let i = 0, keys = Object.keys(object).sort(); i < keys.length; i++) {\n      const key = keys[i];\n\n      result[key] = walk(object[key]);\n    }\n\n    return result;\n  };\n\n  try {\n    return JSON.stringify(walk(object));\n  } catch {\n    return \"\";\n  }\n};\n\n/**\n * FNV-1a hash utilities for fingerprinting\n * 32-bit FNV-1a style mixer; fast & stable enough for fingerprints\n * https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function\n */\nconst FNV_SEED = 0x811c9dc5 | 0;\nconst FNV_PRIME = 16777619;\n\n/**\n * Combine base node fingerprint with child fingerprints using FNV-1a.\n * Order-dependent: child order matters for the final hash.\n * Inlined mixing for maximum performance.\n *\n * For arrays without a base node, pass 0 as baseNode.\n */\nexport const fingerprintNodes = (baseNode: number, childNodes: number[]): number => {\n  let h = Math.imul(FNV_SEED ^ baseNode, FNV_PRIME) | 0;\n  for (let i = 0; i < childNodes.length; i++) {\n    h = Math.imul(h ^ childNodes[i], FNV_PRIME) | 0;\n  }\n  return h >>> 0;\n};\n\nconst FINGERPRINT_KEY = '__version';\n\n/**\n * Recycles subtrees from prevData by replacing equal subtrees in nextData.\n * Uses __version fingerprints for O(1) equality checks.\n *\n * IMPORTANT: Only works with materialized results that have __version fingerprints.\n *\n * @param prevData - Previous materialized snapshot\n * @param nextData - New materialized snapshot to recycle into\n * @returns Recycled snapshot (reuses prevData subtrees where possible)\n */\nexport function recycleSnapshots<T>(prevData: T, nextData: T): T {\n  // Fast path: reference equality\n  if (prevData === nextData) {\n    return nextData;\n  }\n\n  // Only recycle objects and arrays\n  if (\n    typeof prevData !== 'object' ||\n    !prevData ||\n    typeof nextData !== 'object' ||\n    !nextData\n  ) {\n    return nextData;\n  }\n\n  // Only recycle plain objects and arrays\n  const prevIsArray = Array.isArray(prevData);\n  const nextIsArray = Array.isArray(nextData);\n\n  if (prevIsArray !== nextIsArray) {\n    return nextData;\n  }\n\n  if (!prevIsArray && prevData.constructor !== Object) {\n    return nextData;\n  }\n\n  if (!nextIsArray && nextData.constructor !== Object) {\n    return nextData;\n  }\n\n  // Compare fingerprints - materialized results always have __version\n  const prevVersion = (prevData as any)[FINGERPRINT_KEY];\n  const nextVersion = (nextData as any)[FINGERPRINT_KEY];\n\n  if (prevVersion === nextVersion) {\n    // Fingerprints match - data is identical, reuse prevData\n    return prevData;\n  }\n\n  // Fingerprints differ - recycle children\n  if (prevIsArray && nextIsArray) {\n    const prevArray = prevData as any[];\n    const nextArray = nextData as any[];\n\n    // Try to recycle each element by comparing all elements\n    // This handles both append and prepend cases\n    let allEqual = prevArray.length === nextArray.length;\n\n    for (let i = 0; i < nextArray.length; i++) {\n      const nextItem = nextArray[i];\n      const nextFp = (nextItem as any)?.[FINGERPRINT_KEY];\n\n      // Try to find matching item in prevArray by fingerprint\n      let recycled = nextItem;\n      if (nextFp !== undefined) {\n        for (let j = 0; j < prevArray.length; j++) {\n          const prevItem = prevArray[j];\n          const prevFp = (prevItem as any)?.[FINGERPRINT_KEY];\n          if (prevFp === nextFp) {\n            recycled = prevItem;\n            break;\n          }\n        }\n      }\n\n      if (recycled !== nextItem) {\n        nextArray[i] = recycled;\n      }\n      if (i >= prevArray.length || recycled !== prevArray[i]) {\n        allEqual = false;\n      }\n    }\n\n    return allEqual ? prevData : nextData;\n  } else {\n    // Both are plain objects\n    const prevObject = prevData as Record<string, any>;\n    const nextObject = nextData as Record<string, any>;\n    const prevKeys = Object.keys(prevObject);\n    const nextKeys = Object.keys(nextObject);\n\n    if (prevKeys.length !== nextKeys.length) {\n      return nextData;\n    }\n\n    let allEqual = true;\n    for (const key of nextKeys) {\n      const recycled = recycleSnapshots(prevObject[key], nextObject[key]);\n      if (recycled !== nextObject[key]) {\n        nextObject[key] = recycled;\n      }\n      if (recycled !== prevObject[key]) {\n        allEqual = false;\n      }\n    }\n\n    return allEqual ? prevData : nextData;\n  }\n}\n","function _arrayLikeToArray(r, a) {\n  (null == a || a > r.length) && (a = r.length);\n  for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e];\n  return n;\n}\nmodule.exports = _arrayLikeToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var arrayLikeToArray = require(\"./arrayLikeToArray.js\");\nfunction _arrayWithoutHoles(r) {\n  if (Array.isArray(r)) return arrayLikeToArray(r);\n}\nmodule.exports = _arrayWithoutHoles, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var isNativeReflectConstruct = require(\"./isNativeReflectConstruct.js\");\nvar setPrototypeOf = require(\"./setPrototypeOf.js\");\nfunction _construct(t, e, r) {\n  if (isNativeReflectConstruct()) return Reflect.construct.apply(null, arguments);\n  var o = [null];\n  o.push.apply(o, e);\n  var p = new (t.bind.apply(t, o))();\n  return r && setPrototypeOf(p, r.prototype), p;\n}\nmodule.exports = _construct, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var unsupportedIterableToArray = require(\"./unsupportedIterableToArray.js\");\nfunction _createForOfIteratorHelper(r, e) {\n  var t = \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"];\n  if (!t) {\n    if (Array.isArray(r) || (t = unsupportedIterableToArray(r)) || e && r && \"number\" == typeof r.length) {\n      t && (r = t);\n      var _n = 0,\n        F = function F() {};\n      return {\n        s: F,\n        n: function n() {\n          return _n >= r.length ? {\n            done: !0\n          } : {\n            done: !1,\n            value: r[_n++]\n          };\n        },\n        e: function e(r) {\n          throw r;\n        },\n        f: F\n      };\n    }\n    throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n  }\n  var o,\n    a = !0,\n    u = !1;\n  return {\n    s: function s() {\n      t = t.call(r);\n    },\n    n: function n() {\n      var r = t.next();\n      return a = r.done, r;\n    },\n    e: function e(r) {\n      u = !0, o = r;\n    },\n    f: function f() {\n      try {\n        a || null == t[\"return\"] || t[\"return\"]();\n      } finally {\n        if (u) throw o;\n      }\n    }\n  };\n}\nmodule.exports = _createForOfIteratorHelper, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var toPropertyKey = require(\"./toPropertyKey.js\");\nfunction _defineProperty(e, r, t) {\n  return (r = toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\n    value: t,\n    enumerable: !0,\n    configurable: !0,\n    writable: !0\n  }) : e[r] = t, e;\n}\nmodule.exports = _defineProperty, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _getPrototypeOf(t) {\n  return module.exports = _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf.bind() : function (t) {\n    return t.__proto__ || Object.getPrototypeOf(t);\n  }, module.exports.__esModule = true, module.exports[\"default\"] = module.exports, _getPrototypeOf(t);\n}\nmodule.exports = _getPrototypeOf, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var setPrototypeOf = require(\"./setPrototypeOf.js\");\nfunction _inheritsLoose(t, o) {\n  t.prototype = Object.create(o.prototype), t.prototype.constructor = t, setPrototypeOf(t, o);\n}\nmodule.exports = _inheritsLoose, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _interopRequireDefault(e) {\n  return e && e.__esModule ? e : {\n    \"default\": e\n  };\n}\nmodule.exports = _interopRequireDefault, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _isNativeFunction(t) {\n  try {\n    return -1 !== Function.toString.call(t).indexOf(\"[native code]\");\n  } catch (n) {\n    return \"function\" == typeof t;\n  }\n}\nmodule.exports = _isNativeFunction, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _isNativeReflectConstruct() {\n  try {\n    var t = !Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {}));\n  } catch (t) {}\n  return (module.exports = _isNativeReflectConstruct = function _isNativeReflectConstruct() {\n    return !!t;\n  }, module.exports.__esModule = true, module.exports[\"default\"] = module.exports)();\n}\nmodule.exports = _isNativeReflectConstruct, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _iterableToArray(r) {\n  if (\"undefined\" != typeof Symbol && null != r[Symbol.iterator] || null != r[\"@@iterator\"]) return Array.from(r);\n}\nmodule.exports = _iterableToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\nmodule.exports = _nonIterableSpread, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var defineProperty = require(\"./defineProperty.js\");\nfunction ownKeys(e, r) {\n  var t = Object.keys(e);\n  if (Object.getOwnPropertySymbols) {\n    var o = Object.getOwnPropertySymbols(e);\n    r && (o = o.filter(function (r) {\n      return Object.getOwnPropertyDescriptor(e, r).enumerable;\n    })), t.push.apply(t, o);\n  }\n  return t;\n}\nfunction _objectSpread2(e) {\n  for (var r = 1; r < arguments.length; r++) {\n    var t = null != arguments[r] ? arguments[r] : {};\n    r % 2 ? ownKeys(Object(t), !0).forEach(function (r) {\n      defineProperty(e, r, t[r]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) {\n      Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r));\n    });\n  }\n  return e;\n}\nmodule.exports = _objectSpread2, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _objectWithoutPropertiesLoose(r, e) {\n  if (null == r) return {};\n  var t = {};\n  for (var n in r) if ({}.hasOwnProperty.call(r, n)) {\n    if (-1 !== e.indexOf(n)) continue;\n    t[n] = r[n];\n  }\n  return t;\n}\nmodule.exports = _objectWithoutPropertiesLoose, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _setPrototypeOf(t, e) {\n  return module.exports = _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function (t, e) {\n    return t.__proto__ = e, t;\n  }, module.exports.__esModule = true, module.exports[\"default\"] = module.exports, _setPrototypeOf(t, e);\n}\nmodule.exports = _setPrototypeOf, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var arrayWithoutHoles = require(\"./arrayWithoutHoles.js\");\nvar iterableToArray = require(\"./iterableToArray.js\");\nvar unsupportedIterableToArray = require(\"./unsupportedIterableToArray.js\");\nvar nonIterableSpread = require(\"./nonIterableSpread.js\");\nfunction _toConsumableArray(r) {\n  return arrayWithoutHoles(r) || iterableToArray(r) || unsupportedIterableToArray(r) || nonIterableSpread();\n}\nmodule.exports = _toConsumableArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var _typeof = require(\"./typeof.js\")[\"default\"];\nfunction toPrimitive(t, r) {\n  if (\"object\" != _typeof(t) || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r || \"default\");\n    if (\"object\" != _typeof(i)) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\nmodule.exports = toPrimitive, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var _typeof = require(\"./typeof.js\")[\"default\"];\nvar toPrimitive = require(\"./toPrimitive.js\");\nfunction toPropertyKey(t) {\n  var i = toPrimitive(t, \"string\");\n  return \"symbol\" == _typeof(i) ? i : i + \"\";\n}\nmodule.exports = toPropertyKey, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","function _typeof(o) {\n  \"@babel/helpers - typeof\";\n\n  return module.exports = _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) {\n    return typeof o;\n  } : function (o) {\n    return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o;\n  }, module.exports.__esModule = true, module.exports[\"default\"] = module.exports, _typeof(o);\n}\nmodule.exports = _typeof, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var arrayLikeToArray = require(\"./arrayLikeToArray.js\");\nfunction _unsupportedIterableToArray(r, a) {\n  if (r) {\n    if (\"string\" == typeof r) return arrayLikeToArray(r, a);\n    var t = {}.toString.call(r).slice(8, -1);\n    return \"Object\" === t && r.constructor && (t = r.constructor.name), \"Map\" === t || \"Set\" === t ? Array.from(r) : \"Arguments\" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? arrayLikeToArray(r, a) : void 0;\n  }\n}\nmodule.exports = _unsupportedIterableToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","var getPrototypeOf = require(\"./getPrototypeOf.js\");\nvar setPrototypeOf = require(\"./setPrototypeOf.js\");\nvar isNativeFunction = require(\"./isNativeFunction.js\");\nvar construct = require(\"./construct.js\");\nfunction _wrapNativeSuper(t) {\n  var r = \"function\" == typeof Map ? new Map() : void 0;\n  return module.exports = _wrapNativeSuper = function _wrapNativeSuper(t) {\n    if (null === t || !isNativeFunction(t)) return t;\n    if (\"function\" != typeof t) throw new TypeError(\"Super expression must either be null or a function\");\n    if (void 0 !== r) {\n      if (r.has(t)) return r.get(t);\n      r.set(t, Wrapper);\n    }\n    function Wrapper() {\n      return construct(t, arguments, getPrototypeOf(this).constructor);\n    }\n    return Wrapper.prototype = Object.create(t.prototype, {\n      constructor: {\n        value: Wrapper,\n        enumerable: !1,\n        writable: !0,\n        configurable: !0\n      }\n    }), setPrototypeOf(Wrapper, t);\n  }, module.exports.__esModule = true, module.exports[\"default\"] = module.exports, _wrapNativeSuper(t);\n}\nmodule.exports = _wrapNativeSuper, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","import { __assign, __rest } from \"tslib\";\nimport { wrap } from \"optimism\";\nimport { Observable, cacheSizes, getFragmentDefinition, getFragmentQueryDocument, mergeDeepArray, } from \"../../utilities/index.js\";\nimport { WeakCache } from \"@wry/caches\";\nimport { getApolloCacheMemoryInternals } from \"../../utilities/caching/getMemoryInternals.js\";\nimport { equalByQuery } from \"../../core/equalByQuery.js\";\nimport { invariant } from \"../../utilities/globals/index.js\";\nimport { maskFragment } from \"../../masking/index.js\";\nimport { muteDeprecations, warnRemovedOption, } from \"../../utilities/deprecation/index.js\";\nvar ApolloCache = /** @class */ (function () {\n    function ApolloCache() {\n        this.assumeImmutableResults = false;\n        // Make sure we compute the same (===) fragment query document every\n        // time we receive the same fragment in readFragment.\n        this.getFragmentDoc = wrap(getFragmentQueryDocument, {\n            max: cacheSizes[\"cache.fragmentQueryDocuments\"] ||\n                1000 /* defaultCacheSizes[\"cache.fragmentQueryDocuments\"] */,\n            cache: WeakCache,\n        });\n    }\n    // Function used to lookup a fragment when a fragment definition is not part\n    // of the GraphQL document. This is useful for caches, such as InMemoryCache,\n    // that register fragments ahead of time so they can be referenced by name.\n    ApolloCache.prototype.lookupFragment = function (fragmentName) {\n        return null;\n    };\n    // Transactional API\n    // The batch method is intended to replace/subsume both performTransaction\n    // and recordOptimisticTransaction, but performTransaction came first, so we\n    // provide a default batch implementation that's just another way of calling\n    // performTransaction. Subclasses of ApolloCache (such as InMemoryCache) can\n    // override the batch method to do more interesting things with its options.\n    ApolloCache.prototype.batch = function (options) {\n        var _this = this;\n        var optimisticId = typeof options.optimistic === \"string\" ? options.optimistic\n            : options.optimistic === false ? null\n                : void 0;\n        var updateResult;\n        this.performTransaction(function () { return (updateResult = options.update(_this)); }, optimisticId);\n        return updateResult;\n    };\n    ApolloCache.prototype.recordOptimisticTransaction = function (transaction, optimisticId) {\n        this.performTransaction(transaction, optimisticId);\n    };\n    // Optional API\n    // Called once per input document, allowing the cache to make static changes\n    // to the query, such as adding __typename fields.\n    ApolloCache.prototype.transformDocument = function (document) {\n        return document;\n    };\n    // Called before each ApolloLink request, allowing the cache to make dynamic\n    // changes to the query, such as filling in missing fragment definitions.\n    ApolloCache.prototype.transformForLink = function (document) {\n        return document;\n    };\n    ApolloCache.prototype.identify = function (object) {\n        return;\n    };\n    ApolloCache.prototype.gc = function () {\n        return [];\n    };\n    ApolloCache.prototype.modify = function (options) {\n        return false;\n    };\n    // DataProxy API\n    ApolloCache.prototype.readQuery = function (options, optimistic) {\n        var _this = this;\n        if (optimistic === void 0) { optimistic = !!options.optimistic; }\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(options, \"canonizeResults\", \"cache.readQuery\");\n        }\n        return muteDeprecations(\"canonizeResults\", function () {\n            return _this.read(__assign(__assign({}, options), { rootId: options.id || \"ROOT_QUERY\", optimistic: optimistic }));\n        });\n    };\n    /** {@inheritDoc @apollo/client!ApolloClient#watchFragment:member(1)} */\n    ApolloCache.prototype.watchFragment = function (options) {\n        var _this = this;\n        var fragment = options.fragment, fragmentName = options.fragmentName, from = options.from, _a = options.optimistic, optimistic = _a === void 0 ? true : _a, otherOptions = __rest(options, [\"fragment\", \"fragmentName\", \"from\", \"optimistic\"]);\n        var query = this.getFragmentDoc(fragment, fragmentName);\n        // While our TypeScript types do not allow for `undefined` as a valid\n        // `from`, its possible `useFragment` gives us an `undefined` since it\n        // calls` cache.identify` and provides that value to `from`. We are\n        // adding this fix here however to ensure those using plain JavaScript\n        // and using `cache.identify` themselves will avoid seeing the obscure\n        // warning.\n        var id = typeof from === \"undefined\" || typeof from === \"string\" ?\n            from\n            : this.identify(from);\n        var dataMasking = !!options[Symbol.for(\"apollo.dataMasking\")];\n        if (globalThis.__DEV__ !== false) {\n            var actualFragmentName = fragmentName || getFragmentDefinition(fragment).name.value;\n            if (!id) {\n                globalThis.__DEV__ !== false && invariant.warn(1, actualFragmentName);\n            }\n        }\n        var diffOptions = __assign(__assign({}, otherOptions), { returnPartialData: true, id: id, query: query, optimistic: optimistic });\n        var latestDiff;\n        return new Observable(function (observer) {\n            return _this.watch(__assign(__assign({}, diffOptions), { immediate: true, callback: function (diff) {\n                    var data = dataMasking ?\n                        maskFragment(diff.result, fragment, _this, fragmentName)\n                        : diff.result;\n                    if (\n                    // Always ensure we deliver the first result\n                    latestDiff &&\n                        equalByQuery(query, { data: latestDiff.result }, { data: data }, \n                        // TODO: Fix the type on WatchFragmentOptions so that TVars\n                        // extends OperationVariables\n                        options.variables)) {\n                        return;\n                    }\n                    var result = {\n                        data: data,\n                        complete: !!diff.complete,\n                    };\n                    if (diff.missing) {\n                        result.missing = mergeDeepArray(diff.missing.map(function (error) { return error.missing; }));\n                    }\n                    latestDiff = __assign(__assign({}, diff), { result: data });\n                    observer.next(result);\n                } }));\n        });\n    };\n    ApolloCache.prototype.readFragment = function (options, optimistic) {\n        var _this = this;\n        if (optimistic === void 0) { optimistic = !!options.optimistic; }\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(options, \"canonizeResults\", \"cache.readFragment\");\n        }\n        return muteDeprecations(\"canonizeResults\", function () {\n            return _this.read(__assign(__assign({}, options), { query: _this.getFragmentDoc(options.fragment, options.fragmentName), rootId: options.id, optimistic: optimistic }));\n        });\n    };\n    ApolloCache.prototype.writeQuery = function (_a) {\n        var id = _a.id, data = _a.data, options = __rest(_a, [\"id\", \"data\"]);\n        return this.write(Object.assign(options, {\n            dataId: id || \"ROOT_QUERY\",\n            result: data,\n        }));\n    };\n    ApolloCache.prototype.writeFragment = function (_a) {\n        var id = _a.id, data = _a.data, fragment = _a.fragment, fragmentName = _a.fragmentName, options = __rest(_a, [\"id\", \"data\", \"fragment\", \"fragmentName\"]);\n        return this.write(Object.assign(options, {\n            query: this.getFragmentDoc(fragment, fragmentName),\n            dataId: id,\n            result: data,\n        }));\n    };\n    ApolloCache.prototype.updateQuery = function (options, update) {\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(options, \"canonizeResults\", \"cache.updateQuery\");\n        }\n        return this.batch({\n            update: function (cache) {\n                var value = muteDeprecations(\"canonizeResults\", function () {\n                    return cache.readQuery(options);\n                });\n                var data = update(value);\n                if (data === void 0 || data === null)\n                    return value;\n                cache.writeQuery(__assign(__assign({}, options), { data: data }));\n                return data;\n            },\n        });\n    };\n    ApolloCache.prototype.updateFragment = function (options, update) {\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(options, \"canonizeResults\", \"cache.updateFragment\");\n        }\n        return this.batch({\n            update: function (cache) {\n                var value = muteDeprecations(\"canonizeResults\", function () {\n                    return cache.readFragment(options);\n                });\n                var data = update(value);\n                if (data === void 0 || data === null)\n                    return value;\n                cache.writeFragment(__assign(__assign({}, options), { data: data }));\n                return data;\n            },\n        });\n    };\n    return ApolloCache;\n}());\nexport { ApolloCache };\nif (globalThis.__DEV__ !== false) {\n    ApolloCache.prototype.getMemoryInternals = getApolloCacheMemoryInternals;\n}\n//# sourceMappingURL=cache.js.map","import { __extends } from \"tslib\";\nvar MissingFieldError = /** @class */ (function (_super) {\n    __extends(MissingFieldError, _super);\n    function MissingFieldError(message, path, query, variables) {\n        var _a;\n        // 'Error' breaks prototype chain here\n        var _this = _super.call(this, message) || this;\n        _this.message = message;\n        _this.path = path;\n        _this.query = query;\n        _this.variables = variables;\n        if (Array.isArray(_this.path)) {\n            _this.missing = _this.message;\n            for (var i = _this.path.length - 1; i >= 0; --i) {\n                _this.missing = (_a = {}, _a[_this.path[i]] = _this.missing, _a);\n            }\n        }\n        else {\n            _this.missing = _this.path;\n        }\n        // We're not using `Object.setPrototypeOf` here as it isn't fully supported\n        // on Android (see issue #3236).\n        _this.__proto__ = MissingFieldError.prototype;\n        return _this;\n    }\n    return MissingFieldError;\n}(Error));\nexport { MissingFieldError };\n//# sourceMappingURL=common.js.map","import { __assign, __extends, __rest } from \"tslib\";\nimport { invariant } from \"../../utilities/globals/index.js\";\nimport { dep } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport { isReference, makeReference, DeepMerger, maybeDeepFreeze, canUseWeakMap, isNonNullObject, } from \"../../utilities/index.js\";\nimport { hasOwn, fieldNameFromStoreName } from \"./helpers.js\";\nvar DELETE = Object.create(null);\nvar delModifier = function () { return DELETE; };\nvar INVALIDATE = Object.create(null);\nvar EntityStore = /** @class */ (function () {\n    function EntityStore(policies, group) {\n        var _this = this;\n        this.policies = policies;\n        this.group = group;\n        this.data = Object.create(null);\n        // Maps root entity IDs to the number of times they have been retained, minus\n        // the number of times they have been released. Retained entities keep other\n        // entities they reference (even indirectly) from being garbage collected.\n        this.rootIds = Object.create(null);\n        // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n        this.refs = Object.create(null);\n        // Bound function that can be passed around to provide easy access to fields\n        // of Reference objects as well as ordinary objects.\n        this.getFieldValue = function (objectOrReference, storeFieldName) {\n            return maybeDeepFreeze(isReference(objectOrReference) ?\n                _this.get(objectOrReference.__ref, storeFieldName)\n                : objectOrReference && objectOrReference[storeFieldName]);\n        };\n        // Returns true for non-normalized StoreObjects and non-dangling\n        // References, indicating that readField(name, objOrRef) has a chance of\n        // working. Useful for filtering out dangling references from lists.\n        this.canRead = function (objOrRef) {\n            return isReference(objOrRef) ?\n                _this.has(objOrRef.__ref)\n                : typeof objOrRef === \"object\";\n        };\n        // Bound function that converts an id or an object with a __typename and\n        // primary key fields to a Reference object. If called with a Reference object,\n        // that same Reference object is returned. Pass true for mergeIntoStore to persist\n        // an object into the store.\n        this.toReference = function (objOrIdOrRef, mergeIntoStore) {\n            if (typeof objOrIdOrRef === \"string\") {\n                return makeReference(objOrIdOrRef);\n            }\n            if (isReference(objOrIdOrRef)) {\n                return objOrIdOrRef;\n            }\n            var id = _this.policies.identify(objOrIdOrRef)[0];\n            if (id) {\n                var ref = makeReference(id);\n                if (mergeIntoStore) {\n                    _this.merge(id, objOrIdOrRef);\n                }\n                return ref;\n            }\n        };\n    }\n    // Although the EntityStore class is abstract, it contains concrete\n    // implementations of the various NormalizedCache interface methods that\n    // are inherited by the Root and Layer subclasses.\n    EntityStore.prototype.toObject = function () {\n        return __assign({}, this.data);\n    };\n    EntityStore.prototype.has = function (dataId) {\n        return this.lookup(dataId, true) !== void 0;\n    };\n    EntityStore.prototype.get = function (dataId, fieldName) {\n        this.group.depend(dataId, fieldName);\n        if (hasOwn.call(this.data, dataId)) {\n            var storeObject = this.data[dataId];\n            if (storeObject && hasOwn.call(storeObject, fieldName)) {\n                return storeObject[fieldName];\n            }\n        }\n        if (fieldName === \"__typename\" &&\n            hasOwn.call(this.policies.rootTypenamesById, dataId)) {\n            return this.policies.rootTypenamesById[dataId];\n        }\n        if (this instanceof Layer) {\n            return this.parent.get(dataId, fieldName);\n        }\n    };\n    EntityStore.prototype.lookup = function (dataId, dependOnExistence) {\n        // The has method (above) calls lookup with dependOnExistence = true, so\n        // that it can later be invalidated when we add or remove a StoreObject for\n        // this dataId. Any consumer who cares about the contents of the StoreObject\n        // should not rely on this dependency, since the contents could change\n        // without the object being added or removed.\n        if (dependOnExistence)\n            this.group.depend(dataId, \"__exists\");\n        if (hasOwn.call(this.data, dataId)) {\n            return this.data[dataId];\n        }\n        if (this instanceof Layer) {\n            return this.parent.lookup(dataId, dependOnExistence);\n        }\n        if (this.policies.rootTypenamesById[dataId]) {\n            return Object.create(null);\n        }\n    };\n    EntityStore.prototype.merge = function (older, newer) {\n        var _this = this;\n        var dataId;\n        // Convert unexpected references to ID strings.\n        if (isReference(older))\n            older = older.__ref;\n        if (isReference(newer))\n            newer = newer.__ref;\n        var existing = typeof older === \"string\" ? this.lookup((dataId = older)) : older;\n        var incoming = typeof newer === \"string\" ? this.lookup((dataId = newer)) : newer;\n        // If newer was a string ID, but that ID was not defined in this store,\n        // then there are no fields to be merged, so we're done.\n        if (!incoming)\n            return;\n        invariant(typeof dataId === \"string\", 2);\n        var merged = new DeepMerger(storeObjectReconciler).merge(existing, incoming);\n        // Even if merged === existing, existing may have come from a lower\n        // layer, so we always need to set this.data[dataId] on this level.\n        this.data[dataId] = merged;\n        if (merged !== existing) {\n            delete this.refs[dataId];\n            if (this.group.caching) {\n                var fieldsToDirty_1 = Object.create(null);\n                // If we added a new StoreObject where there was previously none, dirty\n                // anything that depended on the existence of this dataId, such as the\n                // EntityStore#has method.\n                if (!existing)\n                    fieldsToDirty_1.__exists = 1;\n                // Now invalidate dependents who called getFieldValue for any fields\n                // that are changing as a result of this merge.\n                Object.keys(incoming).forEach(function (storeFieldName) {\n                    if (!existing ||\n                        existing[storeFieldName] !== merged[storeFieldName]) {\n                        // Always dirty the full storeFieldName, which may include\n                        // serialized arguments following the fieldName prefix.\n                        fieldsToDirty_1[storeFieldName] = 1;\n                        // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n                        // different from storeFieldName and this field does not have\n                        // keyArgs configured, because that means the cache can't make\n                        // any assumptions about how field values with the same field\n                        // name but different arguments might be interrelated, so it\n                        // must err on the side of invalidating all field values that\n                        // share the same short fieldName, regardless of arguments.\n                        var fieldName = fieldNameFromStoreName(storeFieldName);\n                        if (fieldName !== storeFieldName &&\n                            !_this.policies.hasKeyArgs(merged.__typename, fieldName)) {\n                            fieldsToDirty_1[fieldName] = 1;\n                        }\n                        // If merged[storeFieldName] has become undefined, and this is the\n                        // Root layer, actually delete the property from the merged object,\n                        // which is guaranteed to have been created fresh in this method.\n                        if (merged[storeFieldName] === void 0 && !(_this instanceof Layer)) {\n                            delete merged[storeFieldName];\n                        }\n                    }\n                });\n                if (fieldsToDirty_1.__typename &&\n                    !(existing && existing.__typename) &&\n                    // Since we return default root __typename strings\n                    // automatically from store.get, we don't need to dirty the\n                    // ROOT_QUERY.__typename field if merged.__typename is equal\n                    // to the default string (usually \"Query\").\n                    this.policies.rootTypenamesById[dataId] === merged.__typename) {\n                    delete fieldsToDirty_1.__typename;\n                }\n                Object.keys(fieldsToDirty_1).forEach(function (fieldName) {\n                    return _this.group.dirty(dataId, fieldName);\n                });\n            }\n        }\n    };\n    EntityStore.prototype.modify = function (dataId, fields) {\n        var _this = this;\n        var storeObject = this.lookup(dataId);\n        if (storeObject) {\n            var changedFields_1 = Object.create(null);\n            var needToMerge_1 = false;\n            var allDeleted_1 = true;\n            var sharedDetails_1 = {\n                DELETE: DELETE,\n                INVALIDATE: INVALIDATE,\n                isReference: isReference,\n                toReference: this.toReference,\n                canRead: this.canRead,\n                readField: function (fieldNameOrOptions, from) {\n                    return _this.policies.readField(typeof fieldNameOrOptions === \"string\" ?\n                        {\n                            fieldName: fieldNameOrOptions,\n                            from: from || makeReference(dataId),\n                        }\n                        : fieldNameOrOptions, { store: _this });\n                },\n            };\n            Object.keys(storeObject).forEach(function (storeFieldName) {\n                var fieldName = fieldNameFromStoreName(storeFieldName);\n                var fieldValue = storeObject[storeFieldName];\n                if (fieldValue === void 0)\n                    return;\n                var modify = typeof fields === \"function\" ? fields : (fields[storeFieldName] || fields[fieldName]);\n                if (modify) {\n                    var newValue = modify === delModifier ? DELETE : (modify(maybeDeepFreeze(fieldValue), __assign(__assign({}, sharedDetails_1), { fieldName: fieldName, storeFieldName: storeFieldName, storage: _this.getStorage(dataId, storeFieldName) })));\n                    if (newValue === INVALIDATE) {\n                        _this.group.dirty(dataId, storeFieldName);\n                    }\n                    else {\n                        if (newValue === DELETE)\n                            newValue = void 0;\n                        if (newValue !== fieldValue) {\n                            changedFields_1[storeFieldName] = newValue;\n                            needToMerge_1 = true;\n                            fieldValue = newValue;\n                            if (globalThis.__DEV__ !== false) {\n                                var checkReference = function (ref) {\n                                    if (_this.lookup(ref.__ref) === undefined) {\n                                        globalThis.__DEV__ !== false && invariant.warn(3, ref);\n                                        return true;\n                                    }\n                                };\n                                if (isReference(newValue)) {\n                                    checkReference(newValue);\n                                }\n                                else if (Array.isArray(newValue)) {\n                                    // Warn about writing \"mixed\" arrays of Reference and non-Reference objects\n                                    var seenReference = false;\n                                    var someNonReference = void 0;\n                                    for (var _i = 0, newValue_1 = newValue; _i < newValue_1.length; _i++) {\n                                        var value = newValue_1[_i];\n                                        if (isReference(value)) {\n                                            seenReference = true;\n                                            if (checkReference(value))\n                                                break;\n                                        }\n                                        else {\n                                            // Do not warn on primitive values, since those could never be represented\n                                            // by a reference. This is a valid (albeit uncommon) use case.\n                                            if (typeof value === \"object\" && !!value) {\n                                                var id = _this.policies.identify(value)[0];\n                                                // check if object could even be referenced, otherwise we are not interested in it for this warning\n                                                if (id) {\n                                                    someNonReference = value;\n                                                }\n                                            }\n                                        }\n                                        if (seenReference && someNonReference !== undefined) {\n                                            globalThis.__DEV__ !== false && invariant.warn(4, someNonReference);\n                                            break;\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                if (fieldValue !== void 0) {\n                    allDeleted_1 = false;\n                }\n            });\n            if (needToMerge_1) {\n                this.merge(dataId, changedFields_1);\n                if (allDeleted_1) {\n                    if (this instanceof Layer) {\n                        this.data[dataId] = void 0;\n                    }\n                    else {\n                        delete this.data[dataId];\n                    }\n                    this.group.dirty(dataId, \"__exists\");\n                }\n                return true;\n            }\n        }\n        return false;\n    };\n    // If called with only one argument, removes the entire entity\n    // identified by dataId. If called with a fieldName as well, removes all\n    // fields of that entity whose names match fieldName according to the\n    // fieldNameFromStoreName helper function. If called with a fieldName\n    // and variables, removes all fields of that entity whose names match fieldName\n    // and whose arguments when cached exactly match the variables passed.\n    EntityStore.prototype.delete = function (dataId, fieldName, args) {\n        var _a;\n        var storeObject = this.lookup(dataId);\n        if (storeObject) {\n            var typename = this.getFieldValue(storeObject, \"__typename\");\n            var storeFieldName = fieldName && args ?\n                this.policies.getStoreFieldName({ typename: typename, fieldName: fieldName, args: args })\n                : fieldName;\n            return this.modify(dataId, storeFieldName ? (_a = {},\n                _a[storeFieldName] = delModifier,\n                _a) : delModifier);\n        }\n        return false;\n    };\n    EntityStore.prototype.evict = function (options, limit) {\n        var evicted = false;\n        if (options.id) {\n            if (hasOwn.call(this.data, options.id)) {\n                evicted = this.delete(options.id, options.fieldName, options.args);\n            }\n            if (this instanceof Layer && this !== limit) {\n                evicted = this.parent.evict(options, limit) || evicted;\n            }\n            // Always invalidate the field to trigger rereading of watched\n            // queries, even if no cache data was modified by the eviction,\n            // because queries may depend on computed fields with custom read\n            // functions, whose values are not stored in the EntityStore.\n            if (options.fieldName || evicted) {\n                this.group.dirty(options.id, options.fieldName || \"__exists\");\n            }\n        }\n        return evicted;\n    };\n    EntityStore.prototype.clear = function () {\n        this.replace(null);\n    };\n    EntityStore.prototype.extract = function () {\n        var _this = this;\n        var obj = this.toObject();\n        var extraRootIds = [];\n        this.getRootIdSet().forEach(function (id) {\n            if (!hasOwn.call(_this.policies.rootTypenamesById, id)) {\n                extraRootIds.push(id);\n            }\n        });\n        if (extraRootIds.length) {\n            obj.__META = { extraRootIds: extraRootIds.sort() };\n        }\n        return obj;\n    };\n    EntityStore.prototype.replace = function (newData) {\n        var _this = this;\n        Object.keys(this.data).forEach(function (dataId) {\n            if (!(newData && hasOwn.call(newData, dataId))) {\n                _this.delete(dataId);\n            }\n        });\n        if (newData) {\n            var __META = newData.__META, rest_1 = __rest(newData, [\"__META\"]);\n            Object.keys(rest_1).forEach(function (dataId) {\n                _this.merge(dataId, rest_1[dataId]);\n            });\n            if (__META) {\n                __META.extraRootIds.forEach(this.retain, this);\n            }\n        }\n    };\n    EntityStore.prototype.retain = function (rootId) {\n        return (this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1);\n    };\n    EntityStore.prototype.release = function (rootId) {\n        if (this.rootIds[rootId] > 0) {\n            var count = --this.rootIds[rootId];\n            if (!count)\n                delete this.rootIds[rootId];\n            return count;\n        }\n        return 0;\n    };\n    // Return a Set<string> of all the ID strings that have been retained by\n    // this layer/root *and* any layers/roots beneath it.\n    EntityStore.prototype.getRootIdSet = function (ids) {\n        if (ids === void 0) { ids = new Set(); }\n        Object.keys(this.rootIds).forEach(ids.add, ids);\n        if (this instanceof Layer) {\n            this.parent.getRootIdSet(ids);\n        }\n        else {\n            // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n            // always considered roots for garbage collection, regardless of\n            // their retainment counts in this.rootIds.\n            Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n        }\n        return ids;\n    };\n    // The goal of garbage collection is to remove IDs from the Root layer of the\n    // store that are no longer reachable starting from any IDs that have been\n    // explicitly retained (see retain and release, above). Returns an array of\n    // dataId strings that were removed from the store.\n    EntityStore.prototype.gc = function () {\n        var _this = this;\n        var ids = this.getRootIdSet();\n        var snapshot = this.toObject();\n        ids.forEach(function (id) {\n            if (hasOwn.call(snapshot, id)) {\n                // Because we are iterating over an ECMAScript Set, the IDs we add here\n                // will be visited in later iterations of the forEach loop only if they\n                // were not previously contained by the Set.\n                Object.keys(_this.findChildRefIds(id)).forEach(ids.add, ids);\n                // By removing IDs from the snapshot object here, we protect them from\n                // getting removed from the root store layer below.\n                delete snapshot[id];\n            }\n        });\n        var idsToRemove = Object.keys(snapshot);\n        if (idsToRemove.length) {\n            var root_1 = this;\n            while (root_1 instanceof Layer)\n                root_1 = root_1.parent;\n            idsToRemove.forEach(function (id) { return root_1.delete(id); });\n        }\n        return idsToRemove;\n    };\n    EntityStore.prototype.findChildRefIds = function (dataId) {\n        if (!hasOwn.call(this.refs, dataId)) {\n            var found_1 = (this.refs[dataId] = Object.create(null));\n            var root = this.data[dataId];\n            if (!root)\n                return found_1;\n            var workSet_1 = new Set([root]);\n            // Within the store, only arrays and objects can contain child entity\n            // references, so we can prune the traversal using this predicate:\n            workSet_1.forEach(function (obj) {\n                if (isReference(obj)) {\n                    found_1[obj.__ref] = true;\n                    // In rare cases, a { __ref } Reference object may have other fields.\n                    // This often indicates a mismerging of References with StoreObjects,\n                    // but garbage collection should not be fooled by a stray __ref\n                    // property in a StoreObject (ignoring all the other fields just\n                    // because the StoreObject looks like a Reference). To avoid this\n                    // premature termination of findChildRefIds recursion, we fall through\n                    // to the code below, which will handle any other properties of obj.\n                }\n                if (isNonNullObject(obj)) {\n                    Object.keys(obj).forEach(function (key) {\n                        var child = obj[key];\n                        // No need to add primitive values to the workSet, since they cannot\n                        // contain reference objects.\n                        if (isNonNullObject(child)) {\n                            workSet_1.add(child);\n                        }\n                    });\n                }\n            });\n        }\n        return this.refs[dataId];\n    };\n    EntityStore.prototype.makeCacheKey = function () {\n        return this.group.keyMaker.lookupArray(arguments);\n    };\n    return EntityStore;\n}());\nexport { EntityStore };\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nvar CacheGroup = /** @class */ (function () {\n    function CacheGroup(caching, parent) {\n        if (parent === void 0) { parent = null; }\n        this.caching = caching;\n        this.parent = parent;\n        this.d = null;\n        this.resetCaching();\n    }\n    CacheGroup.prototype.resetCaching = function () {\n        this.d = this.caching ? dep() : null;\n        this.keyMaker = new Trie(canUseWeakMap);\n    };\n    CacheGroup.prototype.depend = function (dataId, storeFieldName) {\n        if (this.d) {\n            this.d(makeDepKey(dataId, storeFieldName));\n            var fieldName = fieldNameFromStoreName(storeFieldName);\n            if (fieldName !== storeFieldName) {\n                // Fields with arguments that contribute extra identifying\n                // information to the fieldName (thus forming the storeFieldName)\n                // depend not only on the full storeFieldName but also on the\n                // short fieldName, so the field can be invalidated using either\n                // level of specificity.\n                this.d(makeDepKey(dataId, fieldName));\n            }\n            if (this.parent) {\n                this.parent.depend(dataId, storeFieldName);\n            }\n        }\n    };\n    CacheGroup.prototype.dirty = function (dataId, storeFieldName) {\n        if (this.d) {\n            this.d.dirty(makeDepKey(dataId, storeFieldName), \n            // When storeFieldName === \"__exists\", that means the entity identified\n            // by dataId has either disappeared from the cache or was newly added,\n            // so the result caching system would do well to \"forget everything it\n            // knows\" about that object. To achieve that kind of invalidation, we\n            // not only dirty the associated result cache entry, but also remove it\n            // completely from the dependency graph. For the optimism implementation\n            // details, see https://github.com/benjamn/optimism/pull/195.\n            storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\");\n        }\n    };\n    return CacheGroup;\n}());\nfunction makeDepKey(dataId, storeFieldName) {\n    // Since field names cannot have '#' characters in them, this method\n    // of joining the field name and the ID should be unambiguous, and much\n    // cheaper than JSON.stringify([dataId, fieldName]).\n    return storeFieldName + \"#\" + dataId;\n}\nexport function maybeDependOnExistenceOfEntity(store, entityId) {\n    if (supportsResultCaching(store)) {\n        // We use this pseudo-field __exists elsewhere in the EntityStore code to\n        // represent changes in the existence of the entity object identified by\n        // entityId. This dependency gets reliably dirtied whenever an object with\n        // this ID is deleted (or newly created) within this group, so any result\n        // cache entries (for example, StoreReader#executeSelectionSet results) that\n        // depend on __exists for this entityId will get dirtied as well, leading to\n        // the eventual recomputation (instead of reuse) of those result objects the\n        // next time someone reads them from the cache.\n        store.group.depend(entityId, \"__exists\");\n    }\n}\n(function (EntityStore) {\n    // Refer to this class as EntityStore.Root outside this namespace.\n    var Root = /** @class */ (function (_super) {\n        __extends(Root, _super);\n        function Root(_a) {\n            var policies = _a.policies, _b = _a.resultCaching, resultCaching = _b === void 0 ? true : _b, seed = _a.seed;\n            var _this = _super.call(this, policies, new CacheGroup(resultCaching)) || this;\n            _this.stump = new Stump(_this);\n            _this.storageTrie = new Trie(canUseWeakMap);\n            if (seed)\n                _this.replace(seed);\n            return _this;\n        }\n        Root.prototype.addLayer = function (layerId, replay) {\n            // Adding an optimistic Layer on top of the Root actually adds the Layer\n            // on top of the Stump, so the Stump always comes between the Root and\n            // any Layer objects that we've added.\n            return this.stump.addLayer(layerId, replay);\n        };\n        Root.prototype.removeLayer = function () {\n            // Never remove the root layer.\n            return this;\n        };\n        Root.prototype.getStorage = function () {\n            return this.storageTrie.lookupArray(arguments);\n        };\n        return Root;\n    }(EntityStore));\n    EntityStore.Root = Root;\n})(EntityStore || (EntityStore = {}));\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nvar Layer = /** @class */ (function (_super) {\n    __extends(Layer, _super);\n    function Layer(id, parent, replay, group) {\n        var _this = _super.call(this, parent.policies, group) || this;\n        _this.id = id;\n        _this.parent = parent;\n        _this.replay = replay;\n        _this.group = group;\n        replay(_this);\n        return _this;\n    }\n    Layer.prototype.addLayer = function (layerId, replay) {\n        return new Layer(layerId, this, replay, this.group);\n    };\n    Layer.prototype.removeLayer = function (layerId) {\n        var _this = this;\n        // Remove all instances of the given id, not just the first one.\n        var parent = this.parent.removeLayer(layerId);\n        if (layerId === this.id) {\n            if (this.group.caching) {\n                // Dirty every ID we're removing. Technically we might be able to avoid\n                // dirtying fields that have values in higher layers, but we don't have\n                // easy access to higher layers here, and we're about to recreate those\n                // layers anyway (see parent.addLayer below).\n                Object.keys(this.data).forEach(function (dataId) {\n                    var ownStoreObject = _this.data[dataId];\n                    var parentStoreObject = parent[\"lookup\"](dataId);\n                    if (!parentStoreObject) {\n                        // The StoreObject identified by dataId was defined in this layer\n                        // but will be undefined in the parent layer, so we can delete the\n                        // whole entity using this.delete(dataId). Since we're about to\n                        // throw this layer away, the only goal of this deletion is to dirty\n                        // the removed fields.\n                        _this.delete(dataId);\n                    }\n                    else if (!ownStoreObject) {\n                        // This layer had an entry for dataId but it was undefined, which\n                        // means the entity was deleted in this layer, and it's about to\n                        // become undeleted when we remove this layer, so we need to dirty\n                        // all fields that are about to be reexposed.\n                        _this.group.dirty(dataId, \"__exists\");\n                        Object.keys(parentStoreObject).forEach(function (storeFieldName) {\n                            _this.group.dirty(dataId, storeFieldName);\n                        });\n                    }\n                    else if (ownStoreObject !== parentStoreObject) {\n                        // If ownStoreObject is not exactly the same as parentStoreObject,\n                        // dirty any fields whose values will change as a result of this\n                        // removal.\n                        Object.keys(ownStoreObject).forEach(function (storeFieldName) {\n                            if (!equal(ownStoreObject[storeFieldName], parentStoreObject[storeFieldName])) {\n                                _this.group.dirty(dataId, storeFieldName);\n                            }\n                        });\n                    }\n                });\n            }\n            return parent;\n        }\n        // No changes are necessary if the parent chain remains identical.\n        if (parent === this.parent)\n            return this;\n        // Recreate this layer on top of the new parent.\n        return parent.addLayer(this.id, this.replay);\n    };\n    Layer.prototype.toObject = function () {\n        return __assign(__assign({}, this.parent.toObject()), this.data);\n    };\n    Layer.prototype.findChildRefIds = function (dataId) {\n        var fromParent = this.parent.findChildRefIds(dataId);\n        return hasOwn.call(this.data, dataId) ? __assign(__assign({}, fromParent), _super.prototype.findChildRefIds.call(this, dataId)) : fromParent;\n    };\n    Layer.prototype.getStorage = function () {\n        var p = this.parent;\n        while (p.parent)\n            p = p.parent;\n        return p.getStorage.apply(p, \n        // @ts-expect-error\n        arguments);\n    };\n    return Layer;\n}(EntityStore));\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nvar Stump = /** @class */ (function (_super) {\n    __extends(Stump, _super);\n    function Stump(root) {\n        return _super.call(this, \"EntityStore.Stump\", root, function () { }, new CacheGroup(root.group.caching, root.group)) || this;\n    }\n    Stump.prototype.removeLayer = function () {\n        // Never remove the Stump layer.\n        return this;\n    };\n    Stump.prototype.merge = function (older, newer) {\n        // We never want to write any data into the Stump, so we forward any merge\n        // calls to the Root instead. Another option here would be to throw an\n        // exception, but the toReference(object, true) function can sometimes\n        // trigger Stump writes (which used to be Root writes, before the Stump\n        // concept was introduced).\n        return this.parent.merge(older, newer);\n    };\n    return Stump;\n}(Layer));\nfunction storeObjectReconciler(existingObject, incomingObject, property) {\n    var existingValue = existingObject[property];\n    var incomingValue = incomingObject[property];\n    // Wherever there is a key collision, prefer the incoming value, unless\n    // it is deeply equal to the existing value. It's worth checking deep\n    // equality here (even though blindly returning incoming would be\n    // logically correct) because preserving the referential identity of\n    // existing data can prevent needless rereading and rerendering.\n    return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\nexport function supportsResultCaching(store) {\n    // When result caching is disabled, store.depend will be null.\n    return !!(store instanceof EntityStore && store.group.caching);\n}\n//# sourceMappingURL=entityStore.js.map","import { isReference, isField, DeepMerger, resultKeyNameFromField, shouldInclude, isNonNullObject, compact, createFragmentMap, getFragmentDefinitions, isArray, } from \"../../utilities/index.js\";\nexport var hasOwn = Object.prototype.hasOwnProperty;\nexport function isNullish(value) {\n    return value === null || value === void 0;\n}\nexport { isArray };\nexport function defaultDataIdFromObject(_a, context) {\n    var __typename = _a.__typename, id = _a.id, _id = _a._id;\n    if (typeof __typename === \"string\") {\n        if (context) {\n            context.keyObject =\n                !isNullish(id) ? { id: id }\n                    : !isNullish(_id) ? { _id: _id }\n                        : void 0;\n        }\n        // If there is no object.id, fall back to object._id.\n        if (isNullish(id) && !isNullish(_id)) {\n            id = _id;\n        }\n        if (!isNullish(id)) {\n            return \"\".concat(__typename, \":\").concat(typeof id === \"number\" || typeof id === \"string\" ?\n                id\n                : JSON.stringify(id));\n        }\n    }\n}\nvar defaultConfig = {\n    dataIdFromObject: defaultDataIdFromObject,\n    addTypename: true,\n    resultCaching: true,\n    // Thanks to the shouldCanonizeResults helper, this should be the only line\n    // you have to change to reenable canonization by default in the future.\n    canonizeResults: false,\n};\nexport function normalizeConfig(config) {\n    return compact(defaultConfig, config);\n}\nexport function shouldCanonizeResults(config) {\n    var value = config.canonizeResults;\n    return value === void 0 ? defaultConfig.canonizeResults : value;\n}\nexport function getTypenameFromStoreObject(store, objectOrReference) {\n    return isReference(objectOrReference) ?\n        store.get(objectOrReference.__ref, \"__typename\")\n        : objectOrReference && objectOrReference.__typename;\n}\nexport var TypeOrFieldNameRegExp = /^[_a-z][_0-9a-z]*/i;\nexport function fieldNameFromStoreName(storeFieldName) {\n    var match = storeFieldName.match(TypeOrFieldNameRegExp);\n    return match ? match[0] : storeFieldName;\n}\nexport function selectionSetMatchesResult(selectionSet, result, variables) {\n    if (isNonNullObject(result)) {\n        return isArray(result) ?\n            result.every(function (item) {\n                return selectionSetMatchesResult(selectionSet, item, variables);\n            })\n            : selectionSet.selections.every(function (field) {\n                if (isField(field) && shouldInclude(field, variables)) {\n                    var key = resultKeyNameFromField(field);\n                    return (hasOwn.call(result, key) &&\n                        (!field.selectionSet ||\n                            selectionSetMatchesResult(field.selectionSet, result[key], variables)));\n                }\n                // If the selection has been skipped with @skip(true) or\n                // @include(false), it should not count against the matching. If\n                // the selection is not a field, it must be a fragment (inline or\n                // named). We will determine if selectionSetMatchesResult for that\n                // fragment when we get to it, so for now we return true.\n                return true;\n            });\n    }\n    return false;\n}\nexport function storeValueIsStoreObject(value) {\n    return isNonNullObject(value) && !isReference(value) && !isArray(value);\n}\nexport function makeProcessedFieldsMerger() {\n    return new DeepMerger();\n}\nexport function extractFragmentContext(document, fragments) {\n    // FragmentMap consisting only of fragments defined directly in document, not\n    // including other fragments registered in the FragmentRegistry.\n    var fragmentMap = createFragmentMap(getFragmentDefinitions(document));\n    return {\n        fragmentMap: fragmentMap,\n        lookupFragment: function (name) {\n            var def = fragmentMap[name];\n            if (!def && fragments) {\n                def = fragments.lookup(name);\n            }\n            return def || null;\n        },\n    };\n}\n//# sourceMappingURL=helpers.js.map","import { __assign, __extends } from \"tslib\";\nimport { invariant } from \"../../utilities/globals/index.js\";\n// Make builtins like Map and Set safe to use with non-extensible objects.\nimport \"./fixPolyfills.js\";\nimport { wrap } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { ApolloCache } from \"../core/cache.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport { addTypenameToDocument, isReference, DocumentTransform, canonicalStringify, print, cacheSizes, } from \"../../utilities/index.js\";\nimport { StoreReader } from \"./readFromStore.js\";\nimport { StoreWriter } from \"./writeToStore.js\";\nimport { EntityStore, supportsResultCaching } from \"./entityStore.js\";\nimport { makeVar, forgetCache, recallCache } from \"./reactiveVars.js\";\nimport { Policies } from \"./policies.js\";\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from \"./helpers.js\";\nimport { getInMemoryCacheMemoryInternals } from \"../../utilities/caching/getMemoryInternals.js\";\nimport { muteDeprecations, warnRemovedOption, } from \"../../utilities/deprecation/index.js\";\nvar InMemoryCache = /** @class */ (function (_super) {\n    __extends(InMemoryCache, _super);\n    function InMemoryCache(config) {\n        if (config === void 0) { config = {}; }\n        var _this = _super.call(this) || this;\n        _this.watches = new Set();\n        _this.addTypenameTransform = new DocumentTransform(addTypenameToDocument);\n        // Override the default value, since InMemoryCache result objects are frozen\n        // in development and expected to remain logically immutable in production.\n        _this.assumeImmutableResults = true;\n        _this.makeVar = makeVar;\n        _this.txCount = 0;\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(config, \"addTypename\", \"InMemoryCache\", \"Please remove the `addTypename` option when initializing `InMemoryCache`.\");\n            warnRemovedOption(config, \"canonizeResults\", \"InMemoryCache\", \"Please remove the `canonizeResults` option when initializing `InMemoryCache`.\");\n        }\n        _this.config = normalizeConfig(config);\n        _this.addTypename = !!_this.config.addTypename;\n        _this.policies = new Policies({\n            cache: _this,\n            dataIdFromObject: _this.config.dataIdFromObject,\n            possibleTypes: _this.config.possibleTypes,\n            typePolicies: _this.config.typePolicies,\n        });\n        _this.init();\n        return _this;\n    }\n    InMemoryCache.prototype.init = function () {\n        // Passing { resultCaching: false } in the InMemoryCache constructor options\n        // will completely disable dependency tracking, which will improve memory\n        // usage but worsen the performance of repeated reads.\n        var rootStore = (this.data = new EntityStore.Root({\n            policies: this.policies,\n            resultCaching: this.config.resultCaching,\n        }));\n        // When no optimistic writes are currently active, cache.optimisticData ===\n        // cache.data, so there are no additional layers on top of the actual data.\n        // When an optimistic update happens, this.optimisticData will become a\n        // linked list of EntityStore Layer objects that terminates with the\n        // original this.data cache object.\n        this.optimisticData = rootStore.stump;\n        this.resetResultCache();\n    };\n    InMemoryCache.prototype.resetResultCache = function (resetResultIdentities) {\n        var _this = this;\n        var previousReader = this.storeReader;\n        var fragments = this.config.fragments;\n        this.addTypenameTransform.resetCache();\n        fragments === null || fragments === void 0 ? void 0 : fragments.resetCaches();\n        // The StoreWriter is mostly stateless and so doesn't really need to be\n        // reset, but it does need to have its writer.storeReader reference updated,\n        // so it's simpler to update this.storeWriter as well.\n        this.storeWriter = new StoreWriter(this, (this.storeReader = new StoreReader({\n            cache: this,\n            addTypename: this.addTypename,\n            resultCacheMaxSize: this.config.resultCacheMaxSize,\n            canonizeResults: shouldCanonizeResults(this.config),\n            canon: resetResultIdentities ? void 0 : (previousReader && previousReader.canon),\n            fragments: fragments,\n        })), fragments);\n        this.maybeBroadcastWatch = wrap(function (c, options) {\n            return _this.broadcastWatch(c, options);\n        }, {\n            max: this.config.resultCacheMaxSize ||\n                cacheSizes[\"inMemoryCache.maybeBroadcastWatch\"] ||\n                5000 /* defaultCacheSizes[\"inMemoryCache.maybeBroadcastWatch\"] */,\n            makeCacheKey: function (c) {\n                // Return a cache key (thus enabling result caching) only if we're\n                // currently using a data store that can track cache dependencies.\n                var store = c.optimistic ? _this.optimisticData : _this.data;\n                if (supportsResultCaching(store)) {\n                    var optimistic = c.optimistic, id = c.id, variables = c.variables;\n                    return store.makeCacheKey(c.query, \n                    // Different watches can have the same query, optimistic\n                    // status, rootId, and variables, but if their callbacks are\n                    // different, the (identical) result needs to be delivered to\n                    // each distinct callback. The easiest way to achieve that\n                    // separation is to include c.callback in the cache key for\n                    // maybeBroadcastWatch calls. See issue #5733.\n                    c.callback, canonicalStringify({ optimistic: optimistic, id: id, variables: variables }));\n                }\n            },\n        });\n        // Since we have thrown away all the cached functions that depend on the\n        // CacheGroup dependencies maintained by EntityStore, we should also reset\n        // all CacheGroup dependency information.\n        new Set([this.data.group, this.optimisticData.group]).forEach(function (group) {\n            return group.resetCaching();\n        });\n    };\n    InMemoryCache.prototype.restore = function (data) {\n        this.init();\n        // Since calling this.init() discards/replaces the entire StoreReader, along\n        // with the result caches it maintains, this.data.replace(data) won't have\n        // to bother deleting the old data.\n        if (data)\n            this.data.replace(data);\n        return this;\n    };\n    InMemoryCache.prototype.extract = function (optimistic) {\n        if (optimistic === void 0) { optimistic = false; }\n        return (optimistic ? this.optimisticData : this.data).extract();\n    };\n    InMemoryCache.prototype.read = function (options) {\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(options, \"canonizeResults\", \"cache.read\");\n        }\n        var \n        // Since read returns data or null, without any additional metadata\n        // about whether/where there might have been missing fields, the\n        // default behavior cannot be returnPartialData = true (like it is\n        // for the diff method), since defaulting to true would violate the\n        // integrity of the T in the return type. However, partial data may\n        // be useful in some cases, so returnPartialData:true may be\n        // specified explicitly.\n        _a = options.returnPartialData, \n        // Since read returns data or null, without any additional metadata\n        // about whether/where there might have been missing fields, the\n        // default behavior cannot be returnPartialData = true (like it is\n        // for the diff method), since defaulting to true would violate the\n        // integrity of the T in the return type. However, partial data may\n        // be useful in some cases, so returnPartialData:true may be\n        // specified explicitly.\n        returnPartialData = _a === void 0 ? false : _a;\n        try {\n            return (this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, config: this.config, returnPartialData: returnPartialData })).result || null);\n        }\n        catch (e) {\n            if (e instanceof MissingFieldError) {\n                // Swallow MissingFieldError and return null, so callers do not need to\n                // worry about catching \"normal\" exceptions resulting from incomplete\n                // cache data. Unexpected errors will be re-thrown. If you need more\n                // information about which fields were missing, use cache.diff instead,\n                // and examine diffResult.missing.\n                return null;\n            }\n            throw e;\n        }\n    };\n    InMemoryCache.prototype.write = function (options) {\n        try {\n            ++this.txCount;\n            return this.storeWriter.writeToStore(this.data, options);\n        }\n        finally {\n            if (!--this.txCount && options.broadcast !== false) {\n                this.broadcastWatches();\n            }\n        }\n    };\n    InMemoryCache.prototype.modify = function (options) {\n        if (hasOwn.call(options, \"id\") && !options.id) {\n            // To my knowledge, TypeScript does not currently provide a way to\n            // enforce that an optional property?:type must *not* be undefined\n            // when present. That ability would be useful here, because we want\n            // options.id to default to ROOT_QUERY only when no options.id was\n            // provided. If the caller attempts to pass options.id with a\n            // falsy/undefined value (perhaps because cache.identify failed), we\n            // should not assume the goal was to modify the ROOT_QUERY object.\n            // We could throw, but it seems natural to return false to indicate\n            // that nothing was modified.\n            return false;\n        }\n        var store = ((options.optimistic) // Defaults to false.\n        ) ?\n            this.optimisticData\n            : this.data;\n        try {\n            ++this.txCount;\n            return store.modify(options.id || \"ROOT_QUERY\", options.fields);\n        }\n        finally {\n            if (!--this.txCount && options.broadcast !== false) {\n                this.broadcastWatches();\n            }\n        }\n    };\n    InMemoryCache.prototype.diff = function (options) {\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(options, \"canonizeResults\", \"cache.diff\");\n        }\n        return this.storeReader.diffQueryAgainstStore(__assign(__assign({}, options), { store: options.optimistic ? this.optimisticData : this.data, rootId: options.id || \"ROOT_QUERY\", config: this.config }));\n    };\n    InMemoryCache.prototype.watch = function (watch) {\n        var _this = this;\n        if (!this.watches.size) {\n            // In case we previously called forgetCache(this) because\n            // this.watches became empty (see below), reattach this cache to any\n            // reactive variables on which it previously depended. It might seem\n            // paradoxical that we're able to recall something we supposedly\n            // forgot, but the point of calling forgetCache(this) is to silence\n            // useless broadcasts while this.watches is empty, and to allow the\n            // cache to be garbage collected. If, however, we manage to call\n            // recallCache(this) here, this cache object must not have been\n            // garbage collected yet, and should resume receiving updates from\n            // reactive variables, now that it has a watcher to notify.\n            recallCache(this);\n        }\n        this.watches.add(watch);\n        if (watch.immediate) {\n            this.maybeBroadcastWatch(watch);\n        }\n        return function () {\n            // Once we remove the last watch from this.watches, cache.broadcastWatches\n            // no longer does anything, so we preemptively tell the reactive variable\n            // system to exclude this cache from future broadcasts.\n            if (_this.watches.delete(watch) && !_this.watches.size) {\n                forgetCache(_this);\n            }\n            // Remove this watch from the LRU cache managed by the\n            // maybeBroadcastWatch OptimisticWrapperFunction, to prevent memory\n            // leaks involving the closure of watch.callback.\n            _this.maybeBroadcastWatch.forget(watch);\n        };\n    };\n    InMemoryCache.prototype.gc = function (options) {\n        if (globalThis.__DEV__ !== false) {\n            warnRemovedOption(options || {}, \"resetResultIdentities\", \"cache.gc\", \"First ensure all usages of `canonizeResults` are removed, then remove this option.\");\n        }\n        canonicalStringify.reset();\n        print.reset();\n        var ids = this.optimisticData.gc();\n        if (options && !this.txCount) {\n            if (options.resetResultCache) {\n                this.resetResultCache(options.resetResultIdentities);\n            }\n            else if (options.resetResultIdentities) {\n                this.storeReader.resetCanon();\n            }\n        }\n        return ids;\n    };\n    // Call this method to ensure the given root ID remains in the cache after\n    // garbage collection, along with its transitive child entities. Note that\n    // the cache automatically retains all directly written entities. By default,\n    // the retainment persists after optimistic updates are removed. Pass true\n    // for the optimistic argument if you would prefer for the retainment to be\n    // discarded when the top-most optimistic layer is removed. Returns the\n    // resulting (non-negative) retainment count.\n    InMemoryCache.prototype.retain = function (rootId, optimistic) {\n        return (optimistic ? this.optimisticData : this.data).retain(rootId);\n    };\n    // Call this method to undo the effect of the retain method, above. Once the\n    // retainment count falls to zero, the given ID will no longer be preserved\n    // during garbage collection, though it may still be preserved by other safe\n    // entities that refer to it. Returns the resulting (non-negative) retainment\n    // count, in case that's useful.\n    InMemoryCache.prototype.release = function (rootId, optimistic) {\n        return (optimistic ? this.optimisticData : this.data).release(rootId);\n    };\n    // Returns the canonical ID for a given StoreObject, obeying typePolicies\n    // and keyFields (and dataIdFromObject, if you still use that). At minimum,\n    // the object must contain a __typename and any primary key fields required\n    // to identify entities of that type. If you pass a query result object, be\n    // sure that none of the primary key fields have been renamed by aliasing.\n    // If you pass a Reference object, its __ref ID string will be returned.\n    InMemoryCache.prototype.identify = function (object) {\n        if (isReference(object))\n            return object.__ref;\n        try {\n            return this.policies.identify(object)[0];\n        }\n        catch (e) {\n            globalThis.__DEV__ !== false && invariant.warn(e);\n        }\n    };\n    InMemoryCache.prototype.evict = function (options) {\n        if (!options.id) {\n            if (hasOwn.call(options, \"id\")) {\n                // See comment in modify method about why we return false when\n                // options.id exists but is falsy/undefined.\n                return false;\n            }\n            options = __assign(__assign({}, options), { id: \"ROOT_QUERY\" });\n        }\n        try {\n            // It's unlikely that the eviction will end up invoking any other\n            // cache update operations while it's running, but {in,de}crementing\n            // this.txCount still seems like a good idea, for uniformity with\n            // the other update methods.\n            ++this.txCount;\n            // Pass this.data as a limit on the depth of the eviction, so evictions\n            // during optimistic updates (when this.data is temporarily set equal to\n            // this.optimisticData) do not escape their optimistic Layer.\n            return this.optimisticData.evict(options, this.data);\n        }\n        finally {\n            if (!--this.txCount && options.broadcast !== false) {\n                this.broadcastWatches();\n            }\n        }\n    };\n    InMemoryCache.prototype.reset = function (options) {\n        var _this = this;\n        this.init();\n        canonicalStringify.reset();\n        if (options && options.discardWatches) {\n            // Similar to what happens in the unsubscribe function returned by\n            // cache.watch, applied to all current watches.\n            this.watches.forEach(function (watch) { return _this.maybeBroadcastWatch.forget(watch); });\n            this.watches.clear();\n            forgetCache(this);\n        }\n        else {\n            // Calling this.init() above unblocks all maybeBroadcastWatch caching, so\n            // this.broadcastWatches() triggers a broadcast to every current watcher\n            // (letting them know their data is now missing). This default behavior is\n            // convenient because it means the watches do not have to be manually\n            // reestablished after resetting the cache. To prevent this broadcast and\n            // cancel all watches, pass true for options.discardWatches.\n            this.broadcastWatches();\n        }\n        return Promise.resolve();\n    };\n    InMemoryCache.prototype.removeOptimistic = function (idToRemove) {\n        var newOptimisticData = this.optimisticData.removeLayer(idToRemove);\n        if (newOptimisticData !== this.optimisticData) {\n            this.optimisticData = newOptimisticData;\n            this.broadcastWatches();\n        }\n    };\n    InMemoryCache.prototype.batch = function (options) {\n        var _this = this;\n        var update = options.update, _a = options.optimistic, optimistic = _a === void 0 ? true : _a, removeOptimistic = options.removeOptimistic, onWatchUpdated = options.onWatchUpdated;\n        var updateResult;\n        var perform = function (layer) {\n            var _a = _this, data = _a.data, optimisticData = _a.optimisticData;\n            ++_this.txCount;\n            if (layer) {\n                _this.data = _this.optimisticData = layer;\n            }\n            try {\n                return (updateResult = update(_this));\n            }\n            finally {\n                --_this.txCount;\n                _this.data = data;\n                _this.optimisticData = optimisticData;\n            }\n        };\n        var alreadyDirty = new Set();\n        if (onWatchUpdated && !this.txCount) {\n            // If an options.onWatchUpdated callback is provided, we want to call it\n            // with only the Cache.WatchOptions objects affected by options.update,\n            // but there might be dirty watchers already waiting to be broadcast that\n            // have nothing to do with the update. To prevent including those watchers\n            // in the post-update broadcast, we perform this initial broadcast to\n            // collect the dirty watchers, so we can re-dirty them later, after the\n            // post-update broadcast, allowing them to receive their pending\n            // broadcasts the next time broadcastWatches is called, just as they would\n            // if we never called cache.batch.\n            this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function (watch) {\n                    alreadyDirty.add(watch);\n                    return false;\n                } }));\n        }\n        if (typeof optimistic === \"string\") {\n            // Note that there can be multiple layers with the same optimistic ID.\n            // When removeOptimistic(id) is called for that id, all matching layers\n            // will be removed, and the remaining layers will be reapplied.\n            this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\n        }\n        else if (optimistic === false) {\n            // Ensure both this.data and this.optimisticData refer to the root\n            // (non-optimistic) layer of the cache during the update. Note that\n            // this.data could be a Layer if we are currently executing an optimistic\n            // update function, but otherwise will always be an EntityStore.Root\n            // instance.\n            perform(this.data);\n        }\n        else {\n            // Otherwise, leave this.data and this.optimisticData unchanged and run\n            // the update with broadcast batching.\n            perform();\n        }\n        if (typeof removeOptimistic === \"string\") {\n            this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\n        }\n        // Note: if this.txCount > 0, then alreadyDirty.size === 0, so this code\n        // takes the else branch and calls this.broadcastWatches(options), which\n        // does nothing when this.txCount > 0.\n        if (onWatchUpdated && alreadyDirty.size) {\n            this.broadcastWatches(__assign(__assign({}, options), { onWatchUpdated: function (watch, diff) {\n                    var result = onWatchUpdated.call(this, watch, diff);\n                    if (result !== false) {\n                        // Since onWatchUpdated did not return false, this diff is\n                        // about to be broadcast to watch.callback, so we don't need\n                        // to re-dirty it with the other alreadyDirty watches below.\n                        alreadyDirty.delete(watch);\n                    }\n                    return result;\n                } }));\n            // Silently re-dirty any watches that were already dirty before the update\n            // was performed, and were not broadcast just now.\n            if (alreadyDirty.size) {\n                alreadyDirty.forEach(function (watch) { return _this.maybeBroadcastWatch.dirty(watch); });\n            }\n        }\n        else {\n            // If alreadyDirty is empty or we don't have an onWatchUpdated\n            // function, we don't need to go to the trouble of wrapping\n            // options.onWatchUpdated.\n            this.broadcastWatches(options);\n        }\n        return updateResult;\n    };\n    InMemoryCache.prototype.performTransaction = function (update, optimisticId) {\n        return this.batch({\n            update: update,\n            optimistic: optimisticId || optimisticId !== null,\n        });\n    };\n    InMemoryCache.prototype.transformDocument = function (document) {\n        return this.addTypenameToDocument(this.addFragmentsToDocument(document));\n    };\n    InMemoryCache.prototype.fragmentMatches = function (fragment, typename) {\n        return this.policies.fragmentMatches(fragment, typename);\n    };\n    InMemoryCache.prototype.lookupFragment = function (fragmentName) {\n        var _a;\n        return ((_a = this.config.fragments) === null || _a === void 0 ? void 0 : _a.lookup(fragmentName)) || null;\n    };\n    InMemoryCache.prototype.broadcastWatches = function (options) {\n        var _this = this;\n        if (!this.txCount) {\n            this.watches.forEach(function (c) { return _this.maybeBroadcastWatch(c, options); });\n        }\n    };\n    InMemoryCache.prototype.addFragmentsToDocument = function (document) {\n        var fragments = this.config.fragments;\n        return fragments ? fragments.transform(document) : document;\n    };\n    InMemoryCache.prototype.addTypenameToDocument = function (document) {\n        if (this.addTypename) {\n            return this.addTypenameTransform.transformDocument(document);\n        }\n        return document;\n    };\n    // This method is wrapped by maybeBroadcastWatch, which is called by\n    // broadcastWatches, so that we compute and broadcast results only when\n    // the data that would be broadcast might have changed. It would be\n    // simpler to check for changes after recomputing a result but before\n    // broadcasting it, but this wrapping approach allows us to skip both\n    // the recomputation and the broadcast, in most cases.\n    InMemoryCache.prototype.broadcastWatch = function (c, options) {\n        var _this = this;\n        var lastDiff = c.lastDiff;\n        // Both WatchOptions and DiffOptions extend ReadOptions, and DiffOptions\n        // currently requires no additional properties, so we can use c (a\n        // WatchOptions object) as DiffOptions, without having to allocate a new\n        // object, and without having to enumerate the relevant properties (query,\n        // variables, etc.) explicitly. There will be some additional properties\n        // (lastDiff, callback, etc.), but cache.diff ignores them.\n        var diff = muteDeprecations(\"canonizeResults\", function () { return _this.diff(c); });\n        if (options) {\n            if (c.optimistic && typeof options.optimistic === \"string\") {\n                diff.fromOptimisticTransaction = true;\n            }\n            if (options.onWatchUpdated &&\n                options.onWatchUpdated.call(this, c, diff, lastDiff) === false) {\n                // Returning false from the onWatchUpdated callback will prevent\n                // calling c.callback(diff) for this watcher.\n                return;\n            }\n        }\n        if (!lastDiff || !equal(lastDiff.result, diff.result)) {\n            c.callback((c.lastDiff = diff), lastDiff);\n        }\n    };\n    return InMemoryCache;\n}(ApolloCache));\nexport { InMemoryCache };\nif (globalThis.__DEV__ !== false) {\n    InMemoryCache.prototype.getMemoryInternals = getInMemoryCacheMemoryInternals;\n}\n//# sourceMappingURL=inMemoryCache.js.map","import { invariant } from \"../../utilities/globals/index.js\";\nimport { argumentsObjectFromField, DeepMerger, isNonEmptyArray, isNonNullObject, } from \"../../utilities/index.js\";\nimport { hasOwn, isArray } from \"./helpers.js\";\n// Mapping from JSON-encoded KeySpecifier strings to associated information.\nvar specifierInfoCache = Object.create(null);\nfunction lookupSpecifierInfo(spec) {\n    // It's safe to encode KeySpecifier arrays with JSON.stringify, since they're\n    // just arrays of strings or nested KeySpecifier arrays, and the order of the\n    // array elements is important (and suitably preserved by JSON.stringify).\n    var cacheKey = JSON.stringify(spec);\n    return (specifierInfoCache[cacheKey] ||\n        (specifierInfoCache[cacheKey] = Object.create(null)));\n}\nexport function keyFieldsFnFromSpecifier(specifier) {\n    var info = lookupSpecifierInfo(specifier);\n    return (info.keyFieldsFn || (info.keyFieldsFn = function (object, context) {\n            var extract = function (from, key) {\n                return context.readField(key, from);\n            };\n            var keyObject = (context.keyObject = collectSpecifierPaths(specifier, function (schemaKeyPath) {\n                var extracted = extractKeyPath(context.storeObject, schemaKeyPath, \n                // Using context.readField to extract paths from context.storeObject\n                // allows the extraction to see through Reference objects and respect\n                // custom read functions.\n                extract);\n                if (extracted === void 0 &&\n                    object !== context.storeObject &&\n                    hasOwn.call(object, schemaKeyPath[0])) {\n                    // If context.storeObject fails to provide a value for the requested\n                    // path, fall back to the raw result object, if it has a top-level key\n                    // matching the first key in the path (schemaKeyPath[0]). This allows\n                    // key fields included in the written data to be saved in the cache\n                    // even if they are not selected explicitly in context.selectionSet.\n                    // Not being mentioned by context.selectionSet is convenient here,\n                    // since it means these extra fields cannot be affected by field\n                    // aliasing, which is why we can use extractKey instead of\n                    // context.readField for this extraction.\n                    extracted = extractKeyPath(object, schemaKeyPath, extractKey);\n                }\n                invariant(extracted !== void 0, 5, schemaKeyPath.join(\".\"), object);\n                return extracted;\n            }));\n            return \"\".concat(context.typename, \":\").concat(JSON.stringify(keyObject));\n        }));\n}\n// The keyArgs extraction process is roughly analogous to keyFields extraction,\n// but there are no aliases involved, missing fields are tolerated (by merely\n// omitting them from the key), and drawing from field.directives or variables\n// is allowed (in addition to drawing from the field's arguments object).\n// Concretely, these differences mean passing a different key path extractor\n// function to collectSpecifierPaths, reusing the shared extractKeyPath helper\n// wherever possible.\nexport function keyArgsFnFromSpecifier(specifier) {\n    var info = lookupSpecifierInfo(specifier);\n    return (info.keyArgsFn ||\n        (info.keyArgsFn = function (args, _a) {\n            var field = _a.field, variables = _a.variables, fieldName = _a.fieldName;\n            var collected = collectSpecifierPaths(specifier, function (keyPath) {\n                var firstKey = keyPath[0];\n                var firstChar = firstKey.charAt(0);\n                if (firstChar === \"@\") {\n                    if (field && isNonEmptyArray(field.directives)) {\n                        var directiveName_1 = firstKey.slice(1);\n                        // If the directive appears multiple times, only the first\n                        // occurrence's arguments will be used. TODO Allow repetition?\n                        // TODO Cache this work somehow, a la aliasMap?\n                        var d = field.directives.find(function (d) { return d.name.value === directiveName_1; });\n                        // Fortunately argumentsObjectFromField works for DirectiveNode!\n                        var directiveArgs = d && argumentsObjectFromField(d, variables);\n                        // For directives without arguments (d defined, but directiveArgs ===\n                        // null), the presence or absence of the directive still counts as\n                        // part of the field key, so we return null in those cases. If no\n                        // directive with this name was found for this field (d undefined and\n                        // thus directiveArgs undefined), we return undefined, which causes\n                        // this value to be omitted from the key object returned by\n                        // collectSpecifierPaths.\n                        return (directiveArgs &&\n                            extractKeyPath(directiveArgs, \n                            // If keyPath.length === 1, this code calls extractKeyPath with an\n                            // empty path, which works because it uses directiveArgs as the\n                            // extracted value.\n                            keyPath.slice(1)));\n                    }\n                    // If the key started with @ but there was no corresponding directive,\n                    // we want to omit this value from the key object, not fall through to\n                    // treating @whatever as a normal argument name.\n                    return;\n                }\n                if (firstChar === \"$\") {\n                    var variableName = firstKey.slice(1);\n                    if (variables && hasOwn.call(variables, variableName)) {\n                        var varKeyPath = keyPath.slice(0);\n                        varKeyPath[0] = variableName;\n                        return extractKeyPath(variables, varKeyPath);\n                    }\n                    // If the key started with $ but there was no corresponding variable, we\n                    // want to omit this value from the key object, not fall through to\n                    // treating $whatever as a normal argument name.\n                    return;\n                }\n                if (args) {\n                    return extractKeyPath(args, keyPath);\n                }\n            });\n            var suffix = JSON.stringify(collected);\n            // If no arguments were passed to this field, and it didn't have any other\n            // field key contributions from directives or variables, hide the empty\n            // :{} suffix from the field key. However, a field passed no arguments can\n            // still end up with a non-empty :{...} suffix if its key configuration\n            // refers to directives or variables.\n            if (args || suffix !== \"{}\") {\n                fieldName += \":\" + suffix;\n            }\n            return fieldName;\n        }));\n}\nexport function collectSpecifierPaths(specifier, extractor) {\n    // For each path specified by specifier, invoke the extractor, and repeatedly\n    // merge the results together, with appropriate ancestor context.\n    var merger = new DeepMerger();\n    return getSpecifierPaths(specifier).reduce(function (collected, path) {\n        var _a;\n        var toMerge = extractor(path);\n        if (toMerge !== void 0) {\n            // This path is not expected to contain array indexes, so the toMerge\n            // reconstruction will not contain arrays. TODO Fix this?\n            for (var i = path.length - 1; i >= 0; --i) {\n                toMerge = (_a = {}, _a[path[i]] = toMerge, _a);\n            }\n            collected = merger.merge(collected, toMerge);\n        }\n        return collected;\n    }, Object.create(null));\n}\nexport function getSpecifierPaths(spec) {\n    var info = lookupSpecifierInfo(spec);\n    if (!info.paths) {\n        var paths_1 = (info.paths = []);\n        var currentPath_1 = [];\n        spec.forEach(function (s, i) {\n            if (isArray(s)) {\n                getSpecifierPaths(s).forEach(function (p) { return paths_1.push(currentPath_1.concat(p)); });\n                currentPath_1.length = 0;\n            }\n            else {\n                currentPath_1.push(s);\n                if (!isArray(spec[i + 1])) {\n                    paths_1.push(currentPath_1.slice(0));\n                    currentPath_1.length = 0;\n                }\n            }\n        });\n    }\n    return info.paths;\n}\nfunction extractKey(object, key) {\n    return object[key];\n}\nexport function extractKeyPath(object, path, extract) {\n    // For each key in path, extract the corresponding child property from obj,\n    // flattening arrays if encountered (uncommon for keyFields and keyArgs, but\n    // possible). The final result of path.reduce is normalized so unexpected leaf\n    // objects have their keys safely sorted. That final result is difficult to\n    // type as anything other than any. You're welcome to try to improve the\n    // return type, but keep in mind extractKeyPath is not a public function\n    // (exported only for testing), so the effort may not be worthwhile unless the\n    // limited set of actual callers (see above) pass arguments that TypeScript\n    // can statically type. If we know only that path is some array of strings\n    // (and not, say, a specific tuple of statically known strings), any (or\n    // possibly unknown) is the honest answer.\n    extract = extract || extractKey;\n    return normalize(path.reduce(function reducer(obj, key) {\n        return isArray(obj) ?\n            obj.map(function (child) { return reducer(child, key); })\n            : obj && extract(obj, key);\n    }, object));\n}\nfunction normalize(value) {\n    // Usually the extracted value will be a scalar value, since most primary\n    // key fields are scalar, but just in case we get an object or an array, we\n    // need to do some normalization of the order of (nested) keys.\n    if (isNonNullObject(value)) {\n        if (isArray(value)) {\n            return value.map(normalize);\n        }\n        return collectSpecifierPaths(Object.keys(value).sort(), function (path) {\n            return extractKeyPath(value, path);\n        });\n    }\n    return value;\n}\n//# sourceMappingURL=key-extractor.js.map","import { __assign } from \"tslib\";\nimport { Trie } from \"@wry/trie\";\nimport { canUseWeakMap, canUseWeakSet, isNonNullObject as isObjectOrArray, } from \"../../utilities/index.js\";\nimport { isArray } from \"./helpers.js\";\nfunction shallowCopy(value) {\n    if (isObjectOrArray(value)) {\n        return isArray(value) ?\n            value.slice(0)\n            : __assign({ __proto__: Object.getPrototypeOf(value) }, value);\n    }\n    return value;\n}\n// When programmers talk about the \"canonical form\" of an object, they\n// usually have the following meaning in mind, which I've copied from\n// https://en.wiktionary.org/wiki/canonical_form:\n//\n// 1. A standard or normal presentation of a mathematical entity [or\n//    object]. A canonical form is an element of a set of representatives\n//    of equivalence classes of forms such that there is a function or\n//    procedure which projects every element of each equivalence class\n//    onto that one element, the canonical form of that equivalence\n//    class. The canonical form is expected to be simpler than the rest of\n//    the forms in some way.\n//\n// That's a long-winded way of saying any two objects that have the same\n// canonical form may be considered equivalent, even if they are !==,\n// which usually means the objects are structurally equivalent (deeply\n// equal), but don't necessarily use the same memory.\n//\n// Like a literary or musical canon, this ObjectCanon class represents a\n// collection of unique canonical items (JavaScript objects), with the\n// important property that canon.admit(a) === canon.admit(b) if a and b\n// are deeply equal to each other. In terms of the definition above, the\n// canon.admit method is the \"function or procedure which projects every\"\n// object \"onto that one element, the canonical form.\"\n//\n// In the worst case, the canonicalization process may involve looking at\n// every property in the provided object tree, so it takes the same order\n// of time as deep equality checking. Fortunately, already-canonicalized\n// objects are returned immediately from canon.admit, so the presence of\n// canonical subtrees tends to speed up canonicalization.\n//\n// Since consumers of canonical objects can check for deep equality in\n// constant time, canonicalizing cache results can massively improve the\n// performance of application code that skips re-rendering unchanged\n// results, such as \"pure\" UI components in a framework like React.\n//\n// Of course, since canonical objects may be shared widely between\n// unrelated consumers, it's important to think of them as immutable, even\n// though they are not actually frozen with Object.freeze in production,\n// due to the extra performance overhead that comes with frozen objects.\n//\n// Custom scalar objects whose internal class name is neither Array nor\n// Object can be included safely in the admitted tree, but they will not\n// be replaced with a canonical version (to put it another way, they are\n// assumed to be canonical already).\n//\n// If we ignore custom objects, no detection of cycles or repeated object\n// references is currently required by the StoreReader class, since\n// GraphQL result objects are JSON-serializable trees (and thus contain\n// neither cycles nor repeated subtrees), so we can avoid the complexity\n// of keeping track of objects we've already seen during the recursion of\n// the admit method.\n//\n// In the future, we may consider adding additional cases to the switch\n// statement to handle other common object types, such as \"[object Date]\"\n// objects, as needed.\nvar ObjectCanon = /** @class */ (function () {\n    function ObjectCanon() {\n        // Set of all canonical objects this ObjectCanon has admitted, allowing\n        // canon.admit to return previously-canonicalized objects immediately.\n        this.known = new (canUseWeakSet ? WeakSet : Set)();\n        // Efficient storage/lookup structure for canonical objects.\n        this.pool = new Trie(canUseWeakMap);\n        // Make the ObjectCanon assume this value has already been\n        // canonicalized.\n        this.passes = new WeakMap();\n        // Arrays that contain the same elements in a different order can share\n        // the same SortedKeysInfo object, to save memory.\n        this.keysByJSON = new Map();\n        // This has to come last because it depends on keysByJSON.\n        this.empty = this.admit({});\n    }\n    ObjectCanon.prototype.isKnown = function (value) {\n        return isObjectOrArray(value) && this.known.has(value);\n    };\n    ObjectCanon.prototype.pass = function (value) {\n        if (isObjectOrArray(value)) {\n            var copy = shallowCopy(value);\n            this.passes.set(copy, value);\n            return copy;\n        }\n        return value;\n    };\n    ObjectCanon.prototype.admit = function (value) {\n        var _this = this;\n        if (isObjectOrArray(value)) {\n            var original = this.passes.get(value);\n            if (original)\n                return original;\n            var proto = Object.getPrototypeOf(value);\n            switch (proto) {\n                case Array.prototype: {\n                    if (this.known.has(value))\n                        return value;\n                    var array = value.map(this.admit, this);\n                    // Arrays are looked up in the Trie using their recursively\n                    // canonicalized elements, and the known version of the array is\n                    // preserved as node.array.\n                    var node = this.pool.lookupArray(array);\n                    if (!node.array) {\n                        this.known.add((node.array = array));\n                        // Since canonical arrays may be shared widely between\n                        // unrelated consumers, it's important to regard them as\n                        // immutable, even if they are not frozen in production.\n                        if (globalThis.__DEV__ !== false) {\n                            Object.freeze(array);\n                        }\n                    }\n                    return node.array;\n                }\n                case null:\n                case Object.prototype: {\n                    if (this.known.has(value))\n                        return value;\n                    var proto_1 = Object.getPrototypeOf(value);\n                    var array_1 = [proto_1];\n                    var keys = this.sortedKeys(value);\n                    array_1.push(keys.json);\n                    var firstValueIndex_1 = array_1.length;\n                    keys.sorted.forEach(function (key) {\n                        array_1.push(_this.admit(value[key]));\n                    });\n                    // Objects are looked up in the Trie by their prototype (which\n                    // is *not* recursively canonicalized), followed by a JSON\n                    // representation of their (sorted) keys, followed by the\n                    // sequence of recursively canonicalized values corresponding to\n                    // those keys. To keep the final results unambiguous with other\n                    // sequences (such as arrays that just happen to contain [proto,\n                    // keys.json, value1, value2, ...]), the known version of the\n                    // object is stored as node.object.\n                    var node = this.pool.lookupArray(array_1);\n                    if (!node.object) {\n                        var obj_1 = (node.object = Object.create(proto_1));\n                        this.known.add(obj_1);\n                        keys.sorted.forEach(function (key, i) {\n                            obj_1[key] = array_1[firstValueIndex_1 + i];\n                        });\n                        // Since canonical objects may be shared widely between\n                        // unrelated consumers, it's important to regard them as\n                        // immutable, even if they are not frozen in production.\n                        if (globalThis.__DEV__ !== false) {\n                            Object.freeze(obj_1);\n                        }\n                    }\n                    return node.object;\n                }\n            }\n        }\n        return value;\n    };\n    // It's worthwhile to cache the sorting of arrays of strings, since the\n    // same initial unsorted arrays tend to be encountered many times.\n    // Fortunately, we can reuse the Trie machinery to look up the sorted\n    // arrays in linear time (which is faster than sorting large arrays).\n    ObjectCanon.prototype.sortedKeys = function (obj) {\n        var keys = Object.keys(obj);\n        var node = this.pool.lookupArray(keys);\n        if (!node.keys) {\n            keys.sort();\n            var json = JSON.stringify(keys);\n            if (!(node.keys = this.keysByJSON.get(json))) {\n                this.keysByJSON.set(json, (node.keys = { sorted: keys, json: json }));\n            }\n        }\n        return node.keys;\n    };\n    return ObjectCanon;\n}());\nexport { ObjectCanon };\n//# sourceMappingURL=object-canon.js.map","import { __assign, __rest } from \"tslib\";\nimport { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\nimport { storeKeyNameFromField, argumentsObjectFromField, isReference, getStoreKeyName, isNonNullObject, stringifyForDisplay, } from \"../../utilities/index.js\";\nimport { hasOwn, fieldNameFromStoreName, storeValueIsStoreObject, selectionSetMatchesResult, TypeOrFieldNameRegExp, defaultDataIdFromObject, isArray, } from \"./helpers.js\";\nimport { cacheSlot } from \"./reactiveVars.js\";\nimport { keyArgsFnFromSpecifier, keyFieldsFnFromSpecifier, } from \"./key-extractor.js\";\nimport { disableWarningsSlot } from \"../../masking/index.js\";\nfunction argsFromFieldSpecifier(spec) {\n    return (spec.args !== void 0 ? spec.args\n        : spec.field ? argumentsObjectFromField(spec.field, spec.variables)\n            : null);\n}\nvar nullKeyFieldsFn = function () { return void 0; };\nvar simpleKeyArgsFn = function (_args, context) { return context.fieldName; };\n// These merge functions can be selected by specifying merge:true or\n// merge:false in a field policy.\nvar mergeTrueFn = function (existing, incoming, _a) {\n    var mergeObjects = _a.mergeObjects;\n    return mergeObjects(existing, incoming);\n};\nvar mergeFalseFn = function (_, incoming) { return incoming; };\nvar Policies = /** @class */ (function () {\n    function Policies(config) {\n        this.config = config;\n        this.typePolicies = Object.create(null);\n        this.toBeAdded = Object.create(null);\n        // Map from subtype names to sets of supertype names. Note that this\n        // representation inverts the structure of possibleTypes (whose keys are\n        // supertypes and whose values are arrays of subtypes) because it tends\n        // to be much more efficient to search upwards than downwards.\n        this.supertypeMap = new Map();\n        // Any fuzzy subtypes specified by possibleTypes will be converted to\n        // RegExp objects and recorded here. Every key of this map can also be\n        // found in supertypeMap. In many cases this Map will be empty, which\n        // means no fuzzy subtype checking will happen in fragmentMatches.\n        this.fuzzySubtypes = new Map();\n        this.rootIdsByTypename = Object.create(null);\n        this.rootTypenamesById = Object.create(null);\n        this.usingPossibleTypes = false;\n        this.config = __assign({ dataIdFromObject: defaultDataIdFromObject }, config);\n        this.cache = this.config.cache;\n        this.setRootTypename(\"Query\");\n        this.setRootTypename(\"Mutation\");\n        this.setRootTypename(\"Subscription\");\n        if (config.possibleTypes) {\n            this.addPossibleTypes(config.possibleTypes);\n        }\n        if (config.typePolicies) {\n            this.addTypePolicies(config.typePolicies);\n        }\n    }\n    Policies.prototype.identify = function (object, partialContext) {\n        var _a;\n        var policies = this;\n        var typename = (partialContext &&\n            (partialContext.typename || ((_a = partialContext.storeObject) === null || _a === void 0 ? void 0 : _a.__typename))) ||\n            object.__typename;\n        // It should be possible to write root Query fields with writeFragment,\n        // using { __typename: \"Query\", ... } as the data, but it does not make\n        // sense to allow the same identification behavior for the Mutation and\n        // Subscription types, since application code should never be writing\n        // directly to (or reading directly from) those root objects.\n        if (typename === this.rootTypenamesById.ROOT_QUERY) {\n            return [\"ROOT_QUERY\"];\n        }\n        // Default context.storeObject to object if not otherwise provided.\n        var storeObject = (partialContext && partialContext.storeObject) || object;\n        var context = __assign(__assign({}, partialContext), { typename: typename, storeObject: storeObject, readField: (partialContext && partialContext.readField) ||\n                function () {\n                    var options = normalizeReadFieldOptions(arguments, storeObject);\n                    return policies.readField(options, {\n                        store: policies.cache[\"data\"],\n                        variables: options.variables,\n                    });\n                } });\n        var id;\n        var policy = typename && this.getTypePolicy(typename);\n        var keyFn = (policy && policy.keyFn) || this.config.dataIdFromObject;\n        disableWarningsSlot.withValue(true, function () {\n            while (keyFn) {\n                var specifierOrId = keyFn(__assign(__assign({}, object), storeObject), context);\n                if (isArray(specifierOrId)) {\n                    keyFn = keyFieldsFnFromSpecifier(specifierOrId);\n                }\n                else {\n                    id = specifierOrId;\n                    break;\n                }\n            }\n        });\n        id = id ? String(id) : void 0;\n        return context.keyObject ? [id, context.keyObject] : [id];\n    };\n    Policies.prototype.addTypePolicies = function (typePolicies) {\n        var _this = this;\n        Object.keys(typePolicies).forEach(function (typename) {\n            var _a = typePolicies[typename], queryType = _a.queryType, mutationType = _a.mutationType, subscriptionType = _a.subscriptionType, incoming = __rest(_a, [\"queryType\", \"mutationType\", \"subscriptionType\"]);\n            // Though {query,mutation,subscription}Type configurations are rare,\n            // it's important to call setRootTypename as early as possible,\n            // since these configurations should apply consistently for the\n            // entire lifetime of the cache. Also, since only one __typename can\n            // qualify as one of these root types, these three properties cannot\n            // be inherited, unlike the rest of the incoming properties. That\n            // restriction is convenient, because the purpose of this.toBeAdded\n            // is to delay the processing of type/field policies until the first\n            // time they're used, allowing policies to be added in any order as\n            // long as all relevant policies (including policies for supertypes)\n            // have been added by the time a given policy is used for the first\n            // time. In other words, since inheritance doesn't matter for these\n            // properties, there's also no need to delay their processing using\n            // the this.toBeAdded queue.\n            if (queryType)\n                _this.setRootTypename(\"Query\", typename);\n            if (mutationType)\n                _this.setRootTypename(\"Mutation\", typename);\n            if (subscriptionType)\n                _this.setRootTypename(\"Subscription\", typename);\n            if (hasOwn.call(_this.toBeAdded, typename)) {\n                _this.toBeAdded[typename].push(incoming);\n            }\n            else {\n                _this.toBeAdded[typename] = [incoming];\n            }\n        });\n    };\n    Policies.prototype.updateTypePolicy = function (typename, incoming, existingFieldPolicies) {\n        var existing = this.getTypePolicy(typename);\n        var keyFields = incoming.keyFields, fields = incoming.fields;\n        function setMerge(existing, merge) {\n            existing.merge =\n                typeof merge === \"function\" ? merge\n                    // Pass merge:true as a shorthand for a merge implementation\n                    // that returns options.mergeObjects(existing, incoming).\n                    : merge === true ? mergeTrueFn\n                        // Pass merge:false to make incoming always replace existing\n                        // without any warnings about data clobbering.\n                        : merge === false ? mergeFalseFn\n                            : existing.merge;\n        }\n        // Type policies can define merge functions, as an alternative to\n        // using field policies to merge child objects.\n        setMerge(existing, incoming.merge);\n        existing.keyFn =\n            // Pass false to disable normalization for this typename.\n            keyFields === false ? nullKeyFieldsFn\n                // Pass an array of strings to use those fields to compute a\n                // composite ID for objects of this typename.\n                : isArray(keyFields) ? keyFieldsFnFromSpecifier(keyFields)\n                    // Pass a function to take full control over identification.\n                    : typeof keyFields === \"function\" ? keyFields\n                        // Leave existing.keyFn unchanged if above cases fail.\n                        : existing.keyFn;\n        if (fields) {\n            Object.keys(fields).forEach(function (fieldName) {\n                var existing = existingFieldPolicies[fieldName];\n                // Field policy inheritance is atomic/shallow: you can't inherit a\n                // field policy and then override just its read function, since read\n                // and merge functions often need to cooperate, so changing only one\n                // of them would be a recipe for inconsistency.\n                // So here we avoid merging an inherited field policy with an updated one.\n                if (!existing || (existing === null || existing === void 0 ? void 0 : existing.typename) !== typename) {\n                    existing = existingFieldPolicies[fieldName] = { typename: typename };\n                }\n                var incoming = fields[fieldName];\n                if (typeof incoming === \"function\") {\n                    existing.read = incoming;\n                }\n                else {\n                    var keyArgs = incoming.keyArgs, read = incoming.read, merge = incoming.merge;\n                    existing.keyFn =\n                        // Pass false to disable argument-based differentiation of\n                        // field identities.\n                        keyArgs === false ? simpleKeyArgsFn\n                            // Pass an array of strings to use named arguments to\n                            // compute a composite identity for the field.\n                            : isArray(keyArgs) ? keyArgsFnFromSpecifier(keyArgs)\n                                // Pass a function to take full control over field identity.\n                                : typeof keyArgs === \"function\" ? keyArgs\n                                    // Leave existing.keyFn unchanged if above cases fail.\n                                    : existing.keyFn;\n                    if (typeof read === \"function\") {\n                        existing.read = read;\n                    }\n                    setMerge(existing, merge);\n                }\n                if (existing.read && existing.merge) {\n                    // If we have both a read and a merge function, assume\n                    // keyArgs:false, because read and merge together can take\n                    // responsibility for interpreting arguments in and out. This\n                    // default assumption can always be overridden by specifying\n                    // keyArgs explicitly in the FieldPolicy.\n                    existing.keyFn = existing.keyFn || simpleKeyArgsFn;\n                }\n            });\n        }\n    };\n    Policies.prototype.setRootTypename = function (which, typename) {\n        if (typename === void 0) { typename = which; }\n        var rootId = \"ROOT_\" + which.toUpperCase();\n        var old = this.rootTypenamesById[rootId];\n        if (typename !== old) {\n            invariant(!old || old === which, 6, which);\n            // First, delete any old __typename associated with this rootId from\n            // rootIdsByTypename.\n            if (old)\n                delete this.rootIdsByTypename[old];\n            // Now make this the only __typename that maps to this rootId.\n            this.rootIdsByTypename[typename] = rootId;\n            // Finally, update the __typename associated with this rootId.\n            this.rootTypenamesById[rootId] = typename;\n        }\n    };\n    Policies.prototype.addPossibleTypes = function (possibleTypes) {\n        var _this = this;\n        this.usingPossibleTypes = true;\n        Object.keys(possibleTypes).forEach(function (supertype) {\n            // Make sure all types have an entry in this.supertypeMap, even if\n            // their supertype set is empty, so we can return false immediately\n            // from policies.fragmentMatches for unknown supertypes.\n            _this.getSupertypeSet(supertype, true);\n            possibleTypes[supertype].forEach(function (subtype) {\n                _this.getSupertypeSet(subtype, true).add(supertype);\n                var match = subtype.match(TypeOrFieldNameRegExp);\n                if (!match || match[0] !== subtype) {\n                    // TODO Don't interpret just any invalid typename as a RegExp.\n                    _this.fuzzySubtypes.set(subtype, new RegExp(subtype));\n                }\n            });\n        });\n    };\n    Policies.prototype.getTypePolicy = function (typename) {\n        var _this = this;\n        if (!hasOwn.call(this.typePolicies, typename)) {\n            var policy_1 = (this.typePolicies[typename] = Object.create(null));\n            policy_1.fields = Object.create(null);\n            // When the TypePolicy for typename is first accessed, instead of\n            // starting with an empty policy object, inherit any properties or\n            // fields from the type policies of the supertypes of typename.\n            //\n            // Any properties or fields defined explicitly within the TypePolicy\n            // for typename will take precedence, and if there are multiple\n            // supertypes, the properties of policies whose types were added\n            // later via addPossibleTypes will take precedence over those of\n            // earlier supertypes. TODO Perhaps we should warn about these\n            // conflicts in development, and recommend defining the property\n            // explicitly in the subtype policy?\n            //\n            // Field policy inheritance is atomic/shallow: you can't inherit a\n            // field policy and then override just its read function, since read\n            // and merge functions often need to cooperate, so changing only one\n            // of them would be a recipe for inconsistency.\n            //\n            // Once the TypePolicy for typename has been accessed, its properties can\n            // still be updated directly using addTypePolicies, but future changes to\n            // inherited supertype policies will not be reflected in this subtype\n            // policy, because this code runs at most once per typename.\n            var supertypes_1 = this.supertypeMap.get(typename);\n            if (!supertypes_1 && this.fuzzySubtypes.size) {\n                // To make the inheritance logic work for unknown typename strings that\n                // may have fuzzy supertypes, we give this typename an empty supertype\n                // set and then populate it with any fuzzy supertypes that match.\n                supertypes_1 = this.getSupertypeSet(typename, true);\n                // This only works for typenames that are directly matched by a fuzzy\n                // supertype. What if there is an intermediate chain of supertypes?\n                // While possible, that situation can only be solved effectively by\n                // specifying the intermediate relationships via possibleTypes, manually\n                // and in a non-fuzzy way.\n                this.fuzzySubtypes.forEach(function (regExp, fuzzy) {\n                    if (regExp.test(typename)) {\n                        // The fuzzy parameter is just the original string version of regExp\n                        // (not a valid __typename string), but we can look up the\n                        // associated supertype(s) in this.supertypeMap.\n                        var fuzzySupertypes = _this.supertypeMap.get(fuzzy);\n                        if (fuzzySupertypes) {\n                            fuzzySupertypes.forEach(function (supertype) {\n                                return supertypes_1.add(supertype);\n                            });\n                        }\n                    }\n                });\n            }\n            if (supertypes_1 && supertypes_1.size) {\n                supertypes_1.forEach(function (supertype) {\n                    var _a = _this.getTypePolicy(supertype), fields = _a.fields, rest = __rest(_a, [\"fields\"]);\n                    Object.assign(policy_1, rest);\n                    Object.assign(policy_1.fields, fields);\n                });\n            }\n        }\n        var inbox = this.toBeAdded[typename];\n        if (inbox && inbox.length) {\n            // Merge the pending policies into this.typePolicies, in the order they\n            // were originally passed to addTypePolicy.\n            inbox.splice(0).forEach(function (policy) {\n                _this.updateTypePolicy(typename, policy, _this.typePolicies[typename].fields);\n            });\n        }\n        return this.typePolicies[typename];\n    };\n    Policies.prototype.getFieldPolicy = function (typename, fieldName) {\n        if (typename) {\n            return this.getTypePolicy(typename).fields[fieldName];\n        }\n    };\n    Policies.prototype.getSupertypeSet = function (subtype, createIfMissing) {\n        var supertypeSet = this.supertypeMap.get(subtype);\n        if (!supertypeSet && createIfMissing) {\n            this.supertypeMap.set(subtype, (supertypeSet = new Set()));\n        }\n        return supertypeSet;\n    };\n    Policies.prototype.fragmentMatches = function (fragment, typename, result, variables) {\n        var _this = this;\n        if (!fragment.typeCondition)\n            return true;\n        // If the fragment has a type condition but the object we're matching\n        // against does not have a __typename, the fragment cannot match.\n        if (!typename)\n            return false;\n        var supertype = fragment.typeCondition.name.value;\n        // Common case: fragment type condition and __typename are the same.\n        if (typename === supertype)\n            return true;\n        if (this.usingPossibleTypes && this.supertypeMap.has(supertype)) {\n            var typenameSupertypeSet = this.getSupertypeSet(typename, true);\n            var workQueue_1 = [typenameSupertypeSet];\n            var maybeEnqueue_1 = function (subtype) {\n                var supertypeSet = _this.getSupertypeSet(subtype, false);\n                if (supertypeSet &&\n                    supertypeSet.size &&\n                    workQueue_1.indexOf(supertypeSet) < 0) {\n                    workQueue_1.push(supertypeSet);\n                }\n            };\n            // We need to check fuzzy subtypes only if we encountered fuzzy\n            // subtype strings in addPossibleTypes, and only while writing to\n            // the cache, since that's when selectionSetMatchesResult gives a\n            // strong signal of fragment matching. The StoreReader class calls\n            // policies.fragmentMatches without passing a result object, so\n            // needToCheckFuzzySubtypes is always false while reading.\n            var needToCheckFuzzySubtypes = !!(result && this.fuzzySubtypes.size);\n            var checkingFuzzySubtypes = false;\n            // It's important to keep evaluating workQueue.length each time through\n            // the loop, because the queue can grow while we're iterating over it.\n            for (var i = 0; i < workQueue_1.length; ++i) {\n                var supertypeSet = workQueue_1[i];\n                if (supertypeSet.has(supertype)) {\n                    if (!typenameSupertypeSet.has(supertype)) {\n                        if (checkingFuzzySubtypes) {\n                            globalThis.__DEV__ !== false && invariant.warn(7, typename, supertype);\n                        }\n                        // Record positive results for faster future lookup.\n                        // Unfortunately, we cannot safely cache negative results,\n                        // because new possibleTypes data could always be added to the\n                        // Policies class.\n                        typenameSupertypeSet.add(supertype);\n                    }\n                    return true;\n                }\n                supertypeSet.forEach(maybeEnqueue_1);\n                if (needToCheckFuzzySubtypes &&\n                    // Start checking fuzzy subtypes only after exhausting all\n                    // non-fuzzy subtypes (after the final iteration of the loop).\n                    i === workQueue_1.length - 1 &&\n                    // We could wait to compare fragment.selectionSet to result\n                    // after we verify the supertype, but this check is often less\n                    // expensive than that search, and we will have to do the\n                    // comparison anyway whenever we find a potential match.\n                    selectionSetMatchesResult(fragment.selectionSet, result, variables)) {\n                    // We don't always need to check fuzzy subtypes (if no result\n                    // was provided, or !this.fuzzySubtypes.size), but, when we do,\n                    // we only want to check them once.\n                    needToCheckFuzzySubtypes = false;\n                    checkingFuzzySubtypes = true;\n                    // If we find any fuzzy subtypes that match typename, extend the\n                    // workQueue to search through the supertypes of those fuzzy\n                    // subtypes. Otherwise the for-loop will terminate and we'll\n                    // return false below.\n                    this.fuzzySubtypes.forEach(function (regExp, fuzzyString) {\n                        var match = typename.match(regExp);\n                        if (match && match[0] === typename) {\n                            maybeEnqueue_1(fuzzyString);\n                        }\n                    });\n                }\n            }\n        }\n        return false;\n    };\n    Policies.prototype.hasKeyArgs = function (typename, fieldName) {\n        var policy = this.getFieldPolicy(typename, fieldName);\n        return !!(policy && policy.keyFn);\n    };\n    Policies.prototype.getStoreFieldName = function (fieldSpec) {\n        var typename = fieldSpec.typename, fieldName = fieldSpec.fieldName;\n        var policy = this.getFieldPolicy(typename, fieldName);\n        var storeFieldName;\n        var keyFn = policy && policy.keyFn;\n        if (keyFn && typename) {\n            var context = {\n                typename: typename,\n                fieldName: fieldName,\n                field: fieldSpec.field || null,\n                variables: fieldSpec.variables,\n            };\n            var args = argsFromFieldSpecifier(fieldSpec);\n            while (keyFn) {\n                var specifierOrString = keyFn(args, context);\n                if (isArray(specifierOrString)) {\n                    keyFn = keyArgsFnFromSpecifier(specifierOrString);\n                }\n                else {\n                    // If the custom keyFn returns a falsy value, fall back to\n                    // fieldName instead.\n                    storeFieldName = specifierOrString || fieldName;\n                    break;\n                }\n            }\n        }\n        if (storeFieldName === void 0) {\n            storeFieldName =\n                fieldSpec.field ?\n                    storeKeyNameFromField(fieldSpec.field, fieldSpec.variables)\n                    : getStoreKeyName(fieldName, argsFromFieldSpecifier(fieldSpec));\n        }\n        // Returning false from a keyArgs function is like configuring\n        // keyArgs: false, but more dynamic.\n        if (storeFieldName === false) {\n            return fieldName;\n        }\n        // Make sure custom field names start with the actual field.name.value\n        // of the field, so we can always figure out which properties of a\n        // StoreObject correspond to which original field names.\n        return fieldName === fieldNameFromStoreName(storeFieldName) ? storeFieldName\n            : fieldName + \":\" + storeFieldName;\n    };\n    Policies.prototype.readField = function (options, context) {\n        var objectOrReference = options.from;\n        if (!objectOrReference)\n            return;\n        var nameOrField = options.field || options.fieldName;\n        if (!nameOrField)\n            return;\n        if (options.typename === void 0) {\n            var typename = context.store.getFieldValue(objectOrReference, \"__typename\");\n            if (typename)\n                options.typename = typename;\n        }\n        var storeFieldName = this.getStoreFieldName(options);\n        var fieldName = fieldNameFromStoreName(storeFieldName);\n        var existing = context.store.getFieldValue(objectOrReference, storeFieldName);\n        var policy = this.getFieldPolicy(options.typename, fieldName);\n        var read = policy && policy.read;\n        if (read) {\n            var readOptions = makeFieldFunctionOptions(this, objectOrReference, options, context, context.store.getStorage(isReference(objectOrReference) ?\n                objectOrReference.__ref\n                : objectOrReference, storeFieldName));\n            // Call read(existing, readOptions) with cacheSlot holding this.cache.\n            return cacheSlot.withValue(this.cache, read, [\n                existing,\n                readOptions,\n            ]);\n        }\n        return existing;\n    };\n    Policies.prototype.getReadFunction = function (typename, fieldName) {\n        var policy = this.getFieldPolicy(typename, fieldName);\n        return policy && policy.read;\n    };\n    Policies.prototype.getMergeFunction = function (parentTypename, fieldName, childTypename) {\n        var policy = this.getFieldPolicy(parentTypename, fieldName);\n        var merge = policy && policy.merge;\n        if (!merge && childTypename) {\n            policy = this.getTypePolicy(childTypename);\n            merge = policy && policy.merge;\n        }\n        return merge;\n    };\n    Policies.prototype.runMergeFunction = function (existing, incoming, _a, context, storage) {\n        var field = _a.field, typename = _a.typename, merge = _a.merge;\n        if (merge === mergeTrueFn) {\n            // Instead of going to the trouble of creating a full\n            // FieldFunctionOptions object and calling mergeTrueFn, we can\n            // simply call mergeObjects, as mergeTrueFn would.\n            return makeMergeObjectsFunction(context.store)(existing, incoming);\n        }\n        if (merge === mergeFalseFn) {\n            // Likewise for mergeFalseFn, whose implementation is even simpler.\n            return incoming;\n        }\n        // If cache.writeQuery or cache.writeFragment was called with\n        // options.overwrite set to true, we still call merge functions, but\n        // the existing data is always undefined, so the merge function will\n        // not attempt to combine the incoming data with the existing data.\n        if (context.overwrite) {\n            existing = void 0;\n        }\n        return merge(existing, incoming, makeFieldFunctionOptions(this, \n        // Unlike options.readField for read functions, we do not fall\n        // back to the current object if no foreignObjOrRef is provided,\n        // because it's not clear what the current object should be for\n        // merge functions: the (possibly undefined) existing object, or\n        // the incoming object? If you think your merge function needs\n        // to read sibling fields in order to produce a new value for\n        // the current field, you might want to rethink your strategy,\n        // because that's a recipe for making merge behavior sensitive\n        // to the order in which fields are written into the cache.\n        // However, readField(name, ref) is useful for merge functions\n        // that need to deduplicate child objects and references.\n        void 0, {\n            typename: typename,\n            fieldName: field.name.value,\n            field: field,\n            variables: context.variables,\n        }, context, storage || Object.create(null)));\n    };\n    return Policies;\n}());\nexport { Policies };\nfunction makeFieldFunctionOptions(policies, objectOrReference, fieldSpec, context, storage) {\n    var storeFieldName = policies.getStoreFieldName(fieldSpec);\n    var fieldName = fieldNameFromStoreName(storeFieldName);\n    var variables = fieldSpec.variables || context.variables;\n    var _a = context.store, toReference = _a.toReference, canRead = _a.canRead;\n    return {\n        args: argsFromFieldSpecifier(fieldSpec),\n        field: fieldSpec.field || null,\n        fieldName: fieldName,\n        storeFieldName: storeFieldName,\n        variables: variables,\n        isReference: isReference,\n        toReference: toReference,\n        storage: storage,\n        cache: policies.cache,\n        canRead: canRead,\n        readField: function () {\n            return policies.readField(normalizeReadFieldOptions(arguments, objectOrReference, variables), context);\n        },\n        mergeObjects: makeMergeObjectsFunction(context.store),\n    };\n}\nexport function normalizeReadFieldOptions(readFieldArgs, objectOrReference, variables) {\n    var fieldNameOrOptions = readFieldArgs[0], from = readFieldArgs[1], argc = readFieldArgs.length;\n    var options;\n    if (typeof fieldNameOrOptions === \"string\") {\n        options = {\n            fieldName: fieldNameOrOptions,\n            // Default to objectOrReference only when no second argument was\n            // passed for the from parameter, not when undefined is explicitly\n            // passed as the second argument.\n            from: argc > 1 ? from : objectOrReference,\n        };\n    }\n    else {\n        options = __assign({}, fieldNameOrOptions);\n        // Default to objectOrReference only when fieldNameOrOptions.from is\n        // actually omitted, rather than just undefined.\n        if (!hasOwn.call(options, \"from\")) {\n            options.from = objectOrReference;\n        }\n    }\n    if (globalThis.__DEV__ !== false && options.from === void 0) {\n        globalThis.__DEV__ !== false && invariant.warn(8, stringifyForDisplay(Array.from(readFieldArgs)));\n    }\n    if (void 0 === options.variables) {\n        options.variables = variables;\n    }\n    return options;\n}\nfunction makeMergeObjectsFunction(store) {\n    return function mergeObjects(existing, incoming) {\n        if (isArray(existing) || isArray(incoming)) {\n            throw newInvariantError(9);\n        }\n        // These dynamic checks are necessary because the parameters of a\n        // custom merge function can easily have the any type, so the type\n        // system cannot always enforce the StoreObject | Reference parameter\n        // types of options.mergeObjects.\n        if (isNonNullObject(existing) && isNonNullObject(incoming)) {\n            var eType = store.getFieldValue(existing, \"__typename\");\n            var iType = store.getFieldValue(incoming, \"__typename\");\n            var typesDiffer = eType && iType && eType !== iType;\n            if (typesDiffer) {\n                return incoming;\n            }\n            if (isReference(existing) && storeValueIsStoreObject(incoming)) {\n                // Update the normalized EntityStore for the entity identified by\n                // existing.__ref, preferring/overwriting any fields contributed by the\n                // newer incoming StoreObject.\n                store.merge(existing.__ref, incoming);\n                return existing;\n            }\n            if (storeValueIsStoreObject(existing) && isReference(incoming)) {\n                // Update the normalized EntityStore for the entity identified by\n                // incoming.__ref, taking fields from the older existing object only if\n                // those fields are not already present in the newer StoreObject\n                // identified by incoming.__ref.\n                store.merge(existing, incoming.__ref);\n                return incoming;\n            }\n            if (storeValueIsStoreObject(existing) &&\n                storeValueIsStoreObject(incoming)) {\n                return __assign(__assign({}, existing), incoming);\n            }\n        }\n        return incoming;\n    };\n}\n//# sourceMappingURL=policies.js.map","import { dep, Slot } from \"optimism\";\n// Contextual Slot that acquires its value when custom read functions are\n// called in Policies#readField.\nexport var cacheSlot = new Slot();\nvar cacheInfoMap = new WeakMap();\nfunction getCacheInfo(cache) {\n    var info = cacheInfoMap.get(cache);\n    if (!info) {\n        cacheInfoMap.set(cache, (info = {\n            vars: new Set(),\n            dep: dep(),\n        }));\n    }\n    return info;\n}\nexport function forgetCache(cache) {\n    getCacheInfo(cache).vars.forEach(function (rv) { return rv.forgetCache(cache); });\n}\n// Calling forgetCache(cache) serves to silence broadcasts and allows the\n// cache to be garbage collected. However, the varsByCache WeakMap\n// preserves the set of reactive variables that were previously associated\n// with this cache, which makes it possible to \"recall\" the cache at a\n// later time, by reattaching it to those variables. If the cache has been\n// garbage collected in the meantime, because it is no longer reachable,\n// you won't be able to call recallCache(cache), and the cache will\n// automatically disappear from the varsByCache WeakMap.\nexport function recallCache(cache) {\n    getCacheInfo(cache).vars.forEach(function (rv) { return rv.attachCache(cache); });\n}\nexport function makeVar(value) {\n    var caches = new Set();\n    var listeners = new Set();\n    var rv = function (newValue) {\n        if (arguments.length > 0) {\n            if (value !== newValue) {\n                value = newValue;\n                caches.forEach(function (cache) {\n                    // Invalidate any fields with custom read functions that\n                    // consumed this variable, so query results involving those\n                    // fields will be recomputed the next time we read them.\n                    getCacheInfo(cache).dep.dirty(rv);\n                    // Broadcast changes to any caches that have previously read\n                    // from this variable.\n                    broadcast(cache);\n                });\n                // Finally, notify any listeners added via rv.onNextChange.\n                var oldListeners = Array.from(listeners);\n                listeners.clear();\n                oldListeners.forEach(function (listener) { return listener(value); });\n            }\n        }\n        else {\n            // When reading from the variable, obtain the current cache from\n            // context via cacheSlot. This isn't entirely foolproof, but it's\n            // the same system that powers varDep.\n            var cache = cacheSlot.getValue();\n            if (cache) {\n                attach(cache);\n                getCacheInfo(cache).dep(rv);\n            }\n        }\n        return value;\n    };\n    rv.onNextChange = function (listener) {\n        listeners.add(listener);\n        return function () {\n            listeners.delete(listener);\n        };\n    };\n    var attach = (rv.attachCache = function (cache) {\n        caches.add(cache);\n        getCacheInfo(cache).vars.add(rv);\n        return rv;\n    });\n    rv.forgetCache = function (cache) { return caches.delete(cache); };\n    return rv;\n}\nfunction broadcast(cache) {\n    if (cache.broadcastWatches) {\n        cache.broadcastWatches();\n    }\n}\n//# sourceMappingURL=reactiveVars.js.map","import { __assign } from \"tslib\";\nimport { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\nimport { Kind } from \"graphql\";\nimport { wrap } from \"optimism\";\nimport { isField, resultKeyNameFromField, isReference, makeReference, shouldInclude, addTypenameToDocument, getDefaultValues, getMainDefinition, getQueryDefinition, getFragmentFromSelection, maybeDeepFreeze, mergeDeepArray, DeepMerger, isNonNullObject, canUseWeakMap, compact, canonicalStringify, cacheSizes, } from \"../../utilities/index.js\";\nimport { maybeDependOnExistenceOfEntity, supportsResultCaching, } from \"./entityStore.js\";\nimport { isArray, extractFragmentContext, getTypenameFromStoreObject, shouldCanonizeResults, } from \"./helpers.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport { ObjectCanon } from \"./object-canon.js\";\nfunction execSelectionSetKeyArgs(options) {\n    return [\n        options.selectionSet,\n        options.objectOrReference,\n        options.context,\n        // We split out this property so we can pass different values\n        // independently without modifying options.context itself.\n        options.context.canonizeResults,\n    ];\n}\nvar StoreReader = /** @class */ (function () {\n    function StoreReader(config) {\n        var _this = this;\n        this.knownResults = new (canUseWeakMap ? WeakMap : Map)();\n        this.config = compact(config, {\n            addTypename: config.addTypename !== false,\n            canonizeResults: shouldCanonizeResults(config),\n        });\n        this.canon = config.canon || new ObjectCanon();\n        // memoized functions in this class will be \"garbage-collected\"\n        // by recreating the whole `StoreReader` in\n        // `InMemoryCache.resetResultsCache`\n        // (triggered from `InMemoryCache.gc` with `resetResultCache: true`)\n        this.executeSelectionSet = wrap(function (options) {\n            var _a;\n            var canonizeResults = options.context.canonizeResults;\n            var peekArgs = execSelectionSetKeyArgs(options);\n            // Negate this boolean option so we can find out if we've already read\n            // this result using the other boolean value.\n            peekArgs[3] = !canonizeResults;\n            var other = (_a = _this.executeSelectionSet).peek.apply(_a, peekArgs);\n            if (other) {\n                if (canonizeResults) {\n                    return __assign(__assign({}, other), { \n                        // If we previously read this result without canonizing it, we can\n                        // reuse that result simply by canonizing it now.\n                        result: _this.canon.admit(other.result) });\n                }\n                // If we previously read this result with canonization enabled, we can\n                // return that canonized result as-is.\n                return other;\n            }\n            maybeDependOnExistenceOfEntity(options.context.store, options.enclosingRef.__ref);\n            // Finally, if we didn't find any useful previous results, run the real\n            // execSelectionSetImpl method with the given options.\n            return _this.execSelectionSetImpl(options);\n        }, {\n            max: this.config.resultCacheMaxSize ||\n                cacheSizes[\"inMemoryCache.executeSelectionSet\"] ||\n                50000 /* defaultCacheSizes[\"inMemoryCache.executeSelectionSet\"] */,\n            keyArgs: execSelectionSetKeyArgs,\n            // Note that the parameters of makeCacheKey are determined by the\n            // array returned by keyArgs.\n            makeCacheKey: function (selectionSet, parent, context, canonizeResults) {\n                if (supportsResultCaching(context.store)) {\n                    return context.store.makeCacheKey(selectionSet, isReference(parent) ? parent.__ref : parent, context.varString, canonizeResults);\n                }\n            },\n        });\n        this.executeSubSelectedArray = wrap(function (options) {\n            maybeDependOnExistenceOfEntity(options.context.store, options.enclosingRef.__ref);\n            return _this.execSubSelectedArrayImpl(options);\n        }, {\n            max: this.config.resultCacheMaxSize ||\n                cacheSizes[\"inMemoryCache.executeSubSelectedArray\"] ||\n                10000 /* defaultCacheSizes[\"inMemoryCache.executeSubSelectedArray\"] */,\n            makeCacheKey: function (_a) {\n                var field = _a.field, array = _a.array, context = _a.context;\n                if (supportsResultCaching(context.store)) {\n                    return context.store.makeCacheKey(field, array, context.varString);\n                }\n            },\n        });\n    }\n    StoreReader.prototype.resetCanon = function () {\n        this.canon = new ObjectCanon();\n    };\n    /**\n     * Given a store and a query, return as much of the result as possible and\n     * identify if any data was missing from the store.\n     */\n    StoreReader.prototype.diffQueryAgainstStore = function (_a) {\n        var store = _a.store, query = _a.query, _b = _a.rootId, rootId = _b === void 0 ? \"ROOT_QUERY\" : _b, variables = _a.variables, _c = _a.returnPartialData, returnPartialData = _c === void 0 ? true : _c, _d = _a.canonizeResults, canonizeResults = _d === void 0 ? this.config.canonizeResults : _d;\n        var policies = this.config.cache.policies;\n        variables = __assign(__assign({}, getDefaultValues(getQueryDefinition(query))), variables);\n        var rootRef = makeReference(rootId);\n        var execResult = this.executeSelectionSet({\n            selectionSet: getMainDefinition(query).selectionSet,\n            objectOrReference: rootRef,\n            enclosingRef: rootRef,\n            context: __assign({ store: store, query: query, policies: policies, variables: variables, varString: canonicalStringify(variables), canonizeResults: canonizeResults }, extractFragmentContext(query, this.config.fragments)),\n        });\n        var missing;\n        if (execResult.missing) {\n            // For backwards compatibility we still report an array of\n            // MissingFieldError objects, even though there will only ever be at most\n            // one of them, now that all missing field error messages are grouped\n            // together in the execResult.missing tree.\n            missing = [\n                new MissingFieldError(firstMissing(execResult.missing), execResult.missing, query, variables),\n            ];\n            if (!returnPartialData) {\n                throw missing[0];\n            }\n        }\n        return {\n            result: execResult.result,\n            complete: !missing,\n            missing: missing,\n        };\n    };\n    StoreReader.prototype.isFresh = function (result, parent, selectionSet, context) {\n        if (supportsResultCaching(context.store) &&\n            this.knownResults.get(result) === selectionSet) {\n            var latest = this.executeSelectionSet.peek(selectionSet, parent, context, \n            // If result is canonical, then it could only have been previously\n            // cached by the canonizing version of executeSelectionSet, so we can\n            // avoid checking both possibilities here.\n            this.canon.isKnown(result));\n            if (latest && result === latest.result) {\n                return true;\n            }\n        }\n        return false;\n    };\n    // Uncached version of executeSelectionSet.\n    StoreReader.prototype.execSelectionSetImpl = function (_a) {\n        var _this = this;\n        var selectionSet = _a.selectionSet, objectOrReference = _a.objectOrReference, enclosingRef = _a.enclosingRef, context = _a.context;\n        if (isReference(objectOrReference) &&\n            !context.policies.rootTypenamesById[objectOrReference.__ref] &&\n            !context.store.has(objectOrReference.__ref)) {\n            return {\n                result: this.canon.empty,\n                missing: \"Dangling reference to missing \".concat(objectOrReference.__ref, \" object\"),\n            };\n        }\n        var variables = context.variables, policies = context.policies, store = context.store;\n        var typename = store.getFieldValue(objectOrReference, \"__typename\");\n        var objectsToMerge = [];\n        var missing;\n        var missingMerger = new DeepMerger();\n        if (this.config.addTypename &&\n            typeof typename === \"string\" &&\n            !policies.rootIdsByTypename[typename]) {\n            // Ensure we always include a default value for the __typename\n            // field, if we have one, and this.config.addTypename is true. Note\n            // that this field can be overridden by other merged objects.\n            objectsToMerge.push({ __typename: typename });\n        }\n        function handleMissing(result, resultName) {\n            var _a;\n            if (result.missing) {\n                missing = missingMerger.merge(missing, (_a = {},\n                    _a[resultName] = result.missing,\n                    _a));\n            }\n            return result.result;\n        }\n        var workSet = new Set(selectionSet.selections);\n        workSet.forEach(function (selection) {\n            var _a, _b;\n            // Omit fields with directives @skip(if: <truthy value>) or\n            // @include(if: <falsy value>).\n            if (!shouldInclude(selection, variables))\n                return;\n            if (isField(selection)) {\n                var fieldValue = policies.readField({\n                    fieldName: selection.name.value,\n                    field: selection,\n                    variables: context.variables,\n                    from: objectOrReference,\n                }, context);\n                var resultName = resultKeyNameFromField(selection);\n                if (fieldValue === void 0) {\n                    if (!addTypenameToDocument.added(selection)) {\n                        missing = missingMerger.merge(missing, (_a = {},\n                            _a[resultName] = \"Can't find field '\".concat(selection.name.value, \"' on \").concat(isReference(objectOrReference) ?\n                                objectOrReference.__ref + \" object\"\n                                : \"object \" + JSON.stringify(objectOrReference, null, 2)),\n                            _a));\n                    }\n                }\n                else if (isArray(fieldValue)) {\n                    if (fieldValue.length > 0) {\n                        fieldValue = handleMissing(_this.executeSubSelectedArray({\n                            field: selection,\n                            array: fieldValue,\n                            enclosingRef: enclosingRef,\n                            context: context,\n                        }), resultName);\n                    }\n                }\n                else if (!selection.selectionSet) {\n                    // If the field does not have a selection set, then we handle it\n                    // as a scalar value. To keep this.canon from canonicalizing\n                    // this value, we use this.canon.pass to wrap fieldValue in a\n                    // Pass object that this.canon.admit will later unwrap as-is.\n                    if (context.canonizeResults) {\n                        fieldValue = _this.canon.pass(fieldValue);\n                    }\n                }\n                else if (fieldValue != null) {\n                    // In this case, because we know the field has a selection set,\n                    // it must be trying to query a GraphQLObjectType, which is why\n                    // fieldValue must be != null.\n                    fieldValue = handleMissing(_this.executeSelectionSet({\n                        selectionSet: selection.selectionSet,\n                        objectOrReference: fieldValue,\n                        enclosingRef: isReference(fieldValue) ? fieldValue : enclosingRef,\n                        context: context,\n                    }), resultName);\n                }\n                if (fieldValue !== void 0) {\n                    objectsToMerge.push((_b = {}, _b[resultName] = fieldValue, _b));\n                }\n            }\n            else {\n                var fragment = getFragmentFromSelection(selection, context.lookupFragment);\n                if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n                    throw newInvariantError(10, selection.name.value);\n                }\n                if (fragment && policies.fragmentMatches(fragment, typename)) {\n                    fragment.selectionSet.selections.forEach(workSet.add, workSet);\n                }\n            }\n        });\n        var result = mergeDeepArray(objectsToMerge);\n        var finalResult = { result: result, missing: missing };\n        var frozen = context.canonizeResults ?\n            this.canon.admit(finalResult)\n            // Since this.canon is normally responsible for freezing results (only in\n            // development), freeze them manually if canonization is disabled.\n            : maybeDeepFreeze(finalResult);\n        // Store this result with its selection set so that we can quickly\n        // recognize it again in the StoreReader#isFresh method.\n        if (frozen.result) {\n            this.knownResults.set(frozen.result, selectionSet);\n        }\n        return frozen;\n    };\n    // Uncached version of executeSubSelectedArray.\n    StoreReader.prototype.execSubSelectedArrayImpl = function (_a) {\n        var _this = this;\n        var field = _a.field, array = _a.array, enclosingRef = _a.enclosingRef, context = _a.context;\n        var missing;\n        var missingMerger = new DeepMerger();\n        function handleMissing(childResult, i) {\n            var _a;\n            if (childResult.missing) {\n                missing = missingMerger.merge(missing, (_a = {}, _a[i] = childResult.missing, _a));\n            }\n            return childResult.result;\n        }\n        if (field.selectionSet) {\n            array = array.filter(context.store.canRead);\n        }\n        array = array.map(function (item, i) {\n            // null value in array\n            if (item === null) {\n                return null;\n            }\n            // This is a nested array, recurse\n            if (isArray(item)) {\n                return handleMissing(_this.executeSubSelectedArray({\n                    field: field,\n                    array: item,\n                    enclosingRef: enclosingRef,\n                    context: context,\n                }), i);\n            }\n            // This is an object, run the selection set on it\n            if (field.selectionSet) {\n                return handleMissing(_this.executeSelectionSet({\n                    selectionSet: field.selectionSet,\n                    objectOrReference: item,\n                    enclosingRef: isReference(item) ? item : enclosingRef,\n                    context: context,\n                }), i);\n            }\n            if (globalThis.__DEV__ !== false) {\n                assertSelectionSetForIdValue(context.store, field, item);\n            }\n            return item;\n        });\n        return {\n            result: context.canonizeResults ? this.canon.admit(array) : array,\n            missing: missing,\n        };\n    };\n    return StoreReader;\n}());\nexport { StoreReader };\nfunction firstMissing(tree) {\n    try {\n        JSON.stringify(tree, function (_, value) {\n            if (typeof value === \"string\")\n                throw value;\n            return value;\n        });\n    }\n    catch (result) {\n        return result;\n    }\n}\nfunction assertSelectionSetForIdValue(store, field, fieldValue) {\n    if (!field.selectionSet) {\n        var workSet_1 = new Set([fieldValue]);\n        workSet_1.forEach(function (value) {\n            if (isNonNullObject(value)) {\n                invariant(\n                    !isReference(value),\n                    11,\n                    getTypenameFromStoreObject(store, value),\n                    field.name.value\n                );\n                Object.values(value).forEach(workSet_1.add, workSet_1);\n            }\n        });\n    }\n}\n//# sourceMappingURL=readFromStore.js.map","import { __assign } from \"tslib\";\nimport { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport { Kind } from \"graphql\";\nimport { getFragmentFromSelection, getDefaultValues, getOperationDefinition, getTypenameFromResult, makeReference, isField, resultKeyNameFromField, isReference, shouldInclude, cloneDeep, addTypenameToDocument, isNonEmptyArray, argumentsObjectFromField, canonicalStringify, } from \"../../utilities/index.js\";\nimport { isArray, makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject, extractFragmentContext, } from \"./helpers.js\";\nimport { normalizeReadFieldOptions } from \"./policies.js\";\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor(context, clientOnly, deferred) {\n    var key = \"\".concat(clientOnly).concat(deferred);\n    var flavored = context.flavors.get(key);\n    if (!flavored) {\n        context.flavors.set(key, (flavored =\n            context.clientOnly === clientOnly && context.deferred === deferred ?\n                context\n                : __assign(__assign({}, context), { clientOnly: clientOnly, deferred: deferred })));\n    }\n    return flavored;\n}\nvar StoreWriter = /** @class */ (function () {\n    function StoreWriter(cache, reader, fragments) {\n        this.cache = cache;\n        this.reader = reader;\n        this.fragments = fragments;\n    }\n    StoreWriter.prototype.writeToStore = function (store, _a) {\n        var _this = this;\n        var query = _a.query, result = _a.result, dataId = _a.dataId, variables = _a.variables, overwrite = _a.overwrite;\n        var operationDefinition = getOperationDefinition(query);\n        var merger = makeProcessedFieldsMerger();\n        variables = __assign(__assign({}, getDefaultValues(operationDefinition)), variables);\n        var context = __assign(__assign({ store: store, written: Object.create(null), merge: function (existing, incoming) {\n                return merger.merge(existing, incoming);\n            }, variables: variables, varString: canonicalStringify(variables) }, extractFragmentContext(query, this.fragments)), { overwrite: !!overwrite, incomingById: new Map(), clientOnly: false, deferred: false, flavors: new Map() });\n        var ref = this.processSelectionSet({\n            result: result || Object.create(null),\n            dataId: dataId,\n            selectionSet: operationDefinition.selectionSet,\n            mergeTree: { map: new Map() },\n            context: context,\n        });\n        if (!isReference(ref)) {\n            throw newInvariantError(12, result);\n        }\n        // So far, the store has not been modified, so now it's time to process\n        // context.incomingById and merge those incoming fields into context.store.\n        context.incomingById.forEach(function (_a, dataId) {\n            var storeObject = _a.storeObject, mergeTree = _a.mergeTree, fieldNodeSet = _a.fieldNodeSet;\n            var entityRef = makeReference(dataId);\n            if (mergeTree && mergeTree.map.size) {\n                var applied = _this.applyMerges(mergeTree, entityRef, storeObject, context);\n                if (isReference(applied)) {\n                    // Assume References returned by applyMerges have already been merged\n                    // into the store. See makeMergeObjectsFunction in policies.ts for an\n                    // example of how this can happen.\n                    return;\n                }\n                // Otherwise, applyMerges returned a StoreObject, whose fields we should\n                // merge into the store (see store.merge statement below).\n                storeObject = applied;\n            }\n            if (globalThis.__DEV__ !== false && !context.overwrite) {\n                var fieldsWithSelectionSets_1 = Object.create(null);\n                fieldNodeSet.forEach(function (field) {\n                    if (field.selectionSet) {\n                        fieldsWithSelectionSets_1[field.name.value] = true;\n                    }\n                });\n                var hasSelectionSet_1 = function (storeFieldName) {\n                    return fieldsWithSelectionSets_1[fieldNameFromStoreName(storeFieldName)] ===\n                        true;\n                };\n                var hasMergeFunction_1 = function (storeFieldName) {\n                    var childTree = mergeTree && mergeTree.map.get(storeFieldName);\n                    return Boolean(childTree && childTree.info && childTree.info.merge);\n                };\n                Object.keys(storeObject).forEach(function (storeFieldName) {\n                    // If a merge function was defined for this field, trust that it\n                    // did the right thing about (not) clobbering data. If the field\n                    // has no selection set, it's a scalar field, so it doesn't need\n                    // a merge function (even if it's an object, like JSON data).\n                    if (hasSelectionSet_1(storeFieldName) &&\n                        !hasMergeFunction_1(storeFieldName)) {\n                        warnAboutDataLoss(entityRef, storeObject, storeFieldName, context.store);\n                    }\n                });\n            }\n            store.merge(dataId, storeObject);\n        });\n        // Any IDs written explicitly to the cache will be retained as\n        // reachable root IDs for garbage collection purposes. Although this\n        // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n        // retainment counts are effectively ignored because cache.gc() always\n        // includes them in its root ID set.\n        store.retain(ref.__ref);\n        return ref;\n    };\n    StoreWriter.prototype.processSelectionSet = function (_a) {\n        var _this = this;\n        var dataId = _a.dataId, result = _a.result, selectionSet = _a.selectionSet, context = _a.context, \n        // This object allows processSelectionSet to report useful information\n        // to its callers without explicitly returning that information.\n        mergeTree = _a.mergeTree;\n        var policies = this.cache.policies;\n        // This variable will be repeatedly updated using context.merge to\n        // accumulate all fields that need to be written into the store.\n        var incoming = Object.create(null);\n        // If typename was not passed in, infer it. Note that typename is\n        // always passed in for tricky-to-infer cases such as \"Query\" for\n        // ROOT_QUERY.\n        var typename = (dataId && policies.rootTypenamesById[dataId]) ||\n            getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n            (dataId && context.store.get(dataId, \"__typename\"));\n        if (\"string\" === typeof typename) {\n            incoming.__typename = typename;\n        }\n        // This readField function will be passed as context.readField in the\n        // KeyFieldsContext object created within policies.identify (called below).\n        // In addition to reading from the existing context.store (thanks to the\n        // policies.readField(options, context) line at the very bottom), this\n        // version of readField can read from Reference objects that are currently\n        // pending in context.incomingById, which is important whenever keyFields\n        // need to be extracted from a child object that processSelectionSet has\n        // turned into a Reference.\n        var readField = function () {\n            var options = normalizeReadFieldOptions(arguments, incoming, context.variables);\n            if (isReference(options.from)) {\n                var info = context.incomingById.get(options.from.__ref);\n                if (info) {\n                    var result_1 = policies.readField(__assign(__assign({}, options), { from: info.storeObject }), context);\n                    if (result_1 !== void 0) {\n                        return result_1;\n                    }\n                }\n            }\n            return policies.readField(options, context);\n        };\n        var fieldNodeSet = new Set();\n        this.flattenFields(selectionSet, result, \n        // This WriteContext will be the default context value for fields returned\n        // by the flattenFields method, but some fields may be assigned a modified\n        // context, depending on the presence of @client and other directives.\n        context, typename).forEach(function (context, field) {\n            var _a;\n            var resultFieldKey = resultKeyNameFromField(field);\n            var value = result[resultFieldKey];\n            fieldNodeSet.add(field);\n            if (value !== void 0) {\n                var storeFieldName = policies.getStoreFieldName({\n                    typename: typename,\n                    fieldName: field.name.value,\n                    field: field,\n                    variables: context.variables,\n                });\n                var childTree = getChildMergeTree(mergeTree, storeFieldName);\n                var incomingValue = _this.processFieldValue(value, field, \n                // Reset context.clientOnly and context.deferred to their default\n                // values before processing nested selection sets.\n                field.selectionSet ?\n                    getContextFlavor(context, false, false)\n                    : context, childTree);\n                // To determine if this field holds a child object with a merge function\n                // defined in its type policy (see PR #7070), we need to figure out the\n                // child object's __typename.\n                var childTypename = void 0;\n                // The field's value can be an object that has a __typename only if the\n                // field has a selection set. Otherwise incomingValue is scalar.\n                if (field.selectionSet &&\n                    (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))) {\n                    childTypename = readField(\"__typename\", incomingValue);\n                }\n                var merge = policies.getMergeFunction(typename, field.name.value, childTypename);\n                if (merge) {\n                    childTree.info = {\n                        // TODO Check compatibility against any existing childTree.field?\n                        field: field,\n                        typename: typename,\n                        merge: merge,\n                    };\n                }\n                else {\n                    maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n                }\n                incoming = context.merge(incoming, (_a = {},\n                    _a[storeFieldName] = incomingValue,\n                    _a));\n            }\n            else if (globalThis.__DEV__ !== false &&\n                !context.clientOnly &&\n                !context.deferred &&\n                !addTypenameToDocument.added(field) &&\n                // If the field has a read function, it may be a synthetic field or\n                // provide a default value, so its absence from the written data should\n                // not be cause for alarm.\n                !policies.getReadFunction(typename, field.name.value)) {\n                globalThis.__DEV__ !== false && invariant.error(13, resultKeyNameFromField(field), result);\n            }\n        });\n        // Identify the result object, even if dataId was already provided,\n        // since we always need keyObject below.\n        try {\n            var _b = policies.identify(result, {\n                typename: typename,\n                selectionSet: selectionSet,\n                fragmentMap: context.fragmentMap,\n                storeObject: incoming,\n                readField: readField,\n            }), id = _b[0], keyObject = _b[1];\n            // If dataId was not provided, fall back to the id just generated by\n            // policies.identify.\n            dataId = dataId || id;\n            // Write any key fields that were used during identification, even if\n            // they were not mentioned in the original query.\n            if (keyObject) {\n                // TODO Reverse the order of the arguments?\n                incoming = context.merge(incoming, keyObject);\n            }\n        }\n        catch (e) {\n            // If dataId was provided, tolerate failure of policies.identify.\n            if (!dataId)\n                throw e;\n        }\n        if (\"string\" === typeof dataId) {\n            var dataRef = makeReference(dataId);\n            // Avoid processing the same entity object using the same selection\n            // set more than once. We use an array instead of a Set since most\n            // entity IDs will be written using only one selection set, so the\n            // size of this array is likely to be very small, meaning indexOf is\n            // likely to be faster than Set.prototype.has.\n            var sets = context.written[dataId] || (context.written[dataId] = []);\n            if (sets.indexOf(selectionSet) >= 0)\n                return dataRef;\n            sets.push(selectionSet);\n            // If we're about to write a result object into the store, but we\n            // happen to know that the exact same (===) result object would be\n            // returned if we were to reread the result with the same inputs,\n            // then we can skip the rest of the processSelectionSet work for\n            // this object, and immediately return a Reference to it.\n            if (this.reader &&\n                this.reader.isFresh(result, dataRef, selectionSet, context)) {\n                return dataRef;\n            }\n            var previous_1 = context.incomingById.get(dataId);\n            if (previous_1) {\n                previous_1.storeObject = context.merge(previous_1.storeObject, incoming);\n                previous_1.mergeTree = mergeMergeTrees(previous_1.mergeTree, mergeTree);\n                fieldNodeSet.forEach(function (field) { return previous_1.fieldNodeSet.add(field); });\n            }\n            else {\n                context.incomingById.set(dataId, {\n                    storeObject: incoming,\n                    // Save a reference to mergeTree only if it is not empty, because\n                    // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n                    // reused for entirely different parts of the result tree.\n                    mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n                    fieldNodeSet: fieldNodeSet,\n                });\n            }\n            return dataRef;\n        }\n        return incoming;\n    };\n    StoreWriter.prototype.processFieldValue = function (value, field, context, mergeTree) {\n        var _this = this;\n        if (!field.selectionSet || value === null) {\n            // In development, we need to clone scalar values so that they can be\n            // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n            // it's cheaper to store the scalar values directly in the cache.\n            return globalThis.__DEV__ !== false ? cloneDeep(value) : value;\n        }\n        if (isArray(value)) {\n            return value.map(function (item, i) {\n                var value = _this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i));\n                maybeRecycleChildMergeTree(mergeTree, i);\n                return value;\n            });\n        }\n        return this.processSelectionSet({\n            result: value,\n            selectionSet: field.selectionSet,\n            context: context,\n            mergeTree: mergeTree,\n        });\n    };\n    // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n    // some additions for tracking @client and @defer directives.\n    StoreWriter.prototype.flattenFields = function (selectionSet, result, context, typename) {\n        if (typename === void 0) { typename = getTypenameFromResult(result, selectionSet, context.fragmentMap); }\n        var fieldMap = new Map();\n        var policies = this.cache.policies;\n        var limitingTrie = new Trie(false); // No need for WeakMap, since limitingTrie does not escape.\n        (function flatten(selectionSet, inheritedContext) {\n            var visitedNode = limitingTrie.lookup(selectionSet, \n            // Because we take inheritedClientOnly and inheritedDeferred into\n            // consideration here (in addition to selectionSet), it's possible for\n            // the same selection set to be flattened more than once, if it appears\n            // in the query with different @client and/or @directive configurations.\n            inheritedContext.clientOnly, inheritedContext.deferred);\n            if (visitedNode.visited)\n                return;\n            visitedNode.visited = true;\n            selectionSet.selections.forEach(function (selection) {\n                if (!shouldInclude(selection, context.variables))\n                    return;\n                var clientOnly = inheritedContext.clientOnly, deferred = inheritedContext.deferred;\n                if (\n                // Since the presence of @client or @defer on this field can only\n                // cause clientOnly or deferred to become true, we can skip the\n                // forEach loop if both clientOnly and deferred are already true.\n                !(clientOnly && deferred) &&\n                    isNonEmptyArray(selection.directives)) {\n                    selection.directives.forEach(function (dir) {\n                        var name = dir.name.value;\n                        if (name === \"client\")\n                            clientOnly = true;\n                        if (name === \"defer\") {\n                            var args = argumentsObjectFromField(dir, context.variables);\n                            // The @defer directive takes an optional args.if boolean\n                            // argument, similar to @include(if: boolean). Note that\n                            // @defer(if: false) does not make context.deferred false, but\n                            // instead behaves as if there was no @defer directive.\n                            if (!args || args.if !== false) {\n                                deferred = true;\n                            }\n                            // TODO In the future, we may want to record args.label using\n                            // context.deferred, if a label is specified.\n                        }\n                    });\n                }\n                if (isField(selection)) {\n                    var existing = fieldMap.get(selection);\n                    if (existing) {\n                        // If this field has been visited along another recursive path\n                        // before, the final context should have clientOnly or deferred set\n                        // to true only if *all* paths have the directive (hence the &&).\n                        clientOnly = clientOnly && existing.clientOnly;\n                        deferred = deferred && existing.deferred;\n                    }\n                    fieldMap.set(selection, getContextFlavor(context, clientOnly, deferred));\n                }\n                else {\n                    var fragment = getFragmentFromSelection(selection, context.lookupFragment);\n                    if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n                        throw newInvariantError(14, selection.name.value);\n                    }\n                    if (fragment &&\n                        policies.fragmentMatches(fragment, typename, result, context.variables)) {\n                        flatten(fragment.selectionSet, getContextFlavor(context, clientOnly, deferred));\n                    }\n                }\n            });\n        })(selectionSet, context);\n        return fieldMap;\n    };\n    StoreWriter.prototype.applyMerges = function (mergeTree, existing, incoming, context, getStorageArgs) {\n        var _a;\n        var _this = this;\n        if (mergeTree.map.size && !isReference(incoming)) {\n            var e_1 = \n            // Items in the same position in different arrays are not\n            // necessarily related to each other, so when incoming is an array\n            // we process its elements as if there was no existing data.\n            (!isArray(incoming) &&\n                // Likewise, existing must be either a Reference or a StoreObject\n                // in order for its fields to be safe to merge with the fields of\n                // the incoming object.\n                (isReference(existing) || storeValueIsStoreObject(existing))) ?\n                existing\n                : void 0;\n            // This narrowing is implied by mergeTree.map.size > 0 and\n            // !isReference(incoming), though TypeScript understandably cannot\n            // hope to infer this type.\n            var i_1 = incoming;\n            // The options.storage objects provided to read and merge functions\n            // are derived from the identity of the parent object plus a\n            // sequence of storeFieldName strings/numbers identifying the nested\n            // field name path of each field value to be merged.\n            if (e_1 && !getStorageArgs) {\n                getStorageArgs = [isReference(e_1) ? e_1.__ref : e_1];\n            }\n            // It's possible that applying merge functions to this subtree will\n            // not change the incoming data, so this variable tracks the fields\n            // that did change, so we can create a new incoming object when (and\n            // only when) at least one incoming field has changed. We use a Map\n            // to preserve the type of numeric keys.\n            var changedFields_1;\n            var getValue_1 = function (from, name) {\n                return (isArray(from) ?\n                    typeof name === \"number\" ?\n                        from[name]\n                        : void 0\n                    : context.store.getFieldValue(from, String(name)));\n            };\n            mergeTree.map.forEach(function (childTree, storeFieldName) {\n                var eVal = getValue_1(e_1, storeFieldName);\n                var iVal = getValue_1(i_1, storeFieldName);\n                // If we have no incoming data, leave any existing data untouched.\n                if (void 0 === iVal)\n                    return;\n                if (getStorageArgs) {\n                    getStorageArgs.push(storeFieldName);\n                }\n                var aVal = _this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n                if (aVal !== iVal) {\n                    changedFields_1 = changedFields_1 || new Map();\n                    changedFields_1.set(storeFieldName, aVal);\n                }\n                if (getStorageArgs) {\n                    invariant(getStorageArgs.pop() === storeFieldName);\n                }\n            });\n            if (changedFields_1) {\n                // Shallow clone i so we can add changed fields to it.\n                incoming = (isArray(i_1) ? i_1.slice(0) : __assign({}, i_1));\n                changedFields_1.forEach(function (value, name) {\n                    incoming[name] = value;\n                });\n            }\n        }\n        if (mergeTree.info) {\n            return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && (_a = context.store).getStorage.apply(_a, getStorageArgs));\n        }\n        return incoming;\n    };\n    return StoreWriter;\n}());\nexport { StoreWriter };\nvar emptyMergeTreePool = [];\nfunction getChildMergeTree(_a, name) {\n    var map = _a.map;\n    if (!map.has(name)) {\n        map.set(name, emptyMergeTreePool.pop() || { map: new Map() });\n    }\n    return map.get(name);\n}\nfunction mergeMergeTrees(left, right) {\n    if (left === right || !right || mergeTreeIsEmpty(right))\n        return left;\n    if (!left || mergeTreeIsEmpty(left))\n        return right;\n    var info = left.info && right.info ? __assign(__assign({}, left.info), right.info) : left.info || right.info;\n    var needToMergeMaps = left.map.size && right.map.size;\n    var map = needToMergeMaps ? new Map()\n        : left.map.size ? left.map\n            : right.map;\n    var merged = { info: info, map: map };\n    if (needToMergeMaps) {\n        var remainingRightKeys_1 = new Set(right.map.keys());\n        left.map.forEach(function (leftTree, key) {\n            merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n            remainingRightKeys_1.delete(key);\n        });\n        remainingRightKeys_1.forEach(function (key) {\n            merged.map.set(key, mergeMergeTrees(right.map.get(key), left.map.get(key)));\n        });\n    }\n    return merged;\n}\nfunction mergeTreeIsEmpty(tree) {\n    return !tree || !(tree.info || tree.map.size);\n}\nfunction maybeRecycleChildMergeTree(_a, name) {\n    var map = _a.map;\n    var childTree = map.get(name);\n    if (childTree && mergeTreeIsEmpty(childTree)) {\n        emptyMergeTreePool.push(childTree);\n        map.delete(name);\n    }\n}\nvar warnings = new Set();\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n    var getChild = function (objOrRef) {\n        var child = store.getFieldValue(objOrRef, storeFieldName);\n        return typeof child === \"object\" && child;\n    };\n    var existing = getChild(existingRef);\n    if (!existing)\n        return;\n    var incoming = getChild(incomingObj);\n    if (!incoming)\n        return;\n    // It's always safe to replace a reference, since it refers to data\n    // safely stored elsewhere.\n    if (isReference(existing))\n        return;\n    // If the values are structurally equivalent, we do not need to worry\n    // about incoming replacing existing.\n    if (equal(existing, incoming))\n        return;\n    // If we're replacing every key of the existing object, then the\n    // existing data would be overwritten even if the objects were\n    // normalized, so warning would not be helpful here.\n    if (Object.keys(existing).every(function (key) { return store.getFieldValue(incoming, key) !== void 0; })) {\n        return;\n    }\n    var parentType = store.getFieldValue(existingRef, \"__typename\") ||\n        store.getFieldValue(incomingObj, \"__typename\");\n    var fieldName = fieldNameFromStoreName(storeFieldName);\n    var typeDotName = \"\".concat(parentType, \".\").concat(fieldName);\n    // Avoid warning more than once for the same type and field name.\n    if (warnings.has(typeDotName))\n        return;\n    warnings.add(typeDotName);\n    var childTypenames = [];\n    // Arrays do not have __typename fields, and always need a custom merge\n    // function, even if their elements are normalized entities.\n    if (!isArray(existing) && !isArray(incoming)) {\n        [existing, incoming].forEach(function (child) {\n            var typename = store.getFieldValue(child, \"__typename\");\n            if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n                childTypenames.push(typename);\n            }\n        });\n    }\n    globalThis.__DEV__ !== false && invariant.warn(15, fieldName, parentType, childTypenames.length ?\n        \"either ensure all objects of type \" +\n            childTypenames.join(\" and \") +\n            \" have an ID or a custom merge function, or \"\n        : \"\", typeDotName, __assign({}, existing), __assign({}, incoming));\n}\n//# sourceMappingURL=writeToStore.js.map","import { __rest } from \"tslib\";\nimport equal from \"@wry/equality\";\nimport { createFragmentMap, getFragmentDefinitions, getFragmentFromSelection, getMainDefinition, isField, resultKeyNameFromField, shouldInclude, } from \"../utilities/index.js\";\n// Returns true if aResult and bResult are deeply equal according to the fields\n// selected by the given query, ignoring any fields marked as @nonreactive.\nexport function equalByQuery(query, _a, _b, variables) {\n    var aData = _a.data, aRest = __rest(_a, [\"data\"]);\n    var bData = _b.data, bRest = __rest(_b, [\"data\"]);\n    return (equal(aRest, bRest) &&\n        equalBySelectionSet(getMainDefinition(query).selectionSet, aData, bData, {\n            fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n            variables: variables,\n        }));\n}\nfunction equalBySelectionSet(selectionSet, aResult, bResult, context) {\n    if (aResult === bResult) {\n        return true;\n    }\n    var seenSelections = new Set();\n    // Returning true from this Array.prototype.every callback function skips the\n    // current field/subtree. Returning false aborts the entire traversal\n    // immediately, causing equalBySelectionSet to return false.\n    return selectionSet.selections.every(function (selection) {\n        // Avoid re-processing the same selection at the same level of recursion, in\n        // case the same field gets included via multiple indirect fragment spreads.\n        if (seenSelections.has(selection))\n            return true;\n        seenSelections.add(selection);\n        // Ignore @skip(if: true) and @include(if: false) fields.\n        if (!shouldInclude(selection, context.variables))\n            return true;\n        // If the field or (named) fragment spread has a @nonreactive directive on\n        // it, we don't care if it's different, so we pretend it's the same.\n        if (selectionHasNonreactiveDirective(selection))\n            return true;\n        if (isField(selection)) {\n            var resultKey = resultKeyNameFromField(selection);\n            var aResultChild = aResult && aResult[resultKey];\n            var bResultChild = bResult && bResult[resultKey];\n            var childSelectionSet = selection.selectionSet;\n            if (!childSelectionSet) {\n                // These are scalar values, so we can compare them with deep equal\n                // without redoing the main recursive work.\n                return equal(aResultChild, bResultChild);\n            }\n            var aChildIsArray = Array.isArray(aResultChild);\n            var bChildIsArray = Array.isArray(bResultChild);\n            if (aChildIsArray !== bChildIsArray)\n                return false;\n            if (aChildIsArray && bChildIsArray) {\n                var length_1 = aResultChild.length;\n                if (bResultChild.length !== length_1) {\n                    return false;\n                }\n                for (var i = 0; i < length_1; ++i) {\n                    if (!equalBySelectionSet(childSelectionSet, aResultChild[i], bResultChild[i], context)) {\n                        return false;\n                    }\n                }\n                return true;\n            }\n            return equalBySelectionSet(childSelectionSet, aResultChild, bResultChild, context);\n        }\n        else {\n            var fragment = getFragmentFromSelection(selection, context.fragmentMap);\n            if (fragment) {\n                // The fragment might === selection if it's an inline fragment, but\n                // could be !== if it's a named fragment ...spread.\n                if (selectionHasNonreactiveDirective(fragment))\n                    return true;\n                return equalBySelectionSet(fragment.selectionSet, \n                // Notice that we reuse the same aResult and bResult values here,\n                // since the fragment ...spread does not specify a field name, but\n                // consists of multiple fields (within the fragment's selection set)\n                // that should be applied to the current result value(s).\n                aResult, bResult, context);\n            }\n        }\n    });\n}\nfunction selectionHasNonreactiveDirective(selection) {\n    return (!!selection.directives && selection.directives.some(directiveIsNonreactive));\n}\nfunction directiveIsNonreactive(dir) {\n    return dir.name.value === \"nonreactive\";\n}\n//# sourceMappingURL=equalByQuery.js.map","import { Kind } from \"graphql\";\nimport { getFragmentMaskMode, maybeDeepFreeze, resultKeyNameFromField, } from \"../utilities/index.js\";\nimport { disableWarningsSlot } from \"./utils.js\";\nimport { invariant } from \"../utilities/globals/index.js\";\nexport function maskDefinition(data, selectionSet, context) {\n    return disableWarningsSlot.withValue(true, function () {\n        var masked = maskSelectionSet(data, selectionSet, context, false);\n        if (Object.isFrozen(data)) {\n            maybeDeepFreeze(masked);\n        }\n        return masked;\n    });\n}\nfunction getMutableTarget(data, mutableTargets) {\n    if (mutableTargets.has(data)) {\n        return mutableTargets.get(data);\n    }\n    var mutableTarget = Array.isArray(data) ? [] : Object.create(null);\n    mutableTargets.set(data, mutableTarget);\n    return mutableTarget;\n}\nfunction maskSelectionSet(data, selectionSet, context, migration, path) {\n    var _a;\n    var knownChanged = context.knownChanged;\n    var memo = getMutableTarget(data, context.mutableTargets);\n    if (Array.isArray(data)) {\n        for (var _i = 0, _b = Array.from(data.entries()); _i < _b.length; _i++) {\n            var _c = _b[_i], index = _c[0], item = _c[1];\n            if (item === null) {\n                memo[index] = null;\n                continue;\n            }\n            var masked = maskSelectionSet(item, selectionSet, context, migration, globalThis.__DEV__ !== false ? \"\".concat(path || \"\", \"[\").concat(index, \"]\") : void 0);\n            if (knownChanged.has(masked)) {\n                knownChanged.add(memo);\n            }\n            memo[index] = masked;\n        }\n        return knownChanged.has(memo) ? memo : data;\n    }\n    for (var _d = 0, _e = selectionSet.selections; _d < _e.length; _d++) {\n        var selection = _e[_d];\n        var value = void 0;\n        // we later want to add acessor warnings to the final result\n        // so we need a new object to add the accessor warning to\n        if (migration) {\n            knownChanged.add(memo);\n        }\n        if (selection.kind === Kind.FIELD) {\n            var keyName = resultKeyNameFromField(selection);\n            var childSelectionSet = selection.selectionSet;\n            value = memo[keyName] || data[keyName];\n            if (value === void 0) {\n                continue;\n            }\n            if (childSelectionSet && value !== null) {\n                var masked = maskSelectionSet(data[keyName], childSelectionSet, context, migration, globalThis.__DEV__ !== false ? \"\".concat(path || \"\", \".\").concat(keyName) : void 0);\n                if (knownChanged.has(masked)) {\n                    value = masked;\n                }\n            }\n            if (!(globalThis.__DEV__ !== false)) {\n                memo[keyName] = value;\n            }\n            if (globalThis.__DEV__ !== false) {\n                if (migration &&\n                    keyName !== \"__typename\" &&\n                    // either the field is not present in the memo object\n                    // or it has a `get` descriptor, not a `value` descriptor\n                    // => it is a warning accessor and we can overwrite it\n                    // with another accessor\n                    !((_a = Object.getOwnPropertyDescriptor(memo, keyName)) === null || _a === void 0 ? void 0 : _a.value)) {\n                    Object.defineProperty(memo, keyName, getAccessorWarningDescriptor(keyName, value, path || \"\", context.operationName, context.operationType));\n                }\n                else {\n                    delete memo[keyName];\n                    memo[keyName] = value;\n                }\n            }\n        }\n        if (selection.kind === Kind.INLINE_FRAGMENT &&\n            (!selection.typeCondition ||\n                context.cache.fragmentMatches(selection, data.__typename))) {\n            value = maskSelectionSet(data, selection.selectionSet, context, migration, path);\n        }\n        if (selection.kind === Kind.FRAGMENT_SPREAD) {\n            var fragmentName = selection.name.value;\n            var fragment = context.fragmentMap[fragmentName] ||\n                (context.fragmentMap[fragmentName] =\n                    context.cache.lookupFragment(fragmentName));\n            invariant(fragment, 59, fragmentName);\n            var mode = getFragmentMaskMode(selection);\n            if (mode !== \"mask\") {\n                value = maskSelectionSet(data, fragment.selectionSet, context, mode === \"migrate\", path);\n            }\n        }\n        if (knownChanged.has(value)) {\n            knownChanged.add(memo);\n        }\n    }\n    if (\"__typename\" in data && !(\"__typename\" in memo)) {\n        memo.__typename = data.__typename;\n    }\n    // This check prevents cases where masked fields may accidentally be\n    // returned as part of this object when the fragment also selects\n    // additional fields from the same child selection.\n    if (Object.keys(memo).length !== Object.keys(data).length) {\n        knownChanged.add(memo);\n    }\n    return knownChanged.has(memo) ? memo : data;\n}\nfunction getAccessorWarningDescriptor(fieldName, value, path, operationName, operationType) {\n    var getValue = function () {\n        if (disableWarningsSlot.getValue()) {\n            return value;\n        }\n        globalThis.__DEV__ !== false && invariant.warn(60, operationName ?\n            \"\".concat(operationType, \" '\").concat(operationName, \"'\")\n            : \"anonymous \".concat(operationType), \"\".concat(path, \".\").concat(fieldName).replace(/^\\./, \"\"));\n        getValue = function () { return value; };\n        return value;\n    };\n    return {\n        get: function () {\n            return getValue();\n        },\n        set: function (newValue) {\n            getValue = function () { return newValue; };\n        },\n        enumerable: true,\n        configurable: true,\n    };\n}\n//# sourceMappingURL=maskDefinition.js.map","import { Kind } from \"graphql\";\nimport { MapImpl, SetImpl, warnOnImproperCacheImplementation, } from \"./utils.js\";\nimport { invariant } from \"../utilities/globals/index.js\";\nimport equal from \"@wry/equality\";\nimport { maskDefinition } from \"./maskDefinition.js\";\nimport { createFragmentMap, getFragmentDefinitions, } from \"../utilities/index.js\";\n/** @internal */\nexport function maskFragment(data, document, cache, fragmentName) {\n    if (!cache.fragmentMatches) {\n        if (globalThis.__DEV__ !== false) {\n            warnOnImproperCacheImplementation();\n        }\n        return data;\n    }\n    var fragments = document.definitions.filter(function (node) {\n        return node.kind === Kind.FRAGMENT_DEFINITION;\n    });\n    if (typeof fragmentName === \"undefined\") {\n        invariant(fragments.length === 1, 61, fragments.length);\n        fragmentName = fragments[0].name.value;\n    }\n    var fragment = fragments.find(function (fragment) { return fragment.name.value === fragmentName; });\n    invariant(!!fragment, 62, fragmentName);\n    if (data == null) {\n        // Maintain the original `null` or `undefined` value\n        return data;\n    }\n    if (equal(data, {})) {\n        // Return early and skip the masking algorithm if we don't have any data\n        // yet. This can happen when cache.diff returns an empty object which is\n        // used from watchFragment.\n        return data;\n    }\n    return maskDefinition(data, fragment.selectionSet, {\n        operationType: \"fragment\",\n        operationName: fragment.name.value,\n        fragmentMap: createFragmentMap(getFragmentDefinitions(document)),\n        cache: cache,\n        mutableTargets: new MapImpl(),\n        knownChanged: new SetImpl(),\n    });\n}\n//# sourceMappingURL=maskFragment.js.map","import { Slot } from \"optimism\";\nimport { invariant } from \"../utilities/globals/index.js\";\nimport { canUseWeakMap, canUseWeakSet } from \"../utilities/index.js\";\nexport var MapImpl = canUseWeakMap ? WeakMap : Map;\nexport var SetImpl = canUseWeakSet ? WeakSet : Set;\n// Contextual slot that allows us to disable accessor warnings on fields when in\n// migrate mode.\n/** @internal */\nexport var disableWarningsSlot = new Slot();\nvar issuedWarning = false;\nexport function warnOnImproperCacheImplementation() {\n    if (!issuedWarning) {\n        issuedWarning = true;\n        globalThis.__DEV__ !== false && invariant.warn(64);\n    }\n}\n//# sourceMappingURL=utils.js.map","import { WeakCache, StrongCache } from \"@wry/caches\";\nvar scheduledCleanup = new WeakSet();\nfunction schedule(cache) {\n    if (cache.size <= (cache.max || -1)) {\n        return;\n    }\n    if (!scheduledCleanup.has(cache)) {\n        scheduledCleanup.add(cache);\n        setTimeout(function () {\n            cache.clean();\n            scheduledCleanup.delete(cache);\n        }, 100);\n    }\n}\n/**\n * @internal\n * A version of WeakCache that will auto-schedule a cleanup of the cache when\n * a new item is added and the cache reached maximum size.\n * Throttled to once per 100ms.\n *\n * @privateRemarks\n * Should be used throughout the rest of the codebase instead of WeakCache,\n * with the notable exception of usage in `wrap` from `optimism` - that one\n * already handles cleanup and should remain a `WeakCache`.\n */\nexport var AutoCleanedWeakCache = function (max, dispose) {\n    /*\n    Some builds of `WeakCache` are function prototypes, some are classes.\n    This library still builds with an ES5 target, so we can't extend the\n    real classes.\n    Instead, we have to use this workaround until we switch to a newer build\n    target.\n    */\n    var cache = new WeakCache(max, dispose);\n    cache.set = function (key, value) {\n        var ret = WeakCache.prototype.set.call(this, key, value);\n        schedule(this);\n        return ret;\n    };\n    return cache;\n};\n/**\n * @internal\n * A version of StrongCache that will auto-schedule a cleanup of the cache when\n * a new item is added and the cache reached maximum size.\n * Throttled to once per 100ms.\n *\n * @privateRemarks\n * Should be used throughout the rest of the codebase instead of StrongCache,\n * with the notable exception of usage in `wrap` from `optimism` - that one\n * already handles cleanup and should remain a `StrongCache`.\n */\nexport var AutoCleanedStrongCache = function (max, dispose) {\n    /*\n    Some builds of `StrongCache` are function prototypes, some are classes.\n    This library still builds with an ES5 target, so we can't extend the\n    real classes.\n    Instead, we have to use this workaround until we switch to a newer build\n    target.\n    */\n    var cache = new StrongCache(max, dispose);\n    cache.set = function (key, value) {\n        var ret = StrongCache.prototype.set.call(this, key, value);\n        schedule(this);\n        return ret;\n    };\n    return cache;\n};\n//# sourceMappingURL=caches.js.map","import { __assign, __spreadArray } from \"tslib\";\nimport { cacheSizes } from \"./sizes.js\";\nvar globalCaches = {};\nexport function registerGlobalCache(name, getSize) {\n    globalCaches[name] = getSize;\n}\n/**\n * For internal purposes only - please call `ApolloClient.getMemoryInternals` instead\n * @internal\n */\nexport var getApolloClientMemoryInternals = globalThis.__DEV__ !== false ?\n    _getApolloClientMemoryInternals\n    : undefined;\n/**\n * For internal purposes only - please call `ApolloClient.getMemoryInternals` instead\n * @internal\n */\nexport var getInMemoryCacheMemoryInternals = globalThis.__DEV__ !== false ?\n    _getInMemoryCacheMemoryInternals\n    : undefined;\n/**\n * For internal purposes only - please call `ApolloClient.getMemoryInternals` instead\n * @internal\n */\nexport var getApolloCacheMemoryInternals = globalThis.__DEV__ !== false ?\n    _getApolloCacheMemoryInternals\n    : undefined;\nfunction getCurrentCacheSizes() {\n    // `defaultCacheSizes` is a `const enum` that will be inlined during build, so we have to reconstruct it's shape here\n    var defaults = {\n        parser: 1000 /* defaultCacheSizes[\"parser\"] */,\n        canonicalStringify: 1000 /* defaultCacheSizes[\"canonicalStringify\"] */,\n        print: 2000 /* defaultCacheSizes[\"print\"] */,\n        \"documentTransform.cache\": 2000 /* defaultCacheSizes[\"documentTransform.cache\"] */,\n        \"queryManager.getDocumentInfo\": 2000 /* defaultCacheSizes[\"queryManager.getDocumentInfo\"] */,\n        \"PersistedQueryLink.persistedQueryHashes\": 2000 /* defaultCacheSizes[\"PersistedQueryLink.persistedQueryHashes\"] */,\n        \"fragmentRegistry.transform\": 2000 /* defaultCacheSizes[\"fragmentRegistry.transform\"] */,\n        \"fragmentRegistry.lookup\": 1000 /* defaultCacheSizes[\"fragmentRegistry.lookup\"] */,\n        \"fragmentRegistry.findFragmentSpreads\": 4000 /* defaultCacheSizes[\"fragmentRegistry.findFragmentSpreads\"] */,\n        \"cache.fragmentQueryDocuments\": 1000 /* defaultCacheSizes[\"cache.fragmentQueryDocuments\"] */,\n        \"removeTypenameFromVariables.getVariableDefinitions\": 2000 /* defaultCacheSizes[\"removeTypenameFromVariables.getVariableDefinitions\"] */,\n        \"inMemoryCache.maybeBroadcastWatch\": 5000 /* defaultCacheSizes[\"inMemoryCache.maybeBroadcastWatch\"] */,\n        \"inMemoryCache.executeSelectionSet\": 50000 /* defaultCacheSizes[\"inMemoryCache.executeSelectionSet\"] */,\n        \"inMemoryCache.executeSubSelectedArray\": 10000 /* defaultCacheSizes[\"inMemoryCache.executeSubSelectedArray\"] */,\n    };\n    return Object.fromEntries(Object.entries(defaults).map(function (_a) {\n        var k = _a[0], v = _a[1];\n        return [\n            k,\n            cacheSizes[k] || v,\n        ];\n    }));\n}\nfunction _getApolloClientMemoryInternals() {\n    var _a, _b, _c, _d, _e;\n    if (!(globalThis.__DEV__ !== false))\n        throw new Error(\"only supported in development mode\");\n    return {\n        limits: getCurrentCacheSizes(),\n        sizes: __assign({ print: (_a = globalCaches.print) === null || _a === void 0 ? void 0 : _a.call(globalCaches), parser: (_b = globalCaches.parser) === null || _b === void 0 ? void 0 : _b.call(globalCaches), canonicalStringify: (_c = globalCaches.canonicalStringify) === null || _c === void 0 ? void 0 : _c.call(globalCaches), links: linkInfo(this.link), queryManager: {\n                getDocumentInfo: this[\"queryManager\"][\"transformCache\"].size,\n                documentTransforms: transformInfo(this[\"queryManager\"].documentTransform),\n            } }, (_e = (_d = this.cache).getMemoryInternals) === null || _e === void 0 ? void 0 : _e.call(_d)),\n    };\n}\nfunction _getApolloCacheMemoryInternals() {\n    return {\n        cache: {\n            fragmentQueryDocuments: getWrapperInformation(this[\"getFragmentDoc\"]),\n        },\n    };\n}\nfunction _getInMemoryCacheMemoryInternals() {\n    var fragments = this.config.fragments;\n    return __assign(__assign({}, _getApolloCacheMemoryInternals.apply(this)), { addTypenameDocumentTransform: transformInfo(this[\"addTypenameTransform\"]), inMemoryCache: {\n            executeSelectionSet: getWrapperInformation(this[\"storeReader\"][\"executeSelectionSet\"]),\n            executeSubSelectedArray: getWrapperInformation(this[\"storeReader\"][\"executeSubSelectedArray\"]),\n            maybeBroadcastWatch: getWrapperInformation(this[\"maybeBroadcastWatch\"]),\n        }, fragmentRegistry: {\n            findFragmentSpreads: getWrapperInformation(fragments === null || fragments === void 0 ? void 0 : fragments.findFragmentSpreads),\n            lookup: getWrapperInformation(fragments === null || fragments === void 0 ? void 0 : fragments.lookup),\n            transform: getWrapperInformation(fragments === null || fragments === void 0 ? void 0 : fragments.transform),\n        } });\n}\nfunction isWrapper(f) {\n    return !!f && \"dirtyKey\" in f;\n}\nfunction getWrapperInformation(f) {\n    return isWrapper(f) ? f.size : undefined;\n}\nfunction isDefined(value) {\n    return value != null;\n}\nfunction transformInfo(transform) {\n    return recurseTransformInfo(transform).map(function (cache) { return ({ cache: cache }); });\n}\nfunction recurseTransformInfo(transform) {\n    return transform ?\n        __spreadArray(__spreadArray([\n            getWrapperInformation(transform === null || transform === void 0 ? void 0 : transform[\"performWork\"])\n        ], recurseTransformInfo(transform === null || transform === void 0 ? void 0 : transform[\"left\"]), true), recurseTransformInfo(transform === null || transform === void 0 ? void 0 : transform[\"right\"]), true).filter(isDefined)\n        : [];\n}\nfunction linkInfo(link) {\n    var _a;\n    return link ?\n        __spreadArray(__spreadArray([\n            (_a = link === null || link === void 0 ? void 0 : link.getMemoryInternals) === null || _a === void 0 ? void 0 : _a.call(link)\n        ], linkInfo(link === null || link === void 0 ? void 0 : link.left), true), linkInfo(link === null || link === void 0 ? void 0 : link.right), true).filter(isDefined)\n        : [];\n}\n//# sourceMappingURL=getMemoryInternals.js.map","import { __assign } from \"tslib\";\nimport { global } from \"../globals/index.js\";\nvar cacheSizeSymbol = Symbol.for(\"apollo.cacheSize\");\n/**\n *\n * The global cache size configuration for Apollo Client.\n *\n * @remarks\n *\n * You can directly modify this object, but any modification will\n * only have an effect on caches that are created after the modification.\n *\n * So for global caches, such as `parser`, `canonicalStringify` and `print`,\n * you might need to call `.reset` on them, which will essentially re-create them.\n *\n * Alternatively, you can set `globalThis[Symbol.for(\"apollo.cacheSize\")]` before\n * you load the Apollo Client package:\n *\n * @example\n * ```ts\n * globalThis[Symbol.for(\"apollo.cacheSize\")] = {\n *   parser: 100\n * } satisfies Partial<CacheSizes> // the `satisfies` is optional if using TypeScript\n * ```\n */\nexport var cacheSizes = __assign({}, global[cacheSizeSymbol]);\n//# sourceMappingURL=sizes.js.map","// A version of Array.isArray that works better with readonly arrays.\nexport var isArray = Array.isArray;\nexport function isNonEmptyArray(value) {\n    return Array.isArray(value) && value.length > 0;\n}\n//# sourceMappingURL=arrays.js.map","import { maybe } from \"../globals/index.js\";\nvar isReactNative = maybe(function () { return navigator.product; }) == \"ReactNative\";\nexport var canUseWeakMap = typeof WeakMap === \"function\" &&\n    !(isReactNative && !global.HermesInternal);\nexport var canUseWeakSet = typeof WeakSet === \"function\";\nexport var canUseSymbol = typeof Symbol === \"function\" && typeof Symbol.for === \"function\";\nexport var canUseAsyncIteratorSymbol = canUseSymbol && Symbol.asyncIterator;\nexport var canUseDOM = typeof maybe(function () { return window.document.createElement; }) === \"function\";\nvar usingJSDOM = \n// Following advice found in this comment from @domenic (maintainer of jsdom):\n// https://github.com/jsdom/jsdom/issues/1537#issuecomment-229405327\n//\n// Since we control the version of Jest and jsdom used when running Apollo\n// Client tests, and that version is recent enought to include \" jsdom/x.y.z\"\n// at the end of the user agent string, I believe this case is all we need to\n// check. Testing for \"Node.js\" was recommended for backwards compatibility\n// with older version of jsdom, but we don't have that problem.\nmaybe(function () { return navigator.userAgent.indexOf(\"jsdom\") >= 0; }) || false;\n// Our tests should all continue to pass if we remove this !usingJSDOM\n// condition, thereby allowing useLayoutEffect when using jsdom. Unfortunately,\n// if we allow useLayoutEffect, then useSyncExternalStore generates many\n// warnings about useLayoutEffect doing nothing on the server. While these\n// warnings are harmless, this !usingJSDOM condition seems to be the best way to\n// prevent them (i.e. skipping useLayoutEffect when using jsdom).\nexport var canUseLayoutEffect = (canUseDOM || isReactNative) && !usingJSDOM;\n//# sourceMappingURL=canUse.js.map","import { AutoCleanedStrongCache, cacheSizes, } from \"../../utilities/caching/index.js\";\nimport { registerGlobalCache } from \"../caching/getMemoryInternals.js\";\n/**\n * Like JSON.stringify, but with object keys always sorted in the same order.\n *\n * To achieve performant sorting, this function uses a Map from JSON-serialized\n * arrays of keys (in any order) to sorted arrays of the same keys, with a\n * single sorted array reference shared by all permutations of the keys.\n *\n * As a drawback, this function will add a little bit more memory for every\n * object encountered that has different (more, less, a different order of) keys\n * than in the past.\n *\n * In a typical application, this extra memory usage should not play a\n * significant role, as `canonicalStringify` will be called for only a limited\n * number of object shapes, and the cache will not grow beyond a certain point.\n * But in some edge cases, this could be a problem, so we provide\n * canonicalStringify.reset() as a way of clearing the cache.\n * */\nexport var canonicalStringify = Object.assign(function canonicalStringify(value) {\n    return JSON.stringify(value, stableObjectReplacer);\n}, {\n    reset: function () {\n        // Clearing the sortingMap will reclaim all cached memory, without\n        // affecting the logical results of canonicalStringify, but potentially\n        // sacrificing performance until the cache is refilled.\n        sortingMap = new AutoCleanedStrongCache(cacheSizes.canonicalStringify || 1000 /* defaultCacheSizes.canonicalStringify */);\n    },\n});\nif (globalThis.__DEV__ !== false) {\n    registerGlobalCache(\"canonicalStringify\", function () { return sortingMap.size; });\n}\n// Values are JSON-serialized arrays of object keys (in any order), and values\n// are sorted arrays of the same keys.\nvar sortingMap;\ncanonicalStringify.reset();\n// The JSON.stringify function takes an optional second argument called a\n// replacer function. This function is called for each key-value pair in the\n// object being stringified, and its return value is used instead of the\n// original value. If the replacer function returns a new value, that value is\n// stringified as JSON instead of the original value of the property.\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#the_replacer_parameter\nfunction stableObjectReplacer(key, value) {\n    if (value && typeof value === \"object\") {\n        var proto = Object.getPrototypeOf(value);\n        // We don't want to mess with objects that are not \"plain\" objects, which\n        // means their prototype is either Object.prototype or null. This check also\n        // prevents needlessly rearranging the indices of arrays.\n        if (proto === Object.prototype || proto === null) {\n            var keys = Object.keys(value);\n            // If keys is already sorted, let JSON.stringify serialize the original\n            // value instead of creating a new object with keys in the same order.\n            if (keys.every(everyKeyInOrder))\n                return value;\n            var unsortedKey = JSON.stringify(keys);\n            var sortedKeys = sortingMap.get(unsortedKey);\n            if (!sortedKeys) {\n                keys.sort();\n                var sortedKey = JSON.stringify(keys);\n                // Checking for sortedKey in the sortingMap allows us to share the same\n                // sorted array reference for all permutations of the same set of keys.\n                sortedKeys = sortingMap.get(sortedKey) || keys;\n                sortingMap.set(unsortedKey, sortedKeys);\n                sortingMap.set(sortedKey, sortedKeys);\n            }\n            var sortedObject_1 = Object.create(proto);\n            // Reassigning the keys in sorted order will cause JSON.stringify to\n            // serialize them in sorted order.\n            sortedKeys.forEach(function (key) {\n                sortedObject_1[key] = value[key];\n            });\n            return sortedObject_1;\n        }\n    }\n    return value;\n}\n// Since everything that happens in stableObjectReplacer benefits from being as\n// efficient as possible, we use a static function as the callback for\n// keys.every in order to test if the provided keys are already sorted without\n// allocating extra memory for a callback.\nfunction everyKeyInOrder(key, i, keys) {\n    return i === 0 || keys[i - 1] <= key;\n}\n//# sourceMappingURL=canonicalStringify.js.map","var toString = Object.prototype.toString;\n/**\n * Deeply clones a value to create a new instance.\n */\nexport function cloneDeep(value) {\n    return cloneDeepHelper(value);\n}\nfunction cloneDeepHelper(val, seen) {\n    switch (toString.call(val)) {\n        case \"[object Array]\": {\n            seen = seen || new Map();\n            if (seen.has(val))\n                return seen.get(val);\n            var copy_1 = val.slice(0);\n            seen.set(val, copy_1);\n            copy_1.forEach(function (child, i) {\n                copy_1[i] = cloneDeepHelper(child, seen);\n            });\n            return copy_1;\n        }\n        case \"[object Object]\": {\n            seen = seen || new Map();\n            if (seen.has(val))\n                return seen.get(val);\n            // High fidelity polyfills of Object.create and Object.getPrototypeOf are\n            // possible in all JS environments, so we will assume they exist/work.\n            var copy_2 = Object.create(Object.getPrototypeOf(val));\n            seen.set(val, copy_2);\n            Object.keys(val).forEach(function (key) {\n                copy_2[key] = cloneDeepHelper(val[key], seen);\n            });\n            return copy_2;\n        }\n        default:\n            return val;\n    }\n}\n//# sourceMappingURL=cloneDeep.js.map","/**\n * Merges the provided objects shallowly and removes\n * all properties with an `undefined` value\n */\nexport function compact() {\n    var objects = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        objects[_i] = arguments[_i];\n    }\n    var result = Object.create(null);\n    objects.forEach(function (obj) {\n        if (!obj)\n            return;\n        Object.keys(obj).forEach(function (key) {\n            var value = obj[key];\n            if (value !== void 0) {\n                result[key] = value;\n            }\n        });\n    });\n    return result;\n}\n//# sourceMappingURL=compact.js.map","var prefixCounts = new Map();\n// These IDs won't be globally unique, but they will be unique within this\n// process, thanks to the counter, and unguessable thanks to the random suffix.\nexport function makeUniqueId(prefix) {\n    var count = prefixCounts.get(prefix) || 1;\n    prefixCounts.set(prefix, count + 1);\n    return \"\".concat(prefix, \":\").concat(count, \":\").concat(Math.random().toString(36).slice(2));\n}\n//# sourceMappingURL=makeUniqueId.js.map","import { isNonNullObject } from \"./objects.js\";\nexport function deepFreeze(value) {\n    var workSet = new Set([value]);\n    workSet.forEach(function (obj) {\n        if (isNonNullObject(obj) && shallowFreeze(obj) === obj) {\n            Object.getOwnPropertyNames(obj).forEach(function (name) {\n                if (isNonNullObject(obj[name]))\n                    workSet.add(obj[name]);\n            });\n        }\n    });\n    return value;\n}\nfunction shallowFreeze(obj) {\n    if (globalThis.__DEV__ !== false && !Object.isFrozen(obj)) {\n        try {\n            Object.freeze(obj);\n        }\n        catch (e) {\n            // Some types like Uint8Array and Node.js's Buffer cannot be frozen, but\n            // they all throw a TypeError when you try, so we re-throw any exceptions\n            // that are not TypeErrors, since that would be unexpected.\n            if (e instanceof TypeError)\n                return null;\n            throw e;\n        }\n    }\n    return obj;\n}\nexport function maybeDeepFreeze(obj) {\n    if (globalThis.__DEV__ !== false) {\n        deepFreeze(obj);\n    }\n    return obj;\n}\n//# sourceMappingURL=maybeDeepFreeze.js.map","import { __assign, __spreadArray } from \"tslib\";\nimport { isNonNullObject } from \"./objects.js\";\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nexport function mergeDeep() {\n    var sources = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        sources[_i] = arguments[_i];\n    }\n    return mergeDeepArray(sources);\n}\n// In almost any situation where you could succeed in getting the\n// TypeScript compiler to infer a tuple type for the sources array, you\n// could just use mergeDeep instead of mergeDeepArray, so instead of\n// trying to convert T[] to an intersection type we just infer the array\n// element type, which works perfectly when the sources array has a\n// consistent element type.\nexport function mergeDeepArray(sources) {\n    var target = sources[0] || {};\n    var count = sources.length;\n    if (count > 1) {\n        var merger = new DeepMerger();\n        for (var i = 1; i < count; ++i) {\n            target = merger.merge(target, sources[i]);\n        }\n    }\n    return target;\n}\nvar defaultReconciler = function (target, source, property) {\n    return this.merge(target[property], source[property]);\n};\nvar DeepMerger = /** @class */ (function () {\n    function DeepMerger(reconciler) {\n        if (reconciler === void 0) { reconciler = defaultReconciler; }\n        this.reconciler = reconciler;\n        this.isObject = isNonNullObject;\n        this.pastCopies = new Set();\n    }\n    DeepMerger.prototype.merge = function (target, source) {\n        var _this = this;\n        var context = [];\n        for (var _i = 2; _i < arguments.length; _i++) {\n            context[_i - 2] = arguments[_i];\n        }\n        if (isNonNullObject(source) && isNonNullObject(target)) {\n            Object.keys(source).forEach(function (sourceKey) {\n                if (hasOwnProperty.call(target, sourceKey)) {\n                    var targetValue = target[sourceKey];\n                    if (source[sourceKey] !== targetValue) {\n                        var result = _this.reconciler.apply(_this, __spreadArray([target,\n                            source,\n                            sourceKey], context, false));\n                        // A well-implemented reconciler may return targetValue to indicate\n                        // the merge changed nothing about the structure of the target.\n                        if (result !== targetValue) {\n                            target = _this.shallowCopyForMerge(target);\n                            target[sourceKey] = result;\n                        }\n                    }\n                }\n                else {\n                    // If there is no collision, the target can safely share memory with\n                    // the source, and the recursion can terminate here.\n                    target = _this.shallowCopyForMerge(target);\n                    target[sourceKey] = source[sourceKey];\n                }\n            });\n            return target;\n        }\n        // If source (or target) is not an object, let source replace target.\n        return source;\n    };\n    DeepMerger.prototype.shallowCopyForMerge = function (value) {\n        if (isNonNullObject(value)) {\n            if (!this.pastCopies.has(value)) {\n                if (Array.isArray(value)) {\n                    value = value.slice(0);\n                }\n                else {\n                    value = __assign({ __proto__: Object.getPrototypeOf(value) }, value);\n                }\n                this.pastCopies.add(value);\n            }\n        }\n        return value;\n    };\n    return DeepMerger;\n}());\nexport { DeepMerger };\n//# sourceMappingURL=mergeDeep.js.map","export function isNonNullObject(obj) {\n    return obj !== null && typeof obj === \"object\";\n}\nexport function isPlainObject(obj) {\n    return (obj !== null &&\n        typeof obj === \"object\" &&\n        (Object.getPrototypeOf(obj) === Object.prototype ||\n            Object.getPrototypeOf(obj) === null));\n}\n//# sourceMappingURL=objects.js.map","import { makeUniqueId } from \"./makeUniqueId.js\";\nexport function stringifyForDisplay(value, space) {\n    if (space === void 0) { space = 0; }\n    var undefId = makeUniqueId(\"stringifyForDisplay\");\n    return JSON.stringify(value, function (key, value) {\n        return value === void 0 ? undefId : value;\n    }, space)\n        .split(JSON.stringify(undefId))\n        .join(\"<undefined>\");\n}\n//# sourceMappingURL=stringifyForDisplay.js.map","import { __spreadArray } from \"tslib\";\nimport { Slot } from \"optimism\";\nimport { invariant, global as untypedGlobal } from \"../globals/index.js\";\nvar muteAllDeprecations = Symbol.for(\"apollo.deprecations\");\nvar global = untypedGlobal;\nvar slot = new Slot();\nfunction isMuted(name) {\n    return global[muteAllDeprecations] || (slot.getValue() || []).includes(name);\n}\nexport function muteDeprecations(name) {\n    var args = [];\n    for (var _i = 1; _i < arguments.length; _i++) {\n        args[_i - 1] = arguments[_i];\n    }\n    return slot.withValue.apply(slot, __spreadArray([Array.isArray(name) ? name : [name]], args, false));\n}\nexport function warnRemovedOption(options, name, callSite, recommendation) {\n    if (recommendation === void 0) { recommendation = \"Please remove this option.\"; }\n    warnDeprecated(name, function () {\n        if (name in options) {\n            globalThis.__DEV__ !== false && invariant.warn(104, callSite, name, recommendation);\n        }\n    });\n}\nexport function warnDeprecated(name, cb) {\n    if (!isMuted(name)) {\n        cb();\n    }\n}\nexport function withDisabledDeprecations() {\n    var _a;\n    var prev = global[muteAllDeprecations];\n    global[muteAllDeprecations] = true;\n    return _a = {},\n        _a[Symbol.dispose] = function () {\n            global[muteAllDeprecations] = prev;\n        },\n        _a;\n}\n//# sourceMappingURL=index.js.map","import { maybe } from \"./maybe.js\";\nexport default (maybe(function () { return globalThis; }) ||\n    maybe(function () { return window; }) ||\n    maybe(function () { return self; }) ||\n    maybe(function () { return global; }) || // We don't expect the Function constructor ever to be invoked at runtime, as\n// long as at least one of globalThis, window, self, or global is defined, so\n// we are under no obligation to make it easy for static analysis tools to\n// detect syntactic usage of the Function constructor. If you think you can\n// improve your static analysis to detect this obfuscation, think again. This\n// is an arms race you cannot win, at least not in JavaScript.\nmaybe(function () {\n    return maybe.constructor(\"return this\")();\n}));\n//# sourceMappingURL=global.js.map","import { invariant, newInvariantError, InvariantError, } from \"./invariantWrappers.js\";\nexport { maybe } from \"./maybe.js\";\nexport { default as global } from \"./global.js\";\nexport { invariant, newInvariantError, InvariantError };\n/**\n * @deprecated we do not use this internally anymore,\n * it is just exported for backwards compatibility\n */\n// this file is extempt from automatic `__DEV__` replacement\n// so we have to write it out here\n// @ts-ignore\nexport var DEV = globalThis.__DEV__ !== false;\nexport { DEV as __DEV__ };\n//# sourceMappingURL=index.js.map","import { invariant as originalInvariant, InvariantError } from \"ts-invariant\";\nimport { version } from \"../../version.js\";\nimport global from \"./global.js\";\nimport { stringifyForDisplay } from \"../common/stringifyForDisplay.js\";\nfunction wrap(fn) {\n    return function (message) {\n        var args = [];\n        for (var _i = 1; _i < arguments.length; _i++) {\n            args[_i - 1] = arguments[_i];\n        }\n        if (typeof message === \"number\") {\n            var arg0 = message;\n            message = getHandledErrorMsg(arg0);\n            if (!message) {\n                message = getFallbackErrorMsg(arg0, args);\n                args = [];\n            }\n        }\n        fn.apply(void 0, [message].concat(args));\n    };\n}\nvar invariant = Object.assign(function invariant(condition, message) {\n    var args = [];\n    for (var _i = 2; _i < arguments.length; _i++) {\n        args[_i - 2] = arguments[_i];\n    }\n    if (!condition) {\n        originalInvariant(condition, getHandledErrorMsg(message, args) || getFallbackErrorMsg(message, args));\n    }\n}, {\n    debug: wrap(originalInvariant.debug),\n    log: wrap(originalInvariant.log),\n    warn: wrap(originalInvariant.warn),\n    error: wrap(originalInvariant.error),\n});\n/**\n * Returns an InvariantError.\n *\n * `message` can only be a string, a concatenation of strings, or a ternary statement\n * that results in a string. This will be enforced on build, where the message will\n * be replaced with a message number.\n * String substitutions with %s are supported and will also return\n * pretty-stringified objects.\n * Excess `optionalParams` will be swallowed.\n */\nfunction newInvariantError(message) {\n    var optionalParams = [];\n    for (var _i = 1; _i < arguments.length; _i++) {\n        optionalParams[_i - 1] = arguments[_i];\n    }\n    return new InvariantError(getHandledErrorMsg(message, optionalParams) ||\n        getFallbackErrorMsg(message, optionalParams));\n}\nvar ApolloErrorMessageHandler = Symbol.for(\"ApolloErrorMessageHandler_\" + version);\nfunction stringify(arg) {\n    if (typeof arg == \"string\") {\n        return arg;\n    }\n    try {\n        return stringifyForDisplay(arg, 2).slice(0, 1000);\n    }\n    catch (_a) {\n        return \"<non-serializable>\";\n    }\n}\nfunction getHandledErrorMsg(message, messageArgs) {\n    if (messageArgs === void 0) { messageArgs = []; }\n    if (!message)\n        return;\n    return (global[ApolloErrorMessageHandler] &&\n        global[ApolloErrorMessageHandler](message, messageArgs.map(stringify)));\n}\nfunction getFallbackErrorMsg(message, messageArgs) {\n    if (messageArgs === void 0) { messageArgs = []; }\n    if (!message)\n        return;\n    return \"An error occurred! For more details, see the full error text at https://go.apollo.dev/c/err#\".concat(encodeURIComponent(JSON.stringify({\n        version: version,\n        message: message,\n        args: messageArgs.map(stringify),\n    })));\n}\nexport { invariant, InvariantError, newInvariantError, ApolloErrorMessageHandler, };\n//# sourceMappingURL=invariantWrappers.js.map","export function maybe(thunk) {\n    try {\n        return thunk();\n    }\n    catch (_a) { }\n}\n//# sourceMappingURL=maybe.js.map","import { Trie } from \"@wry/trie\";\nimport { canUseWeakMap, canUseWeakSet } from \"../common/canUse.js\";\nimport { checkDocument } from \"./getFromAST.js\";\nimport { invariant } from \"../globals/index.js\";\nimport { WeakCache } from \"@wry/caches\";\nimport { wrap } from \"optimism\";\nimport { cacheSizes } from \"../caching/index.js\";\nfunction identity(document) {\n    return document;\n}\nvar DocumentTransform = /** @class */ (function () {\n    function DocumentTransform(transform, options) {\n        if (options === void 0) { options = Object.create(null); }\n        this.resultCache = canUseWeakSet ? new WeakSet() : new Set();\n        this.transform = transform;\n        if (options.getCacheKey) {\n            // Override default `getCacheKey` function, which returns [document].\n            this.getCacheKey = options.getCacheKey;\n        }\n        this.cached = options.cache !== false;\n        this.resetCache();\n    }\n    // This default implementation of getCacheKey can be overridden by providing\n    // options.getCacheKey to the DocumentTransform constructor. In general, a\n    // getCacheKey function may either return an array of keys (often including\n    // the document) to be used as a cache key, or undefined to indicate the\n    // transform for this document should not be cached.\n    DocumentTransform.prototype.getCacheKey = function (document) {\n        return [document];\n    };\n    DocumentTransform.identity = function () {\n        // No need to cache this transform since it just returns the document\n        // unchanged. This should save a bit of memory that would otherwise be\n        // needed to populate the `documentCache` of this transform.\n        return new DocumentTransform(identity, { cache: false });\n    };\n    DocumentTransform.split = function (predicate, left, right) {\n        if (right === void 0) { right = DocumentTransform.identity(); }\n        return Object.assign(new DocumentTransform(function (document) {\n            var documentTransform = predicate(document) ? left : right;\n            return documentTransform.transformDocument(document);\n        }, \n        // Reasonably assume both `left` and `right` transforms handle their own caching\n        { cache: false }), { left: left, right: right });\n    };\n    /**\n     * Resets the internal cache of this transform, if it has one.\n     */\n    DocumentTransform.prototype.resetCache = function () {\n        var _this = this;\n        if (this.cached) {\n            var stableCacheKeys_1 = new Trie(canUseWeakMap);\n            this.performWork = wrap(DocumentTransform.prototype.performWork.bind(this), {\n                makeCacheKey: function (document) {\n                    var cacheKeys = _this.getCacheKey(document);\n                    if (cacheKeys) {\n                        invariant(Array.isArray(cacheKeys), 105);\n                        return stableCacheKeys_1.lookupArray(cacheKeys);\n                    }\n                },\n                max: cacheSizes[\"documentTransform.cache\"],\n                cache: (WeakCache),\n            });\n        }\n    };\n    DocumentTransform.prototype.performWork = function (document) {\n        checkDocument(document);\n        return this.transform(document);\n    };\n    DocumentTransform.prototype.transformDocument = function (document) {\n        // If a user passes an already transformed result back to this function,\n        // immediately return it.\n        if (this.resultCache.has(document)) {\n            return document;\n        }\n        var transformedDocument = this.performWork(document);\n        this.resultCache.add(transformedDocument);\n        return transformedDocument;\n    };\n    DocumentTransform.prototype.concat = function (otherTransform) {\n        var _this = this;\n        return Object.assign(new DocumentTransform(function (document) {\n            return otherTransform.transformDocument(_this.transformDocument(document));\n        }, \n        // Reasonably assume both transforms handle their own caching\n        { cache: false }), {\n            left: this,\n            right: otherTransform,\n        });\n    };\n    return DocumentTransform;\n}());\nexport { DocumentTransform };\n//# sourceMappingURL=DocumentTransform.js.map","import { invariant } from \"../globals/index.js\";\nimport { visit, BREAK, Kind } from \"graphql\";\nexport function shouldInclude(_a, variables) {\n    var directives = _a.directives;\n    if (!directives || !directives.length) {\n        return true;\n    }\n    return getInclusionDirectives(directives).every(function (_a) {\n        var directive = _a.directive, ifArgument = _a.ifArgument;\n        var evaledValue = false;\n        if (ifArgument.value.kind === \"Variable\") {\n            evaledValue =\n                variables && variables[ifArgument.value.name.value];\n            invariant(evaledValue !== void 0, 106, directive.name.value);\n        }\n        else {\n            evaledValue = ifArgument.value.value;\n        }\n        return directive.name.value === \"skip\" ? !evaledValue : evaledValue;\n    });\n}\nexport function getDirectiveNames(root) {\n    var names = [];\n    visit(root, {\n        Directive: function (node) {\n            names.push(node.name.value);\n        },\n    });\n    return names;\n}\nexport var hasAnyDirectives = function (names, root) {\n    return hasDirectives(names, root, false);\n};\nexport var hasAllDirectives = function (names, root) {\n    return hasDirectives(names, root, true);\n};\nexport function hasDirectives(names, root, all) {\n    var nameSet = new Set(names);\n    var uniqueCount = nameSet.size;\n    visit(root, {\n        Directive: function (node) {\n            if (nameSet.delete(node.name.value) && (!all || !nameSet.size)) {\n                return BREAK;\n            }\n        },\n    });\n    // If we found all the names, nameSet will be empty. If we only care about\n    // finding some of them, the < condition is sufficient.\n    return all ? !nameSet.size : nameSet.size < uniqueCount;\n}\nexport function hasClientExports(document) {\n    return document && hasDirectives([\"client\", \"export\"], document, true);\n}\nfunction isInclusionDirective(_a) {\n    var value = _a.name.value;\n    return value === \"skip\" || value === \"include\";\n}\nexport function getInclusionDirectives(directives) {\n    var result = [];\n    if (directives && directives.length) {\n        directives.forEach(function (directive) {\n            if (!isInclusionDirective(directive))\n                return;\n            var directiveArguments = directive.arguments;\n            var directiveName = directive.name.value;\n            invariant(directiveArguments && directiveArguments.length === 1, 107, directiveName);\n            var ifArgument = directiveArguments[0];\n            invariant(ifArgument.name && ifArgument.name.value === \"if\", 108, directiveName);\n            var ifValue = ifArgument.value;\n            // means it has to be a variable value if this is a valid @skip or @include directive\n            invariant(ifValue &&\n                (ifValue.kind === \"Variable\" || ifValue.kind === \"BooleanValue\"), 109, directiveName);\n            result.push({ directive: directive, ifArgument: ifArgument });\n        });\n    }\n    return result;\n}\n/** @internal */\nexport function getFragmentMaskMode(fragment) {\n    var _a, _b;\n    var directive = (_a = fragment.directives) === null || _a === void 0 ? void 0 : _a.find(function (_a) {\n        var name = _a.name;\n        return name.value === \"unmask\";\n    });\n    if (!directive) {\n        return \"mask\";\n    }\n    var modeArg = (_b = directive.arguments) === null || _b === void 0 ? void 0 : _b.find(function (_a) {\n        var name = _a.name;\n        return name.value === \"mode\";\n    });\n    if (globalThis.__DEV__ !== false) {\n        if (modeArg) {\n            if (modeArg.value.kind === Kind.VARIABLE) {\n                globalThis.__DEV__ !== false && invariant.warn(110);\n            }\n            else if (modeArg.value.kind !== Kind.STRING) {\n                globalThis.__DEV__ !== false && invariant.warn(111);\n            }\n            else if (modeArg.value.value !== \"migrate\") {\n                globalThis.__DEV__ !== false && invariant.warn(112, modeArg.value.value);\n            }\n        }\n    }\n    if (modeArg &&\n        \"value\" in modeArg.value &&\n        modeArg.value.value === \"migrate\") {\n        return \"migrate\";\n    }\n    return \"unmask\";\n}\n//# sourceMappingURL=directives.js.map","import { __assign, __spreadArray } from \"tslib\";\nimport { invariant, newInvariantError } from \"../globals/index.js\";\nimport { BREAK, visit } from \"graphql\";\n/**\n * Returns a query document which adds a single query operation that only\n * spreads the target fragment inside of it.\n *\n * So for example a document of:\n *\n * ```graphql\n * fragment foo on Foo { a b c }\n * ```\n *\n * Turns into:\n *\n * ```graphql\n * { ...foo }\n *\n * fragment foo on Foo { a b c }\n * ```\n *\n * The target fragment will either be the only fragment in the document, or a\n * fragment specified by the provided `fragmentName`. If there is more than one\n * fragment, but a `fragmentName` was not defined then an error will be thrown.\n */\nexport function getFragmentQueryDocument(document, fragmentName) {\n    var actualFragmentName = fragmentName;\n    // Build an array of all our fragment definitions that will be used for\n    // validations. We also do some validations on the other definitions in the\n    // document while building this list.\n    var fragments = [];\n    document.definitions.forEach(function (definition) {\n        // Throw an error if we encounter an operation definition because we will\n        // define our own operation definition later on.\n        if (definition.kind === \"OperationDefinition\") {\n            throw newInvariantError(\n                113,\n                definition.operation,\n                definition.name ? \" named '\".concat(definition.name.value, \"'\") : \"\"\n            );\n        }\n        // Add our definition to the fragments array if it is a fragment\n        // definition.\n        if (definition.kind === \"FragmentDefinition\") {\n            fragments.push(definition);\n        }\n    });\n    // If the user did not give us a fragment name then let us try to get a\n    // name from a single fragment in the definition.\n    if (typeof actualFragmentName === \"undefined\") {\n        invariant(fragments.length === 1, 114, fragments.length);\n        actualFragmentName = fragments[0].name.value;\n    }\n    // Generate a query document with an operation that simply spreads the\n    // fragment inside of it.\n    var query = __assign(__assign({}, document), { definitions: __spreadArray([\n            {\n                kind: \"OperationDefinition\",\n                // OperationTypeNode is an enum\n                operation: \"query\",\n                selectionSet: {\n                    kind: \"SelectionSet\",\n                    selections: [\n                        {\n                            kind: \"FragmentSpread\",\n                            name: {\n                                kind: \"Name\",\n                                value: actualFragmentName,\n                            },\n                        },\n                    ],\n                },\n            }\n        ], document.definitions, true) });\n    return query;\n}\n// Utility function that takes a list of fragment definitions and makes a hash out of them\n// that maps the name of the fragment to the fragment definition.\nexport function createFragmentMap(fragments) {\n    if (fragments === void 0) { fragments = []; }\n    var symTable = {};\n    fragments.forEach(function (fragment) {\n        symTable[fragment.name.value] = fragment;\n    });\n    return symTable;\n}\nexport function getFragmentFromSelection(selection, fragmentMap) {\n    switch (selection.kind) {\n        case \"InlineFragment\":\n            return selection;\n        case \"FragmentSpread\": {\n            var fragmentName = selection.name.value;\n            if (typeof fragmentMap === \"function\") {\n                return fragmentMap(fragmentName);\n            }\n            var fragment = fragmentMap && fragmentMap[fragmentName];\n            invariant(fragment, 115, fragmentName);\n            return fragment || null;\n        }\n        default:\n            return null;\n    }\n}\nexport function isFullyUnmaskedOperation(document) {\n    var isUnmasked = true;\n    visit(document, {\n        FragmentSpread: function (node) {\n            isUnmasked =\n                !!node.directives &&\n                    node.directives.some(function (directive) { return directive.name.value === \"unmask\"; });\n            if (!isUnmasked) {\n                return BREAK;\n            }\n        },\n    });\n    return isUnmasked;\n}\n//# sourceMappingURL=fragments.js.map","import { invariant, newInvariantError } from \"../globals/index.js\";\nimport { valueToObjectRepresentation } from \"./storeUtils.js\";\n// Checks the document for errors and throws an exception if there is an error.\nexport function checkDocument(doc) {\n    invariant(doc && doc.kind === \"Document\", 116);\n    var operations = doc.definitions\n        .filter(function (d) { return d.kind !== \"FragmentDefinition\"; })\n        .map(function (definition) {\n        if (definition.kind !== \"OperationDefinition\") {\n            throw newInvariantError(117, definition.kind);\n        }\n        return definition;\n    });\n    invariant(operations.length <= 1, 118, operations.length);\n    return doc;\n}\nexport function getOperationDefinition(doc) {\n    checkDocument(doc);\n    return doc.definitions.filter(function (definition) {\n        return definition.kind === \"OperationDefinition\";\n    })[0];\n}\nexport function getOperationName(doc) {\n    return (doc.definitions\n        .filter(function (definition) {\n        return definition.kind === \"OperationDefinition\" && !!definition.name;\n    })\n        .map(function (x) { return x.name.value; })[0] || null);\n}\n// Returns the FragmentDefinitions from a particular document as an array\nexport function getFragmentDefinitions(doc) {\n    return doc.definitions.filter(function (definition) {\n        return definition.kind === \"FragmentDefinition\";\n    });\n}\nexport function getQueryDefinition(doc) {\n    var queryDef = getOperationDefinition(doc);\n    invariant(queryDef && queryDef.operation === \"query\", 119);\n    return queryDef;\n}\nexport function getFragmentDefinition(doc) {\n    invariant(doc.kind === \"Document\", 120);\n    invariant(doc.definitions.length <= 1, 121);\n    var fragmentDef = doc.definitions[0];\n    invariant(fragmentDef.kind === \"FragmentDefinition\", 122);\n    return fragmentDef;\n}\n/**\n * Returns the first operation definition found in this document.\n * If no operation definition is found, the first fragment definition will be returned.\n * If no definitions are found, an error will be thrown.\n */\nexport function getMainDefinition(queryDoc) {\n    checkDocument(queryDoc);\n    var fragmentDefinition;\n    for (var _i = 0, _a = queryDoc.definitions; _i < _a.length; _i++) {\n        var definition = _a[_i];\n        if (definition.kind === \"OperationDefinition\") {\n            var operation = definition.operation;\n            if (operation === \"query\" ||\n                operation === \"mutation\" ||\n                operation === \"subscription\") {\n                return definition;\n            }\n        }\n        if (definition.kind === \"FragmentDefinition\" && !fragmentDefinition) {\n            // we do this because we want to allow multiple fragment definitions\n            // to precede an operation definition.\n            fragmentDefinition = definition;\n        }\n    }\n    if (fragmentDefinition) {\n        return fragmentDefinition;\n    }\n    throw newInvariantError(123);\n}\nexport function getDefaultValues(definition) {\n    var defaultValues = Object.create(null);\n    var defs = definition && definition.variableDefinitions;\n    if (defs && defs.length) {\n        defs.forEach(function (def) {\n            if (def.defaultValue) {\n                valueToObjectRepresentation(defaultValues, def.variable.name, def.defaultValue);\n            }\n        });\n    }\n    return defaultValues;\n}\n//# sourceMappingURL=getFromAST.js.map","import { print as origPrint } from \"graphql\";\nimport { AutoCleanedWeakCache, cacheSizes, } from \"../caching/index.js\";\nimport { registerGlobalCache } from \"../caching/getMemoryInternals.js\";\nvar printCache;\nexport var print = Object.assign(function (ast) {\n    var result = printCache.get(ast);\n    if (!result) {\n        result = origPrint(ast);\n        printCache.set(ast, result);\n    }\n    return result;\n}, {\n    reset: function () {\n        printCache = new AutoCleanedWeakCache(cacheSizes.print || 2000 /* defaultCacheSizes.print */);\n    },\n});\nprint.reset();\nif (globalThis.__DEV__ !== false) {\n    registerGlobalCache(\"print\", function () { return (printCache ? printCache.size : 0); });\n}\n//# sourceMappingURL=print.js.map","import { newInvariantError } from \"../globals/index.js\";\nimport { isNonNullObject } from \"../common/objects.js\";\nimport { getFragmentFromSelection } from \"./fragments.js\";\nimport { canonicalStringify } from \"../common/canonicalStringify.js\";\nexport function makeReference(id) {\n    return { __ref: String(id) };\n}\nexport function isReference(obj) {\n    return Boolean(obj && typeof obj === \"object\" && typeof obj.__ref === \"string\");\n}\nexport function isDocumentNode(value) {\n    return (isNonNullObject(value) &&\n        value.kind === \"Document\" &&\n        Array.isArray(value.definitions));\n}\nfunction isStringValue(value) {\n    return value.kind === \"StringValue\";\n}\nfunction isBooleanValue(value) {\n    return value.kind === \"BooleanValue\";\n}\nfunction isIntValue(value) {\n    return value.kind === \"IntValue\";\n}\nfunction isFloatValue(value) {\n    return value.kind === \"FloatValue\";\n}\nfunction isVariable(value) {\n    return value.kind === \"Variable\";\n}\nfunction isObjectValue(value) {\n    return value.kind === \"ObjectValue\";\n}\nfunction isListValue(value) {\n    return value.kind === \"ListValue\";\n}\nfunction isEnumValue(value) {\n    return value.kind === \"EnumValue\";\n}\nfunction isNullValue(value) {\n    return value.kind === \"NullValue\";\n}\nexport function valueToObjectRepresentation(argObj, name, value, variables) {\n    if (isIntValue(value) || isFloatValue(value)) {\n        argObj[name.value] = Number(value.value);\n    }\n    else if (isBooleanValue(value) || isStringValue(value)) {\n        argObj[name.value] = value.value;\n    }\n    else if (isObjectValue(value)) {\n        var nestedArgObj_1 = {};\n        value.fields.map(function (obj) {\n            return valueToObjectRepresentation(nestedArgObj_1, obj.name, obj.value, variables);\n        });\n        argObj[name.value] = nestedArgObj_1;\n    }\n    else if (isVariable(value)) {\n        var variableValue = (variables || {})[value.name.value];\n        argObj[name.value] = variableValue;\n    }\n    else if (isListValue(value)) {\n        argObj[name.value] = value.values.map(function (listValue) {\n            var nestedArgArrayObj = {};\n            valueToObjectRepresentation(nestedArgArrayObj, name, listValue, variables);\n            return nestedArgArrayObj[name.value];\n        });\n    }\n    else if (isEnumValue(value)) {\n        argObj[name.value] = value.value;\n    }\n    else if (isNullValue(value)) {\n        argObj[name.value] = null;\n    }\n    else {\n        throw newInvariantError(124, name.value, value.kind);\n    }\n}\nexport function storeKeyNameFromField(field, variables) {\n    var directivesObj = null;\n    if (field.directives) {\n        directivesObj = {};\n        field.directives.forEach(function (directive) {\n            directivesObj[directive.name.value] = {};\n            if (directive.arguments) {\n                directive.arguments.forEach(function (_a) {\n                    var name = _a.name, value = _a.value;\n                    return valueToObjectRepresentation(directivesObj[directive.name.value], name, value, variables);\n                });\n            }\n        });\n    }\n    var argObj = null;\n    if (field.arguments && field.arguments.length) {\n        argObj = {};\n        field.arguments.forEach(function (_a) {\n            var name = _a.name, value = _a.value;\n            return valueToObjectRepresentation(argObj, name, value, variables);\n        });\n    }\n    return getStoreKeyName(field.name.value, argObj, directivesObj);\n}\nvar KNOWN_DIRECTIVES = [\n    \"connection\",\n    \"include\",\n    \"skip\",\n    \"client\",\n    \"rest\",\n    \"export\",\n    \"nonreactive\",\n];\n// Default stable JSON.stringify implementation used by getStoreKeyName. Can be\n// updated/replaced with something better by calling\n// getStoreKeyName.setStringify(newStringifyFunction).\nvar storeKeyNameStringify = canonicalStringify;\nexport var getStoreKeyName = Object.assign(function (fieldName, args, directives) {\n    if (args &&\n        directives &&\n        directives[\"connection\"] &&\n        directives[\"connection\"][\"key\"]) {\n        if (directives[\"connection\"][\"filter\"] &&\n            directives[\"connection\"][\"filter\"].length > 0) {\n            var filterKeys = directives[\"connection\"][\"filter\"] ?\n                directives[\"connection\"][\"filter\"]\n                : [];\n            filterKeys.sort();\n            var filteredArgs_1 = {};\n            filterKeys.forEach(function (key) {\n                filteredArgs_1[key] = args[key];\n            });\n            return \"\".concat(directives[\"connection\"][\"key\"], \"(\").concat(storeKeyNameStringify(filteredArgs_1), \")\");\n        }\n        else {\n            return directives[\"connection\"][\"key\"];\n        }\n    }\n    var completeFieldName = fieldName;\n    if (args) {\n        // We can't use `JSON.stringify` here since it's non-deterministic,\n        // and can lead to different store key names being created even though\n        // the `args` object used during creation has the same properties/values.\n        var stringifiedArgs = storeKeyNameStringify(args);\n        completeFieldName += \"(\".concat(stringifiedArgs, \")\");\n    }\n    if (directives) {\n        Object.keys(directives).forEach(function (key) {\n            if (KNOWN_DIRECTIVES.indexOf(key) !== -1)\n                return;\n            if (directives[key] && Object.keys(directives[key]).length) {\n                completeFieldName += \"@\".concat(key, \"(\").concat(storeKeyNameStringify(directives[key]), \")\");\n            }\n            else {\n                completeFieldName += \"@\".concat(key);\n            }\n        });\n    }\n    return completeFieldName;\n}, {\n    setStringify: function (s) {\n        var previous = storeKeyNameStringify;\n        storeKeyNameStringify = s;\n        return previous;\n    },\n});\nexport function argumentsObjectFromField(field, variables) {\n    if (field.arguments && field.arguments.length) {\n        var argObj_1 = {};\n        field.arguments.forEach(function (_a) {\n            var name = _a.name, value = _a.value;\n            return valueToObjectRepresentation(argObj_1, name, value, variables);\n        });\n        return argObj_1;\n    }\n    return null;\n}\nexport function resultKeyNameFromField(field) {\n    return field.alias ? field.alias.value : field.name.value;\n}\nexport function getTypenameFromResult(result, selectionSet, fragmentMap) {\n    var fragments;\n    for (var _i = 0, _a = selectionSet.selections; _i < _a.length; _i++) {\n        var selection = _a[_i];\n        if (isField(selection)) {\n            if (selection.name.value === \"__typename\") {\n                return result[resultKeyNameFromField(selection)];\n            }\n        }\n        else if (fragments) {\n            fragments.push(selection);\n        }\n        else {\n            fragments = [selection];\n        }\n    }\n    if (typeof result.__typename === \"string\") {\n        return result.__typename;\n    }\n    if (fragments) {\n        for (var _b = 0, fragments_1 = fragments; _b < fragments_1.length; _b++) {\n            var selection = fragments_1[_b];\n            var typename = getTypenameFromResult(result, getFragmentFromSelection(selection, fragmentMap).selectionSet, fragmentMap);\n            if (typeof typename === \"string\") {\n                return typename;\n            }\n        }\n    }\n}\nexport function isField(selection) {\n    return selection.kind === \"Field\";\n}\nexport function isInlineFragment(selection) {\n    return selection.kind === \"InlineFragment\";\n}\n//# sourceMappingURL=storeUtils.js.map","import { __assign, __spreadArray } from \"tslib\";\nimport { invariant } from \"../globals/index.js\";\nimport { visit, Kind } from \"graphql\";\nimport { checkDocument, getOperationDefinition, getFragmentDefinition, getFragmentDefinitions, getMainDefinition, } from \"./getFromAST.js\";\nimport { isField } from \"./storeUtils.js\";\nimport { createFragmentMap } from \"./fragments.js\";\nimport { isArray, isNonEmptyArray } from \"../common/arrays.js\";\nvar TYPENAME_FIELD = {\n    kind: Kind.FIELD,\n    name: {\n        kind: Kind.NAME,\n        value: \"__typename\",\n    },\n};\nfunction isEmpty(op, fragmentMap) {\n    return (!op ||\n        op.selectionSet.selections.every(function (selection) {\n            return selection.kind === Kind.FRAGMENT_SPREAD &&\n                isEmpty(fragmentMap[selection.name.value], fragmentMap);\n        }));\n}\nfunction nullIfDocIsEmpty(doc) {\n    return (isEmpty(getOperationDefinition(doc) || getFragmentDefinition(doc), createFragmentMap(getFragmentDefinitions(doc)))) ?\n        null\n        : doc;\n}\nfunction getDirectiveMatcher(configs) {\n    var names = new Map();\n    var tests = new Map();\n    configs.forEach(function (directive) {\n        if (directive) {\n            if (directive.name) {\n                names.set(directive.name, directive);\n            }\n            else if (directive.test) {\n                tests.set(directive.test, directive);\n            }\n        }\n    });\n    return function (directive) {\n        var config = names.get(directive.name.value);\n        if (!config && tests.size) {\n            tests.forEach(function (testConfig, test) {\n                if (test(directive)) {\n                    config = testConfig;\n                }\n            });\n        }\n        return config;\n    };\n}\nfunction makeInUseGetterFunction(defaultKey) {\n    var map = new Map();\n    return function inUseGetterFunction(key) {\n        if (key === void 0) { key = defaultKey; }\n        var inUse = map.get(key);\n        if (!inUse) {\n            map.set(key, (inUse = {\n                // Variable and fragment spread names used directly within this\n                // operation or fragment definition, as identified by key. These sets\n                // will be populated during the first traversal of the document in\n                // removeDirectivesFromDocument below.\n                variables: new Set(),\n                fragmentSpreads: new Set(),\n            }));\n        }\n        return inUse;\n    };\n}\nexport function removeDirectivesFromDocument(directives, doc) {\n    checkDocument(doc);\n    // Passing empty strings to makeInUseGetterFunction means we handle anonymous\n    // operations as if their names were \"\". Anonymous fragment definitions are\n    // not supposed to be possible, but the same default naming strategy seems\n    // appropriate for that case as well.\n    var getInUseByOperationName = makeInUseGetterFunction(\"\");\n    var getInUseByFragmentName = makeInUseGetterFunction(\"\");\n    var getInUse = function (ancestors) {\n        for (var p = 0, ancestor = void 0; p < ancestors.length && (ancestor = ancestors[p]); ++p) {\n            if (isArray(ancestor))\n                continue;\n            if (ancestor.kind === Kind.OPERATION_DEFINITION) {\n                // If an operation is anonymous, we use the empty string as its key.\n                return getInUseByOperationName(ancestor.name && ancestor.name.value);\n            }\n            if (ancestor.kind === Kind.FRAGMENT_DEFINITION) {\n                return getInUseByFragmentName(ancestor.name.value);\n            }\n        }\n        globalThis.__DEV__ !== false && invariant.error(125);\n        return null;\n    };\n    var operationCount = 0;\n    for (var i = doc.definitions.length - 1; i >= 0; --i) {\n        if (doc.definitions[i].kind === Kind.OPERATION_DEFINITION) {\n            ++operationCount;\n        }\n    }\n    var directiveMatcher = getDirectiveMatcher(directives);\n    var shouldRemoveField = function (nodeDirectives) {\n        return isNonEmptyArray(nodeDirectives) &&\n            nodeDirectives\n                .map(directiveMatcher)\n                .some(function (config) { return config && config.remove; });\n    };\n    var originalFragmentDefsByPath = new Map();\n    // Any time the first traversal of the document below makes a change like\n    // removing a fragment (by returning null), this variable should be set to\n    // true. Once it becomes true, it should never be set to false again. If this\n    // variable remains false throughout the traversal, then we can return the\n    // original doc immediately without any modifications.\n    var firstVisitMadeChanges = false;\n    var fieldOrInlineFragmentVisitor = {\n        enter: function (node) {\n            if (shouldRemoveField(node.directives)) {\n                firstVisitMadeChanges = true;\n                return null;\n            }\n        },\n    };\n    var docWithoutDirectiveSubtrees = visit(doc, {\n        // These two AST node types share the same implementation, defined above.\n        Field: fieldOrInlineFragmentVisitor,\n        InlineFragment: fieldOrInlineFragmentVisitor,\n        VariableDefinition: {\n            enter: function () {\n                // VariableDefinition nodes do not count as variables in use, though\n                // they do contain Variable nodes that might be visited below. To avoid\n                // counting variable declarations as usages, we skip visiting the\n                // contents of this VariableDefinition node by returning false.\n                return false;\n            },\n        },\n        Variable: {\n            enter: function (node, _key, _parent, _path, ancestors) {\n                var inUse = getInUse(ancestors);\n                if (inUse) {\n                    inUse.variables.add(node.name.value);\n                }\n            },\n        },\n        FragmentSpread: {\n            enter: function (node, _key, _parent, _path, ancestors) {\n                if (shouldRemoveField(node.directives)) {\n                    firstVisitMadeChanges = true;\n                    return null;\n                }\n                var inUse = getInUse(ancestors);\n                if (inUse) {\n                    inUse.fragmentSpreads.add(node.name.value);\n                }\n                // We might like to remove this FragmentSpread by returning null here if\n                // the corresponding FragmentDefinition node is also going to be removed\n                // by the logic below, but we can't control the relative order of those\n                // events, so we have to postpone the removal of dangling FragmentSpread\n                // nodes until after the current visit of the document has finished.\n            },\n        },\n        FragmentDefinition: {\n            enter: function (node, _key, _parent, path) {\n                originalFragmentDefsByPath.set(JSON.stringify(path), node);\n            },\n            leave: function (node, _key, _parent, path) {\n                var originalNode = originalFragmentDefsByPath.get(JSON.stringify(path));\n                if (node === originalNode) {\n                    // If the FragmentNode received by this leave function is identical to\n                    // the one received by the corresponding enter function (above), then\n                    // the visitor must not have made any changes within this\n                    // FragmentDefinition node. This fragment definition may still be\n                    // removed if there are no ...spread references to it, but it won't be\n                    // removed just because it has only a __typename field.\n                    return node;\n                }\n                if (\n                // This logic applies only if the document contains one or more\n                // operations, since removing all fragments from a document containing\n                // only fragments makes the document useless.\n                operationCount > 0 &&\n                    node.selectionSet.selections.every(function (selection) {\n                        return selection.kind === Kind.FIELD &&\n                            selection.name.value === \"__typename\";\n                    })) {\n                    // This is a somewhat opinionated choice: if a FragmentDefinition ends\n                    // up having no fields other than __typename, we remove the whole\n                    // fragment definition, and later prune ...spread references to it.\n                    getInUseByFragmentName(node.name.value).removed = true;\n                    firstVisitMadeChanges = true;\n                    return null;\n                }\n            },\n        },\n        Directive: {\n            leave: function (node) {\n                // If a matching directive is found, remove the directive itself. Note\n                // that this does not remove the target (field, argument, etc) of the\n                // directive, but only the directive itself.\n                if (directiveMatcher(node)) {\n                    firstVisitMadeChanges = true;\n                    return null;\n                }\n            },\n        },\n    });\n    if (!firstVisitMadeChanges) {\n        // If our first pass did not change anything about the document, then there\n        // is no cleanup we need to do, and we can return the original doc.\n        return doc;\n    }\n    // Utility for making sure inUse.transitiveVars is recursively populated.\n    // Because this logic assumes inUse.fragmentSpreads has been completely\n    // populated and inUse.removed has been set if appropriate,\n    // populateTransitiveVars must be called after that information has been\n    // collected by the first traversal of the document.\n    var populateTransitiveVars = function (inUse) {\n        if (!inUse.transitiveVars) {\n            inUse.transitiveVars = new Set(inUse.variables);\n            if (!inUse.removed) {\n                inUse.fragmentSpreads.forEach(function (childFragmentName) {\n                    populateTransitiveVars(getInUseByFragmentName(childFragmentName)).transitiveVars.forEach(function (varName) {\n                        inUse.transitiveVars.add(varName);\n                    });\n                });\n            }\n        }\n        return inUse;\n    };\n    // Since we've been keeping track of fragment spreads used by particular\n    // operations and fragment definitions, we now need to compute the set of all\n    // spreads used (transitively) by any operations in the document.\n    var allFragmentNamesUsed = new Set();\n    docWithoutDirectiveSubtrees.definitions.forEach(function (def) {\n        if (def.kind === Kind.OPERATION_DEFINITION) {\n            populateTransitiveVars(getInUseByOperationName(def.name && def.name.value)).fragmentSpreads.forEach(function (childFragmentName) {\n                allFragmentNamesUsed.add(childFragmentName);\n            });\n        }\n        else if (def.kind === Kind.FRAGMENT_DEFINITION &&\n            // If there are no operations in the document, then all fragment\n            // definitions count as usages of their own fragment names. This heuristic\n            // prevents accidentally removing all fragment definitions from the\n            // document just because it contains no operations that use the fragments.\n            operationCount === 0 &&\n            !getInUseByFragmentName(def.name.value).removed) {\n            allFragmentNamesUsed.add(def.name.value);\n        }\n    });\n    // Now that we have added all fragment spreads used by operations to the\n    // allFragmentNamesUsed set, we can complete the set by transitively adding\n    // all fragment spreads used by those fragments, and so on.\n    allFragmentNamesUsed.forEach(function (fragmentName) {\n        // Once all the childFragmentName strings added here have been seen already,\n        // the top-level allFragmentNamesUsed.forEach loop will terminate.\n        populateTransitiveVars(getInUseByFragmentName(fragmentName)).fragmentSpreads.forEach(function (childFragmentName) {\n            allFragmentNamesUsed.add(childFragmentName);\n        });\n    });\n    var fragmentWillBeRemoved = function (fragmentName) {\n        return !!(\n        // A fragment definition will be removed if there are no spreads that refer\n        // to it, or the fragment was explicitly removed because it had no fields\n        // other than __typename.\n        (!allFragmentNamesUsed.has(fragmentName) ||\n            getInUseByFragmentName(fragmentName).removed));\n    };\n    var enterVisitor = {\n        enter: function (node) {\n            if (fragmentWillBeRemoved(node.name.value)) {\n                return null;\n            }\n        },\n    };\n    return nullIfDocIsEmpty(visit(docWithoutDirectiveSubtrees, {\n        // If the fragment is going to be removed, then leaving any dangling\n        // FragmentSpread nodes with the same name would be a mistake.\n        FragmentSpread: enterVisitor,\n        // This is where the fragment definition is actually removed.\n        FragmentDefinition: enterVisitor,\n        OperationDefinition: {\n            leave: function (node) {\n                // Upon leaving each operation in the depth-first AST traversal, prune\n                // any variables that are declared by the operation but unused within.\n                if (node.variableDefinitions) {\n                    var usedVariableNames_1 = populateTransitiveVars(\n                    // If an operation is anonymous, we use the empty string as its key.\n                    getInUseByOperationName(node.name && node.name.value)).transitiveVars;\n                    // According to the GraphQL spec, all variables declared by an\n                    // operation must either be used by that operation or used by some\n                    // fragment included transitively into that operation:\n                    // https://spec.graphql.org/draft/#sec-All-Variables-Used\n                    //\n                    // To stay on the right side of this validation rule, if/when we\n                    // remove the last $var references from an operation or its fragments,\n                    // we must also remove the corresponding $var declaration from the\n                    // enclosing operation. This pruning applies only to operations and\n                    // not fragment definitions, at the moment. Fragments may be able to\n                    // declare variables eventually, but today they can only consume them.\n                    if (usedVariableNames_1.size < node.variableDefinitions.length) {\n                        return __assign(__assign({}, node), { variableDefinitions: node.variableDefinitions.filter(function (varDef) {\n                                return usedVariableNames_1.has(varDef.variable.name.value);\n                            }) });\n                    }\n                }\n            },\n        },\n    }));\n}\nexport var addTypenameToDocument = Object.assign(function (doc) {\n    return visit(doc, {\n        SelectionSet: {\n            enter: function (node, _key, parent) {\n                // Don't add __typename to OperationDefinitions.\n                if (parent &&\n                    parent.kind ===\n                        Kind.OPERATION_DEFINITION) {\n                    return;\n                }\n                // No changes if no selections.\n                var selections = node.selections;\n                if (!selections) {\n                    return;\n                }\n                // If selections already have a __typename, or are part of an\n                // introspection query, do nothing.\n                var skip = selections.some(function (selection) {\n                    return (isField(selection) &&\n                        (selection.name.value === \"__typename\" ||\n                            selection.name.value.lastIndexOf(\"__\", 0) === 0));\n                });\n                if (skip) {\n                    return;\n                }\n                // If this SelectionSet is @export-ed as an input variable, it should\n                // not have a __typename field (see issue #4691).\n                var field = parent;\n                if (isField(field) &&\n                    field.directives &&\n                    field.directives.some(function (d) { return d.name.value === \"export\"; })) {\n                    return;\n                }\n                // Create and return a new SelectionSet with a __typename Field.\n                return __assign(__assign({}, node), { selections: __spreadArray(__spreadArray([], selections, true), [TYPENAME_FIELD], false) });\n            },\n        },\n    });\n}, {\n    added: function (field) {\n        return field === TYPENAME_FIELD;\n    },\n});\nvar connectionRemoveConfig = {\n    test: function (directive) {\n        var willRemove = directive.name.value === \"connection\";\n        if (willRemove) {\n            if (!directive.arguments ||\n                !directive.arguments.some(function (arg) { return arg.name.value === \"key\"; })) {\n                globalThis.__DEV__ !== false && invariant.warn(126);\n            }\n        }\n        return willRemove;\n    },\n};\nexport function removeConnectionDirectiveFromDocument(doc) {\n    return removeDirectivesFromDocument([connectionRemoveConfig], checkDocument(doc));\n}\nfunction hasDirectivesInSelectionSet(directives, selectionSet, nestedCheck) {\n    if (nestedCheck === void 0) { nestedCheck = true; }\n    return (!!selectionSet &&\n        selectionSet.selections &&\n        selectionSet.selections.some(function (selection) {\n            return hasDirectivesInSelection(directives, selection, nestedCheck);\n        }));\n}\nfunction hasDirectivesInSelection(directives, selection, nestedCheck) {\n    if (nestedCheck === void 0) { nestedCheck = true; }\n    if (!isField(selection)) {\n        return true;\n    }\n    if (!selection.directives) {\n        return false;\n    }\n    return (selection.directives.some(getDirectiveMatcher(directives)) ||\n        (nestedCheck &&\n            hasDirectivesInSelectionSet(directives, selection.selectionSet, nestedCheck)));\n}\nfunction getArgumentMatcher(config) {\n    return function argumentMatcher(argument) {\n        return config.some(function (aConfig) {\n            return argument.value &&\n                argument.value.kind === Kind.VARIABLE &&\n                argument.value.name &&\n                (aConfig.name === argument.value.name.value ||\n                    (aConfig.test && aConfig.test(argument)));\n        });\n    };\n}\nexport function removeArgumentsFromDocument(config, doc) {\n    var argMatcher = getArgumentMatcher(config);\n    return nullIfDocIsEmpty(visit(doc, {\n        OperationDefinition: {\n            enter: function (node) {\n                return __assign(__assign({}, node), { \n                    // Remove matching top level variables definitions.\n                    variableDefinitions: node.variableDefinitions ?\n                        node.variableDefinitions.filter(function (varDef) {\n                            return !config.some(function (arg) { return arg.name === varDef.variable.name.value; });\n                        })\n                        : [] });\n            },\n        },\n        Field: {\n            enter: function (node) {\n                // If `remove` is set to true for an argument, and an argument match\n                // is found for a field, remove the field as well.\n                var shouldRemoveField = config.some(function (argConfig) { return argConfig.remove; });\n                if (shouldRemoveField) {\n                    var argMatchCount_1 = 0;\n                    if (node.arguments) {\n                        node.arguments.forEach(function (arg) {\n                            if (argMatcher(arg)) {\n                                argMatchCount_1 += 1;\n                            }\n                        });\n                    }\n                    if (argMatchCount_1 === 1) {\n                        return null;\n                    }\n                }\n            },\n        },\n        Argument: {\n            enter: function (node) {\n                // Remove all matching arguments.\n                if (argMatcher(node)) {\n                    return null;\n                }\n            },\n        },\n    }));\n}\nexport function removeFragmentSpreadFromDocument(config, doc) {\n    function enter(node) {\n        if (config.some(function (def) { return def.name === node.name.value; })) {\n            return null;\n        }\n    }\n    return nullIfDocIsEmpty(visit(doc, {\n        FragmentSpread: { enter: enter },\n        FragmentDefinition: { enter: enter },\n    }));\n}\n// If the incoming document is a query, return it as is. Otherwise, build a\n// new document containing a query operation based on the selection set\n// of the previous main operation.\nexport function buildQueryFromSelectionSet(document) {\n    var definition = getMainDefinition(document);\n    var definitionOperation = definition.operation;\n    if (definitionOperation === \"query\") {\n        // Already a query, so return the existing document.\n        return document;\n    }\n    // Build a new query using the selection set of the main operation.\n    var modifiedDoc = visit(document, {\n        OperationDefinition: {\n            enter: function (node) {\n                return __assign(__assign({}, node), { operation: \"query\" });\n            },\n        },\n    });\n    return modifiedDoc;\n}\n// Remove fields / selection sets that include an @client directive.\nexport function removeClientSetsFromDocument(document) {\n    checkDocument(document);\n    var modifiedDoc = removeDirectivesFromDocument([\n        {\n            test: function (directive) { return directive.name.value === \"client\"; },\n            remove: true,\n        },\n    ], document);\n    return modifiedDoc;\n}\nexport function addNonReactiveToNamedFragments(document) {\n    checkDocument(document);\n    return visit(document, {\n        FragmentSpread: function (node) {\n            var _a;\n            // Do not add `@nonreactive` if the fragment is marked with `@unmask`\n            // since we want to react to changes in this fragment.\n            if ((_a = node.directives) === null || _a === void 0 ? void 0 : _a.some(function (directive) { return directive.name.value === \"unmask\"; })) {\n                return;\n            }\n            return __assign(__assign({}, node), { directives: __spreadArray(__spreadArray([], (node.directives || []), true), [\n                    {\n                        kind: Kind.DIRECTIVE,\n                        name: { kind: Kind.NAME, value: \"nonreactive\" },\n                    },\n                ], false) });\n        },\n    });\n}\n//# sourceMappingURL=transform.js.map","import { __assign, __rest as __rest_1, __spreadArray } from \"tslib\";\nimport { __rest } from \"tslib\";\nimport { mergeDeep } from \"../common/mergeDeep.js\";\n// A very basic pagination field policy that always concatenates new\n// results onto the existing array, without examining options.args.\nexport function concatPagination(keyArgs) {\n    if (keyArgs === void 0) { keyArgs = false; }\n    return {\n        keyArgs: keyArgs,\n        merge: function (existing, incoming) {\n            return existing ? __spreadArray(__spreadArray([], existing, true), incoming, true) : incoming;\n        },\n    };\n}\n// A basic field policy that uses options.args.{offset,limit} to splice\n// the incoming data into the existing array. If your arguments are called\n// something different (like args.{start,count}), feel free to copy/paste\n// this implementation and make the appropriate changes.\nexport function offsetLimitPagination(keyArgs) {\n    if (keyArgs === void 0) { keyArgs = false; }\n    return {\n        keyArgs: keyArgs,\n        merge: function (existing, incoming, _a) {\n            var args = _a.args;\n            var merged = existing ? existing.slice(0) : [];\n            if (incoming) {\n                if (args) {\n                    // Assume an offset of 0 if args.offset omitted.\n                    var _b = args.offset, offset = _b === void 0 ? 0 : _b;\n                    for (var i = 0; i < incoming.length; ++i) {\n                        merged[offset + i] = incoming[i];\n                    }\n                }\n                else {\n                    // It's unusual (probably a mistake) for a paginated field not\n                    // to receive any arguments, so you might prefer to throw an\n                    // exception here, instead of recovering by appending incoming\n                    // onto the existing array.\n                    merged.push.apply(merged, incoming);\n                }\n            }\n            return merged;\n        },\n    };\n}\n// As proof of the flexibility of field policies, this function generates\n// one that handles Relay-style pagination, without Apollo Client knowing\n// anything about connections, edges, cursors, or pageInfo objects.\nexport function relayStylePagination(keyArgs) {\n    if (keyArgs === void 0) { keyArgs = false; }\n    return {\n        keyArgs: keyArgs,\n        read: function (existing, _a) {\n            var canRead = _a.canRead, readField = _a.readField;\n            if (!existing)\n                return existing;\n            var edges = [];\n            var firstEdgeCursor = \"\";\n            var lastEdgeCursor = \"\";\n            existing.edges.forEach(function (edge) {\n                // Edges themselves could be Reference objects, so it's important\n                // to use readField to access the edge.edge.node property.\n                if (canRead(readField(\"node\", edge))) {\n                    edges.push(edge);\n                    if (edge.cursor) {\n                        firstEdgeCursor = firstEdgeCursor || edge.cursor || \"\";\n                        lastEdgeCursor = edge.cursor || lastEdgeCursor;\n                    }\n                }\n            });\n            if (edges.length > 1 && firstEdgeCursor === lastEdgeCursor) {\n                firstEdgeCursor = \"\";\n            }\n            var _b = existing.pageInfo || {}, startCursor = _b.startCursor, endCursor = _b.endCursor;\n            return __assign(__assign({}, getExtras(existing)), { edges: edges, pageInfo: __assign(__assign({}, existing.pageInfo), { \n                    // If existing.pageInfo.{start,end}Cursor are undefined or \"\", default\n                    // to firstEdgeCursor and/or lastEdgeCursor.\n                    startCursor: startCursor || firstEdgeCursor, endCursor: endCursor || lastEdgeCursor }) });\n        },\n        merge: function (existing, incoming, _a) {\n            var args = _a.args, isReference = _a.isReference, readField = _a.readField;\n            if (!existing) {\n                existing = makeEmptyData();\n            }\n            if (!incoming) {\n                return existing;\n            }\n            var incomingEdges = incoming.edges ?\n                incoming.edges.map(function (edge) {\n                    if (isReference((edge = __assign({}, edge)))) {\n                        // In case edge is a Reference, we read out its cursor field and\n                        // store it as an extra property of the Reference object.\n                        edge.cursor = readField(\"cursor\", edge);\n                    }\n                    return edge;\n                })\n                : [];\n            if (incoming.pageInfo) {\n                var pageInfo_1 = incoming.pageInfo;\n                var startCursor = pageInfo_1.startCursor, endCursor = pageInfo_1.endCursor;\n                var firstEdge = incomingEdges[0];\n                var lastEdge = incomingEdges[incomingEdges.length - 1];\n                // In case we did not request the cursor field for edges in this\n                // query, we can still infer cursors from pageInfo.\n                if (firstEdge && startCursor) {\n                    firstEdge.cursor = startCursor;\n                }\n                if (lastEdge && endCursor) {\n                    lastEdge.cursor = endCursor;\n                }\n                // Cursors can also come from edges, so we default\n                // pageInfo.{start,end}Cursor to {first,last}Edge.cursor.\n                var firstCursor = firstEdge && firstEdge.cursor;\n                if (firstCursor && !startCursor) {\n                    incoming = mergeDeep(incoming, {\n                        pageInfo: {\n                            startCursor: firstCursor,\n                        },\n                    });\n                }\n                var lastCursor = lastEdge && lastEdge.cursor;\n                if (lastCursor && !endCursor) {\n                    incoming = mergeDeep(incoming, {\n                        pageInfo: {\n                            endCursor: lastCursor,\n                        },\n                    });\n                }\n            }\n            var prefix = existing.edges;\n            var suffix = [];\n            if (args && args.after) {\n                // This comparison does not need to use readField(\"cursor\", edge),\n                // because we stored the cursor field of any Reference edges as an\n                // extra property of the Reference object.\n                var index = prefix.findIndex(function (edge) { return edge.cursor === args.after; });\n                if (index >= 0) {\n                    prefix = prefix.slice(0, index + 1);\n                    // suffix = []; // already true\n                }\n            }\n            else if (args && args.before) {\n                var index = prefix.findIndex(function (edge) { return edge.cursor === args.before; });\n                suffix = index < 0 ? prefix : prefix.slice(index);\n                prefix = [];\n            }\n            else if (incoming.edges) {\n                // If we have neither args.after nor args.before, the incoming\n                // edges cannot be spliced into the existing edges, so they must\n                // replace the existing edges. See #6592 for a motivating example.\n                prefix = [];\n            }\n            var edges = __spreadArray(__spreadArray(__spreadArray([], prefix, true), incomingEdges, true), suffix, true);\n            var pageInfo = __assign(__assign({}, incoming.pageInfo), existing.pageInfo);\n            if (incoming.pageInfo) {\n                var _b = incoming.pageInfo, hasPreviousPage = _b.hasPreviousPage, hasNextPage = _b.hasNextPage, startCursor = _b.startCursor, endCursor = _b.endCursor, extras = __rest_1(_b, [\"hasPreviousPage\", \"hasNextPage\", \"startCursor\", \"endCursor\"]);\n                // If incoming.pageInfo had any extra non-standard properties,\n                // assume they should take precedence over any existing properties\n                // of the same name, regardless of where this page falls with\n                // respect to the existing data.\n                Object.assign(pageInfo, extras);\n                // Keep existing.pageInfo.has{Previous,Next}Page unless the\n                // placement of the incoming edges means incoming.hasPreviousPage\n                // or incoming.hasNextPage should become the new values for those\n                // properties in existing.pageInfo. Note that these updates are\n                // only permitted when the beginning or end of the incoming page\n                // coincides with the beginning or end of the existing data, as\n                // determined using prefix.length and suffix.length.\n                if (!prefix.length) {\n                    if (void 0 !== hasPreviousPage)\n                        pageInfo.hasPreviousPage = hasPreviousPage;\n                    if (void 0 !== startCursor)\n                        pageInfo.startCursor = startCursor;\n                }\n                if (!suffix.length) {\n                    if (void 0 !== hasNextPage)\n                        pageInfo.hasNextPage = hasNextPage;\n                    if (void 0 !== endCursor)\n                        pageInfo.endCursor = endCursor;\n                }\n            }\n            return __assign(__assign(__assign({}, getExtras(existing)), getExtras(incoming)), { edges: edges, pageInfo: pageInfo });\n        },\n    };\n}\n// Returns any unrecognized properties of the given object.\nvar getExtras = function (obj) { return __rest(obj, notExtras); };\nvar notExtras = [\"edges\", \"pageInfo\"];\nfunction makeEmptyData() {\n    return {\n        edges: [],\n        pageInfo: {\n            hasPreviousPage: false,\n            hasNextPage: true,\n            startCursor: \"\",\n            endCursor: \"\",\n        },\n    };\n}\n//# sourceMappingURL=pagination.js.map","export var version = \"3.14.0\";\n//# sourceMappingURL=version.js.map","function defaultDispose() { }\nexport class StrongCache {\n    constructor(max = Infinity, dispose = defaultDispose) {\n        this.max = max;\n        this.dispose = dispose;\n        this.map = new Map();\n        this.newest = null;\n        this.oldest = null;\n    }\n    has(key) {\n        return this.map.has(key);\n    }\n    get(key) {\n        const node = this.getNode(key);\n        return node && node.value;\n    }\n    get size() {\n        return this.map.size;\n    }\n    getNode(key) {\n        const node = this.map.get(key);\n        if (node && node !== this.newest) {\n            const { older, newer } = node;\n            if (newer) {\n                newer.older = older;\n            }\n            if (older) {\n                older.newer = newer;\n            }\n            node.older = this.newest;\n            node.older.newer = node;\n            node.newer = null;\n            this.newest = node;\n            if (node === this.oldest) {\n                this.oldest = newer;\n            }\n        }\n        return node;\n    }\n    set(key, value) {\n        let node = this.getNode(key);\n        if (node) {\n            return node.value = value;\n        }\n        node = {\n            key,\n            value,\n            newer: null,\n            older: this.newest\n        };\n        if (this.newest) {\n            this.newest.newer = node;\n        }\n        this.newest = node;\n        this.oldest = this.oldest || node;\n        this.map.set(key, node);\n        return node.value;\n    }\n    clean() {\n        while (this.oldest && this.map.size > this.max) {\n            this.delete(this.oldest.key);\n        }\n    }\n    delete(key) {\n        const node = this.map.get(key);\n        if (node) {\n            if (node === this.newest) {\n                this.newest = node.older;\n            }\n            if (node === this.oldest) {\n                this.oldest = node.newer;\n            }\n            if (node.newer) {\n                node.newer.older = node.older;\n            }\n            if (node.older) {\n                node.older.newer = node.newer;\n            }\n            this.map.delete(key);\n            this.dispose(node.value, key);\n            return true;\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=strong.js.map","function noop() { }\nconst defaultDispose = noop;\nconst _WeakRef = typeof WeakRef !== \"undefined\"\n    ? WeakRef\n    : function (value) {\n        return { deref: () => value };\n    };\nconst _WeakMap = typeof WeakMap !== \"undefined\" ? WeakMap : Map;\nconst _FinalizationRegistry = typeof FinalizationRegistry !== \"undefined\"\n    ? FinalizationRegistry\n    : function () {\n        return {\n            register: noop,\n            unregister: noop,\n        };\n    };\nconst finalizationBatchSize = 10024;\nexport class WeakCache {\n    constructor(max = Infinity, dispose = defaultDispose) {\n        this.max = max;\n        this.dispose = dispose;\n        this.map = new _WeakMap();\n        this.newest = null;\n        this.oldest = null;\n        this.unfinalizedNodes = new Set();\n        this.finalizationScheduled = false;\n        this.size = 0;\n        this.finalize = () => {\n            const iterator = this.unfinalizedNodes.values();\n            for (let i = 0; i < finalizationBatchSize; i++) {\n                const node = iterator.next().value;\n                if (!node)\n                    break;\n                this.unfinalizedNodes.delete(node);\n                const key = node.key;\n                delete node.key;\n                node.keyRef = new _WeakRef(key);\n                this.registry.register(key, node, node);\n            }\n            if (this.unfinalizedNodes.size > 0) {\n                queueMicrotask(this.finalize);\n            }\n            else {\n                this.finalizationScheduled = false;\n            }\n        };\n        this.registry = new _FinalizationRegistry(this.deleteNode.bind(this));\n    }\n    has(key) {\n        return this.map.has(key);\n    }\n    get(key) {\n        const node = this.getNode(key);\n        return node && node.value;\n    }\n    getNode(key) {\n        const node = this.map.get(key);\n        if (node && node !== this.newest) {\n            const { older, newer } = node;\n            if (newer) {\n                newer.older = older;\n            }\n            if (older) {\n                older.newer = newer;\n            }\n            node.older = this.newest;\n            node.older.newer = node;\n            node.newer = null;\n            this.newest = node;\n            if (node === this.oldest) {\n                this.oldest = newer;\n            }\n        }\n        return node;\n    }\n    set(key, value) {\n        let node = this.getNode(key);\n        if (node) {\n            return (node.value = value);\n        }\n        node = {\n            key,\n            value,\n            newer: null,\n            older: this.newest,\n        };\n        if (this.newest) {\n            this.newest.newer = node;\n        }\n        this.newest = node;\n        this.oldest = this.oldest || node;\n        this.scheduleFinalization(node);\n        this.map.set(key, node);\n        this.size++;\n        return node.value;\n    }\n    clean() {\n        while (this.oldest && this.size > this.max) {\n            this.deleteNode(this.oldest);\n        }\n    }\n    deleteNode(node) {\n        if (node === this.newest) {\n            this.newest = node.older;\n        }\n        if (node === this.oldest) {\n            this.oldest = node.newer;\n        }\n        if (node.newer) {\n            node.newer.older = node.older;\n        }\n        if (node.older) {\n            node.older.newer = node.newer;\n        }\n        this.size--;\n        const key = node.key || (node.keyRef && node.keyRef.deref());\n        this.dispose(node.value, key);\n        if (!node.keyRef) {\n            this.unfinalizedNodes.delete(node);\n        }\n        else {\n            this.registry.unregister(node);\n        }\n        if (key)\n            this.map.delete(key);\n    }\n    delete(key) {\n        const node = this.map.get(key);\n        if (node) {\n            this.deleteNode(node);\n            return true;\n        }\n        return false;\n    }\n    scheduleFinalization(node) {\n        this.unfinalizedNodes.add(node);\n        if (!this.finalizationScheduled) {\n            this.finalizationScheduled = true;\n            queueMicrotask(this.finalize);\n        }\n    }\n}\n//# sourceMappingURL=weak.js.map","import { Slot } from \"./slot.js\";\nexport { Slot };\nexport const { bind, noContext } = Slot;\n// Like global.setTimeout, except the callback runs with captured context.\nexport { setTimeoutWithContext as setTimeout };\nfunction setTimeoutWithContext(callback, delay) {\n    return setTimeout(bind(callback), delay);\n}\n// Turn any generator function into an async function (using yield instead\n// of await), with context automatically preserved across yields.\nexport function asyncFromGen(genFn) {\n    return function () {\n        const gen = genFn.apply(this, arguments);\n        const boundNext = bind(gen.next);\n        const boundThrow = bind(gen.throw);\n        return new Promise((resolve, reject) => {\n            function invoke(method, argument) {\n                try {\n                    var result = method.call(gen, argument);\n                }\n                catch (error) {\n                    return reject(error);\n                }\n                const next = result.done ? resolve : invokeNext;\n                if (isPromiseLike(result.value)) {\n                    result.value.then(next, result.done ? reject : invokeThrow);\n                }\n                else {\n                    next(result.value);\n                }\n            }\n            const invokeNext = (value) => invoke(boundNext, value);\n            const invokeThrow = (error) => invoke(boundThrow, error);\n            invokeNext();\n        });\n    };\n}\nfunction isPromiseLike(value) {\n    return value && typeof value.then === \"function\";\n}\n// If you use the fibers npm package to implement coroutines in Node.js,\n// you should call this function at least once to ensure context management\n// remains coherent across any yields.\nconst wrappedFibers = [];\nexport function wrapYieldingFiberMethods(Fiber) {\n    // There can be only one implementation of Fiber per process, so this array\n    // should never grow longer than one element.\n    if (wrappedFibers.indexOf(Fiber) < 0) {\n        const wrap = (obj, method) => {\n            const fn = obj[method];\n            obj[method] = function () {\n                return noContext(fn, arguments, this);\n            };\n        };\n        // These methods can yield, according to\n        // https://github.com/laverdet/node-fibers/blob/ddebed9b8ae3883e57f822e2108e6943e5c8d2a8/fibers.js#L97-L100\n        wrap(Fiber, \"yield\");\n        wrap(Fiber.prototype, \"run\");\n        wrap(Fiber.prototype, \"throwInto\");\n        wrappedFibers.push(Fiber);\n    }\n    return Fiber;\n}\n//# sourceMappingURL=index.js.map","// This currentContext variable will only be used if the makeSlotClass\n// function is called, which happens only if this is the first copy of the\n// @wry/context package to be imported.\nlet currentContext = null;\n// This unique internal object is used to denote the absence of a value\n// for a given Slot, and is never exposed to outside code.\nconst MISSING_VALUE = {};\nlet idCounter = 1;\n// Although we can't do anything about the cost of duplicated code from\n// accidentally bundling multiple copies of the @wry/context package, we can\n// avoid creating the Slot class more than once using makeSlotClass.\nconst makeSlotClass = () => class Slot {\n    constructor() {\n        // If you have a Slot object, you can find out its slot.id, but you cannot\n        // guess the slot.id of a Slot you don't have access to, thanks to the\n        // randomized suffix.\n        this.id = [\n            \"slot\",\n            idCounter++,\n            Date.now(),\n            Math.random().toString(36).slice(2),\n        ].join(\":\");\n    }\n    hasValue() {\n        for (let context = currentContext; context; context = context.parent) {\n            // We use the Slot object iself as a key to its value, which means the\n            // value cannot be obtained without a reference to the Slot object.\n            if (this.id in context.slots) {\n                const value = context.slots[this.id];\n                if (value === MISSING_VALUE)\n                    break;\n                if (context !== currentContext) {\n                    // Cache the value in currentContext.slots so the next lookup will\n                    // be faster. This caching is safe because the tree of contexts and\n                    // the values of the slots are logically immutable.\n                    currentContext.slots[this.id] = value;\n                }\n                return true;\n            }\n        }\n        if (currentContext) {\n            // If a value was not found for this Slot, it's never going to be found\n            // no matter how many times we look it up, so we might as well cache\n            // the absence of the value, too.\n            currentContext.slots[this.id] = MISSING_VALUE;\n        }\n        return false;\n    }\n    getValue() {\n        if (this.hasValue()) {\n            return currentContext.slots[this.id];\n        }\n    }\n    withValue(value, callback, \n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args, thisArg) {\n        const slots = {\n            __proto__: null,\n            [this.id]: value,\n        };\n        const parent = currentContext;\n        currentContext = { parent, slots };\n        try {\n            // Function.prototype.apply allows the arguments array argument to be\n            // omitted or undefined, so args! is fine here.\n            return callback.apply(thisArg, args);\n        }\n        finally {\n            currentContext = parent;\n        }\n    }\n    // Capture the current context and wrap a callback function so that it\n    // reestablishes the captured context when called.\n    static bind(callback) {\n        const context = currentContext;\n        return function () {\n            const saved = currentContext;\n            try {\n                currentContext = context;\n                return callback.apply(this, arguments);\n            }\n            finally {\n                currentContext = saved;\n            }\n        };\n    }\n    // Immediately run a callback function without any captured context.\n    static noContext(callback, \n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args, thisArg) {\n        if (currentContext) {\n            const saved = currentContext;\n            try {\n                currentContext = null;\n                // Function.prototype.apply allows the arguments array argument to be\n                // omitted or undefined, so args! is fine here.\n                return callback.apply(thisArg, args);\n            }\n            finally {\n                currentContext = saved;\n            }\n        }\n        else {\n            return callback.apply(thisArg, args);\n        }\n    }\n};\nfunction maybe(fn) {\n    try {\n        return fn();\n    }\n    catch (ignored) { }\n}\n// We store a single global implementation of the Slot class as a permanent\n// non-enumerable property of the globalThis object. This obfuscation does\n// nothing to prevent access to the Slot class, but at least it ensures the\n// implementation (i.e. currentContext) cannot be tampered with, and all copies\n// of the @wry/context package (hopefully just one) will share the same Slot\n// implementation. Since the first copy of the @wry/context package to be\n// imported wins, this technique imposes a steep cost for any future breaking\n// changes to the Slot class.\nconst globalKey = \"@wry/context:Slot\";\nconst host = \n// Prefer globalThis when available.\n// https://github.com/benjamn/wryware/issues/347\nmaybe(() => globalThis) ||\n    // Fall back to global, which works in Node.js and may be converted by some\n    // bundlers to the appropriate identifier (window, self, ...) depending on the\n    // bundling target. https://github.com/endojs/endo/issues/576#issuecomment-1178515224\n    maybe(() => global) ||\n    // Otherwise, use a dummy host that's local to this module. We used to fall\n    // back to using the Array constructor as a namespace, but that was flagged in\n    // https://github.com/benjamn/wryware/issues/347, and can be avoided.\n    Object.create(null);\n// Whichever globalHost we're using, make TypeScript happy about the additional\n// globalKey property.\nconst globalHost = host;\nexport const Slot = globalHost[globalKey] ||\n    // Earlier versions of this package stored the globalKey property on the Array\n    // constructor, so we check there as well, to prevent Slot class duplication.\n    Array[globalKey] ||\n    (function (Slot) {\n        try {\n            Object.defineProperty(globalHost, globalKey, {\n                value: Slot,\n                enumerable: false,\n                writable: false,\n                // When it was possible for globalHost to be the Array constructor (a\n                // legacy Slot dedup strategy), it was important for the property to be\n                // configurable:true so it could be deleted. That does not seem to be as\n                // important when globalHost is the global object, but I don't want to\n                // cause similar problems again, and configurable:true seems safest.\n                // https://github.com/endojs/endo/issues/576#issuecomment-1178274008\n                configurable: true\n            });\n        }\n        finally {\n            return Slot;\n        }\n    })(makeSlotClass());\n//# sourceMappingURL=slot.js.map","const { toString, hasOwnProperty } = Object.prototype;\nconst fnToStr = Function.prototype.toString;\nconst previousComparisons = new Map();\n/**\n * Performs a deep equality check on two JavaScript values, tolerating cycles.\n */\nexport function equal(a, b) {\n    try {\n        return check(a, b);\n    }\n    finally {\n        previousComparisons.clear();\n    }\n}\n// Allow default imports as well.\nexport default equal;\nfunction check(a, b) {\n    // If the two values are strictly equal, our job is easy.\n    if (a === b) {\n        return true;\n    }\n    // Object.prototype.toString returns a representation of the runtime type of\n    // the given value that is considerably more precise than typeof.\n    const aTag = toString.call(a);\n    const bTag = toString.call(b);\n    // If the runtime types of a and b are different, they could maybe be equal\n    // under some interpretation of equality, but for simplicity and performance\n    // we just return false instead.\n    if (aTag !== bTag) {\n        return false;\n    }\n    switch (aTag) {\n        case '[object Array]':\n            // Arrays are a lot like other objects, but we can cheaply compare their\n            // lengths as a short-cut before comparing their elements.\n            if (a.length !== b.length)\n                return false;\n        // Fall through to object case...\n        case '[object Object]': {\n            if (previouslyCompared(a, b))\n                return true;\n            const aKeys = definedKeys(a);\n            const bKeys = definedKeys(b);\n            // If `a` and `b` have a different number of enumerable keys, they\n            // must be different.\n            const keyCount = aKeys.length;\n            if (keyCount !== bKeys.length)\n                return false;\n            // Now make sure they have the same keys.\n            for (let k = 0; k < keyCount; ++k) {\n                if (!hasOwnProperty.call(b, aKeys[k])) {\n                    return false;\n                }\n            }\n            // Finally, check deep equality of all child properties.\n            for (let k = 0; k < keyCount; ++k) {\n                const key = aKeys[k];\n                if (!check(a[key], b[key])) {\n                    return false;\n                }\n            }\n            return true;\n        }\n        case '[object Error]':\n            return a.name === b.name && a.message === b.message;\n        case '[object Number]':\n            // Handle NaN, which is !== itself.\n            if (a !== a)\n                return b !== b;\n        // Fall through to shared +a === +b case...\n        case '[object Boolean]':\n        case '[object Date]':\n            return +a === +b;\n        case '[object RegExp]':\n        case '[object String]':\n            return a == `${b}`;\n        case '[object Map]':\n        case '[object Set]': {\n            if (a.size !== b.size)\n                return false;\n            if (previouslyCompared(a, b))\n                return true;\n            const aIterator = a.entries();\n            const isMap = aTag === '[object Map]';\n            while (true) {\n                const info = aIterator.next();\n                if (info.done)\n                    break;\n                // If a instanceof Set, aValue === aKey.\n                const [aKey, aValue] = info.value;\n                // So this works the same way for both Set and Map.\n                if (!b.has(aKey)) {\n                    return false;\n                }\n                // However, we care about deep equality of values only when dealing\n                // with Map structures.\n                if (isMap && !check(aValue, b.get(aKey))) {\n                    return false;\n                }\n            }\n            return true;\n        }\n        case '[object Uint16Array]':\n        case '[object Uint8Array]': // Buffer, in Node.js.\n        case '[object Uint32Array]':\n        case '[object Int32Array]':\n        case '[object Int8Array]':\n        case '[object Int16Array]':\n        case '[object ArrayBuffer]':\n            // DataView doesn't need these conversions, but the equality check is\n            // otherwise the same.\n            a = new Uint8Array(a);\n            b = new Uint8Array(b);\n        // Fall through...\n        case '[object DataView]': {\n            let len = a.byteLength;\n            if (len === b.byteLength) {\n                while (len-- && a[len] === b[len]) {\n                    // Keep looping as long as the bytes are equal.\n                }\n            }\n            return len === -1;\n        }\n        case '[object AsyncFunction]':\n        case '[object GeneratorFunction]':\n        case '[object AsyncGeneratorFunction]':\n        case '[object Function]': {\n            const aCode = fnToStr.call(a);\n            if (aCode !== fnToStr.call(b)) {\n                return false;\n            }\n            // We consider non-native functions equal if they have the same code\n            // (native functions require === because their code is censored).\n            // Note that this behavior is not entirely sound, since !== function\n            // objects with the same code can behave differently depending on\n            // their closure scope. However, any function can behave differently\n            // depending on the values of its input arguments (including this)\n            // and its calling context (including its closure scope), even\n            // though the function object is === to itself; and it is entirely\n            // possible for functions that are not === to behave exactly the\n            // same under all conceivable circumstances. Because none of these\n            // factors are statically decidable in JavaScript, JS function\n            // equality is not well-defined. This ambiguity allows us to\n            // consider the best possible heuristic among various imperfect\n            // options, and equating non-native functions that have the same\n            // code has enormous practical benefits, such as when comparing\n            // functions that are repeatedly passed as fresh function\n            // expressions within objects that are otherwise deeply equal. Since\n            // any function created from the same syntactic expression (in the\n            // same code location) will always stringify to the same code\n            // according to fnToStr.call, we can reasonably expect these\n            // repeatedly passed function expressions to have the same code, and\n            // thus behave \"the same\" (with all the caveats mentioned above),\n            // even though the runtime function objects are !== to one another.\n            return !endsWith(aCode, nativeCodeSuffix);\n        }\n    }\n    // Otherwise the values are not equal.\n    return false;\n}\nfunction definedKeys(obj) {\n    // Remember that the second argument to Array.prototype.filter will be\n    // used as `this` within the callback function.\n    return Object.keys(obj).filter(isDefinedKey, obj);\n}\nfunction isDefinedKey(key) {\n    return this[key] !== void 0;\n}\nconst nativeCodeSuffix = \"{ [native code] }\";\nfunction endsWith(full, suffix) {\n    const fromIndex = full.length - suffix.length;\n    return fromIndex >= 0 &&\n        full.indexOf(suffix, fromIndex) === fromIndex;\n}\nfunction previouslyCompared(a, b) {\n    // Though cyclic references can make an object graph appear infinite from the\n    // perspective of a depth-first traversal, the graph still contains a finite\n    // number of distinct object references. We use the previousComparisons cache\n    // to avoid comparing the same pair of object references more than once, which\n    // guarantees termination (even if we end up comparing every object in one\n    // graph to every object in the other graph, which is extremely unlikely),\n    // while still allowing weird isomorphic structures (like rings with different\n    // lengths) a chance to pass the equality test.\n    let bSet = previousComparisons.get(a);\n    if (bSet) {\n        // Return true here because we can be sure false will be returned somewhere\n        // else if the objects are not equivalent.\n        if (bSet.has(b))\n            return true;\n    }\n    else {\n        previousComparisons.set(a, bSet = new Set);\n    }\n    bSet.add(b);\n    return false;\n}\n//# sourceMappingURL=index.js.map","// A [trie](https://en.wikipedia.org/wiki/Trie) data structure that holds\n// object keys weakly, yet can also hold non-object keys, unlike the\n// native `WeakMap`.\n// If no makeData function is supplied, the looked-up data will be an empty,\n// null-prototype Object.\nconst defaultMakeData = () => Object.create(null);\n// Useful for processing arguments objects as well as arrays.\nconst { forEach, slice } = Array.prototype;\nconst { hasOwnProperty } = Object.prototype;\nexport class Trie {\n    constructor(weakness = true, makeData = defaultMakeData) {\n        this.weakness = weakness;\n        this.makeData = makeData;\n    }\n    lookup() {\n        return this.lookupArray(arguments);\n    }\n    lookupArray(array) {\n        let node = this;\n        forEach.call(array, key => node = node.getChildTrie(key));\n        return hasOwnProperty.call(node, \"data\")\n            ? node.data\n            : node.data = this.makeData(slice.call(array));\n    }\n    peek() {\n        return this.peekArray(arguments);\n    }\n    peekArray(array) {\n        let node = this;\n        for (let i = 0, len = array.length; node && i < len; ++i) {\n            const map = node.mapFor(array[i], false);\n            node = map && map.get(array[i]);\n        }\n        return node && node.data;\n    }\n    remove() {\n        return this.removeArray(arguments);\n    }\n    removeArray(array) {\n        let data;\n        if (array.length) {\n            const head = array[0];\n            const map = this.mapFor(head, false);\n            const child = map && map.get(head);\n            if (child) {\n                data = child.removeArray(slice.call(array, 1));\n                if (!child.data && !child.weak && !(child.strong && child.strong.size)) {\n                    map.delete(head);\n                }\n            }\n        }\n        else {\n            data = this.data;\n            delete this.data;\n        }\n        return data;\n    }\n    getChildTrie(key) {\n        const map = this.mapFor(key, true);\n        let child = map.get(key);\n        if (!child)\n            map.set(key, child = new Trie(this.weakness, this.makeData));\n        return child;\n    }\n    mapFor(key, create) {\n        return this.weakness && isObjRef(key)\n            ? this.weak || (create ? this.weak = new WeakMap : void 0)\n            : this.strong || (create ? this.strong = new Map : void 0);\n    }\n}\nfunction isObjRef(value) {\n    switch (typeof value) {\n        case \"object\":\n            if (value === null)\n                break;\n        // Fall through to return true...\n        case \"function\":\n            return true;\n    }\n    return false;\n}\n//# sourceMappingURL=index.js.map","import { isObjectLike } from '../jsutils/isObjectLike.mjs';\nimport { getLocation } from '../language/location.mjs';\nimport {\n  printLocation,\n  printSourceLocation,\n} from '../language/printLocation.mjs';\n\nfunction toNormalizedOptions(args) {\n  const firstArg = args[0];\n\n  if (firstArg == null || 'kind' in firstArg || 'length' in firstArg) {\n    return {\n      nodes: firstArg,\n      source: args[1],\n      positions: args[2],\n      path: args[3],\n      originalError: args[4],\n      extensions: args[5],\n    };\n  }\n\n  return firstArg;\n}\n/**\n * A GraphQLError describes an Error found during the parse, validate, or\n * execute phases of performing a GraphQL operation. In addition to a message\n * and stack trace, it also includes information about the locations in a\n * GraphQL document and/or execution result that correspond to the Error.\n */\n\nexport class GraphQLError extends Error {\n  /**\n   * An array of `{ line, column }` locations within the source GraphQL document\n   * which correspond to this error.\n   *\n   * Errors during validation often contain multiple locations, for example to\n   * point out two things with the same name. Errors during execution include a\n   * single location, the field which produced the error.\n   *\n   * Enumerable, and appears in the result of JSON.stringify().\n   */\n\n  /**\n   * An array describing the JSON-path into the execution response which\n   * corresponds to this error. Only included for errors during execution.\n   *\n   * Enumerable, and appears in the result of JSON.stringify().\n   */\n\n  /**\n   * An array of GraphQL AST Nodes corresponding to this error.\n   */\n\n  /**\n   * The source GraphQL document for the first location of this error.\n   *\n   * Note that if this Error represents more than one node, the source may not\n   * represent nodes after the first node.\n   */\n\n  /**\n   * An array of character offsets within the source GraphQL document\n   * which correspond to this error.\n   */\n\n  /**\n   * The original error thrown from a field resolver during execution.\n   */\n\n  /**\n   * Extension fields to add to the formatted error.\n   */\n\n  /**\n   * @deprecated Please use the `GraphQLErrorOptions` constructor overload instead.\n   */\n  constructor(message, ...rawArgs) {\n    var _this$nodes, _nodeLocations$, _ref;\n\n    const { nodes, source, positions, path, originalError, extensions } =\n      toNormalizedOptions(rawArgs);\n    super(message);\n    this.name = 'GraphQLError';\n    this.path = path !== null && path !== void 0 ? path : undefined;\n    this.originalError =\n      originalError !== null && originalError !== void 0\n        ? originalError\n        : undefined; // Compute list of blame nodes.\n\n    this.nodes = undefinedIfEmpty(\n      Array.isArray(nodes) ? nodes : nodes ? [nodes] : undefined,\n    );\n    const nodeLocations = undefinedIfEmpty(\n      (_this$nodes = this.nodes) === null || _this$nodes === void 0\n        ? void 0\n        : _this$nodes.map((node) => node.loc).filter((loc) => loc != null),\n    ); // Compute locations in the source for the given nodes/positions.\n\n    this.source =\n      source !== null && source !== void 0\n        ? source\n        : nodeLocations === null || nodeLocations === void 0\n        ? void 0\n        : (_nodeLocations$ = nodeLocations[0]) === null ||\n          _nodeLocations$ === void 0\n        ? void 0\n        : _nodeLocations$.source;\n    this.positions =\n      positions !== null && positions !== void 0\n        ? positions\n        : nodeLocations === null || nodeLocations === void 0\n        ? void 0\n        : nodeLocations.map((loc) => loc.start);\n    this.locations =\n      positions && source\n        ? positions.map((pos) => getLocation(source, pos))\n        : nodeLocations === null || nodeLocations === void 0\n        ? void 0\n        : nodeLocations.map((loc) => getLocation(loc.source, loc.start));\n    const originalExtensions = isObjectLike(\n      originalError === null || originalError === void 0\n        ? void 0\n        : originalError.extensions,\n    )\n      ? originalError === null || originalError === void 0\n        ? void 0\n        : originalError.extensions\n      : undefined;\n    this.extensions =\n      (_ref =\n        extensions !== null && extensions !== void 0\n          ? extensions\n          : originalExtensions) !== null && _ref !== void 0\n        ? _ref\n        : Object.create(null); // Only properties prescribed by the spec should be enumerable.\n    // Keep the rest as non-enumerable.\n\n    Object.defineProperties(this, {\n      message: {\n        writable: true,\n        enumerable: true,\n      },\n      name: {\n        enumerable: false,\n      },\n      nodes: {\n        enumerable: false,\n      },\n      source: {\n        enumerable: false,\n      },\n      positions: {\n        enumerable: false,\n      },\n      originalError: {\n        enumerable: false,\n      },\n    }); // Include (non-enumerable) stack trace.\n\n    /* c8 ignore start */\n    // FIXME: https://github.com/graphql/graphql-js/issues/2317\n\n    if (\n      originalError !== null &&\n      originalError !== void 0 &&\n      originalError.stack\n    ) {\n      Object.defineProperty(this, 'stack', {\n        value: originalError.stack,\n        writable: true,\n        configurable: true,\n      });\n    } else if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, GraphQLError);\n    } else {\n      Object.defineProperty(this, 'stack', {\n        value: Error().stack,\n        writable: true,\n        configurable: true,\n      });\n    }\n    /* c8 ignore stop */\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'GraphQLError';\n  }\n\n  toString() {\n    let output = this.message;\n\n    if (this.nodes) {\n      for (const node of this.nodes) {\n        if (node.loc) {\n          output += '\\n\\n' + printLocation(node.loc);\n        }\n      }\n    } else if (this.source && this.locations) {\n      for (const location of this.locations) {\n        output += '\\n\\n' + printSourceLocation(this.source, location);\n      }\n    }\n\n    return output;\n  }\n\n  toJSON() {\n    const formattedError = {\n      message: this.message,\n    };\n\n    if (this.locations != null) {\n      formattedError.locations = this.locations;\n    }\n\n    if (this.path != null) {\n      formattedError.path = this.path;\n    }\n\n    if (this.extensions != null && Object.keys(this.extensions).length > 0) {\n      formattedError.extensions = this.extensions;\n    }\n\n    return formattedError;\n  }\n}\n\nfunction undefinedIfEmpty(array) {\n  return array === undefined || array.length === 0 ? undefined : array;\n}\n/**\n * See: https://spec.graphql.org/draft/#sec-Errors\n */\n\n/**\n * Prints a GraphQLError to a string, representing useful location information\n * about the error's position in the source.\n *\n * @deprecated Please use `error.toString` instead. Will be removed in v17\n */\nexport function printError(error) {\n  return error.toString();\n}\n/**\n * Given a GraphQLError, format it according to the rules described by the\n * Response Format, Errors section of the GraphQL Specification.\n *\n * @deprecated Please use `error.toJSON` instead. Will be removed in v17\n */\n\nexport function formatError(error) {\n  return error.toJSON();\n}\n","import { GraphQLError } from './GraphQLError.mjs';\n/**\n * Produces a GraphQLError representing a syntax error, containing useful\n * descriptive information about the syntax error's position in the source.\n */\n\nexport function syntaxError(source, position, description) {\n  return new GraphQLError(`Syntax Error: ${description}`, {\n    source,\n    positions: [position],\n  });\n}\n","export function devAssert(condition, message) {\n  const booleanCondition = Boolean(condition);\n\n  if (!booleanCondition) {\n    throw new Error(message);\n  }\n}\n","const MAX_ARRAY_LENGTH = 10;\nconst MAX_RECURSIVE_DEPTH = 2;\n/**\n * Used to print values in error messages.\n */\n\nexport function inspect(value) {\n  return formatValue(value, []);\n}\n\nfunction formatValue(value, seenValues) {\n  switch (typeof value) {\n    case 'string':\n      return JSON.stringify(value);\n\n    case 'function':\n      return value.name ? `[function ${value.name}]` : '[function]';\n\n    case 'object':\n      return formatObjectValue(value, seenValues);\n\n    default:\n      return String(value);\n  }\n}\n\nfunction formatObjectValue(value, previouslySeenValues) {\n  if (value === null) {\n    return 'null';\n  }\n\n  if (previouslySeenValues.includes(value)) {\n    return '[Circular]';\n  }\n\n  const seenValues = [...previouslySeenValues, value];\n\n  if (isJSONable(value)) {\n    const jsonValue = value.toJSON(); // check for infinite recursion\n\n    if (jsonValue !== value) {\n      return typeof jsonValue === 'string'\n        ? jsonValue\n        : formatValue(jsonValue, seenValues);\n    }\n  } else if (Array.isArray(value)) {\n    return formatArray(value, seenValues);\n  }\n\n  return formatObject(value, seenValues);\n}\n\nfunction isJSONable(value) {\n  return typeof value.toJSON === 'function';\n}\n\nfunction formatObject(object, seenValues) {\n  const entries = Object.entries(object);\n\n  if (entries.length === 0) {\n    return '{}';\n  }\n\n  if (seenValues.length > MAX_RECURSIVE_DEPTH) {\n    return '[' + getObjectTag(object) + ']';\n  }\n\n  const properties = entries.map(\n    ([key, value]) => key + ': ' + formatValue(value, seenValues),\n  );\n  return '{ ' + properties.join(', ') + ' }';\n}\n\nfunction formatArray(array, seenValues) {\n  if (array.length === 0) {\n    return '[]';\n  }\n\n  if (seenValues.length > MAX_RECURSIVE_DEPTH) {\n    return '[Array]';\n  }\n\n  const len = Math.min(MAX_ARRAY_LENGTH, array.length);\n  const remaining = array.length - len;\n  const items = [];\n\n  for (let i = 0; i < len; ++i) {\n    items.push(formatValue(array[i], seenValues));\n  }\n\n  if (remaining === 1) {\n    items.push('... 1 more item');\n  } else if (remaining > 1) {\n    items.push(`... ${remaining} more items`);\n  }\n\n  return '[' + items.join(', ') + ']';\n}\n\nfunction getObjectTag(object) {\n  const tag = Object.prototype.toString\n    .call(object)\n    .replace(/^\\[object /, '')\n    .replace(/]$/, '');\n\n  if (tag === 'Object' && typeof object.constructor === 'function') {\n    const name = object.constructor.name;\n\n    if (typeof name === 'string' && name !== '') {\n      return name;\n    }\n  }\n\n  return tag;\n}\n","import { inspect } from './inspect.mjs';\n/* c8 ignore next 3 */\n\nconst isProduction =\n  globalThis.process && // eslint-disable-next-line no-undef\n  process.env.NODE_ENV === 'production';\n/**\n * A replacement for instanceof which includes an error warning when multi-realm\n * constructors are detected.\n * See: https://expressjs.com/en/advanced/best-practice-performance.html#set-node_env-to-production\n * See: https://webpack.js.org/guides/production/\n */\n\nexport const instanceOf =\n  /* c8 ignore next 6 */\n  // FIXME: https://github.com/graphql/graphql-js/issues/2317\n  isProduction\n    ? function instanceOf(value, constructor) {\n        return value instanceof constructor;\n      }\n    : function instanceOf(value, constructor) {\n        if (value instanceof constructor) {\n          return true;\n        }\n\n        if (typeof value === 'object' && value !== null) {\n          var _value$constructor;\n\n          // Prefer Symbol.toStringTag since it is immune to minification.\n          const className = constructor.prototype[Symbol.toStringTag];\n          const valueClassName = // We still need to support constructor's name to detect conflicts with older versions of this library.\n            Symbol.toStringTag in value // @ts-expect-error TS bug see, https://github.com/microsoft/TypeScript/issues/38009\n              ? value[Symbol.toStringTag]\n              : (_value$constructor = value.constructor) === null ||\n                _value$constructor === void 0\n              ? void 0\n              : _value$constructor.name;\n\n          if (className === valueClassName) {\n            const stringifiedValue = inspect(value);\n            throw new Error(`Cannot use ${className} \"${stringifiedValue}\" from another module or realm.\n\nEnsure that there is only one instance of \"graphql\" in the node_modules\ndirectory. If different versions of \"graphql\" are the dependencies of other\nrelied on modules, use \"resolutions\" to ensure only one version is installed.\n\nhttps://yarnpkg.com/en/docs/selective-version-resolutions\n\nDuplicate \"graphql\" modules cannot be used at the same time since different\nversions may have different capabilities and behavior. The data from one\nversion used in the function from another could produce confusing and\nspurious results.`);\n          }\n        }\n\n        return false;\n      };\n","export function invariant(condition, message) {\n  const booleanCondition = Boolean(condition);\n\n  if (!booleanCondition) {\n    throw new Error(\n      message != null ? message : 'Unexpected invariant triggered.',\n    );\n  }\n}\n","/**\n * Return true if `value` is object-like. A value is object-like if it's not\n * `null` and has a `typeof` result of \"object\".\n */\nexport function isObjectLike(value) {\n  return typeof value == 'object' && value !== null;\n}\n","/**\n * Contains a range of UTF-8 character offsets and token references that\n * identify the region of the source from which the AST derived.\n */\nexport class Location {\n  /**\n   * The character offset at which this Node begins.\n   */\n\n  /**\n   * The character offset at which this Node ends.\n   */\n\n  /**\n   * The Token at which this Node begins.\n   */\n\n  /**\n   * The Token at which this Node ends.\n   */\n\n  /**\n   * The Source document the AST represents.\n   */\n  constructor(startToken, endToken, source) {\n    this.start = startToken.start;\n    this.end = endToken.end;\n    this.startToken = startToken;\n    this.endToken = endToken;\n    this.source = source;\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'Location';\n  }\n\n  toJSON() {\n    return {\n      start: this.start,\n      end: this.end,\n    };\n  }\n}\n/**\n * Represents a range of characters represented by a lexical token\n * within a Source.\n */\n\nexport class Token {\n  /**\n   * The kind of Token.\n   */\n\n  /**\n   * The character offset at which this Node begins.\n   */\n\n  /**\n   * The character offset at which this Node ends.\n   */\n\n  /**\n   * The 1-indexed line number on which this Token appears.\n   */\n\n  /**\n   * The 1-indexed column number at which this Token begins.\n   */\n\n  /**\n   * For non-punctuation tokens, represents the interpreted value of the token.\n   *\n   * Note: is undefined for punctuation tokens, but typed as string for\n   * convenience in the parser.\n   */\n\n  /**\n   * Tokens exist as nodes in a double-linked-list amongst all tokens\n   * including ignored tokens. <SOF> is always the first node and <EOF>\n   * the last.\n   */\n  constructor(kind, start, end, line, column, value) {\n    this.kind = kind;\n    this.start = start;\n    this.end = end;\n    this.line = line;\n    this.column = column; // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n\n    this.value = value;\n    this.prev = null;\n    this.next = null;\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'Token';\n  }\n\n  toJSON() {\n    return {\n      kind: this.kind,\n      value: this.value,\n      line: this.line,\n      column: this.column,\n    };\n  }\n}\n/**\n * The list of all possible AST node types.\n */\n\n/**\n * @internal\n */\nexport const QueryDocumentKeys = {\n  Name: [],\n  Document: ['definitions'],\n  OperationDefinition: [\n    'name',\n    'variableDefinitions',\n    'directives',\n    'selectionSet',\n  ],\n  VariableDefinition: ['variable', 'type', 'defaultValue', 'directives'],\n  Variable: ['name'],\n  SelectionSet: ['selections'],\n  Field: ['alias', 'name', 'arguments', 'directives', 'selectionSet'],\n  Argument: ['name', 'value'],\n  FragmentSpread: ['name', 'directives'],\n  InlineFragment: ['typeCondition', 'directives', 'selectionSet'],\n  FragmentDefinition: [\n    'name', // Note: fragment variable definitions are deprecated and will removed in v17.0.0\n    'variableDefinitions',\n    'typeCondition',\n    'directives',\n    'selectionSet',\n  ],\n  IntValue: [],\n  FloatValue: [],\n  StringValue: [],\n  BooleanValue: [],\n  NullValue: [],\n  EnumValue: [],\n  ListValue: ['values'],\n  ObjectValue: ['fields'],\n  ObjectField: ['name', 'value'],\n  Directive: ['name', 'arguments'],\n  NamedType: ['name'],\n  ListType: ['type'],\n  NonNullType: ['type'],\n  SchemaDefinition: ['description', 'directives', 'operationTypes'],\n  OperationTypeDefinition: ['type'],\n  ScalarTypeDefinition: ['description', 'name', 'directives'],\n  ObjectTypeDefinition: [\n    'description',\n    'name',\n    'interfaces',\n    'directives',\n    'fields',\n  ],\n  FieldDefinition: ['description', 'name', 'arguments', 'type', 'directives'],\n  InputValueDefinition: [\n    'description',\n    'name',\n    'type',\n    'defaultValue',\n    'directives',\n  ],\n  InterfaceTypeDefinition: [\n    'description',\n    'name',\n    'interfaces',\n    'directives',\n    'fields',\n  ],\n  UnionTypeDefinition: ['description', 'name', 'directives', 'types'],\n  EnumTypeDefinition: ['description', 'name', 'directives', 'values'],\n  EnumValueDefinition: ['description', 'name', 'directives'],\n  InputObjectTypeDefinition: ['description', 'name', 'directives', 'fields'],\n  DirectiveDefinition: ['description', 'name', 'arguments', 'locations'],\n  SchemaExtension: ['directives', 'operationTypes'],\n  ScalarTypeExtension: ['name', 'directives'],\n  ObjectTypeExtension: ['name', 'interfaces', 'directives', 'fields'],\n  InterfaceTypeExtension: ['name', 'interfaces', 'directives', 'fields'],\n  UnionTypeExtension: ['name', 'directives', 'types'],\n  EnumTypeExtension: ['name', 'directives', 'values'],\n  InputObjectTypeExtension: ['name', 'directives', 'fields'],\n};\nconst kindValues = new Set(Object.keys(QueryDocumentKeys));\n/**\n * @internal\n */\n\nexport function isNode(maybeNode) {\n  const maybeKind =\n    maybeNode === null || maybeNode === void 0 ? void 0 : maybeNode.kind;\n  return typeof maybeKind === 'string' && kindValues.has(maybeKind);\n}\n/** Name */\n\nvar OperationTypeNode;\n\n(function (OperationTypeNode) {\n  OperationTypeNode['QUERY'] = 'query';\n  OperationTypeNode['MUTATION'] = 'mutation';\n  OperationTypeNode['SUBSCRIPTION'] = 'subscription';\n})(OperationTypeNode || (OperationTypeNode = {}));\n\nexport { OperationTypeNode };\n","import { isWhiteSpace } from './characterClasses.mjs';\n/**\n * Produces the value of a block string from its parsed raw value, similar to\n * CoffeeScript's block string, Python's docstring trim or Ruby's strip_heredoc.\n *\n * This implements the GraphQL spec's BlockStringValue() static algorithm.\n *\n * @internal\n */\n\nexport function dedentBlockStringLines(lines) {\n  var _firstNonEmptyLine2;\n\n  let commonIndent = Number.MAX_SAFE_INTEGER;\n  let firstNonEmptyLine = null;\n  let lastNonEmptyLine = -1;\n\n  for (let i = 0; i < lines.length; ++i) {\n    var _firstNonEmptyLine;\n\n    const line = lines[i];\n    const indent = leadingWhitespace(line);\n\n    if (indent === line.length) {\n      continue; // skip empty lines\n    }\n\n    firstNonEmptyLine =\n      (_firstNonEmptyLine = firstNonEmptyLine) !== null &&\n      _firstNonEmptyLine !== void 0\n        ? _firstNonEmptyLine\n        : i;\n    lastNonEmptyLine = i;\n\n    if (i !== 0 && indent < commonIndent) {\n      commonIndent = indent;\n    }\n  }\n\n  return lines // Remove common indentation from all lines but first.\n    .map((line, i) => (i === 0 ? line : line.slice(commonIndent))) // Remove leading and trailing blank lines.\n    .slice(\n      (_firstNonEmptyLine2 = firstNonEmptyLine) !== null &&\n        _firstNonEmptyLine2 !== void 0\n        ? _firstNonEmptyLine2\n        : 0,\n      lastNonEmptyLine + 1,\n    );\n}\n\nfunction leadingWhitespace(str) {\n  let i = 0;\n\n  while (i < str.length && isWhiteSpace(str.charCodeAt(i))) {\n    ++i;\n  }\n\n  return i;\n}\n/**\n * @internal\n */\n\nexport function isPrintableAsBlockString(value) {\n  if (value === '') {\n    return true; // empty string is printable\n  }\n\n  let isEmptyLine = true;\n  let hasIndent = false;\n  let hasCommonIndent = true;\n  let seenNonEmptyLine = false;\n\n  for (let i = 0; i < value.length; ++i) {\n    switch (value.codePointAt(i)) {\n      case 0x0000:\n      case 0x0001:\n      case 0x0002:\n      case 0x0003:\n      case 0x0004:\n      case 0x0005:\n      case 0x0006:\n      case 0x0007:\n      case 0x0008:\n      case 0x000b:\n      case 0x000c:\n      case 0x000e:\n      case 0x000f:\n        return false;\n      // Has non-printable characters\n\n      case 0x000d:\n        //  \\r\n        return false;\n      // Has \\r or \\r\\n which will be replaced as \\n\n\n      case 10:\n        //  \\n\n        if (isEmptyLine && !seenNonEmptyLine) {\n          return false; // Has leading new line\n        }\n\n        seenNonEmptyLine = true;\n        isEmptyLine = true;\n        hasIndent = false;\n        break;\n\n      case 9: //   \\t\n\n      case 32:\n        //  <space>\n        hasIndent || (hasIndent = isEmptyLine);\n        break;\n\n      default:\n        hasCommonIndent && (hasCommonIndent = hasIndent);\n        isEmptyLine = false;\n    }\n  }\n\n  if (isEmptyLine) {\n    return false; // Has trailing empty lines\n  }\n\n  if (hasCommonIndent && seenNonEmptyLine) {\n    return false; // Has internal indent\n  }\n\n  return true;\n}\n/**\n * Print a block string in the indented block form by adding a leading and\n * trailing blank line. However, if a block string starts with whitespace and is\n * a single-line, adding a leading blank line would strip that whitespace.\n *\n * @internal\n */\n\nexport function printBlockString(value, options) {\n  const escapedValue = value.replace(/\"\"\"/g, '\\\\\"\"\"'); // Expand a block string's raw value into independent lines.\n\n  const lines = escapedValue.split(/\\r\\n|[\\n\\r]/g);\n  const isSingleLine = lines.length === 1; // If common indentation is found we can fix some of those cases by adding leading new line\n\n  const forceLeadingNewLine =\n    lines.length > 1 &&\n    lines\n      .slice(1)\n      .every((line) => line.length === 0 || isWhiteSpace(line.charCodeAt(0))); // Trailing triple quotes just looks confusing but doesn't force trailing new line\n\n  const hasTrailingTripleQuotes = escapedValue.endsWith('\\\\\"\"\"'); // Trailing quote (single or double) or slash forces trailing new line\n\n  const hasTrailingQuote = value.endsWith('\"') && !hasTrailingTripleQuotes;\n  const hasTrailingSlash = value.endsWith('\\\\');\n  const forceTrailingNewline = hasTrailingQuote || hasTrailingSlash;\n  const printAsMultipleLines =\n    !(options !== null && options !== void 0 && options.minimize) && // add leading and trailing new lines only if it improves readability\n    (!isSingleLine ||\n      value.length > 70 ||\n      forceTrailingNewline ||\n      forceLeadingNewLine ||\n      hasTrailingTripleQuotes);\n  let result = ''; // Format a multi-line block quote to account for leading space.\n\n  const skipLeadingNewLine = isSingleLine && isWhiteSpace(value.charCodeAt(0));\n\n  if ((printAsMultipleLines && !skipLeadingNewLine) || forceLeadingNewLine) {\n    result += '\\n';\n  }\n\n  result += escapedValue;\n\n  if (printAsMultipleLines || forceTrailingNewline) {\n    result += '\\n';\n  }\n\n  return '\"\"\"' + result + '\"\"\"';\n}\n","/**\n * ```\n * WhiteSpace ::\n *   - \"Horizontal Tab (U+0009)\"\n *   - \"Space (U+0020)\"\n * ```\n * @internal\n */\nexport function isWhiteSpace(code) {\n  return code === 0x0009 || code === 0x0020;\n}\n/**\n * ```\n * Digit :: one of\n *   - `0` `1` `2` `3` `4` `5` `6` `7` `8` `9`\n * ```\n * @internal\n */\n\nexport function isDigit(code) {\n  return code >= 0x0030 && code <= 0x0039;\n}\n/**\n * ```\n * Letter :: one of\n *   - `A` `B` `C` `D` `E` `F` `G` `H` `I` `J` `K` `L` `M`\n *   - `N` `O` `P` `Q` `R` `S` `T` `U` `V` `W` `X` `Y` `Z`\n *   - `a` `b` `c` `d` `e` `f` `g` `h` `i` `j` `k` `l` `m`\n *   - `n` `o` `p` `q` `r` `s` `t` `u` `v` `w` `x` `y` `z`\n * ```\n * @internal\n */\n\nexport function isLetter(code) {\n  return (\n    (code >= 0x0061 && code <= 0x007a) || // A-Z\n    (code >= 0x0041 && code <= 0x005a) // a-z\n  );\n}\n/**\n * ```\n * NameStart ::\n *   - Letter\n *   - `_`\n * ```\n * @internal\n */\n\nexport function isNameStart(code) {\n  return isLetter(code) || code === 0x005f;\n}\n/**\n * ```\n * NameContinue ::\n *   - Letter\n *   - Digit\n *   - `_`\n * ```\n * @internal\n */\n\nexport function isNameContinue(code) {\n  return isLetter(code) || isDigit(code) || code === 0x005f;\n}\n","/**\n * The set of allowed directive location values.\n */\nvar DirectiveLocation;\n\n(function (DirectiveLocation) {\n  DirectiveLocation['QUERY'] = 'QUERY';\n  DirectiveLocation['MUTATION'] = 'MUTATION';\n  DirectiveLocation['SUBSCRIPTION'] = 'SUBSCRIPTION';\n  DirectiveLocation['FIELD'] = 'FIELD';\n  DirectiveLocation['FRAGMENT_DEFINITION'] = 'FRAGMENT_DEFINITION';\n  DirectiveLocation['FRAGMENT_SPREAD'] = 'FRAGMENT_SPREAD';\n  DirectiveLocation['INLINE_FRAGMENT'] = 'INLINE_FRAGMENT';\n  DirectiveLocation['VARIABLE_DEFINITION'] = 'VARIABLE_DEFINITION';\n  DirectiveLocation['SCHEMA'] = 'SCHEMA';\n  DirectiveLocation['SCALAR'] = 'SCALAR';\n  DirectiveLocation['OBJECT'] = 'OBJECT';\n  DirectiveLocation['FIELD_DEFINITION'] = 'FIELD_DEFINITION';\n  DirectiveLocation['ARGUMENT_DEFINITION'] = 'ARGUMENT_DEFINITION';\n  DirectiveLocation['INTERFACE'] = 'INTERFACE';\n  DirectiveLocation['UNION'] = 'UNION';\n  DirectiveLocation['ENUM'] = 'ENUM';\n  DirectiveLocation['ENUM_VALUE'] = 'ENUM_VALUE';\n  DirectiveLocation['INPUT_OBJECT'] = 'INPUT_OBJECT';\n  DirectiveLocation['INPUT_FIELD_DEFINITION'] = 'INPUT_FIELD_DEFINITION';\n})(DirectiveLocation || (DirectiveLocation = {}));\n\nexport { DirectiveLocation };\n/**\n * The enum type representing the directive location values.\n *\n * @deprecated Please use `DirectiveLocation`. Will be remove in v17.\n */\n","/**\n * The set of allowed kind values for AST nodes.\n */\nvar Kind;\n\n(function (Kind) {\n  Kind['NAME'] = 'Name';\n  Kind['DOCUMENT'] = 'Document';\n  Kind['OPERATION_DEFINITION'] = 'OperationDefinition';\n  Kind['VARIABLE_DEFINITION'] = 'VariableDefinition';\n  Kind['SELECTION_SET'] = 'SelectionSet';\n  Kind['FIELD'] = 'Field';\n  Kind['ARGUMENT'] = 'Argument';\n  Kind['FRAGMENT_SPREAD'] = 'FragmentSpread';\n  Kind['INLINE_FRAGMENT'] = 'InlineFragment';\n  Kind['FRAGMENT_DEFINITION'] = 'FragmentDefinition';\n  Kind['VARIABLE'] = 'Variable';\n  Kind['INT'] = 'IntValue';\n  Kind['FLOAT'] = 'FloatValue';\n  Kind['STRING'] = 'StringValue';\n  Kind['BOOLEAN'] = 'BooleanValue';\n  Kind['NULL'] = 'NullValue';\n  Kind['ENUM'] = 'EnumValue';\n  Kind['LIST'] = 'ListValue';\n  Kind['OBJECT'] = 'ObjectValue';\n  Kind['OBJECT_FIELD'] = 'ObjectField';\n  Kind['DIRECTIVE'] = 'Directive';\n  Kind['NAMED_TYPE'] = 'NamedType';\n  Kind['LIST_TYPE'] = 'ListType';\n  Kind['NON_NULL_TYPE'] = 'NonNullType';\n  Kind['SCHEMA_DEFINITION'] = 'SchemaDefinition';\n  Kind['OPERATION_TYPE_DEFINITION'] = 'OperationTypeDefinition';\n  Kind['SCALAR_TYPE_DEFINITION'] = 'ScalarTypeDefinition';\n  Kind['OBJECT_TYPE_DEFINITION'] = 'ObjectTypeDefinition';\n  Kind['FIELD_DEFINITION'] = 'FieldDefinition';\n  Kind['INPUT_VALUE_DEFINITION'] = 'InputValueDefinition';\n  Kind['INTERFACE_TYPE_DEFINITION'] = 'InterfaceTypeDefinition';\n  Kind['UNION_TYPE_DEFINITION'] = 'UnionTypeDefinition';\n  Kind['ENUM_TYPE_DEFINITION'] = 'EnumTypeDefinition';\n  Kind['ENUM_VALUE_DEFINITION'] = 'EnumValueDefinition';\n  Kind['INPUT_OBJECT_TYPE_DEFINITION'] = 'InputObjectTypeDefinition';\n  Kind['DIRECTIVE_DEFINITION'] = 'DirectiveDefinition';\n  Kind['SCHEMA_EXTENSION'] = 'SchemaExtension';\n  Kind['SCALAR_TYPE_EXTENSION'] = 'ScalarTypeExtension';\n  Kind['OBJECT_TYPE_EXTENSION'] = 'ObjectTypeExtension';\n  Kind['INTERFACE_TYPE_EXTENSION'] = 'InterfaceTypeExtension';\n  Kind['UNION_TYPE_EXTENSION'] = 'UnionTypeExtension';\n  Kind['ENUM_TYPE_EXTENSION'] = 'EnumTypeExtension';\n  Kind['INPUT_OBJECT_TYPE_EXTENSION'] = 'InputObjectTypeExtension';\n})(Kind || (Kind = {}));\n\nexport { Kind };\n/**\n * The enum type representing the possible kind values of AST nodes.\n *\n * @deprecated Please use `Kind`. Will be remove in v17.\n */\n","import { syntaxError } from '../error/syntaxError.mjs';\nimport { Token } from './ast.mjs';\nimport { dedentBlockStringLines } from './blockString.mjs';\nimport { isDigit, isNameContinue, isNameStart } from './characterClasses.mjs';\nimport { TokenKind } from './tokenKind.mjs';\n/**\n * Given a Source object, creates a Lexer for that source.\n * A Lexer is a stateful stream generator in that every time\n * it is advanced, it returns the next token in the Source. Assuming the\n * source lexes, the final Token emitted by the lexer will be of kind\n * EOF, after which the lexer will repeatedly return the same EOF token\n * whenever called.\n */\n\nexport class Lexer {\n  /**\n   * The previously focused non-ignored token.\n   */\n\n  /**\n   * The currently focused non-ignored token.\n   */\n\n  /**\n   * The (1-indexed) line containing the current token.\n   */\n\n  /**\n   * The character offset at which the current line begins.\n   */\n  constructor(source) {\n    const startOfFileToken = new Token(TokenKind.SOF, 0, 0, 0, 0);\n    this.source = source;\n    this.lastToken = startOfFileToken;\n    this.token = startOfFileToken;\n    this.line = 1;\n    this.lineStart = 0;\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'Lexer';\n  }\n  /**\n   * Advances the token stream to the next non-ignored token.\n   */\n\n  advance() {\n    this.lastToken = this.token;\n    const token = (this.token = this.lookahead());\n    return token;\n  }\n  /**\n   * Looks ahead and returns the next non-ignored token, but does not change\n   * the state of Lexer.\n   */\n\n  lookahead() {\n    let token = this.token;\n\n    if (token.kind !== TokenKind.EOF) {\n      do {\n        if (token.next) {\n          token = token.next;\n        } else {\n          // Read the next token and form a link in the token linked-list.\n          const nextToken = readNextToken(this, token.end); // @ts-expect-error next is only mutable during parsing.\n\n          token.next = nextToken; // @ts-expect-error prev is only mutable during parsing.\n\n          nextToken.prev = token;\n          token = nextToken;\n        }\n      } while (token.kind === TokenKind.COMMENT);\n    }\n\n    return token;\n  }\n}\n/**\n * @internal\n */\n\nexport function isPunctuatorTokenKind(kind) {\n  return (\n    kind === TokenKind.BANG ||\n    kind === TokenKind.DOLLAR ||\n    kind === TokenKind.AMP ||\n    kind === TokenKind.PAREN_L ||\n    kind === TokenKind.PAREN_R ||\n    kind === TokenKind.SPREAD ||\n    kind === TokenKind.COLON ||\n    kind === TokenKind.EQUALS ||\n    kind === TokenKind.AT ||\n    kind === TokenKind.BRACKET_L ||\n    kind === TokenKind.BRACKET_R ||\n    kind === TokenKind.BRACE_L ||\n    kind === TokenKind.PIPE ||\n    kind === TokenKind.BRACE_R\n  );\n}\n/**\n * A Unicode scalar value is any Unicode code point except surrogate code\n * points. In other words, the inclusive ranges of values 0x0000 to 0xD7FF and\n * 0xE000 to 0x10FFFF.\n *\n * SourceCharacter ::\n *   - \"Any Unicode scalar value\"\n */\n\nfunction isUnicodeScalarValue(code) {\n  return (\n    (code >= 0x0000 && code <= 0xd7ff) || (code >= 0xe000 && code <= 0x10ffff)\n  );\n}\n/**\n * The GraphQL specification defines source text as a sequence of unicode scalar\n * values (which Unicode defines to exclude surrogate code points). However\n * JavaScript defines strings as a sequence of UTF-16 code units which may\n * include surrogates. A surrogate pair is a valid source character as it\n * encodes a supplementary code point (above U+FFFF), but unpaired surrogate\n * code points are not valid source characters.\n */\n\nfunction isSupplementaryCodePoint(body, location) {\n  return (\n    isLeadingSurrogate(body.charCodeAt(location)) &&\n    isTrailingSurrogate(body.charCodeAt(location + 1))\n  );\n}\n\nfunction isLeadingSurrogate(code) {\n  return code >= 0xd800 && code <= 0xdbff;\n}\n\nfunction isTrailingSurrogate(code) {\n  return code >= 0xdc00 && code <= 0xdfff;\n}\n/**\n * Prints the code point (or end of file reference) at a given location in a\n * source for use in error messages.\n *\n * Printable ASCII is printed quoted, while other points are printed in Unicode\n * code point form (ie. U+1234).\n */\n\nfunction printCodePointAt(lexer, location) {\n  const code = lexer.source.body.codePointAt(location);\n\n  if (code === undefined) {\n    return TokenKind.EOF;\n  } else if (code >= 0x0020 && code <= 0x007e) {\n    // Printable ASCII\n    const char = String.fromCodePoint(code);\n    return char === '\"' ? \"'\\\"'\" : `\"${char}\"`;\n  } // Unicode code point\n\n  return 'U+' + code.toString(16).toUpperCase().padStart(4, '0');\n}\n/**\n * Create a token with line and column location information.\n */\n\nfunction createToken(lexer, kind, start, end, value) {\n  const line = lexer.line;\n  const col = 1 + start - lexer.lineStart;\n  return new Token(kind, start, end, line, col, value);\n}\n/**\n * Gets the next token from the source starting at the given position.\n *\n * This skips over whitespace until it finds the next lexable token, then lexes\n * punctuators immediately or calls the appropriate helper function for more\n * complicated tokens.\n */\n\nfunction readNextToken(lexer, start) {\n  const body = lexer.source.body;\n  const bodyLength = body.length;\n  let position = start;\n\n  while (position < bodyLength) {\n    const code = body.charCodeAt(position); // SourceCharacter\n\n    switch (code) {\n      // Ignored ::\n      //   - UnicodeBOM\n      //   - WhiteSpace\n      //   - LineTerminator\n      //   - Comment\n      //   - Comma\n      //\n      // UnicodeBOM :: \"Byte Order Mark (U+FEFF)\"\n      //\n      // WhiteSpace ::\n      //   - \"Horizontal Tab (U+0009)\"\n      //   - \"Space (U+0020)\"\n      //\n      // Comma :: ,\n      case 0xfeff: // <BOM>\n\n      case 0x0009: // \\t\n\n      case 0x0020: // <space>\n\n      case 0x002c:\n        // ,\n        ++position;\n        continue;\n      // LineTerminator ::\n      //   - \"New Line (U+000A)\"\n      //   - \"Carriage Return (U+000D)\" [lookahead != \"New Line (U+000A)\"]\n      //   - \"Carriage Return (U+000D)\" \"New Line (U+000A)\"\n\n      case 0x000a:\n        // \\n\n        ++position;\n        ++lexer.line;\n        lexer.lineStart = position;\n        continue;\n\n      case 0x000d:\n        // \\r\n        if (body.charCodeAt(position + 1) === 0x000a) {\n          position += 2;\n        } else {\n          ++position;\n        }\n\n        ++lexer.line;\n        lexer.lineStart = position;\n        continue;\n      // Comment\n\n      case 0x0023:\n        // #\n        return readComment(lexer, position);\n      // Token ::\n      //   - Punctuator\n      //   - Name\n      //   - IntValue\n      //   - FloatValue\n      //   - StringValue\n      //\n      // Punctuator :: one of ! $ & ( ) ... : = @ [ ] { | }\n\n      case 0x0021:\n        // !\n        return createToken(lexer, TokenKind.BANG, position, position + 1);\n\n      case 0x0024:\n        // $\n        return createToken(lexer, TokenKind.DOLLAR, position, position + 1);\n\n      case 0x0026:\n        // &\n        return createToken(lexer, TokenKind.AMP, position, position + 1);\n\n      case 0x0028:\n        // (\n        return createToken(lexer, TokenKind.PAREN_L, position, position + 1);\n\n      case 0x0029:\n        // )\n        return createToken(lexer, TokenKind.PAREN_R, position, position + 1);\n\n      case 0x002e:\n        // .\n        if (\n          body.charCodeAt(position + 1) === 0x002e &&\n          body.charCodeAt(position + 2) === 0x002e\n        ) {\n          return createToken(lexer, TokenKind.SPREAD, position, position + 3);\n        }\n\n        break;\n\n      case 0x003a:\n        // :\n        return createToken(lexer, TokenKind.COLON, position, position + 1);\n\n      case 0x003d:\n        // =\n        return createToken(lexer, TokenKind.EQUALS, position, position + 1);\n\n      case 0x0040:\n        // @\n        return createToken(lexer, TokenKind.AT, position, position + 1);\n\n      case 0x005b:\n        // [\n        return createToken(lexer, TokenKind.BRACKET_L, position, position + 1);\n\n      case 0x005d:\n        // ]\n        return createToken(lexer, TokenKind.BRACKET_R, position, position + 1);\n\n      case 0x007b:\n        // {\n        return createToken(lexer, TokenKind.BRACE_L, position, position + 1);\n\n      case 0x007c:\n        // |\n        return createToken(lexer, TokenKind.PIPE, position, position + 1);\n\n      case 0x007d:\n        // }\n        return createToken(lexer, TokenKind.BRACE_R, position, position + 1);\n      // StringValue\n\n      case 0x0022:\n        // \"\n        if (\n          body.charCodeAt(position + 1) === 0x0022 &&\n          body.charCodeAt(position + 2) === 0x0022\n        ) {\n          return readBlockString(lexer, position);\n        }\n\n        return readString(lexer, position);\n    } // IntValue | FloatValue (Digit | -)\n\n    if (isDigit(code) || code === 0x002d) {\n      return readNumber(lexer, position, code);\n    } // Name\n\n    if (isNameStart(code)) {\n      return readName(lexer, position);\n    }\n\n    throw syntaxError(\n      lexer.source,\n      position,\n      code === 0x0027\n        ? 'Unexpected single quote character (\\'), did you mean to use a double quote (\")?'\n        : isUnicodeScalarValue(code) || isSupplementaryCodePoint(body, position)\n        ? `Unexpected character: ${printCodePointAt(lexer, position)}.`\n        : `Invalid character: ${printCodePointAt(lexer, position)}.`,\n    );\n  }\n\n  return createToken(lexer, TokenKind.EOF, bodyLength, bodyLength);\n}\n/**\n * Reads a comment token from the source file.\n *\n * ```\n * Comment :: # CommentChar* [lookahead != CommentChar]\n *\n * CommentChar :: SourceCharacter but not LineTerminator\n * ```\n */\n\nfunction readComment(lexer, start) {\n  const body = lexer.source.body;\n  const bodyLength = body.length;\n  let position = start + 1;\n\n  while (position < bodyLength) {\n    const code = body.charCodeAt(position); // LineTerminator (\\n | \\r)\n\n    if (code === 0x000a || code === 0x000d) {\n      break;\n    } // SourceCharacter\n\n    if (isUnicodeScalarValue(code)) {\n      ++position;\n    } else if (isSupplementaryCodePoint(body, position)) {\n      position += 2;\n    } else {\n      break;\n    }\n  }\n\n  return createToken(\n    lexer,\n    TokenKind.COMMENT,\n    start,\n    position,\n    body.slice(start + 1, position),\n  );\n}\n/**\n * Reads a number token from the source file, either a FloatValue or an IntValue\n * depending on whether a FractionalPart or ExponentPart is encountered.\n *\n * ```\n * IntValue :: IntegerPart [lookahead != {Digit, `.`, NameStart}]\n *\n * IntegerPart ::\n *   - NegativeSign? 0\n *   - NegativeSign? NonZeroDigit Digit*\n *\n * NegativeSign :: -\n *\n * NonZeroDigit :: Digit but not `0`\n *\n * FloatValue ::\n *   - IntegerPart FractionalPart ExponentPart [lookahead != {Digit, `.`, NameStart}]\n *   - IntegerPart FractionalPart [lookahead != {Digit, `.`, NameStart}]\n *   - IntegerPart ExponentPart [lookahead != {Digit, `.`, NameStart}]\n *\n * FractionalPart :: . Digit+\n *\n * ExponentPart :: ExponentIndicator Sign? Digit+\n *\n * ExponentIndicator :: one of `e` `E`\n *\n * Sign :: one of + -\n * ```\n */\n\nfunction readNumber(lexer, start, firstCode) {\n  const body = lexer.source.body;\n  let position = start;\n  let code = firstCode;\n  let isFloat = false; // NegativeSign (-)\n\n  if (code === 0x002d) {\n    code = body.charCodeAt(++position);\n  } // Zero (0)\n\n  if (code === 0x0030) {\n    code = body.charCodeAt(++position);\n\n    if (isDigit(code)) {\n      throw syntaxError(\n        lexer.source,\n        position,\n        `Invalid number, unexpected digit after 0: ${printCodePointAt(\n          lexer,\n          position,\n        )}.`,\n      );\n    }\n  } else {\n    position = readDigits(lexer, position, code);\n    code = body.charCodeAt(position);\n  } // Full stop (.)\n\n  if (code === 0x002e) {\n    isFloat = true;\n    code = body.charCodeAt(++position);\n    position = readDigits(lexer, position, code);\n    code = body.charCodeAt(position);\n  } // E e\n\n  if (code === 0x0045 || code === 0x0065) {\n    isFloat = true;\n    code = body.charCodeAt(++position); // + -\n\n    if (code === 0x002b || code === 0x002d) {\n      code = body.charCodeAt(++position);\n    }\n\n    position = readDigits(lexer, position, code);\n    code = body.charCodeAt(position);\n  } // Numbers cannot be followed by . or NameStart\n\n  if (code === 0x002e || isNameStart(code)) {\n    throw syntaxError(\n      lexer.source,\n      position,\n      `Invalid number, expected digit but got: ${printCodePointAt(\n        lexer,\n        position,\n      )}.`,\n    );\n  }\n\n  return createToken(\n    lexer,\n    isFloat ? TokenKind.FLOAT : TokenKind.INT,\n    start,\n    position,\n    body.slice(start, position),\n  );\n}\n/**\n * Returns the new position in the source after reading one or more digits.\n */\n\nfunction readDigits(lexer, start, firstCode) {\n  if (!isDigit(firstCode)) {\n    throw syntaxError(\n      lexer.source,\n      start,\n      `Invalid number, expected digit but got: ${printCodePointAt(\n        lexer,\n        start,\n      )}.`,\n    );\n  }\n\n  const body = lexer.source.body;\n  let position = start + 1; // +1 to skip first firstCode\n\n  while (isDigit(body.charCodeAt(position))) {\n    ++position;\n  }\n\n  return position;\n}\n/**\n * Reads a single-quote string token from the source file.\n *\n * ```\n * StringValue ::\n *   - `\"\"` [lookahead != `\"`]\n *   - `\"` StringCharacter+ `\"`\n *\n * StringCharacter ::\n *   - SourceCharacter but not `\"` or `\\` or LineTerminator\n *   - `\\u` EscapedUnicode\n *   - `\\` EscapedCharacter\n *\n * EscapedUnicode ::\n *   - `{` HexDigit+ `}`\n *   - HexDigit HexDigit HexDigit HexDigit\n *\n * EscapedCharacter :: one of `\"` `\\` `/` `b` `f` `n` `r` `t`\n * ```\n */\n\nfunction readString(lexer, start) {\n  const body = lexer.source.body;\n  const bodyLength = body.length;\n  let position = start + 1;\n  let chunkStart = position;\n  let value = '';\n\n  while (position < bodyLength) {\n    const code = body.charCodeAt(position); // Closing Quote (\")\n\n    if (code === 0x0022) {\n      value += body.slice(chunkStart, position);\n      return createToken(lexer, TokenKind.STRING, start, position + 1, value);\n    } // Escape Sequence (\\)\n\n    if (code === 0x005c) {\n      value += body.slice(chunkStart, position);\n      const escape =\n        body.charCodeAt(position + 1) === 0x0075 // u\n          ? body.charCodeAt(position + 2) === 0x007b // {\n            ? readEscapedUnicodeVariableWidth(lexer, position)\n            : readEscapedUnicodeFixedWidth(lexer, position)\n          : readEscapedCharacter(lexer, position);\n      value += escape.value;\n      position += escape.size;\n      chunkStart = position;\n      continue;\n    } // LineTerminator (\\n | \\r)\n\n    if (code === 0x000a || code === 0x000d) {\n      break;\n    } // SourceCharacter\n\n    if (isUnicodeScalarValue(code)) {\n      ++position;\n    } else if (isSupplementaryCodePoint(body, position)) {\n      position += 2;\n    } else {\n      throw syntaxError(\n        lexer.source,\n        position,\n        `Invalid character within String: ${printCodePointAt(\n          lexer,\n          position,\n        )}.`,\n      );\n    }\n  }\n\n  throw syntaxError(lexer.source, position, 'Unterminated string.');\n} // The string value and lexed size of an escape sequence.\n\nfunction readEscapedUnicodeVariableWidth(lexer, position) {\n  const body = lexer.source.body;\n  let point = 0;\n  let size = 3; // Cannot be larger than 12 chars (\\u{00000000}).\n\n  while (size < 12) {\n    const code = body.charCodeAt(position + size++); // Closing Brace (})\n\n    if (code === 0x007d) {\n      // Must be at least 5 chars (\\u{0}) and encode a Unicode scalar value.\n      if (size < 5 || !isUnicodeScalarValue(point)) {\n        break;\n      }\n\n      return {\n        value: String.fromCodePoint(point),\n        size,\n      };\n    } // Append this hex digit to the code point.\n\n    point = (point << 4) | readHexDigit(code);\n\n    if (point < 0) {\n      break;\n    }\n  }\n\n  throw syntaxError(\n    lexer.source,\n    position,\n    `Invalid Unicode escape sequence: \"${body.slice(\n      position,\n      position + size,\n    )}\".`,\n  );\n}\n\nfunction readEscapedUnicodeFixedWidth(lexer, position) {\n  const body = lexer.source.body;\n  const code = read16BitHexCode(body, position + 2);\n\n  if (isUnicodeScalarValue(code)) {\n    return {\n      value: String.fromCodePoint(code),\n      size: 6,\n    };\n  } // GraphQL allows JSON-style surrogate pair escape sequences, but only when\n  // a valid pair is formed.\n\n  if (isLeadingSurrogate(code)) {\n    // \\u\n    if (\n      body.charCodeAt(position + 6) === 0x005c &&\n      body.charCodeAt(position + 7) === 0x0075\n    ) {\n      const trailingCode = read16BitHexCode(body, position + 8);\n\n      if (isTrailingSurrogate(trailingCode)) {\n        // JavaScript defines strings as a sequence of UTF-16 code units and\n        // encodes Unicode code points above U+FFFF using a surrogate pair of\n        // code units. Since this is a surrogate pair escape sequence, just\n        // include both codes into the JavaScript string value. Had JavaScript\n        // not been internally based on UTF-16, then this surrogate pair would\n        // be decoded to retrieve the supplementary code point.\n        return {\n          value: String.fromCodePoint(code, trailingCode),\n          size: 12,\n        };\n      }\n    }\n  }\n\n  throw syntaxError(\n    lexer.source,\n    position,\n    `Invalid Unicode escape sequence: \"${body.slice(position, position + 6)}\".`,\n  );\n}\n/**\n * Reads four hexadecimal characters and returns the positive integer that 16bit\n * hexadecimal string represents. For example, \"000f\" will return 15, and \"dead\"\n * will return 57005.\n *\n * Returns a negative number if any char was not a valid hexadecimal digit.\n */\n\nfunction read16BitHexCode(body, position) {\n  // readHexDigit() returns -1 on error. ORing a negative value with any other\n  // value always produces a negative value.\n  return (\n    (readHexDigit(body.charCodeAt(position)) << 12) |\n    (readHexDigit(body.charCodeAt(position + 1)) << 8) |\n    (readHexDigit(body.charCodeAt(position + 2)) << 4) |\n    readHexDigit(body.charCodeAt(position + 3))\n  );\n}\n/**\n * Reads a hexadecimal character and returns its positive integer value (0-15).\n *\n * '0' becomes 0, '9' becomes 9\n * 'A' becomes 10, 'F' becomes 15\n * 'a' becomes 10, 'f' becomes 15\n *\n * Returns -1 if the provided character code was not a valid hexadecimal digit.\n *\n * HexDigit :: one of\n *   - `0` `1` `2` `3` `4` `5` `6` `7` `8` `9`\n *   - `A` `B` `C` `D` `E` `F`\n *   - `a` `b` `c` `d` `e` `f`\n */\n\nfunction readHexDigit(code) {\n  return code >= 0x0030 && code <= 0x0039 // 0-9\n    ? code - 0x0030\n    : code >= 0x0041 && code <= 0x0046 // A-F\n    ? code - 0x0037\n    : code >= 0x0061 && code <= 0x0066 // a-f\n    ? code - 0x0057\n    : -1;\n}\n/**\n * | Escaped Character | Code Point | Character Name               |\n * | ----------------- | ---------- | ---------------------------- |\n * | `\"`               | U+0022     | double quote                 |\n * | `\\`               | U+005C     | reverse solidus (back slash) |\n * | `/`               | U+002F     | solidus (forward slash)      |\n * | `b`               | U+0008     | backspace                    |\n * | `f`               | U+000C     | form feed                    |\n * | `n`               | U+000A     | line feed (new line)         |\n * | `r`               | U+000D     | carriage return              |\n * | `t`               | U+0009     | horizontal tab               |\n */\n\nfunction readEscapedCharacter(lexer, position) {\n  const body = lexer.source.body;\n  const code = body.charCodeAt(position + 1);\n\n  switch (code) {\n    case 0x0022:\n      // \"\n      return {\n        value: '\\u0022',\n        size: 2,\n      };\n\n    case 0x005c:\n      // \\\n      return {\n        value: '\\u005c',\n        size: 2,\n      };\n\n    case 0x002f:\n      // /\n      return {\n        value: '\\u002f',\n        size: 2,\n      };\n\n    case 0x0062:\n      // b\n      return {\n        value: '\\u0008',\n        size: 2,\n      };\n\n    case 0x0066:\n      // f\n      return {\n        value: '\\u000c',\n        size: 2,\n      };\n\n    case 0x006e:\n      // n\n      return {\n        value: '\\u000a',\n        size: 2,\n      };\n\n    case 0x0072:\n      // r\n      return {\n        value: '\\u000d',\n        size: 2,\n      };\n\n    case 0x0074:\n      // t\n      return {\n        value: '\\u0009',\n        size: 2,\n      };\n  }\n\n  throw syntaxError(\n    lexer.source,\n    position,\n    `Invalid character escape sequence: \"${body.slice(\n      position,\n      position + 2,\n    )}\".`,\n  );\n}\n/**\n * Reads a block string token from the source file.\n *\n * ```\n * StringValue ::\n *   - `\"\"\"` BlockStringCharacter* `\"\"\"`\n *\n * BlockStringCharacter ::\n *   - SourceCharacter but not `\"\"\"` or `\\\"\"\"`\n *   - `\\\"\"\"`\n * ```\n */\n\nfunction readBlockString(lexer, start) {\n  const body = lexer.source.body;\n  const bodyLength = body.length;\n  let lineStart = lexer.lineStart;\n  let position = start + 3;\n  let chunkStart = position;\n  let currentLine = '';\n  const blockLines = [];\n\n  while (position < bodyLength) {\n    const code = body.charCodeAt(position); // Closing Triple-Quote (\"\"\")\n\n    if (\n      code === 0x0022 &&\n      body.charCodeAt(position + 1) === 0x0022 &&\n      body.charCodeAt(position + 2) === 0x0022\n    ) {\n      currentLine += body.slice(chunkStart, position);\n      blockLines.push(currentLine);\n      const token = createToken(\n        lexer,\n        TokenKind.BLOCK_STRING,\n        start,\n        position + 3, // Return a string of the lines joined with U+000A.\n        dedentBlockStringLines(blockLines).join('\\n'),\n      );\n      lexer.line += blockLines.length - 1;\n      lexer.lineStart = lineStart;\n      return token;\n    } // Escaped Triple-Quote (\\\"\"\")\n\n    if (\n      code === 0x005c &&\n      body.charCodeAt(position + 1) === 0x0022 &&\n      body.charCodeAt(position + 2) === 0x0022 &&\n      body.charCodeAt(position + 3) === 0x0022\n    ) {\n      currentLine += body.slice(chunkStart, position);\n      chunkStart = position + 1; // skip only slash\n\n      position += 4;\n      continue;\n    } // LineTerminator\n\n    if (code === 0x000a || code === 0x000d) {\n      currentLine += body.slice(chunkStart, position);\n      blockLines.push(currentLine);\n\n      if (code === 0x000d && body.charCodeAt(position + 1) === 0x000a) {\n        position += 2;\n      } else {\n        ++position;\n      }\n\n      currentLine = '';\n      chunkStart = position;\n      lineStart = position;\n      continue;\n    } // SourceCharacter\n\n    if (isUnicodeScalarValue(code)) {\n      ++position;\n    } else if (isSupplementaryCodePoint(body, position)) {\n      position += 2;\n    } else {\n      throw syntaxError(\n        lexer.source,\n        position,\n        `Invalid character within String: ${printCodePointAt(\n          lexer,\n          position,\n        )}.`,\n      );\n    }\n  }\n\n  throw syntaxError(lexer.source, position, 'Unterminated string.');\n}\n/**\n * Reads an alphanumeric + underscore name from the source.\n *\n * ```\n * Name ::\n *   - NameStart NameContinue* [lookahead != NameContinue]\n * ```\n */\n\nfunction readName(lexer, start) {\n  const body = lexer.source.body;\n  const bodyLength = body.length;\n  let position = start + 1;\n\n  while (position < bodyLength) {\n    const code = body.charCodeAt(position);\n\n    if (isNameContinue(code)) {\n      ++position;\n    } else {\n      break;\n    }\n  }\n\n  return createToken(\n    lexer,\n    TokenKind.NAME,\n    start,\n    position,\n    body.slice(start, position),\n  );\n}\n","import { invariant } from '../jsutils/invariant.mjs';\nconst LineRegExp = /\\r\\n|[\\n\\r]/g;\n/**\n * Represents a location in a Source.\n */\n\n/**\n * Takes a Source and a UTF-8 character offset, and returns the corresponding\n * line and column as a SourceLocation.\n */\nexport function getLocation(source, position) {\n  let lastLineStart = 0;\n  let line = 1;\n\n  for (const match of source.body.matchAll(LineRegExp)) {\n    typeof match.index === 'number' || invariant(false);\n\n    if (match.index >= position) {\n      break;\n    }\n\n    lastLineStart = match.index + match[0].length;\n    line += 1;\n  }\n\n  return {\n    line,\n    column: position + 1 - lastLineStart,\n  };\n}\n","import { syntaxError } from '../error/syntaxError.mjs';\nimport { Location, OperationTypeNode } from './ast.mjs';\nimport { DirectiveLocation } from './directiveLocation.mjs';\nimport { Kind } from './kinds.mjs';\nimport { isPunctuatorTokenKind, Lexer } from './lexer.mjs';\nimport { isSource, Source } from './source.mjs';\nimport { TokenKind } from './tokenKind.mjs';\n/**\n * Configuration options to control parser behavior\n */\n\n/**\n * Given a GraphQL source, parses it into a Document.\n * Throws GraphQLError if a syntax error is encountered.\n */\nexport function parse(source, options) {\n  const parser = new Parser(source, options);\n  const document = parser.parseDocument();\n  Object.defineProperty(document, 'tokenCount', {\n    enumerable: false,\n    value: parser.tokenCount,\n  });\n  return document;\n}\n/**\n * Given a string containing a GraphQL value (ex. `[42]`), parse the AST for\n * that value.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Values directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: valueFromAST().\n */\n\nexport function parseValue(source, options) {\n  const parser = new Parser(source, options);\n  parser.expectToken(TokenKind.SOF);\n  const value = parser.parseValueLiteral(false);\n  parser.expectToken(TokenKind.EOF);\n  return value;\n}\n/**\n * Similar to parseValue(), but raises a parse error if it encounters a\n * variable. The return type will be a constant value.\n */\n\nexport function parseConstValue(source, options) {\n  const parser = new Parser(source, options);\n  parser.expectToken(TokenKind.SOF);\n  const value = parser.parseConstValueLiteral();\n  parser.expectToken(TokenKind.EOF);\n  return value;\n}\n/**\n * Given a string containing a GraphQL Type (ex. `[Int!]`), parse the AST for\n * that type.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Types directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: typeFromAST().\n */\n\nexport function parseType(source, options) {\n  const parser = new Parser(source, options);\n  parser.expectToken(TokenKind.SOF);\n  const type = parser.parseTypeReference();\n  parser.expectToken(TokenKind.EOF);\n  return type;\n}\n/**\n * This class is exported only to assist people in implementing their own parsers\n * without duplicating too much code and should be used only as last resort for cases\n * such as experimental syntax or if certain features could not be contributed upstream.\n *\n * It is still part of the internal API and is versioned, so any changes to it are never\n * considered breaking changes. If you still need to support multiple versions of the\n * library, please use the `versionInfo` variable for version detection.\n *\n * @internal\n */\n\nexport class Parser {\n  constructor(source, options = {}) {\n    const sourceObj = isSource(source) ? source : new Source(source);\n    this._lexer = new Lexer(sourceObj);\n    this._options = options;\n    this._tokenCounter = 0;\n  }\n\n  get tokenCount() {\n    return this._tokenCounter;\n  }\n  /**\n   * Converts a name lex token into a name parse node.\n   */\n\n  parseName() {\n    const token = this.expectToken(TokenKind.NAME);\n    return this.node(token, {\n      kind: Kind.NAME,\n      value: token.value,\n    });\n  } // Implements the parsing rules in the Document section.\n\n  /**\n   * Document : Definition+\n   */\n\n  parseDocument() {\n    return this.node(this._lexer.token, {\n      kind: Kind.DOCUMENT,\n      definitions: this.many(\n        TokenKind.SOF,\n        this.parseDefinition,\n        TokenKind.EOF,\n      ),\n    });\n  }\n  /**\n   * Definition :\n   *   - ExecutableDefinition\n   *   - TypeSystemDefinition\n   *   - TypeSystemExtension\n   *\n   * ExecutableDefinition :\n   *   - OperationDefinition\n   *   - FragmentDefinition\n   *\n   * TypeSystemDefinition :\n   *   - SchemaDefinition\n   *   - TypeDefinition\n   *   - DirectiveDefinition\n   *\n   * TypeDefinition :\n   *   - ScalarTypeDefinition\n   *   - ObjectTypeDefinition\n   *   - InterfaceTypeDefinition\n   *   - UnionTypeDefinition\n   *   - EnumTypeDefinition\n   *   - InputObjectTypeDefinition\n   */\n\n  parseDefinition() {\n    if (this.peek(TokenKind.BRACE_L)) {\n      return this.parseOperationDefinition();\n    } // Many definitions begin with a description and require a lookahead.\n\n    const hasDescription = this.peekDescription();\n    const keywordToken = hasDescription\n      ? this._lexer.lookahead()\n      : this._lexer.token;\n\n    if (keywordToken.kind === TokenKind.NAME) {\n      switch (keywordToken.value) {\n        case 'schema':\n          return this.parseSchemaDefinition();\n\n        case 'scalar':\n          return this.parseScalarTypeDefinition();\n\n        case 'type':\n          return this.parseObjectTypeDefinition();\n\n        case 'interface':\n          return this.parseInterfaceTypeDefinition();\n\n        case 'union':\n          return this.parseUnionTypeDefinition();\n\n        case 'enum':\n          return this.parseEnumTypeDefinition();\n\n        case 'input':\n          return this.parseInputObjectTypeDefinition();\n\n        case 'directive':\n          return this.parseDirectiveDefinition();\n      }\n\n      if (hasDescription) {\n        throw syntaxError(\n          this._lexer.source,\n          this._lexer.token.start,\n          'Unexpected description, descriptions are supported only on type definitions.',\n        );\n      }\n\n      switch (keywordToken.value) {\n        case 'query':\n        case 'mutation':\n        case 'subscription':\n          return this.parseOperationDefinition();\n\n        case 'fragment':\n          return this.parseFragmentDefinition();\n\n        case 'extend':\n          return this.parseTypeSystemExtension();\n      }\n    }\n\n    throw this.unexpected(keywordToken);\n  } // Implements the parsing rules in the Operations section.\n\n  /**\n   * OperationDefinition :\n   *  - SelectionSet\n   *  - OperationType Name? VariableDefinitions? Directives? SelectionSet\n   */\n\n  parseOperationDefinition() {\n    const start = this._lexer.token;\n\n    if (this.peek(TokenKind.BRACE_L)) {\n      return this.node(start, {\n        kind: Kind.OPERATION_DEFINITION,\n        operation: OperationTypeNode.QUERY,\n        name: undefined,\n        variableDefinitions: [],\n        directives: [],\n        selectionSet: this.parseSelectionSet(),\n      });\n    }\n\n    const operation = this.parseOperationType();\n    let name;\n\n    if (this.peek(TokenKind.NAME)) {\n      name = this.parseName();\n    }\n\n    return this.node(start, {\n      kind: Kind.OPERATION_DEFINITION,\n      operation,\n      name,\n      variableDefinitions: this.parseVariableDefinitions(),\n      directives: this.parseDirectives(false),\n      selectionSet: this.parseSelectionSet(),\n    });\n  }\n  /**\n   * OperationType : one of query mutation subscription\n   */\n\n  parseOperationType() {\n    const operationToken = this.expectToken(TokenKind.NAME);\n\n    switch (operationToken.value) {\n      case 'query':\n        return OperationTypeNode.QUERY;\n\n      case 'mutation':\n        return OperationTypeNode.MUTATION;\n\n      case 'subscription':\n        return OperationTypeNode.SUBSCRIPTION;\n    }\n\n    throw this.unexpected(operationToken);\n  }\n  /**\n   * VariableDefinitions : ( VariableDefinition+ )\n   */\n\n  parseVariableDefinitions() {\n    return this.optionalMany(\n      TokenKind.PAREN_L,\n      this.parseVariableDefinition,\n      TokenKind.PAREN_R,\n    );\n  }\n  /**\n   * VariableDefinition : Variable : Type DefaultValue? Directives[Const]?\n   */\n\n  parseVariableDefinition() {\n    return this.node(this._lexer.token, {\n      kind: Kind.VARIABLE_DEFINITION,\n      variable: this.parseVariable(),\n      type: (this.expectToken(TokenKind.COLON), this.parseTypeReference()),\n      defaultValue: this.expectOptionalToken(TokenKind.EQUALS)\n        ? this.parseConstValueLiteral()\n        : undefined,\n      directives: this.parseConstDirectives(),\n    });\n  }\n  /**\n   * Variable : $ Name\n   */\n\n  parseVariable() {\n    const start = this._lexer.token;\n    this.expectToken(TokenKind.DOLLAR);\n    return this.node(start, {\n      kind: Kind.VARIABLE,\n      name: this.parseName(),\n    });\n  }\n  /**\n   * ```\n   * SelectionSet : { Selection+ }\n   * ```\n   */\n\n  parseSelectionSet() {\n    return this.node(this._lexer.token, {\n      kind: Kind.SELECTION_SET,\n      selections: this.many(\n        TokenKind.BRACE_L,\n        this.parseSelection,\n        TokenKind.BRACE_R,\n      ),\n    });\n  }\n  /**\n   * Selection :\n   *   - Field\n   *   - FragmentSpread\n   *   - InlineFragment\n   */\n\n  parseSelection() {\n    return this.peek(TokenKind.SPREAD)\n      ? this.parseFragment()\n      : this.parseField();\n  }\n  /**\n   * Field : Alias? Name Arguments? Directives? SelectionSet?\n   *\n   * Alias : Name :\n   */\n\n  parseField() {\n    const start = this._lexer.token;\n    const nameOrAlias = this.parseName();\n    let alias;\n    let name;\n\n    if (this.expectOptionalToken(TokenKind.COLON)) {\n      alias = nameOrAlias;\n      name = this.parseName();\n    } else {\n      name = nameOrAlias;\n    }\n\n    return this.node(start, {\n      kind: Kind.FIELD,\n      alias,\n      name,\n      arguments: this.parseArguments(false),\n      directives: this.parseDirectives(false),\n      selectionSet: this.peek(TokenKind.BRACE_L)\n        ? this.parseSelectionSet()\n        : undefined,\n    });\n  }\n  /**\n   * Arguments[Const] : ( Argument[?Const]+ )\n   */\n\n  parseArguments(isConst) {\n    const item = isConst ? this.parseConstArgument : this.parseArgument;\n    return this.optionalMany(TokenKind.PAREN_L, item, TokenKind.PAREN_R);\n  }\n  /**\n   * Argument[Const] : Name : Value[?Const]\n   */\n\n  parseArgument(isConst = false) {\n    const start = this._lexer.token;\n    const name = this.parseName();\n    this.expectToken(TokenKind.COLON);\n    return this.node(start, {\n      kind: Kind.ARGUMENT,\n      name,\n      value: this.parseValueLiteral(isConst),\n    });\n  }\n\n  parseConstArgument() {\n    return this.parseArgument(true);\n  } // Implements the parsing rules in the Fragments section.\n\n  /**\n   * Corresponds to both FragmentSpread and InlineFragment in the spec.\n   *\n   * FragmentSpread : ... FragmentName Directives?\n   *\n   * InlineFragment : ... TypeCondition? Directives? SelectionSet\n   */\n\n  parseFragment() {\n    const start = this._lexer.token;\n    this.expectToken(TokenKind.SPREAD);\n    const hasTypeCondition = this.expectOptionalKeyword('on');\n\n    if (!hasTypeCondition && this.peek(TokenKind.NAME)) {\n      return this.node(start, {\n        kind: Kind.FRAGMENT_SPREAD,\n        name: this.parseFragmentName(),\n        directives: this.parseDirectives(false),\n      });\n    }\n\n    return this.node(start, {\n      kind: Kind.INLINE_FRAGMENT,\n      typeCondition: hasTypeCondition ? this.parseNamedType() : undefined,\n      directives: this.parseDirectives(false),\n      selectionSet: this.parseSelectionSet(),\n    });\n  }\n  /**\n   * FragmentDefinition :\n   *   - fragment FragmentName on TypeCondition Directives? SelectionSet\n   *\n   * TypeCondition : NamedType\n   */\n\n  parseFragmentDefinition() {\n    const start = this._lexer.token;\n    this.expectKeyword('fragment'); // Legacy support for defining variables within fragments changes\n    // the grammar of FragmentDefinition:\n    //   - fragment FragmentName VariableDefinitions? on TypeCondition Directives? SelectionSet\n\n    if (this._options.allowLegacyFragmentVariables === true) {\n      return this.node(start, {\n        kind: Kind.FRAGMENT_DEFINITION,\n        name: this.parseFragmentName(),\n        variableDefinitions: this.parseVariableDefinitions(),\n        typeCondition: (this.expectKeyword('on'), this.parseNamedType()),\n        directives: this.parseDirectives(false),\n        selectionSet: this.parseSelectionSet(),\n      });\n    }\n\n    return this.node(start, {\n      kind: Kind.FRAGMENT_DEFINITION,\n      name: this.parseFragmentName(),\n      typeCondition: (this.expectKeyword('on'), this.parseNamedType()),\n      directives: this.parseDirectives(false),\n      selectionSet: this.parseSelectionSet(),\n    });\n  }\n  /**\n   * FragmentName : Name but not `on`\n   */\n\n  parseFragmentName() {\n    if (this._lexer.token.value === 'on') {\n      throw this.unexpected();\n    }\n\n    return this.parseName();\n  } // Implements the parsing rules in the Values section.\n\n  /**\n   * Value[Const] :\n   *   - [~Const] Variable\n   *   - IntValue\n   *   - FloatValue\n   *   - StringValue\n   *   - BooleanValue\n   *   - NullValue\n   *   - EnumValue\n   *   - ListValue[?Const]\n   *   - ObjectValue[?Const]\n   *\n   * BooleanValue : one of `true` `false`\n   *\n   * NullValue : `null`\n   *\n   * EnumValue : Name but not `true`, `false` or `null`\n   */\n\n  parseValueLiteral(isConst) {\n    const token = this._lexer.token;\n\n    switch (token.kind) {\n      case TokenKind.BRACKET_L:\n        return this.parseList(isConst);\n\n      case TokenKind.BRACE_L:\n        return this.parseObject(isConst);\n\n      case TokenKind.INT:\n        this.advanceLexer();\n        return this.node(token, {\n          kind: Kind.INT,\n          value: token.value,\n        });\n\n      case TokenKind.FLOAT:\n        this.advanceLexer();\n        return this.node(token, {\n          kind: Kind.FLOAT,\n          value: token.value,\n        });\n\n      case TokenKind.STRING:\n      case TokenKind.BLOCK_STRING:\n        return this.parseStringLiteral();\n\n      case TokenKind.NAME:\n        this.advanceLexer();\n\n        switch (token.value) {\n          case 'true':\n            return this.node(token, {\n              kind: Kind.BOOLEAN,\n              value: true,\n            });\n\n          case 'false':\n            return this.node(token, {\n              kind: Kind.BOOLEAN,\n              value: false,\n            });\n\n          case 'null':\n            return this.node(token, {\n              kind: Kind.NULL,\n            });\n\n          default:\n            return this.node(token, {\n              kind: Kind.ENUM,\n              value: token.value,\n            });\n        }\n\n      case TokenKind.DOLLAR:\n        if (isConst) {\n          this.expectToken(TokenKind.DOLLAR);\n\n          if (this._lexer.token.kind === TokenKind.NAME) {\n            const varName = this._lexer.token.value;\n            throw syntaxError(\n              this._lexer.source,\n              token.start,\n              `Unexpected variable \"$${varName}\" in constant value.`,\n            );\n          } else {\n            throw this.unexpected(token);\n          }\n        }\n\n        return this.parseVariable();\n\n      default:\n        throw this.unexpected();\n    }\n  }\n\n  parseConstValueLiteral() {\n    return this.parseValueLiteral(true);\n  }\n\n  parseStringLiteral() {\n    const token = this._lexer.token;\n    this.advanceLexer();\n    return this.node(token, {\n      kind: Kind.STRING,\n      value: token.value,\n      block: token.kind === TokenKind.BLOCK_STRING,\n    });\n  }\n  /**\n   * ListValue[Const] :\n   *   - [ ]\n   *   - [ Value[?Const]+ ]\n   */\n\n  parseList(isConst) {\n    const item = () => this.parseValueLiteral(isConst);\n\n    return this.node(this._lexer.token, {\n      kind: Kind.LIST,\n      values: this.any(TokenKind.BRACKET_L, item, TokenKind.BRACKET_R),\n    });\n  }\n  /**\n   * ```\n   * ObjectValue[Const] :\n   *   - { }\n   *   - { ObjectField[?Const]+ }\n   * ```\n   */\n\n  parseObject(isConst) {\n    const item = () => this.parseObjectField(isConst);\n\n    return this.node(this._lexer.token, {\n      kind: Kind.OBJECT,\n      fields: this.any(TokenKind.BRACE_L, item, TokenKind.BRACE_R),\n    });\n  }\n  /**\n   * ObjectField[Const] : Name : Value[?Const]\n   */\n\n  parseObjectField(isConst) {\n    const start = this._lexer.token;\n    const name = this.parseName();\n    this.expectToken(TokenKind.COLON);\n    return this.node(start, {\n      kind: Kind.OBJECT_FIELD,\n      name,\n      value: this.parseValueLiteral(isConst),\n    });\n  } // Implements the parsing rules in the Directives section.\n\n  /**\n   * Directives[Const] : Directive[?Const]+\n   */\n\n  parseDirectives(isConst) {\n    const directives = [];\n\n    while (this.peek(TokenKind.AT)) {\n      directives.push(this.parseDirective(isConst));\n    }\n\n    return directives;\n  }\n\n  parseConstDirectives() {\n    return this.parseDirectives(true);\n  }\n  /**\n   * ```\n   * Directive[Const] : @ Name Arguments[?Const]?\n   * ```\n   */\n\n  parseDirective(isConst) {\n    const start = this._lexer.token;\n    this.expectToken(TokenKind.AT);\n    return this.node(start, {\n      kind: Kind.DIRECTIVE,\n      name: this.parseName(),\n      arguments: this.parseArguments(isConst),\n    });\n  } // Implements the parsing rules in the Types section.\n\n  /**\n   * Type :\n   *   - NamedType\n   *   - ListType\n   *   - NonNullType\n   */\n\n  parseTypeReference() {\n    const start = this._lexer.token;\n    let type;\n\n    if (this.expectOptionalToken(TokenKind.BRACKET_L)) {\n      const innerType = this.parseTypeReference();\n      this.expectToken(TokenKind.BRACKET_R);\n      type = this.node(start, {\n        kind: Kind.LIST_TYPE,\n        type: innerType,\n      });\n    } else {\n      type = this.parseNamedType();\n    }\n\n    if (this.expectOptionalToken(TokenKind.BANG)) {\n      return this.node(start, {\n        kind: Kind.NON_NULL_TYPE,\n        type,\n      });\n    }\n\n    return type;\n  }\n  /**\n   * NamedType : Name\n   */\n\n  parseNamedType() {\n    return this.node(this._lexer.token, {\n      kind: Kind.NAMED_TYPE,\n      name: this.parseName(),\n    });\n  } // Implements the parsing rules in the Type Definition section.\n\n  peekDescription() {\n    return this.peek(TokenKind.STRING) || this.peek(TokenKind.BLOCK_STRING);\n  }\n  /**\n   * Description : StringValue\n   */\n\n  parseDescription() {\n    if (this.peekDescription()) {\n      return this.parseStringLiteral();\n    }\n  }\n  /**\n   * ```\n   * SchemaDefinition : Description? schema Directives[Const]? { OperationTypeDefinition+ }\n   * ```\n   */\n\n  parseSchemaDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('schema');\n    const directives = this.parseConstDirectives();\n    const operationTypes = this.many(\n      TokenKind.BRACE_L,\n      this.parseOperationTypeDefinition,\n      TokenKind.BRACE_R,\n    );\n    return this.node(start, {\n      kind: Kind.SCHEMA_DEFINITION,\n      description,\n      directives,\n      operationTypes,\n    });\n  }\n  /**\n   * OperationTypeDefinition : OperationType : NamedType\n   */\n\n  parseOperationTypeDefinition() {\n    const start = this._lexer.token;\n    const operation = this.parseOperationType();\n    this.expectToken(TokenKind.COLON);\n    const type = this.parseNamedType();\n    return this.node(start, {\n      kind: Kind.OPERATION_TYPE_DEFINITION,\n      operation,\n      type,\n    });\n  }\n  /**\n   * ScalarTypeDefinition : Description? scalar Name Directives[Const]?\n   */\n\n  parseScalarTypeDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('scalar');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n    return this.node(start, {\n      kind: Kind.SCALAR_TYPE_DEFINITION,\n      description,\n      name,\n      directives,\n    });\n  }\n  /**\n   * ObjectTypeDefinition :\n   *   Description?\n   *   type Name ImplementsInterfaces? Directives[Const]? FieldsDefinition?\n   */\n\n  parseObjectTypeDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('type');\n    const name = this.parseName();\n    const interfaces = this.parseImplementsInterfaces();\n    const directives = this.parseConstDirectives();\n    const fields = this.parseFieldsDefinition();\n    return this.node(start, {\n      kind: Kind.OBJECT_TYPE_DEFINITION,\n      description,\n      name,\n      interfaces,\n      directives,\n      fields,\n    });\n  }\n  /**\n   * ImplementsInterfaces :\n   *   - implements `&`? NamedType\n   *   - ImplementsInterfaces & NamedType\n   */\n\n  parseImplementsInterfaces() {\n    return this.expectOptionalKeyword('implements')\n      ? this.delimitedMany(TokenKind.AMP, this.parseNamedType)\n      : [];\n  }\n  /**\n   * ```\n   * FieldsDefinition : { FieldDefinition+ }\n   * ```\n   */\n\n  parseFieldsDefinition() {\n    return this.optionalMany(\n      TokenKind.BRACE_L,\n      this.parseFieldDefinition,\n      TokenKind.BRACE_R,\n    );\n  }\n  /**\n   * FieldDefinition :\n   *   - Description? Name ArgumentsDefinition? : Type Directives[Const]?\n   */\n\n  parseFieldDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    const name = this.parseName();\n    const args = this.parseArgumentDefs();\n    this.expectToken(TokenKind.COLON);\n    const type = this.parseTypeReference();\n    const directives = this.parseConstDirectives();\n    return this.node(start, {\n      kind: Kind.FIELD_DEFINITION,\n      description,\n      name,\n      arguments: args,\n      type,\n      directives,\n    });\n  }\n  /**\n   * ArgumentsDefinition : ( InputValueDefinition+ )\n   */\n\n  parseArgumentDefs() {\n    return this.optionalMany(\n      TokenKind.PAREN_L,\n      this.parseInputValueDef,\n      TokenKind.PAREN_R,\n    );\n  }\n  /**\n   * InputValueDefinition :\n   *   - Description? Name : Type DefaultValue? Directives[Const]?\n   */\n\n  parseInputValueDef() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    const name = this.parseName();\n    this.expectToken(TokenKind.COLON);\n    const type = this.parseTypeReference();\n    let defaultValue;\n\n    if (this.expectOptionalToken(TokenKind.EQUALS)) {\n      defaultValue = this.parseConstValueLiteral();\n    }\n\n    const directives = this.parseConstDirectives();\n    return this.node(start, {\n      kind: Kind.INPUT_VALUE_DEFINITION,\n      description,\n      name,\n      type,\n      defaultValue,\n      directives,\n    });\n  }\n  /**\n   * InterfaceTypeDefinition :\n   *   - Description? interface Name Directives[Const]? FieldsDefinition?\n   */\n\n  parseInterfaceTypeDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('interface');\n    const name = this.parseName();\n    const interfaces = this.parseImplementsInterfaces();\n    const directives = this.parseConstDirectives();\n    const fields = this.parseFieldsDefinition();\n    return this.node(start, {\n      kind: Kind.INTERFACE_TYPE_DEFINITION,\n      description,\n      name,\n      interfaces,\n      directives,\n      fields,\n    });\n  }\n  /**\n   * UnionTypeDefinition :\n   *   - Description? union Name Directives[Const]? UnionMemberTypes?\n   */\n\n  parseUnionTypeDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('union');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n    const types = this.parseUnionMemberTypes();\n    return this.node(start, {\n      kind: Kind.UNION_TYPE_DEFINITION,\n      description,\n      name,\n      directives,\n      types,\n    });\n  }\n  /**\n   * UnionMemberTypes :\n   *   - = `|`? NamedType\n   *   - UnionMemberTypes | NamedType\n   */\n\n  parseUnionMemberTypes() {\n    return this.expectOptionalToken(TokenKind.EQUALS)\n      ? this.delimitedMany(TokenKind.PIPE, this.parseNamedType)\n      : [];\n  }\n  /**\n   * EnumTypeDefinition :\n   *   - Description? enum Name Directives[Const]? EnumValuesDefinition?\n   */\n\n  parseEnumTypeDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('enum');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n    const values = this.parseEnumValuesDefinition();\n    return this.node(start, {\n      kind: Kind.ENUM_TYPE_DEFINITION,\n      description,\n      name,\n      directives,\n      values,\n    });\n  }\n  /**\n   * ```\n   * EnumValuesDefinition : { EnumValueDefinition+ }\n   * ```\n   */\n\n  parseEnumValuesDefinition() {\n    return this.optionalMany(\n      TokenKind.BRACE_L,\n      this.parseEnumValueDefinition,\n      TokenKind.BRACE_R,\n    );\n  }\n  /**\n   * EnumValueDefinition : Description? EnumValue Directives[Const]?\n   */\n\n  parseEnumValueDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    const name = this.parseEnumValueName();\n    const directives = this.parseConstDirectives();\n    return this.node(start, {\n      kind: Kind.ENUM_VALUE_DEFINITION,\n      description,\n      name,\n      directives,\n    });\n  }\n  /**\n   * EnumValue : Name but not `true`, `false` or `null`\n   */\n\n  parseEnumValueName() {\n    if (\n      this._lexer.token.value === 'true' ||\n      this._lexer.token.value === 'false' ||\n      this._lexer.token.value === 'null'\n    ) {\n      throw syntaxError(\n        this._lexer.source,\n        this._lexer.token.start,\n        `${getTokenDesc(\n          this._lexer.token,\n        )} is reserved and cannot be used for an enum value.`,\n      );\n    }\n\n    return this.parseName();\n  }\n  /**\n   * InputObjectTypeDefinition :\n   *   - Description? input Name Directives[Const]? InputFieldsDefinition?\n   */\n\n  parseInputObjectTypeDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('input');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n    const fields = this.parseInputFieldsDefinition();\n    return this.node(start, {\n      kind: Kind.INPUT_OBJECT_TYPE_DEFINITION,\n      description,\n      name,\n      directives,\n      fields,\n    });\n  }\n  /**\n   * ```\n   * InputFieldsDefinition : { InputValueDefinition+ }\n   * ```\n   */\n\n  parseInputFieldsDefinition() {\n    return this.optionalMany(\n      TokenKind.BRACE_L,\n      this.parseInputValueDef,\n      TokenKind.BRACE_R,\n    );\n  }\n  /**\n   * TypeSystemExtension :\n   *   - SchemaExtension\n   *   - TypeExtension\n   *\n   * TypeExtension :\n   *   - ScalarTypeExtension\n   *   - ObjectTypeExtension\n   *   - InterfaceTypeExtension\n   *   - UnionTypeExtension\n   *   - EnumTypeExtension\n   *   - InputObjectTypeDefinition\n   */\n\n  parseTypeSystemExtension() {\n    const keywordToken = this._lexer.lookahead();\n\n    if (keywordToken.kind === TokenKind.NAME) {\n      switch (keywordToken.value) {\n        case 'schema':\n          return this.parseSchemaExtension();\n\n        case 'scalar':\n          return this.parseScalarTypeExtension();\n\n        case 'type':\n          return this.parseObjectTypeExtension();\n\n        case 'interface':\n          return this.parseInterfaceTypeExtension();\n\n        case 'union':\n          return this.parseUnionTypeExtension();\n\n        case 'enum':\n          return this.parseEnumTypeExtension();\n\n        case 'input':\n          return this.parseInputObjectTypeExtension();\n      }\n    }\n\n    throw this.unexpected(keywordToken);\n  }\n  /**\n   * ```\n   * SchemaExtension :\n   *  - extend schema Directives[Const]? { OperationTypeDefinition+ }\n   *  - extend schema Directives[Const]\n   * ```\n   */\n\n  parseSchemaExtension() {\n    const start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('schema');\n    const directives = this.parseConstDirectives();\n    const operationTypes = this.optionalMany(\n      TokenKind.BRACE_L,\n      this.parseOperationTypeDefinition,\n      TokenKind.BRACE_R,\n    );\n\n    if (directives.length === 0 && operationTypes.length === 0) {\n      throw this.unexpected();\n    }\n\n    return this.node(start, {\n      kind: Kind.SCHEMA_EXTENSION,\n      directives,\n      operationTypes,\n    });\n  }\n  /**\n   * ScalarTypeExtension :\n   *   - extend scalar Name Directives[Const]\n   */\n\n  parseScalarTypeExtension() {\n    const start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('scalar');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n\n    if (directives.length === 0) {\n      throw this.unexpected();\n    }\n\n    return this.node(start, {\n      kind: Kind.SCALAR_TYPE_EXTENSION,\n      name,\n      directives,\n    });\n  }\n  /**\n   * ObjectTypeExtension :\n   *  - extend type Name ImplementsInterfaces? Directives[Const]? FieldsDefinition\n   *  - extend type Name ImplementsInterfaces? Directives[Const]\n   *  - extend type Name ImplementsInterfaces\n   */\n\n  parseObjectTypeExtension() {\n    const start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('type');\n    const name = this.parseName();\n    const interfaces = this.parseImplementsInterfaces();\n    const directives = this.parseConstDirectives();\n    const fields = this.parseFieldsDefinition();\n\n    if (\n      interfaces.length === 0 &&\n      directives.length === 0 &&\n      fields.length === 0\n    ) {\n      throw this.unexpected();\n    }\n\n    return this.node(start, {\n      kind: Kind.OBJECT_TYPE_EXTENSION,\n      name,\n      interfaces,\n      directives,\n      fields,\n    });\n  }\n  /**\n   * InterfaceTypeExtension :\n   *  - extend interface Name ImplementsInterfaces? Directives[Const]? FieldsDefinition\n   *  - extend interface Name ImplementsInterfaces? Directives[Const]\n   *  - extend interface Name ImplementsInterfaces\n   */\n\n  parseInterfaceTypeExtension() {\n    const start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('interface');\n    const name = this.parseName();\n    const interfaces = this.parseImplementsInterfaces();\n    const directives = this.parseConstDirectives();\n    const fields = this.parseFieldsDefinition();\n\n    if (\n      interfaces.length === 0 &&\n      directives.length === 0 &&\n      fields.length === 0\n    ) {\n      throw this.unexpected();\n    }\n\n    return this.node(start, {\n      kind: Kind.INTERFACE_TYPE_EXTENSION,\n      name,\n      interfaces,\n      directives,\n      fields,\n    });\n  }\n  /**\n   * UnionTypeExtension :\n   *   - extend union Name Directives[Const]? UnionMemberTypes\n   *   - extend union Name Directives[Const]\n   */\n\n  parseUnionTypeExtension() {\n    const start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('union');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n    const types = this.parseUnionMemberTypes();\n\n    if (directives.length === 0 && types.length === 0) {\n      throw this.unexpected();\n    }\n\n    return this.node(start, {\n      kind: Kind.UNION_TYPE_EXTENSION,\n      name,\n      directives,\n      types,\n    });\n  }\n  /**\n   * EnumTypeExtension :\n   *   - extend enum Name Directives[Const]? EnumValuesDefinition\n   *   - extend enum Name Directives[Const]\n   */\n\n  parseEnumTypeExtension() {\n    const start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('enum');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n    const values = this.parseEnumValuesDefinition();\n\n    if (directives.length === 0 && values.length === 0) {\n      throw this.unexpected();\n    }\n\n    return this.node(start, {\n      kind: Kind.ENUM_TYPE_EXTENSION,\n      name,\n      directives,\n      values,\n    });\n  }\n  /**\n   * InputObjectTypeExtension :\n   *   - extend input Name Directives[Const]? InputFieldsDefinition\n   *   - extend input Name Directives[Const]\n   */\n\n  parseInputObjectTypeExtension() {\n    const start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('input');\n    const name = this.parseName();\n    const directives = this.parseConstDirectives();\n    const fields = this.parseInputFieldsDefinition();\n\n    if (directives.length === 0 && fields.length === 0) {\n      throw this.unexpected();\n    }\n\n    return this.node(start, {\n      kind: Kind.INPUT_OBJECT_TYPE_EXTENSION,\n      name,\n      directives,\n      fields,\n    });\n  }\n  /**\n   * ```\n   * DirectiveDefinition :\n   *   - Description? directive @ Name ArgumentsDefinition? `repeatable`? on DirectiveLocations\n   * ```\n   */\n\n  parseDirectiveDefinition() {\n    const start = this._lexer.token;\n    const description = this.parseDescription();\n    this.expectKeyword('directive');\n    this.expectToken(TokenKind.AT);\n    const name = this.parseName();\n    const args = this.parseArgumentDefs();\n    const repeatable = this.expectOptionalKeyword('repeatable');\n    this.expectKeyword('on');\n    const locations = this.parseDirectiveLocations();\n    return this.node(start, {\n      kind: Kind.DIRECTIVE_DEFINITION,\n      description,\n      name,\n      arguments: args,\n      repeatable,\n      locations,\n    });\n  }\n  /**\n   * DirectiveLocations :\n   *   - `|`? DirectiveLocation\n   *   - DirectiveLocations | DirectiveLocation\n   */\n\n  parseDirectiveLocations() {\n    return this.delimitedMany(TokenKind.PIPE, this.parseDirectiveLocation);\n  }\n  /*\n   * DirectiveLocation :\n   *   - ExecutableDirectiveLocation\n   *   - TypeSystemDirectiveLocation\n   *\n   * ExecutableDirectiveLocation : one of\n   *   `QUERY`\n   *   `MUTATION`\n   *   `SUBSCRIPTION`\n   *   `FIELD`\n   *   `FRAGMENT_DEFINITION`\n   *   `FRAGMENT_SPREAD`\n   *   `INLINE_FRAGMENT`\n   *\n   * TypeSystemDirectiveLocation : one of\n   *   `SCHEMA`\n   *   `SCALAR`\n   *   `OBJECT`\n   *   `FIELD_DEFINITION`\n   *   `ARGUMENT_DEFINITION`\n   *   `INTERFACE`\n   *   `UNION`\n   *   `ENUM`\n   *   `ENUM_VALUE`\n   *   `INPUT_OBJECT`\n   *   `INPUT_FIELD_DEFINITION`\n   */\n\n  parseDirectiveLocation() {\n    const start = this._lexer.token;\n    const name = this.parseName();\n\n    if (Object.prototype.hasOwnProperty.call(DirectiveLocation, name.value)) {\n      return name;\n    }\n\n    throw this.unexpected(start);\n  } // Core parsing utility functions\n\n  /**\n   * Returns a node that, if configured to do so, sets a \"loc\" field as a\n   * location object, used to identify the place in the source that created a\n   * given parsed object.\n   */\n\n  node(startToken, node) {\n    if (this._options.noLocation !== true) {\n      node.loc = new Location(\n        startToken,\n        this._lexer.lastToken,\n        this._lexer.source,\n      );\n    }\n\n    return node;\n  }\n  /**\n   * Determines if the next token is of a given kind\n   */\n\n  peek(kind) {\n    return this._lexer.token.kind === kind;\n  }\n  /**\n   * If the next token is of the given kind, return that token after advancing the lexer.\n   * Otherwise, do not change the parser state and throw an error.\n   */\n\n  expectToken(kind) {\n    const token = this._lexer.token;\n\n    if (token.kind === kind) {\n      this.advanceLexer();\n      return token;\n    }\n\n    throw syntaxError(\n      this._lexer.source,\n      token.start,\n      `Expected ${getTokenKindDesc(kind)}, found ${getTokenDesc(token)}.`,\n    );\n  }\n  /**\n   * If the next token is of the given kind, return \"true\" after advancing the lexer.\n   * Otherwise, do not change the parser state and return \"false\".\n   */\n\n  expectOptionalToken(kind) {\n    const token = this._lexer.token;\n\n    if (token.kind === kind) {\n      this.advanceLexer();\n      return true;\n    }\n\n    return false;\n  }\n  /**\n   * If the next token is a given keyword, advance the lexer.\n   * Otherwise, do not change the parser state and throw an error.\n   */\n\n  expectKeyword(value) {\n    const token = this._lexer.token;\n\n    if (token.kind === TokenKind.NAME && token.value === value) {\n      this.advanceLexer();\n    } else {\n      throw syntaxError(\n        this._lexer.source,\n        token.start,\n        `Expected \"${value}\", found ${getTokenDesc(token)}.`,\n      );\n    }\n  }\n  /**\n   * If the next token is a given keyword, return \"true\" after advancing the lexer.\n   * Otherwise, do not change the parser state and return \"false\".\n   */\n\n  expectOptionalKeyword(value) {\n    const token = this._lexer.token;\n\n    if (token.kind === TokenKind.NAME && token.value === value) {\n      this.advanceLexer();\n      return true;\n    }\n\n    return false;\n  }\n  /**\n   * Helper function for creating an error when an unexpected lexed token is encountered.\n   */\n\n  unexpected(atToken) {\n    const token =\n      atToken !== null && atToken !== void 0 ? atToken : this._lexer.token;\n    return syntaxError(\n      this._lexer.source,\n      token.start,\n      `Unexpected ${getTokenDesc(token)}.`,\n    );\n  }\n  /**\n   * Returns a possibly empty list of parse nodes, determined by the parseFn.\n   * This list begins with a lex token of openKind and ends with a lex token of closeKind.\n   * Advances the parser to the next lex token after the closing token.\n   */\n\n  any(openKind, parseFn, closeKind) {\n    this.expectToken(openKind);\n    const nodes = [];\n\n    while (!this.expectOptionalToken(closeKind)) {\n      nodes.push(parseFn.call(this));\n    }\n\n    return nodes;\n  }\n  /**\n   * Returns a list of parse nodes, determined by the parseFn.\n   * It can be empty only if open token is missing otherwise it will always return non-empty list\n   * that begins with a lex token of openKind and ends with a lex token of closeKind.\n   * Advances the parser to the next lex token after the closing token.\n   */\n\n  optionalMany(openKind, parseFn, closeKind) {\n    if (this.expectOptionalToken(openKind)) {\n      const nodes = [];\n\n      do {\n        nodes.push(parseFn.call(this));\n      } while (!this.expectOptionalToken(closeKind));\n\n      return nodes;\n    }\n\n    return [];\n  }\n  /**\n   * Returns a non-empty list of parse nodes, determined by the parseFn.\n   * This list begins with a lex token of openKind and ends with a lex token of closeKind.\n   * Advances the parser to the next lex token after the closing token.\n   */\n\n  many(openKind, parseFn, closeKind) {\n    this.expectToken(openKind);\n    const nodes = [];\n\n    do {\n      nodes.push(parseFn.call(this));\n    } while (!this.expectOptionalToken(closeKind));\n\n    return nodes;\n  }\n  /**\n   * Returns a non-empty list of parse nodes, determined by the parseFn.\n   * This list may begin with a lex token of delimiterKind followed by items separated by lex tokens of tokenKind.\n   * Advances the parser to the next lex token after last item in the list.\n   */\n\n  delimitedMany(delimiterKind, parseFn) {\n    this.expectOptionalToken(delimiterKind);\n    const nodes = [];\n\n    do {\n      nodes.push(parseFn.call(this));\n    } while (this.expectOptionalToken(delimiterKind));\n\n    return nodes;\n  }\n\n  advanceLexer() {\n    const { maxTokens } = this._options;\n\n    const token = this._lexer.advance();\n\n    if (token.kind !== TokenKind.EOF) {\n      ++this._tokenCounter;\n\n      if (maxTokens !== undefined && this._tokenCounter > maxTokens) {\n        throw syntaxError(\n          this._lexer.source,\n          token.start,\n          `Document contains more that ${maxTokens} tokens. Parsing aborted.`,\n        );\n      }\n    }\n  }\n}\n/**\n * A helper function to describe a token as a string for debugging.\n */\n\nfunction getTokenDesc(token) {\n  const value = token.value;\n  return getTokenKindDesc(token.kind) + (value != null ? ` \"${value}\"` : '');\n}\n/**\n * A helper function to describe a token kind as a string for debugging.\n */\n\nfunction getTokenKindDesc(kind) {\n  return isPunctuatorTokenKind(kind) ? `\"${kind}\"` : kind;\n}\n","import { getLocation } from './location.mjs';\n\n/**\n * Render a helpful description of the location in the GraphQL Source document.\n */\nexport function printLocation(location) {\n  return printSourceLocation(\n    location.source,\n    getLocation(location.source, location.start),\n  );\n}\n/**\n * Render a helpful description of the location in the GraphQL Source document.\n */\n\nexport function printSourceLocation(source, sourceLocation) {\n  const firstLineColumnOffset = source.locationOffset.column - 1;\n  const body = ''.padStart(firstLineColumnOffset) + source.body;\n  const lineIndex = sourceLocation.line - 1;\n  const lineOffset = source.locationOffset.line - 1;\n  const lineNum = sourceLocation.line + lineOffset;\n  const columnOffset = sourceLocation.line === 1 ? firstLineColumnOffset : 0;\n  const columnNum = sourceLocation.column + columnOffset;\n  const locationStr = `${source.name}:${lineNum}:${columnNum}\\n`;\n  const lines = body.split(/\\r\\n|[\\n\\r]/g);\n  const locationLine = lines[lineIndex]; // Special case for minified documents\n\n  if (locationLine.length > 120) {\n    const subLineIndex = Math.floor(columnNum / 80);\n    const subLineColumnNum = columnNum % 80;\n    const subLines = [];\n\n    for (let i = 0; i < locationLine.length; i += 80) {\n      subLines.push(locationLine.slice(i, i + 80));\n    }\n\n    return (\n      locationStr +\n      printPrefixedLines([\n        [`${lineNum} |`, subLines[0]],\n        ...subLines.slice(1, subLineIndex + 1).map((subLine) => ['|', subLine]),\n        ['|', '^'.padStart(subLineColumnNum)],\n        ['|', subLines[subLineIndex + 1]],\n      ])\n    );\n  }\n\n  return (\n    locationStr +\n    printPrefixedLines([\n      // Lines specified like this: [\"prefix\", \"string\"],\n      [`${lineNum - 1} |`, lines[lineIndex - 1]],\n      [`${lineNum} |`, locationLine],\n      ['|', '^'.padStart(columnNum)],\n      [`${lineNum + 1} |`, lines[lineIndex + 1]],\n    ])\n  );\n}\n\nfunction printPrefixedLines(lines) {\n  const existingLines = lines.filter(([_, line]) => line !== undefined);\n  const padLen = Math.max(...existingLines.map(([prefix]) => prefix.length));\n  return existingLines\n    .map(([prefix, line]) => prefix.padStart(padLen) + (line ? ' ' + line : ''))\n    .join('\\n');\n}\n","/**\n * Prints a string as a GraphQL StringValue literal. Replaces control characters\n * and excluded characters (\" U+0022 and \\\\ U+005C) with escape sequences.\n */\nexport function printString(str) {\n  return `\"${str.replace(escapedRegExp, escapedReplacer)}\"`;\n} // eslint-disable-next-line no-control-regex\n\nconst escapedRegExp = /[\\x00-\\x1f\\x22\\x5c\\x7f-\\x9f]/g;\n\nfunction escapedReplacer(str) {\n  return escapeSequences[str.charCodeAt(0)];\n} // prettier-ignore\n\nconst escapeSequences = [\n  '\\\\u0000',\n  '\\\\u0001',\n  '\\\\u0002',\n  '\\\\u0003',\n  '\\\\u0004',\n  '\\\\u0005',\n  '\\\\u0006',\n  '\\\\u0007',\n  '\\\\b',\n  '\\\\t',\n  '\\\\n',\n  '\\\\u000B',\n  '\\\\f',\n  '\\\\r',\n  '\\\\u000E',\n  '\\\\u000F',\n  '\\\\u0010',\n  '\\\\u0011',\n  '\\\\u0012',\n  '\\\\u0013',\n  '\\\\u0014',\n  '\\\\u0015',\n  '\\\\u0016',\n  '\\\\u0017',\n  '\\\\u0018',\n  '\\\\u0019',\n  '\\\\u001A',\n  '\\\\u001B',\n  '\\\\u001C',\n  '\\\\u001D',\n  '\\\\u001E',\n  '\\\\u001F',\n  '',\n  '',\n  '\\\\\"',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 2F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 3F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 4F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '\\\\\\\\',\n  '',\n  '',\n  '', // 5F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 6F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '\\\\u007F',\n  '\\\\u0080',\n  '\\\\u0081',\n  '\\\\u0082',\n  '\\\\u0083',\n  '\\\\u0084',\n  '\\\\u0085',\n  '\\\\u0086',\n  '\\\\u0087',\n  '\\\\u0088',\n  '\\\\u0089',\n  '\\\\u008A',\n  '\\\\u008B',\n  '\\\\u008C',\n  '\\\\u008D',\n  '\\\\u008E',\n  '\\\\u008F',\n  '\\\\u0090',\n  '\\\\u0091',\n  '\\\\u0092',\n  '\\\\u0093',\n  '\\\\u0094',\n  '\\\\u0095',\n  '\\\\u0096',\n  '\\\\u0097',\n  '\\\\u0098',\n  '\\\\u0099',\n  '\\\\u009A',\n  '\\\\u009B',\n  '\\\\u009C',\n  '\\\\u009D',\n  '\\\\u009E',\n  '\\\\u009F',\n];\n","import { printBlockString } from './blockString.mjs';\nimport { printString } from './printString.mjs';\nimport { visit } from './visitor.mjs';\n/**\n * Converts an AST into a string, using one set of reasonable\n * formatting rules.\n */\n\nexport function print(ast) {\n  return visit(ast, printDocASTReducer);\n}\nconst MAX_LINE_LENGTH = 80;\nconst printDocASTReducer = {\n  Name: {\n    leave: (node) => node.value,\n  },\n  Variable: {\n    leave: (node) => '$' + node.name,\n  },\n  // Document\n  Document: {\n    leave: (node) => join(node.definitions, '\\n\\n'),\n  },\n  OperationDefinition: {\n    leave(node) {\n      const varDefs = wrap('(', join(node.variableDefinitions, ', '), ')');\n      const prefix = join(\n        [\n          node.operation,\n          join([node.name, varDefs]),\n          join(node.directives, ' '),\n        ],\n        ' ',\n      ); // Anonymous queries with no directives or variable definitions can use\n      // the query short form.\n\n      return (prefix === 'query' ? '' : prefix + ' ') + node.selectionSet;\n    },\n  },\n  VariableDefinition: {\n    leave: ({ variable, type, defaultValue, directives }) =>\n      variable +\n      ': ' +\n      type +\n      wrap(' = ', defaultValue) +\n      wrap(' ', join(directives, ' ')),\n  },\n  SelectionSet: {\n    leave: ({ selections }) => block(selections),\n  },\n  Field: {\n    leave({ alias, name, arguments: args, directives, selectionSet }) {\n      const prefix = wrap('', alias, ': ') + name;\n      let argsLine = prefix + wrap('(', join(args, ', '), ')');\n\n      if (argsLine.length > MAX_LINE_LENGTH) {\n        argsLine = prefix + wrap('(\\n', indent(join(args, '\\n')), '\\n)');\n      }\n\n      return join([argsLine, join(directives, ' '), selectionSet], ' ');\n    },\n  },\n  Argument: {\n    leave: ({ name, value }) => name + ': ' + value,\n  },\n  // Fragments\n  FragmentSpread: {\n    leave: ({ name, directives }) =>\n      '...' + name + wrap(' ', join(directives, ' ')),\n  },\n  InlineFragment: {\n    leave: ({ typeCondition, directives, selectionSet }) =>\n      join(\n        [\n          '...',\n          wrap('on ', typeCondition),\n          join(directives, ' '),\n          selectionSet,\n        ],\n        ' ',\n      ),\n  },\n  FragmentDefinition: {\n    leave: (\n      { name, typeCondition, variableDefinitions, directives, selectionSet }, // Note: fragment variable definitions are experimental and may be changed\n    ) =>\n      // or removed in the future.\n      `fragment ${name}${wrap('(', join(variableDefinitions, ', '), ')')} ` +\n      `on ${typeCondition} ${wrap('', join(directives, ' '), ' ')}` +\n      selectionSet,\n  },\n  // Value\n  IntValue: {\n    leave: ({ value }) => value,\n  },\n  FloatValue: {\n    leave: ({ value }) => value,\n  },\n  StringValue: {\n    leave: ({ value, block: isBlockString }) =>\n      isBlockString ? printBlockString(value) : printString(value),\n  },\n  BooleanValue: {\n    leave: ({ value }) => (value ? 'true' : 'false'),\n  },\n  NullValue: {\n    leave: () => 'null',\n  },\n  EnumValue: {\n    leave: ({ value }) => value,\n  },\n  ListValue: {\n    leave: ({ values }) => '[' + join(values, ', ') + ']',\n  },\n  ObjectValue: {\n    leave: ({ fields }) => '{' + join(fields, ', ') + '}',\n  },\n  ObjectField: {\n    leave: ({ name, value }) => name + ': ' + value,\n  },\n  // Directive\n  Directive: {\n    leave: ({ name, arguments: args }) =>\n      '@' + name + wrap('(', join(args, ', '), ')'),\n  },\n  // Type\n  NamedType: {\n    leave: ({ name }) => name,\n  },\n  ListType: {\n    leave: ({ type }) => '[' + type + ']',\n  },\n  NonNullType: {\n    leave: ({ type }) => type + '!',\n  },\n  // Type System Definitions\n  SchemaDefinition: {\n    leave: ({ description, directives, operationTypes }) =>\n      wrap('', description, '\\n') +\n      join(['schema', join(directives, ' '), block(operationTypes)], ' '),\n  },\n  OperationTypeDefinition: {\n    leave: ({ operation, type }) => operation + ': ' + type,\n  },\n  ScalarTypeDefinition: {\n    leave: ({ description, name, directives }) =>\n      wrap('', description, '\\n') +\n      join(['scalar', name, join(directives, ' ')], ' '),\n  },\n  ObjectTypeDefinition: {\n    leave: ({ description, name, interfaces, directives, fields }) =>\n      wrap('', description, '\\n') +\n      join(\n        [\n          'type',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  FieldDefinition: {\n    leave: ({ description, name, arguments: args, type, directives }) =>\n      wrap('', description, '\\n') +\n      name +\n      (hasMultilineItems(args)\n        ? wrap('(\\n', indent(join(args, '\\n')), '\\n)')\n        : wrap('(', join(args, ', '), ')')) +\n      ': ' +\n      type +\n      wrap(' ', join(directives, ' ')),\n  },\n  InputValueDefinition: {\n    leave: ({ description, name, type, defaultValue, directives }) =>\n      wrap('', description, '\\n') +\n      join(\n        [name + ': ' + type, wrap('= ', defaultValue), join(directives, ' ')],\n        ' ',\n      ),\n  },\n  InterfaceTypeDefinition: {\n    leave: ({ description, name, interfaces, directives, fields }) =>\n      wrap('', description, '\\n') +\n      join(\n        [\n          'interface',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  UnionTypeDefinition: {\n    leave: ({ description, name, directives, types }) =>\n      wrap('', description, '\\n') +\n      join(\n        ['union', name, join(directives, ' '), wrap('= ', join(types, ' | '))],\n        ' ',\n      ),\n  },\n  EnumTypeDefinition: {\n    leave: ({ description, name, directives, values }) =>\n      wrap('', description, '\\n') +\n      join(['enum', name, join(directives, ' '), block(values)], ' '),\n  },\n  EnumValueDefinition: {\n    leave: ({ description, name, directives }) =>\n      wrap('', description, '\\n') + join([name, join(directives, ' ')], ' '),\n  },\n  InputObjectTypeDefinition: {\n    leave: ({ description, name, directives, fields }) =>\n      wrap('', description, '\\n') +\n      join(['input', name, join(directives, ' '), block(fields)], ' '),\n  },\n  DirectiveDefinition: {\n    leave: ({ description, name, arguments: args, repeatable, locations }) =>\n      wrap('', description, '\\n') +\n      'directive @' +\n      name +\n      (hasMultilineItems(args)\n        ? wrap('(\\n', indent(join(args, '\\n')), '\\n)')\n        : wrap('(', join(args, ', '), ')')) +\n      (repeatable ? ' repeatable' : '') +\n      ' on ' +\n      join(locations, ' | '),\n  },\n  SchemaExtension: {\n    leave: ({ directives, operationTypes }) =>\n      join(\n        ['extend schema', join(directives, ' '), block(operationTypes)],\n        ' ',\n      ),\n  },\n  ScalarTypeExtension: {\n    leave: ({ name, directives }) =>\n      join(['extend scalar', name, join(directives, ' ')], ' '),\n  },\n  ObjectTypeExtension: {\n    leave: ({ name, interfaces, directives, fields }) =>\n      join(\n        [\n          'extend type',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  InterfaceTypeExtension: {\n    leave: ({ name, interfaces, directives, fields }) =>\n      join(\n        [\n          'extend interface',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  UnionTypeExtension: {\n    leave: ({ name, directives, types }) =>\n      join(\n        [\n          'extend union',\n          name,\n          join(directives, ' '),\n          wrap('= ', join(types, ' | ')),\n        ],\n        ' ',\n      ),\n  },\n  EnumTypeExtension: {\n    leave: ({ name, directives, values }) =>\n      join(['extend enum', name, join(directives, ' '), block(values)], ' '),\n  },\n  InputObjectTypeExtension: {\n    leave: ({ name, directives, fields }) =>\n      join(['extend input', name, join(directives, ' '), block(fields)], ' '),\n  },\n};\n/**\n * Given maybeArray, print an empty string if it is null or empty, otherwise\n * print all items together separated by separator if provided\n */\n\nfunction join(maybeArray, separator = '') {\n  var _maybeArray$filter$jo;\n\n  return (_maybeArray$filter$jo =\n    maybeArray === null || maybeArray === void 0\n      ? void 0\n      : maybeArray.filter((x) => x).join(separator)) !== null &&\n    _maybeArray$filter$jo !== void 0\n    ? _maybeArray$filter$jo\n    : '';\n}\n/**\n * Given array, print each item on its own line, wrapped in an indented `{ }` block.\n */\n\nfunction block(array) {\n  return wrap('{\\n', indent(join(array, '\\n')), '\\n}');\n}\n/**\n * If maybeString is not null or empty, then wrap with start and end, otherwise print an empty string.\n */\n\nfunction wrap(start, maybeString, end = '') {\n  return maybeString != null && maybeString !== ''\n    ? start + maybeString + end\n    : '';\n}\n\nfunction indent(str) {\n  return wrap('  ', str.replace(/\\n/g, '\\n  '));\n}\n\nfunction hasMultilineItems(maybeArray) {\n  var _maybeArray$some;\n\n  // FIXME: https://github.com/graphql/graphql-js/issues/2203\n\n  /* c8 ignore next */\n  return (_maybeArray$some =\n    maybeArray === null || maybeArray === void 0\n      ? void 0\n      : maybeArray.some((str) => str.includes('\\n'))) !== null &&\n    _maybeArray$some !== void 0\n    ? _maybeArray$some\n    : false;\n}\n","import { devAssert } from '../jsutils/devAssert.mjs';\nimport { inspect } from '../jsutils/inspect.mjs';\nimport { instanceOf } from '../jsutils/instanceOf.mjs';\n\n/**\n * A representation of source input to GraphQL. The `name` and `locationOffset` parameters are\n * optional, but they are useful for clients who store GraphQL documents in source files.\n * For example, if the GraphQL input starts at line 40 in a file named `Foo.graphql`, it might\n * be useful for `name` to be `\"Foo.graphql\"` and location to be `{ line: 40, column: 1 }`.\n * The `line` and `column` properties in `locationOffset` are 1-indexed.\n */\nexport class Source {\n  constructor(\n    body,\n    name = 'GraphQL request',\n    locationOffset = {\n      line: 1,\n      column: 1,\n    },\n  ) {\n    typeof body === 'string' ||\n      devAssert(false, `Body must be a string. Received: ${inspect(body)}.`);\n    this.body = body;\n    this.name = name;\n    this.locationOffset = locationOffset;\n    this.locationOffset.line > 0 ||\n      devAssert(\n        false,\n        'line in locationOffset is 1-indexed and must be positive.',\n      );\n    this.locationOffset.column > 0 ||\n      devAssert(\n        false,\n        'column in locationOffset is 1-indexed and must be positive.',\n      );\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'Source';\n  }\n}\n/**\n * Test if the given value is a Source object.\n *\n * @internal\n */\n\nexport function isSource(source) {\n  return instanceOf(source, Source);\n}\n","/**\n * An exported enum describing the different kinds of tokens that the\n * lexer emits.\n */\nvar TokenKind;\n\n(function (TokenKind) {\n  TokenKind['SOF'] = '<SOF>';\n  TokenKind['EOF'] = '<EOF>';\n  TokenKind['BANG'] = '!';\n  TokenKind['DOLLAR'] = '$';\n  TokenKind['AMP'] = '&';\n  TokenKind['PAREN_L'] = '(';\n  TokenKind['PAREN_R'] = ')';\n  TokenKind['SPREAD'] = '...';\n  TokenKind['COLON'] = ':';\n  TokenKind['EQUALS'] = '=';\n  TokenKind['AT'] = '@';\n  TokenKind['BRACKET_L'] = '[';\n  TokenKind['BRACKET_R'] = ']';\n  TokenKind['BRACE_L'] = '{';\n  TokenKind['PIPE'] = '|';\n  TokenKind['BRACE_R'] = '}';\n  TokenKind['NAME'] = 'Name';\n  TokenKind['INT'] = 'Int';\n  TokenKind['FLOAT'] = 'Float';\n  TokenKind['STRING'] = 'String';\n  TokenKind['BLOCK_STRING'] = 'BlockString';\n  TokenKind['COMMENT'] = 'Comment';\n})(TokenKind || (TokenKind = {}));\n\nexport { TokenKind };\n/**\n * The enum type representing the token kinds values.\n *\n * @deprecated Please use `TokenKind`. Will be remove in v17.\n */\n","import { devAssert } from '../jsutils/devAssert.mjs';\nimport { inspect } from '../jsutils/inspect.mjs';\nimport { isNode, QueryDocumentKeys } from './ast.mjs';\nimport { Kind } from './kinds.mjs';\n/**\n * A visitor is provided to visit, it contains the collection of\n * relevant functions to be called during the visitor's traversal.\n */\n\nexport const BREAK = Object.freeze({});\n/**\n * visit() will walk through an AST using a depth-first traversal, calling\n * the visitor's enter function at each node in the traversal, and calling the\n * leave function after visiting that node and all of its child nodes.\n *\n * By returning different values from the enter and leave functions, the\n * behavior of the visitor can be altered, including skipping over a sub-tree of\n * the AST (by returning false), editing the AST by returning a value or null\n * to remove the value, or to stop the whole traversal by returning BREAK.\n *\n * When using visit() to edit an AST, the original AST will not be modified, and\n * a new version of the AST with the changes applied will be returned from the\n * visit function.\n *\n * ```ts\n * const editedAST = visit(ast, {\n *   enter(node, key, parent, path, ancestors) {\n *     // @return\n *     //   undefined: no action\n *     //   false: skip visiting this node\n *     //   visitor.BREAK: stop visiting altogether\n *     //   null: delete this node\n *     //   any value: replace this node with the returned value\n *   },\n *   leave(node, key, parent, path, ancestors) {\n *     // @return\n *     //   undefined: no action\n *     //   false: no action\n *     //   visitor.BREAK: stop visiting altogether\n *     //   null: delete this node\n *     //   any value: replace this node with the returned value\n *   }\n * });\n * ```\n *\n * Alternatively to providing enter() and leave() functions, a visitor can\n * instead provide functions named the same as the kinds of AST nodes, or\n * enter/leave visitors at a named key, leading to three permutations of the\n * visitor API:\n *\n * 1) Named visitors triggered when entering a node of a specific kind.\n *\n * ```ts\n * visit(ast, {\n *   Kind(node) {\n *     // enter the \"Kind\" node\n *   }\n * })\n * ```\n *\n * 2) Named visitors that trigger upon entering and leaving a node of a specific kind.\n *\n * ```ts\n * visit(ast, {\n *   Kind: {\n *     enter(node) {\n *       // enter the \"Kind\" node\n *     }\n *     leave(node) {\n *       // leave the \"Kind\" node\n *     }\n *   }\n * })\n * ```\n *\n * 3) Generic visitors that trigger upon entering and leaving any node.\n *\n * ```ts\n * visit(ast, {\n *   enter(node) {\n *     // enter any node\n *   },\n *   leave(node) {\n *     // leave any node\n *   }\n * })\n * ```\n */\n\nexport function visit(root, visitor, visitorKeys = QueryDocumentKeys) {\n  const enterLeaveMap = new Map();\n\n  for (const kind of Object.values(Kind)) {\n    enterLeaveMap.set(kind, getEnterLeaveForKind(visitor, kind));\n  }\n  /* eslint-disable no-undef-init */\n\n  let stack = undefined;\n  let inArray = Array.isArray(root);\n  let keys = [root];\n  let index = -1;\n  let edits = [];\n  let node = root;\n  let key = undefined;\n  let parent = undefined;\n  const path = [];\n  const ancestors = [];\n  /* eslint-enable no-undef-init */\n\n  do {\n    index++;\n    const isLeaving = index === keys.length;\n    const isEdited = isLeaving && edits.length !== 0;\n\n    if (isLeaving) {\n      key = ancestors.length === 0 ? undefined : path[path.length - 1];\n      node = parent;\n      parent = ancestors.pop();\n\n      if (isEdited) {\n        if (inArray) {\n          node = node.slice();\n          let editOffset = 0;\n\n          for (const [editKey, editValue] of edits) {\n            const arrayKey = editKey - editOffset;\n\n            if (editValue === null) {\n              node.splice(arrayKey, 1);\n              editOffset++;\n            } else {\n              node[arrayKey] = editValue;\n            }\n          }\n        } else {\n          node = { ...node };\n\n          for (const [editKey, editValue] of edits) {\n            node[editKey] = editValue;\n          }\n        }\n      }\n\n      index = stack.index;\n      keys = stack.keys;\n      edits = stack.edits;\n      inArray = stack.inArray;\n      stack = stack.prev;\n    } else if (parent) {\n      key = inArray ? index : keys[index];\n      node = parent[key];\n\n      if (node === null || node === undefined) {\n        continue;\n      }\n\n      path.push(key);\n    }\n\n    let result;\n\n    if (!Array.isArray(node)) {\n      var _enterLeaveMap$get, _enterLeaveMap$get2;\n\n      isNode(node) || devAssert(false, `Invalid AST Node: ${inspect(node)}.`);\n      const visitFn = isLeaving\n        ? (_enterLeaveMap$get = enterLeaveMap.get(node.kind)) === null ||\n          _enterLeaveMap$get === void 0\n          ? void 0\n          : _enterLeaveMap$get.leave\n        : (_enterLeaveMap$get2 = enterLeaveMap.get(node.kind)) === null ||\n          _enterLeaveMap$get2 === void 0\n        ? void 0\n        : _enterLeaveMap$get2.enter;\n      result =\n        visitFn === null || visitFn === void 0\n          ? void 0\n          : visitFn.call(visitor, node, key, parent, path, ancestors);\n\n      if (result === BREAK) {\n        break;\n      }\n\n      if (result === false) {\n        if (!isLeaving) {\n          path.pop();\n          continue;\n        }\n      } else if (result !== undefined) {\n        edits.push([key, result]);\n\n        if (!isLeaving) {\n          if (isNode(result)) {\n            node = result;\n          } else {\n            path.pop();\n            continue;\n          }\n        }\n      }\n    }\n\n    if (result === undefined && isEdited) {\n      edits.push([key, node]);\n    }\n\n    if (isLeaving) {\n      path.pop();\n    } else {\n      var _node$kind;\n\n      stack = {\n        inArray,\n        index,\n        keys,\n        edits,\n        prev: stack,\n      };\n      inArray = Array.isArray(node);\n      keys = inArray\n        ? node\n        : (_node$kind = visitorKeys[node.kind]) !== null &&\n          _node$kind !== void 0\n        ? _node$kind\n        : [];\n      index = -1;\n      edits = [];\n\n      if (parent) {\n        ancestors.push(parent);\n      }\n\n      parent = node;\n    }\n  } while (stack !== undefined);\n\n  if (edits.length !== 0) {\n    // New root\n    return edits[edits.length - 1][1];\n  }\n\n  return root;\n}\n/**\n * Creates a new visitor instance which delegates to many visitors to run in\n * parallel. Each visitor will be visited for each node before moving on.\n *\n * If a prior visitor edits a node, no following visitors will see that node.\n */\n\nexport function visitInParallel(visitors) {\n  const skipping = new Array(visitors.length).fill(null);\n  const mergedVisitor = Object.create(null);\n\n  for (const kind of Object.values(Kind)) {\n    let hasVisitor = false;\n    const enterList = new Array(visitors.length).fill(undefined);\n    const leaveList = new Array(visitors.length).fill(undefined);\n\n    for (let i = 0; i < visitors.length; ++i) {\n      const { enter, leave } = getEnterLeaveForKind(visitors[i], kind);\n      hasVisitor || (hasVisitor = enter != null || leave != null);\n      enterList[i] = enter;\n      leaveList[i] = leave;\n    }\n\n    if (!hasVisitor) {\n      continue;\n    }\n\n    const mergedEnterLeave = {\n      enter(...args) {\n        const node = args[0];\n\n        for (let i = 0; i < visitors.length; i++) {\n          if (skipping[i] === null) {\n            var _enterList$i;\n\n            const result =\n              (_enterList$i = enterList[i]) === null || _enterList$i === void 0\n                ? void 0\n                : _enterList$i.apply(visitors[i], args);\n\n            if (result === false) {\n              skipping[i] = node;\n            } else if (result === BREAK) {\n              skipping[i] = BREAK;\n            } else if (result !== undefined) {\n              return result;\n            }\n          }\n        }\n      },\n\n      leave(...args) {\n        const node = args[0];\n\n        for (let i = 0; i < visitors.length; i++) {\n          if (skipping[i] === null) {\n            var _leaveList$i;\n\n            const result =\n              (_leaveList$i = leaveList[i]) === null || _leaveList$i === void 0\n                ? void 0\n                : _leaveList$i.apply(visitors[i], args);\n\n            if (result === BREAK) {\n              skipping[i] = BREAK;\n            } else if (result !== undefined && result !== false) {\n              return result;\n            }\n          } else if (skipping[i] === node) {\n            skipping[i] = null;\n          }\n        }\n      },\n    };\n    mergedVisitor[kind] = mergedEnterLeave;\n  }\n\n  return mergedVisitor;\n}\n/**\n * Given a visitor instance and a node kind, return EnterLeaveVisitor for that kind.\n */\n\nexport function getEnterLeaveForKind(visitor, kind) {\n  const kindVisitor = visitor[kind];\n\n  if (typeof kindVisitor === 'object') {\n    // { Kind: { enter() {}, leave() {} } }\n    return kindVisitor;\n  } else if (typeof kindVisitor === 'function') {\n    // { Kind() {} }\n    return {\n      enter: kindVisitor,\n      leave: undefined,\n    };\n  } // { enter() {}, leave() {} }\n\n  return {\n    enter: visitor.enter,\n    leave: visitor.leave,\n  };\n}\n/**\n * Given a visitor instance, if it is leaving or not, and a node kind, return\n * the function the visitor runtime should call.\n *\n * @deprecated Please use `getEnterLeaveForKind` instead. Will be removed in v17\n */\n\n/* c8 ignore next 8 */\n\nexport function getVisitFn(visitor, kind, isLeaving) {\n  const { enter, leave } = getEnterLeaveForKind(visitor, kind);\n  return isLeaving ? leave : enter;\n}\n","import { Slot } from \"@wry/context\";\nexport const parentEntrySlot = new Slot();\nexport function nonReactive(fn) {\n    return parentEntrySlot.withValue(void 0, fn);\n}\nexport { Slot };\nexport { bind as bindContext, noContext, setTimeout, asyncFromGen, } from \"@wry/context\";\n//# sourceMappingURL=context.js.map","import { parentEntrySlot } from \"./context.js\";\nimport { hasOwnProperty, maybeUnsubscribe, arrayFromSet, } from \"./helpers.js\";\nconst EntryMethods = {\n    setDirty: true,\n    dispose: true,\n    forget: true, // Fully remove parent Entry from LRU cache and computation graph\n};\nexport function dep(options) {\n    const depsByKey = new Map();\n    const subscribe = options && options.subscribe;\n    function depend(key) {\n        const parent = parentEntrySlot.getValue();\n        if (parent) {\n            let dep = depsByKey.get(key);\n            if (!dep) {\n                depsByKey.set(key, dep = new Set);\n            }\n            parent.dependOn(dep);\n            if (typeof subscribe === \"function\") {\n                maybeUnsubscribe(dep);\n                dep.unsubscribe = subscribe(key);\n            }\n        }\n    }\n    depend.dirty = function dirty(key, entryMethodName) {\n        const dep = depsByKey.get(key);\n        if (dep) {\n            const m = (entryMethodName &&\n                hasOwnProperty.call(EntryMethods, entryMethodName)) ? entryMethodName : \"setDirty\";\n            // We have to use arrayFromSet(dep).forEach instead of dep.forEach,\n            // because modifying a Set while iterating over it can cause elements in\n            // the Set to be removed from the Set before they've been iterated over.\n            arrayFromSet(dep).forEach(entry => entry[m]());\n            depsByKey.delete(key);\n            maybeUnsubscribe(dep);\n        }\n    };\n    return depend;\n}\n//# sourceMappingURL=dep.js.map","import { parentEntrySlot } from \"./context.js\";\nimport { maybeUnsubscribe, arrayFromSet } from \"./helpers.js\";\nconst emptySetPool = [];\nconst POOL_TARGET_SIZE = 100;\n// Since this package might be used browsers, we should avoid using the\n// Node built-in assert module.\nfunction assert(condition, optionalMessage) {\n    if (!condition) {\n        throw new Error(optionalMessage || \"assertion failure\");\n    }\n}\nfunction valueIs(a, b) {\n    const len = a.length;\n    return (\n    // Unknown values are not equal to each other.\n    len > 0 &&\n        // Both values must be ordinary (or both exceptional) to be equal.\n        len === b.length &&\n        // The underlying value or exception must be the same.\n        a[len - 1] === b[len - 1]);\n}\nfunction valueGet(value) {\n    switch (value.length) {\n        case 0: throw new Error(\"unknown value\");\n        case 1: return value[0];\n        case 2: throw value[1];\n    }\n}\nfunction valueCopy(value) {\n    return value.slice(0);\n}\nexport class Entry {\n    constructor(fn) {\n        this.fn = fn;\n        this.parents = new Set();\n        this.childValues = new Map();\n        // When this Entry has children that are dirty, this property becomes\n        // a Set containing other Entry objects, borrowed from emptySetPool.\n        // When the set becomes empty, it gets recycled back to emptySetPool.\n        this.dirtyChildren = null;\n        this.dirty = true;\n        this.recomputing = false;\n        this.value = [];\n        this.deps = null;\n        ++Entry.count;\n    }\n    peek() {\n        if (this.value.length === 1 && !mightBeDirty(this)) {\n            rememberParent(this);\n            return this.value[0];\n        }\n    }\n    // This is the most important method of the Entry API, because it\n    // determines whether the cached this.value can be returned immediately,\n    // or must be recomputed. The overall performance of the caching system\n    // depends on the truth of the following observations: (1) this.dirty is\n    // usually false, (2) this.dirtyChildren is usually null/empty, and thus\n    // (3) valueGet(this.value) is usually returned without recomputation.\n    recompute(args) {\n        assert(!this.recomputing, \"already recomputing\");\n        rememberParent(this);\n        return mightBeDirty(this)\n            ? reallyRecompute(this, args)\n            : valueGet(this.value);\n    }\n    setDirty() {\n        if (this.dirty)\n            return;\n        this.dirty = true;\n        reportDirty(this);\n        // We can go ahead and unsubscribe here, since any further dirty\n        // notifications we receive will be redundant, and unsubscribing may\n        // free up some resources, e.g. file watchers.\n        maybeUnsubscribe(this);\n    }\n    dispose() {\n        this.setDirty();\n        // Sever any dependency relationships with our own children, so those\n        // children don't retain this parent Entry in their child.parents sets,\n        // thereby preventing it from being fully garbage collected.\n        forgetChildren(this);\n        // Because this entry has been kicked out of the cache (in index.js),\n        // we've lost the ability to find out if/when this entry becomes dirty,\n        // whether that happens through a subscription, because of a direct call\n        // to entry.setDirty(), or because one of its children becomes dirty.\n        // Because of this loss of future information, we have to assume the\n        // worst (that this entry might have become dirty very soon), so we must\n        // immediately mark this entry's parents as dirty. Normally we could\n        // just call entry.setDirty() rather than calling parent.setDirty() for\n        // each parent, but that would leave this entry in parent.childValues\n        // and parent.dirtyChildren, which would prevent the child from being\n        // truly forgotten.\n        eachParent(this, (parent, child) => {\n            parent.setDirty();\n            forgetChild(parent, this);\n        });\n    }\n    forget() {\n        // The code that creates Entry objects in index.ts will replace this method\n        // with one that actually removes the Entry from the cache, which will also\n        // trigger the entry.dispose method.\n        this.dispose();\n    }\n    dependOn(dep) {\n        dep.add(this);\n        if (!this.deps) {\n            this.deps = emptySetPool.pop() || new Set();\n        }\n        this.deps.add(dep);\n    }\n    forgetDeps() {\n        if (this.deps) {\n            arrayFromSet(this.deps).forEach(dep => dep.delete(this));\n            this.deps.clear();\n            emptySetPool.push(this.deps);\n            this.deps = null;\n        }\n    }\n}\nEntry.count = 0;\nfunction rememberParent(child) {\n    const parent = parentEntrySlot.getValue();\n    if (parent) {\n        child.parents.add(parent);\n        if (!parent.childValues.has(child)) {\n            parent.childValues.set(child, []);\n        }\n        if (mightBeDirty(child)) {\n            reportDirtyChild(parent, child);\n        }\n        else {\n            reportCleanChild(parent, child);\n        }\n        return parent;\n    }\n}\nfunction reallyRecompute(entry, args) {\n    forgetChildren(entry);\n    // Set entry as the parent entry while calling recomputeNewValue(entry).\n    parentEntrySlot.withValue(entry, recomputeNewValue, [entry, args]);\n    if (maybeSubscribe(entry, args)) {\n        // If we successfully recomputed entry.value and did not fail to\n        // (re)subscribe, then this Entry is no longer explicitly dirty.\n        setClean(entry);\n    }\n    return valueGet(entry.value);\n}\nfunction recomputeNewValue(entry, args) {\n    entry.recomputing = true;\n    const { normalizeResult } = entry;\n    let oldValueCopy;\n    if (normalizeResult && entry.value.length === 1) {\n        oldValueCopy = valueCopy(entry.value);\n    }\n    // Make entry.value an empty array, representing an unknown value.\n    entry.value.length = 0;\n    try {\n        // If entry.fn succeeds, entry.value will become a normal Value.\n        entry.value[0] = entry.fn.apply(null, args);\n        // If we have a viable oldValueCopy to compare with the (successfully\n        // recomputed) new entry.value, and they are not already === identical, give\n        // normalizeResult a chance to pick/choose/reuse parts of oldValueCopy[0]\n        // and/or entry.value[0] to determine the final cached entry.value.\n        if (normalizeResult && oldValueCopy && !valueIs(oldValueCopy, entry.value)) {\n            try {\n                entry.value[0] = normalizeResult(entry.value[0], oldValueCopy[0]);\n            }\n            catch (_a) {\n                // If normalizeResult throws, just use the newer value, rather than\n                // saving the exception as entry.value[1].\n            }\n        }\n    }\n    catch (e) {\n        // If entry.fn throws, entry.value will hold that exception.\n        entry.value[1] = e;\n    }\n    // Either way, this line is always reached.\n    entry.recomputing = false;\n}\nfunction mightBeDirty(entry) {\n    return entry.dirty || !!(entry.dirtyChildren && entry.dirtyChildren.size);\n}\nfunction setClean(entry) {\n    entry.dirty = false;\n    if (mightBeDirty(entry)) {\n        // This Entry may still have dirty children, in which case we can't\n        // let our parents know we're clean just yet.\n        return;\n    }\n    reportClean(entry);\n}\nfunction reportDirty(child) {\n    eachParent(child, reportDirtyChild);\n}\nfunction reportClean(child) {\n    eachParent(child, reportCleanChild);\n}\nfunction eachParent(child, callback) {\n    const parentCount = child.parents.size;\n    if (parentCount) {\n        const parents = arrayFromSet(child.parents);\n        for (let i = 0; i < parentCount; ++i) {\n            callback(parents[i], child);\n        }\n    }\n}\n// Let a parent Entry know that one of its children may be dirty.\nfunction reportDirtyChild(parent, child) {\n    // Must have called rememberParent(child) before calling\n    // reportDirtyChild(parent, child).\n    assert(parent.childValues.has(child));\n    assert(mightBeDirty(child));\n    const parentWasClean = !mightBeDirty(parent);\n    if (!parent.dirtyChildren) {\n        parent.dirtyChildren = emptySetPool.pop() || new Set;\n    }\n    else if (parent.dirtyChildren.has(child)) {\n        // If we already know this child is dirty, then we must have already\n        // informed our own parents that we are dirty, so we can terminate\n        // the recursion early.\n        return;\n    }\n    parent.dirtyChildren.add(child);\n    // If parent was clean before, it just became (possibly) dirty (according to\n    // mightBeDirty), since we just added child to parent.dirtyChildren.\n    if (parentWasClean) {\n        reportDirty(parent);\n    }\n}\n// Let a parent Entry know that one of its children is no longer dirty.\nfunction reportCleanChild(parent, child) {\n    // Must have called rememberChild(child) before calling\n    // reportCleanChild(parent, child).\n    assert(parent.childValues.has(child));\n    assert(!mightBeDirty(child));\n    const childValue = parent.childValues.get(child);\n    if (childValue.length === 0) {\n        parent.childValues.set(child, valueCopy(child.value));\n    }\n    else if (!valueIs(childValue, child.value)) {\n        parent.setDirty();\n    }\n    removeDirtyChild(parent, child);\n    if (mightBeDirty(parent)) {\n        return;\n    }\n    reportClean(parent);\n}\nfunction removeDirtyChild(parent, child) {\n    const dc = parent.dirtyChildren;\n    if (dc) {\n        dc.delete(child);\n        if (dc.size === 0) {\n            if (emptySetPool.length < POOL_TARGET_SIZE) {\n                emptySetPool.push(dc);\n            }\n            parent.dirtyChildren = null;\n        }\n    }\n}\n// Removes all children from this entry and returns an array of the\n// removed children.\nfunction forgetChildren(parent) {\n    if (parent.childValues.size > 0) {\n        parent.childValues.forEach((_value, child) => {\n            forgetChild(parent, child);\n        });\n    }\n    // Remove this parent Entry from any sets to which it was added by the\n    // addToSet method.\n    parent.forgetDeps();\n    // After we forget all our children, this.dirtyChildren must be empty\n    // and therefore must have been reset to null.\n    assert(parent.dirtyChildren === null);\n}\nfunction forgetChild(parent, child) {\n    child.parents.delete(parent);\n    parent.childValues.delete(child);\n    removeDirtyChild(parent, child);\n}\nfunction maybeSubscribe(entry, args) {\n    if (typeof entry.subscribe === \"function\") {\n        try {\n            maybeUnsubscribe(entry); // Prevent double subscriptions.\n            entry.unsubscribe = entry.subscribe.apply(null, args);\n        }\n        catch (e) {\n            // If this Entry has a subscribe function and it threw an exception\n            // (or an unsubscribe function it previously returned now throws),\n            // return false to indicate that we were not able to subscribe (or\n            // unsubscribe), and this Entry should remain dirty.\n            entry.setDirty();\n            return false;\n        }\n    }\n    // Returning true indicates either that there was no entry.subscribe\n    // function or that it succeeded.\n    return true;\n}\n//# sourceMappingURL=entry.js.map","export const { hasOwnProperty, } = Object.prototype;\nexport const arrayFromSet = Array.from ||\n    function (set) {\n        const array = [];\n        set.forEach(item => array.push(item));\n        return array;\n    };\nexport function maybeUnsubscribe(entryOrDep) {\n    const { unsubscribe } = entryOrDep;\n    if (typeof unsubscribe === \"function\") {\n        entryOrDep.unsubscribe = void 0;\n        unsubscribe();\n    }\n}\n//# sourceMappingURL=helpers.js.map","import { Trie } from \"@wry/trie\";\nimport { StrongCache } from \"@wry/caches\";\nimport { Entry } from \"./entry.js\";\nimport { parentEntrySlot } from \"./context.js\";\n// These helper functions are important for making optimism work with\n// asynchronous code. In order to register parent-child dependencies,\n// optimism needs to know about any currently active parent computations.\n// In ordinary synchronous code, the parent context is implicit in the\n// execution stack, but asynchronous code requires some extra guidance in\n// order to propagate context from one async task segment to the next.\nexport { bindContext, noContext, nonReactive, setTimeout, asyncFromGen, Slot, } from \"./context.js\";\n// A lighter-weight dependency, similar to OptimisticWrapperFunction, except\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\n// and no result value. Useful for representing dependency leaves in the graph\n// of computation. Subscriptions are supported.\nexport { dep } from \"./dep.js\";\n// The defaultMakeCacheKey function is remarkably powerful, because it gives\n// a unique object for any shallow-identical list of arguments. If you need\n// to implement a custom makeCacheKey function, you may find it helpful to\n// delegate the final work to defaultMakeCacheKey, which is why we export it\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\n// does not support WeakMap, or you have the ability to return a string key.\n// In those cases, just write your own custom makeCacheKey functions.\nlet defaultKeyTrie;\nexport function defaultMakeCacheKey(...args) {\n    const trie = defaultKeyTrie || (defaultKeyTrie = new Trie(typeof WeakMap === \"function\"));\n    return trie.lookupArray(args);\n}\n// If you're paranoid about memory leaks, or you want to avoid using WeakMap\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\n// import this constructor to create your own tries.\nexport { Trie as KeyTrie };\n;\nconst caches = new Set();\nexport function wrap(originalFunction, { max = Math.pow(2, 16), keyArgs, makeCacheKey = defaultMakeCacheKey, normalizeResult, subscribe, cache: cacheOption = StrongCache, } = Object.create(null)) {\n    const cache = typeof cacheOption === \"function\"\n        ? new cacheOption(max, entry => entry.dispose())\n        : cacheOption;\n    const optimistic = function () {\n        const key = makeCacheKey.apply(null, keyArgs ? keyArgs.apply(null, arguments) : arguments);\n        if (key === void 0) {\n            return originalFunction.apply(null, arguments);\n        }\n        let entry = cache.get(key);\n        if (!entry) {\n            cache.set(key, entry = new Entry(originalFunction));\n            entry.normalizeResult = normalizeResult;\n            entry.subscribe = subscribe;\n            // Give the Entry the ability to trigger cache.delete(key), even though\n            // the Entry itself does not know about key or cache.\n            entry.forget = () => cache.delete(key);\n        }\n        const value = entry.recompute(Array.prototype.slice.call(arguments));\n        // Move this entry to the front of the least-recently used queue,\n        // since we just finished computing its value.\n        cache.set(key, entry);\n        caches.add(cache);\n        // Clean up any excess entries in the cache, but only if there is no\n        // active parent entry, meaning we're not in the middle of a larger\n        // computation that might be flummoxed by the cleaning.\n        if (!parentEntrySlot.hasValue()) {\n            caches.forEach(cache => cache.clean());\n            caches.clear();\n        }\n        return value;\n    };\n    Object.defineProperty(optimistic, \"size\", {\n        get: () => cache.size,\n        configurable: false,\n        enumerable: false,\n    });\n    Object.freeze(optimistic.options = {\n        max,\n        keyArgs,\n        makeCacheKey,\n        normalizeResult,\n        subscribe,\n        cache,\n    });\n    function dirtyKey(key) {\n        const entry = key && cache.get(key);\n        if (entry) {\n            entry.setDirty();\n        }\n    }\n    optimistic.dirtyKey = dirtyKey;\n    optimistic.dirty = function dirty() {\n        dirtyKey(makeCacheKey.apply(null, arguments));\n    };\n    function peekKey(key) {\n        const entry = key && cache.get(key);\n        if (entry) {\n            return entry.peek();\n        }\n    }\n    optimistic.peekKey = peekKey;\n    optimistic.peek = function peek() {\n        return peekKey(makeCacheKey.apply(null, arguments));\n    };\n    function forgetKey(key) {\n        return key ? cache.delete(key) : false;\n    }\n    optimistic.forgetKey = forgetKey;\n    optimistic.forget = function forget() {\n        return forgetKey(makeCacheKey.apply(null, arguments));\n    };\n    optimistic.makeCacheKey = makeCacheKey;\n    optimistic.getKey = keyArgs ? function getKey() {\n        return makeCacheKey.apply(null, keyArgs.apply(null, arguments));\n    } : makeCacheKey;\n    return Object.freeze(optimistic);\n}\n//# sourceMappingURL=index.js.map","import { __extends } from \"tslib\";\nvar genericMessage = \"Invariant Violation\";\nvar _a = Object.setPrototypeOf, setPrototypeOf = _a === void 0 ? function (obj, proto) {\n    obj.__proto__ = proto;\n    return obj;\n} : _a;\nvar InvariantError = /** @class */ (function (_super) {\n    __extends(InvariantError, _super);\n    function InvariantError(message) {\n        if (message === void 0) { message = genericMessage; }\n        var _this = _super.call(this, typeof message === \"number\"\n            ? genericMessage + \": \" + message + \" (see https://github.com/apollographql/invariant-packages)\"\n            : message) || this;\n        _this.framesToPop = 1;\n        _this.name = genericMessage;\n        setPrototypeOf(_this, InvariantError.prototype);\n        return _this;\n    }\n    return InvariantError;\n}(Error));\nexport { InvariantError };\nexport function invariant(condition, message) {\n    if (!condition) {\n        throw new InvariantError(message);\n    }\n}\nvar verbosityLevels = [\"debug\", \"log\", \"warn\", \"error\", \"silent\"];\nvar verbosityLevel = verbosityLevels.indexOf(\"log\");\nfunction wrapConsoleMethod(name) {\n    return function () {\n        if (verbosityLevels.indexOf(name) >= verbosityLevel) {\n            // Default to console.log if this host environment happens not to provide\n            // all the console.* methods we need.\n            var method = console[name] || console.log;\n            return method.apply(console, arguments);\n        }\n    };\n}\n(function (invariant) {\n    invariant.debug = wrapConsoleMethod(\"debug\");\n    invariant.log = wrapConsoleMethod(\"log\");\n    invariant.warn = wrapConsoleMethod(\"warn\");\n    invariant.error = wrapConsoleMethod(\"error\");\n})(invariant || (invariant = {}));\nexport function setVerbosity(level) {\n    var old = verbosityLevels[verbosityLevel];\n    verbosityLevel = Math.max(0, verbosityLevels.indexOf(level));\n    return old;\n}\nexport default invariant;\n//# sourceMappingURL=invariant.js.map","/******************************************************************************\nCopyright (c) Microsoft Corporation.\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n***************************************************************************** */\n/* global Reflect, Promise, SuppressedError, Symbol, Iterator */\n\nvar extendStatics = function(d, b) {\n  extendStatics = Object.setPrototypeOf ||\n      ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n      function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n  return extendStatics(d, b);\n};\n\nexport function __extends(d, b) {\n  if (typeof b !== \"function\" && b !== null)\n      throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n  extendStatics(d, b);\n  function __() { this.constructor = d; }\n  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n}\n\nexport var __assign = function() {\n  __assign = Object.assign || function __assign(t) {\n      for (var s, i = 1, n = arguments.length; i < n; i++) {\n          s = arguments[i];\n          for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n      }\n      return t;\n  }\n  return __assign.apply(this, arguments);\n}\n\nexport function __rest(s, e) {\n  var t = {};\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n      t[p] = s[p];\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n      for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n          if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n              t[p[i]] = s[p[i]];\n      }\n  return t;\n}\n\nexport function __decorate(decorators, target, key, desc) {\n  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n  if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n}\n\nexport function __param(paramIndex, decorator) {\n  return function (target, key) { decorator(target, key, paramIndex); }\n}\n\nexport function __esDecorate(ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {\n  function accept(f) { if (f !== void 0 && typeof f !== \"function\") throw new TypeError(\"Function expected\"); return f; }\n  var kind = contextIn.kind, key = kind === \"getter\" ? \"get\" : kind === \"setter\" ? \"set\" : \"value\";\n  var target = !descriptorIn && ctor ? contextIn[\"static\"] ? ctor : ctor.prototype : null;\n  var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});\n  var _, done = false;\n  for (var i = decorators.length - 1; i >= 0; i--) {\n      var context = {};\n      for (var p in contextIn) context[p] = p === \"access\" ? {} : contextIn[p];\n      for (var p in contextIn.access) context.access[p] = contextIn.access[p];\n      context.addInitializer = function (f) { if (done) throw new TypeError(\"Cannot add initializers after decoration has completed\"); extraInitializers.push(accept(f || null)); };\n      var result = (0, decorators[i])(kind === \"accessor\" ? { get: descriptor.get, set: descriptor.set } : descriptor[key], context);\n      if (kind === \"accessor\") {\n          if (result === void 0) continue;\n          if (result === null || typeof result !== \"object\") throw new TypeError(\"Object expected\");\n          if (_ = accept(result.get)) descriptor.get = _;\n          if (_ = accept(result.set)) descriptor.set = _;\n          if (_ = accept(result.init)) initializers.unshift(_);\n      }\n      else if (_ = accept(result)) {\n          if (kind === \"field\") initializers.unshift(_);\n          else descriptor[key] = _;\n      }\n  }\n  if (target) Object.defineProperty(target, contextIn.name, descriptor);\n  done = true;\n};\n\nexport function __runInitializers(thisArg, initializers, value) {\n  var useValue = arguments.length > 2;\n  for (var i = 0; i < initializers.length; i++) {\n      value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);\n  }\n  return useValue ? value : void 0;\n};\n\nexport function __propKey(x) {\n  return typeof x === \"symbol\" ? x : \"\".concat(x);\n};\n\nexport function __setFunctionName(f, name, prefix) {\n  if (typeof name === \"symbol\") name = name.description ? \"[\".concat(name.description, \"]\") : \"\";\n  return Object.defineProperty(f, \"name\", { configurable: true, value: prefix ? \"\".concat(prefix, \" \", name) : name });\n};\n\nexport function __metadata(metadataKey, metadataValue) {\n  if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\n}\n\nexport function __awaiter(thisArg, _arguments, P, generator) {\n  function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n  return new (P || (P = Promise))(function (resolve, reject) {\n      function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n      function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n      function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n      step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n}\n\nexport function __generator(thisArg, body) {\n  var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g = Object.create((typeof Iterator === \"function\" ? Iterator : Object).prototype);\n  return g.next = verb(0), g[\"throw\"] = verb(1), g[\"return\"] = verb(2), typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n  function verb(n) { return function (v) { return step([n, v]); }; }\n  function step(op) {\n      if (f) throw new TypeError(\"Generator is already executing.\");\n      while (g && (g = 0, op[0] && (_ = 0)), _) try {\n          if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n          if (y = 0, t) op = [op[0] & 2, t.value];\n          switch (op[0]) {\n              case 0: case 1: t = op; break;\n              case 4: _.label++; return { value: op[1], done: false };\n              case 5: _.label++; y = op[1]; op = [0]; continue;\n              case 7: op = _.ops.pop(); _.trys.pop(); continue;\n              default:\n                  if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                  if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                  if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                  if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                  if (t[2]) _.ops.pop();\n                  _.trys.pop(); continue;\n          }\n          op = body.call(thisArg, _);\n      } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n      if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n  }\n}\n\nexport var __createBinding = Object.create ? (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n  }\n  Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\n\nexport function __exportStar(m, o) {\n  for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\n}\n\nexport function __values(o) {\n  var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\n  if (m) return m.call(o);\n  if (o && typeof o.length === \"number\") return {\n      next: function () {\n          if (o && i >= o.length) o = void 0;\n          return { value: o && o[i++], done: !o };\n      }\n  };\n  throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\n}\n\nexport function __read(o, n) {\n  var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n  if (!m) return o;\n  var i = m.call(o), r, ar = [], e;\n  try {\n      while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\n  }\n  catch (error) { e = { error: error }; }\n  finally {\n      try {\n          if (r && !r.done && (m = i[\"return\"])) m.call(i);\n      }\n      finally { if (e) throw e.error; }\n  }\n  return ar;\n}\n\n/** @deprecated */\nexport function __spread() {\n  for (var ar = [], i = 0; i < arguments.length; i++)\n      ar = ar.concat(__read(arguments[i]));\n  return ar;\n}\n\n/** @deprecated */\nexport function __spreadArrays() {\n  for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n  for (var r = Array(s), k = 0, i = 0; i < il; i++)\n      for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n          r[k] = a[j];\n  return r;\n}\n\nexport function __spreadArray(to, from, pack) {\n  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\n      if (ar || !(i in from)) {\n          if (!ar) ar = Array.prototype.slice.call(from, 0, i);\n          ar[i] = from[i];\n      }\n  }\n  return to.concat(ar || Array.prototype.slice.call(from));\n}\n\nexport function __await(v) {\n  return this instanceof __await ? (this.v = v, this) : new __await(v);\n}\n\nexport function __asyncGenerator(thisArg, _arguments, generator) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var g = generator.apply(thisArg, _arguments || []), i, q = [];\n  return i = Object.create((typeof AsyncIterator === \"function\" ? AsyncIterator : Object).prototype), verb(\"next\"), verb(\"throw\"), verb(\"return\", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;\n  function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }\n  function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }\n  function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n  function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n  function fulfill(value) { resume(\"next\", value); }\n  function reject(value) { resume(\"throw\", value); }\n  function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n}\n\nexport function __asyncDelegator(o) {\n  var i, p;\n  return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\n  function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: false } : f ? f(v) : v; } : f; }\n}\n\nexport function __asyncValues(o) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var m = o[Symbol.asyncIterator], i;\n  return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n  function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n  function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n}\n\nexport function __makeTemplateObject(cooked, raw) {\n  if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\n  return cooked;\n};\n\nvar __setModuleDefault = Object.create ? (function(o, v) {\n  Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n  o[\"default\"] = v;\n};\n\nvar ownKeys = function(o) {\n  ownKeys = Object.getOwnPropertyNames || function (o) {\n    var ar = [];\n    for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;\n    return ar;\n  };\n  return ownKeys(o);\n};\n\nexport function __importStar(mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== \"default\") __createBinding(result, mod, k[i]);\n  __setModuleDefault(result, mod);\n  return result;\n}\n\nexport function __importDefault(mod) {\n  return (mod && mod.__esModule) ? mod : { default: mod };\n}\n\nexport function __classPrivateFieldGet(receiver, state, kind, f) {\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n  return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\n\nexport function __classPrivateFieldSet(receiver, state, value, kind, f) {\n  if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n  return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n}\n\nexport function __classPrivateFieldIn(state, receiver) {\n  if (receiver === null || (typeof receiver !== \"object\" && typeof receiver !== \"function\")) throw new TypeError(\"Cannot use 'in' operator on non-object\");\n  return typeof state === \"function\" ? receiver === state : state.has(receiver);\n}\n\nexport function __addDisposableResource(env, value, async) {\n  if (value !== null && value !== void 0) {\n    if (typeof value !== \"object\" && typeof value !== \"function\") throw new TypeError(\"Object expected.\");\n    var dispose, inner;\n    if (async) {\n      if (!Symbol.asyncDispose) throw new TypeError(\"Symbol.asyncDispose is not defined.\");\n      dispose = value[Symbol.asyncDispose];\n    }\n    if (dispose === void 0) {\n      if (!Symbol.dispose) throw new TypeError(\"Symbol.dispose is not defined.\");\n      dispose = value[Symbol.dispose];\n      if (async) inner = dispose;\n    }\n    if (typeof dispose !== \"function\") throw new TypeError(\"Object not disposable.\");\n    if (inner) dispose = function() { try { inner.call(this); } catch (e) { return Promise.reject(e); } };\n    env.stack.push({ value: value, dispose: dispose, async: async });\n  }\n  else if (async) {\n    env.stack.push({ async: true });\n  }\n  return value;\n}\n\nvar _SuppressedError = typeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\n  var e = new Error(message);\n  return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\n};\n\nexport function __disposeResources(env) {\n  function fail(e) {\n    env.error = env.hasError ? new _SuppressedError(e, env.error, \"An error was suppressed during disposal.\") : e;\n    env.hasError = true;\n  }\n  var r, s = 0;\n  function next() {\n    while (r = env.stack.pop()) {\n      try {\n        if (!r.async && s === 1) return s = 0, env.stack.push(r), Promise.resolve().then(next);\n        if (r.dispose) {\n          var result = r.dispose.call(r.value);\n          if (r.async) return s |= 2, Promise.resolve(result).then(next, function(e) { fail(e); return next(); });\n        }\n        else s |= 1;\n      }\n      catch (e) {\n        fail(e);\n      }\n    }\n    if (s === 1) return env.hasError ? Promise.reject(env.error) : Promise.resolve();\n    if (env.hasError) throw env.error;\n  }\n  return next();\n}\n\nexport function __rewriteRelativeImportExtension(path, preserveJsx) {\n  if (typeof path === \"string\" && /^\\.\\.?\\//.test(path)) {\n      return path.replace(/\\.(tsx)$|((?:\\.d)?)((?:\\.[^./]+?)?)\\.([cm]?)ts$/i, function (m, tsx, d, ext, cm) {\n          return tsx ? preserveJsx ? \".jsx\" : \".js\" : d && (!ext || !cm) ? m : (d + ext + \".\" + cm.toLowerCase() + \"js\");\n      });\n  }\n  return path;\n}\n\nexport default {\n  __extends,\n  __assign,\n  __rest,\n  __decorate,\n  __param,\n  __esDecorate,\n  __runInitializers,\n  __propKey,\n  __setFunctionName,\n  __metadata,\n  __awaiter,\n  __generator,\n  __createBinding,\n  __exportStar,\n  __values,\n  __read,\n  __spread,\n  __spreadArrays,\n  __spreadArray,\n  __await,\n  __asyncGenerator,\n  __asyncDelegator,\n  __asyncValues,\n  __makeTemplateObject,\n  __importStar,\n  __importDefault,\n  __classPrivateFieldGet,\n  __classPrivateFieldSet,\n  __classPrivateFieldIn,\n  __addDisposableResource,\n  __disposeResources,\n  __rewriteRelativeImportExtension,\n};\n","function _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\n// === Symbol Support ===\nvar hasSymbols = function () {\n  return typeof Symbol === 'function';\n};\n\nvar hasSymbol = function (name) {\n  return hasSymbols() && Boolean(Symbol[name]);\n};\n\nvar getSymbol = function (name) {\n  return hasSymbol(name) ? Symbol[name] : '@@' + name;\n};\n\nif (hasSymbols() && !hasSymbol('observable')) {\n  Symbol.observable = Symbol('observable');\n}\n\nvar SymbolIterator = getSymbol('iterator');\nvar SymbolObservable = getSymbol('observable');\nvar SymbolSpecies = getSymbol('species'); // === Abstract Operations ===\n\nfunction getMethod(obj, key) {\n  var value = obj[key];\n  if (value == null) return undefined;\n  if (typeof value !== 'function') throw new TypeError(value + ' is not a function');\n  return value;\n}\n\nfunction getSpecies(obj) {\n  var ctor = obj.constructor;\n\n  if (ctor !== undefined) {\n    ctor = ctor[SymbolSpecies];\n\n    if (ctor === null) {\n      ctor = undefined;\n    }\n  }\n\n  return ctor !== undefined ? ctor : Observable;\n}\n\nfunction isObservable(x) {\n  return x instanceof Observable; // SPEC: Brand check\n}\n\nfunction hostReportError(e) {\n  if (hostReportError.log) {\n    hostReportError.log(e);\n  } else {\n    setTimeout(function () {\n      throw e;\n    });\n  }\n}\n\nfunction enqueue(fn) {\n  Promise.resolve().then(function () {\n    try {\n      fn();\n    } catch (e) {\n      hostReportError(e);\n    }\n  });\n}\n\nfunction cleanupSubscription(subscription) {\n  var cleanup = subscription._cleanup;\n  if (cleanup === undefined) return;\n  subscription._cleanup = undefined;\n\n  if (!cleanup) {\n    return;\n  }\n\n  try {\n    if (typeof cleanup === 'function') {\n      cleanup();\n    } else {\n      var unsubscribe = getMethod(cleanup, 'unsubscribe');\n\n      if (unsubscribe) {\n        unsubscribe.call(cleanup);\n      }\n    }\n  } catch (e) {\n    hostReportError(e);\n  }\n}\n\nfunction closeSubscription(subscription) {\n  subscription._observer = undefined;\n  subscription._queue = undefined;\n  subscription._state = 'closed';\n}\n\nfunction flushSubscription(subscription) {\n  var queue = subscription._queue;\n\n  if (!queue) {\n    return;\n  }\n\n  subscription._queue = undefined;\n  subscription._state = 'ready';\n\n  for (var i = 0; i < queue.length; ++i) {\n    notifySubscription(subscription, queue[i].type, queue[i].value);\n    if (subscription._state === 'closed') break;\n  }\n}\n\nfunction notifySubscription(subscription, type, value) {\n  subscription._state = 'running';\n  var observer = subscription._observer;\n\n  try {\n    var m = getMethod(observer, type);\n\n    switch (type) {\n      case 'next':\n        if (m) m.call(observer, value);\n        break;\n\n      case 'error':\n        closeSubscription(subscription);\n        if (m) m.call(observer, value);else throw value;\n        break;\n\n      case 'complete':\n        closeSubscription(subscription);\n        if (m) m.call(observer);\n        break;\n    }\n  } catch (e) {\n    hostReportError(e);\n  }\n\n  if (subscription._state === 'closed') cleanupSubscription(subscription);else if (subscription._state === 'running') subscription._state = 'ready';\n}\n\nfunction onNotify(subscription, type, value) {\n  if (subscription._state === 'closed') return;\n\n  if (subscription._state === 'buffering') {\n    subscription._queue.push({\n      type: type,\n      value: value\n    });\n\n    return;\n  }\n\n  if (subscription._state !== 'ready') {\n    subscription._state = 'buffering';\n    subscription._queue = [{\n      type: type,\n      value: value\n    }];\n    enqueue(function () {\n      return flushSubscription(subscription);\n    });\n    return;\n  }\n\n  notifySubscription(subscription, type, value);\n}\n\nvar Subscription = /*#__PURE__*/function () {\n  function Subscription(observer, subscriber) {\n    // ASSERT: observer is an object\n    // ASSERT: subscriber is callable\n    this._cleanup = undefined;\n    this._observer = observer;\n    this._queue = undefined;\n    this._state = 'initializing';\n    var subscriptionObserver = new SubscriptionObserver(this);\n\n    try {\n      this._cleanup = subscriber.call(undefined, subscriptionObserver);\n    } catch (e) {\n      subscriptionObserver.error(e);\n    }\n\n    if (this._state === 'initializing') this._state = 'ready';\n  }\n\n  var _proto = Subscription.prototype;\n\n  _proto.unsubscribe = function unsubscribe() {\n    if (this._state !== 'closed') {\n      closeSubscription(this);\n      cleanupSubscription(this);\n    }\n  };\n\n  _createClass(Subscription, [{\n    key: \"closed\",\n    get: function () {\n      return this._state === 'closed';\n    }\n  }]);\n\n  return Subscription;\n}();\n\nvar SubscriptionObserver = /*#__PURE__*/function () {\n  function SubscriptionObserver(subscription) {\n    this._subscription = subscription;\n  }\n\n  var _proto2 = SubscriptionObserver.prototype;\n\n  _proto2.next = function next(value) {\n    onNotify(this._subscription, 'next', value);\n  };\n\n  _proto2.error = function error(value) {\n    onNotify(this._subscription, 'error', value);\n  };\n\n  _proto2.complete = function complete() {\n    onNotify(this._subscription, 'complete');\n  };\n\n  _createClass(SubscriptionObserver, [{\n    key: \"closed\",\n    get: function () {\n      return this._subscription._state === 'closed';\n    }\n  }]);\n\n  return SubscriptionObserver;\n}();\n\nvar Observable = /*#__PURE__*/function () {\n  function Observable(subscriber) {\n    if (!(this instanceof Observable)) throw new TypeError('Observable cannot be called as a function');\n    if (typeof subscriber !== 'function') throw new TypeError('Observable initializer must be a function');\n    this._subscriber = subscriber;\n  }\n\n  var _proto3 = Observable.prototype;\n\n  _proto3.subscribe = function subscribe(observer) {\n    if (typeof observer !== 'object' || observer === null) {\n      observer = {\n        next: observer,\n        error: arguments[1],\n        complete: arguments[2]\n      };\n    }\n\n    return new Subscription(observer, this._subscriber);\n  };\n\n  _proto3.forEach = function forEach(fn) {\n    var _this = this;\n\n    return new Promise(function (resolve, reject) {\n      if (typeof fn !== 'function') {\n        reject(new TypeError(fn + ' is not a function'));\n        return;\n      }\n\n      function done() {\n        subscription.unsubscribe();\n        resolve();\n      }\n\n      var subscription = _this.subscribe({\n        next: function (value) {\n          try {\n            fn(value, done);\n          } catch (e) {\n            reject(e);\n            subscription.unsubscribe();\n          }\n        },\n        error: reject,\n        complete: resolve\n      });\n    });\n  };\n\n  _proto3.map = function map(fn) {\n    var _this2 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      return _this2.subscribe({\n        next: function (value) {\n          try {\n            value = fn(value);\n          } catch (e) {\n            return observer.error(e);\n          }\n\n          observer.next(value);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.filter = function filter(fn) {\n    var _this3 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      return _this3.subscribe({\n        next: function (value) {\n          try {\n            if (!fn(value)) return;\n          } catch (e) {\n            return observer.error(e);\n          }\n\n          observer.next(value);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.reduce = function reduce(fn) {\n    var _this4 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    var hasSeed = arguments.length > 1;\n    var hasValue = false;\n    var seed = arguments[1];\n    var acc = seed;\n    return new C(function (observer) {\n      return _this4.subscribe({\n        next: function (value) {\n          var first = !hasValue;\n          hasValue = true;\n\n          if (!first || hasSeed) {\n            try {\n              acc = fn(acc, value);\n            } catch (e) {\n              return observer.error(e);\n            }\n          } else {\n            acc = value;\n          }\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          if (!hasValue && !hasSeed) return observer.error(new TypeError('Cannot reduce an empty sequence'));\n          observer.next(acc);\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.concat = function concat() {\n    var _this5 = this;\n\n    for (var _len = arguments.length, sources = new Array(_len), _key = 0; _key < _len; _key++) {\n      sources[_key] = arguments[_key];\n    }\n\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      var subscription;\n      var index = 0;\n\n      function startNext(next) {\n        subscription = next.subscribe({\n          next: function (v) {\n            observer.next(v);\n          },\n          error: function (e) {\n            observer.error(e);\n          },\n          complete: function () {\n            if (index === sources.length) {\n              subscription = undefined;\n              observer.complete();\n            } else {\n              startNext(C.from(sources[index++]));\n            }\n          }\n        });\n      }\n\n      startNext(_this5);\n      return function () {\n        if (subscription) {\n          subscription.unsubscribe();\n          subscription = undefined;\n        }\n      };\n    });\n  };\n\n  _proto3.flatMap = function flatMap(fn) {\n    var _this6 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      var subscriptions = [];\n\n      var outer = _this6.subscribe({\n        next: function (value) {\n          if (fn) {\n            try {\n              value = fn(value);\n            } catch (e) {\n              return observer.error(e);\n            }\n          }\n\n          var inner = C.from(value).subscribe({\n            next: function (value) {\n              observer.next(value);\n            },\n            error: function (e) {\n              observer.error(e);\n            },\n            complete: function () {\n              var i = subscriptions.indexOf(inner);\n              if (i >= 0) subscriptions.splice(i, 1);\n              completeIfDone();\n            }\n          });\n          subscriptions.push(inner);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          completeIfDone();\n        }\n      });\n\n      function completeIfDone() {\n        if (outer.closed && subscriptions.length === 0) observer.complete();\n      }\n\n      return function () {\n        subscriptions.forEach(function (s) {\n          return s.unsubscribe();\n        });\n        outer.unsubscribe();\n      };\n    });\n  };\n\n  _proto3[SymbolObservable] = function () {\n    return this;\n  };\n\n  Observable.from = function from(x) {\n    var C = typeof this === 'function' ? this : Observable;\n    if (x == null) throw new TypeError(x + ' is not an object');\n    var method = getMethod(x, SymbolObservable);\n\n    if (method) {\n      var observable = method.call(x);\n      if (Object(observable) !== observable) throw new TypeError(observable + ' is not an object');\n      if (isObservable(observable) && observable.constructor === C) return observable;\n      return new C(function (observer) {\n        return observable.subscribe(observer);\n      });\n    }\n\n    if (hasSymbol('iterator')) {\n      method = getMethod(x, SymbolIterator);\n\n      if (method) {\n        return new C(function (observer) {\n          enqueue(function () {\n            if (observer.closed) return;\n\n            for (var _iterator = _createForOfIteratorHelperLoose(method.call(x)), _step; !(_step = _iterator()).done;) {\n              var item = _step.value;\n              observer.next(item);\n              if (observer.closed) return;\n            }\n\n            observer.complete();\n          });\n        });\n      }\n    }\n\n    if (Array.isArray(x)) {\n      return new C(function (observer) {\n        enqueue(function () {\n          if (observer.closed) return;\n\n          for (var i = 0; i < x.length; ++i) {\n            observer.next(x[i]);\n            if (observer.closed) return;\n          }\n\n          observer.complete();\n        });\n      });\n    }\n\n    throw new TypeError(x + ' is not observable');\n  };\n\n  Observable.of = function of() {\n    for (var _len2 = arguments.length, items = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      items[_key2] = arguments[_key2];\n    }\n\n    var C = typeof this === 'function' ? this : Observable;\n    return new C(function (observer) {\n      enqueue(function () {\n        if (observer.closed) return;\n\n        for (var i = 0; i < items.length; ++i) {\n          observer.next(items[i]);\n          if (observer.closed) return;\n        }\n\n        observer.complete();\n      });\n    });\n  };\n\n  _createClass(Observable, null, [{\n    key: SymbolSpecies,\n    get: function () {\n      return this;\n    }\n  }]);\n\n  return Observable;\n}();\n\nif (hasSymbols()) {\n  Object.defineProperty(Observable, Symbol('extensions'), {\n    value: {\n      symbol: SymbolObservable,\n      hostReportError: hostReportError\n    },\n    configurable: true\n  });\n}\n\nexport { Observable };\n","var webpackQueues =\n\ttypeof Symbol === \"function\"\n\t\t? Symbol(\"webpack queues\")\n\t\t: \"__webpack_queues__\";\nvar webpackExports =\n\ttypeof Symbol === \"function\"\n\t\t? Symbol(\"webpack exports\")\n\t\t: \"__webpack_exports__\";\nvar webpackError =\n\ttypeof Symbol === \"function\" ? Symbol(\"webpack error\") : \"__webpack_error__\";\nvar resolveQueue = (queue) => {\n  if (queue && queue.d < 1) {\n    queue.d = 1;\n    queue.forEach((fn) => (fn.r--));\n\t\tqueue.forEach((fn) => (fn.r-- ? fn.r++ : fn()));\n\t}\n}\nvar wrapDeps = (deps) => {\n\treturn deps.map((dep) => {\n\t\tif (dep !== null && typeof dep === \"object\") {\n\t\t\tif (dep[webpackQueues]) return dep;\n\t\t\tif (dep.then) {\n\t\t\t\tvar queue = [];\n\t\t\t\tqueue.d = 0;\n\t\t\t\tdep.then((r) => {\n\t\t\t\t\tobj[webpackExports] = r;\n\t\t\t\t\tresolveQueue(queue);\n\t\t\t\t},(e) => {\n\t\t\t\t\tobj[webpackError] = e;\n\t\t\t\t\tresolveQueue(queue);\n\t\t\t\t});\n\t\t\t\tvar obj = {};\n\t\t\t\tobj[webpackQueues] = (fn) => (fn(queue));\n\t\t\t\treturn obj;\n\t\t\t}\n\t\t}\n\t\tvar ret = {};\n\t\tret[webpackQueues] = function() {};\n\t\tret[webpackExports] = dep;\n\t\treturn ret;\n\t});\n};\n__webpack_require__.a = (module, body, hasAwait) => {\n\tvar queue;\n\thasAwait && ((queue = []).d = -1);\n\tvar depQueues = new Set();\n\tvar exports = module.exports;\n\tvar currentDeps;\n\tvar outerResolve;\n\tvar reject;\n\tvar promise = new Promise((resolve, rej) => {\n\t\treject = rej;\n\t\touterResolve = resolve;\n\t});\n\tpromise[webpackExports] = exports;\n\tpromise[webpackQueues] = (fn) => { queue && fn(queue), depQueues.forEach(fn), promise[\"catch\"](function() {}); };\n\tmodule.exports = promise;\n\tbody((deps) => {\n\t\tcurrentDeps = wrapDeps(deps);\n\t\tvar fn;\n\t\tvar getResult = () => {\n\t\t\treturn currentDeps.map((d) => {\n\t\t\t\tif (d[webpackError]) throw d[webpackError];\n\t\t\t\treturn d[webpackExports];\n\t\t\t});\n\t\t}\n\t\tvar promise = new Promise((resolve) => {\n\t\t\tfn = () => (resolve(getResult));\n\t\t\tfn.r = 0;\n\t\t\tvar fnQueue = (q) => (q !== queue && !depQueues.has(q) && (depQueues.add(q), q && !q.d && (fn.r++, q.push(fn))));\n\t\t\tcurrentDeps.map((dep) => (dep[webpackQueues](fnQueue)));\n\t\t});\n\t\treturn fn.r ? promise : getResult();\n\t}, (err) => ((err ? reject(promise[webpackError] = err) : outerResolve(exports)), resolveQueue(queue)));\n\tqueue && queue.d < 0 && (queue.d = 0);\n};","// getDefaultExport function for compatibility with non-ESM modules\n__webpack_require__.n = (module) => {\n\tvar getter = module && module.__esModule ?\n\t\t() => (module['default']) :\n\t\t() => (module);\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};\n","__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n        if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n            Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n        }\n    }\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACxHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC/KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AClPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC/IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC3QA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACh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zXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACnJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AChJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC3TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACxRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACnPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACtfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC7FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC1NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC71BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC7QA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC/dA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC5HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvCA;AACA;AACA;AACA;AACA;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;;;;;;;ACvJA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAwDA;AASA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAWA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCA;;;;;;;;;;;;;;;;;;AC9PA;AAWA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AAEA;;;;AAIA;AAeA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAKA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AAGA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;AAYA;AAKA;AACA;AACA;AACA;AAEA;AACA;AAKA;AAEA;AACA;AAIA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AAIA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;ACveA;;;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;AAIA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;;AAIA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;;;;;;;;;;;;;AC3EA;AACA;;;;;;;;;;;;;ACFA;AAUA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AAEA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAAA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AAEA;AAKA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;AAIA;AAKA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAOA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;AAQA;AAOA;AAEA;AAEA;AACA;AACA;AAEA;AADA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAGA;AAEA;AAEA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;ACpSA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;AAMA;AAEA;AACA;AACA;AAEA;;;;AAIA;AAMA;AACA;AACA;AACA;AAEA;;;;;;;;AAQA;AAMA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;AClGA;AAWA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AAGA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;;;AAGA;AAIA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;;;AAGA;AAMA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;AAGA;AAKA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;AC1JA;AAcA;;;;AAIA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;;;AAGA;AAYA;AALA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACpZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA4JA;;;;AAIA;AAEA;AACA;AACA;AAUA;AAEA;AACA;AAIA;AAEA;AACA;AAIA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;ACpSA;;AAEA;AAIA;AAEA;AAEA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AAMA;AAWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAiEA;;;AAGA;AAEA;AAEA;;;;AAIA;AAGA;;;;AAIA;AAMA;AACA;AAEA;AAGA;AAEA;;;AAGA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AAUA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AAGA;AAFA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AAEA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;AAKA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAEA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACxgCA;;AAEA;;AAIA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;AAIA;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AASA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;ACxEA;AAuCA;AAaA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAMA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAOA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AASA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACzSA;AACA;AAEA;AAmBA;;;;AAIA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;;;;AAIA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AAEA;AAWA;AAVA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;;;;AAIA;AAEA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC7TA;AACA;AAgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;;;;;AAOA;AAEA;AACA;AACA;AAEA;;;AAGA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;;;AAGA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAKA;AACA;AAEA;AACA;AAEA;AAEA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACpQA;;;AAGA;;;;;;;;;;;;;;;;ACEA;AACA;AAyCA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;AAIA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAwJA;AAIA;AACA;AACA;AAEA;AACA;AAEA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AAEA;;AAEA;AASA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AAMA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAKA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AClmBA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AA+DA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAGA;AAFA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAGA;AAFA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AADA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAsBA;AAbA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAGA;AAFA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AADA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;;;;;;;;;;;AC7+BA;AAOA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;;;;;;;;;;;AChDA;AAGA;AAoCA;AAcA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AAEA;AAOA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AAGA;AAOA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AC/ZA;;;AAGA;AAgBA;;;;;AAKA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AAEA;;;;;AAKA;AAIA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;AAIA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;AAIA;AAEA;AAEA;;;;;;AAMA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;AASA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAMA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;ACjUA;AACA;AACA;AACA;AACA;AACA;;;;ACLA;AACA;AACA;AACA;AACA;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACTA;AACA;AACA;AACA;AACA;AACA;;;;ACLA;AACA;AACA;AACA;AACA;;;;ACJA;AACA;AACA;AACA;AACA;AACA;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACRA;AACA;AACA;AACA;;;;ACHA;AACA;AACA;AACA;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACt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pBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC5eA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AC/LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACpLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AC1UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AChhBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AC/GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC7FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC/GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACpNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACpfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvMA;AACA;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AClKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACjFA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AC5PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACx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jLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACr4BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC5/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC/KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AClVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACrWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AC5SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AChZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/jBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACNA;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA"}